{
    "\"Evatronix NAND Flash controller ip-core.\" {Online}. Available: http://www.evatronix-ip.com/ip-cores/memory-controllers/nand-flash.html": {
        "acm_key": null,
        "key": "\"Evatronix NAND Flash controller ip-core.\" {Online}. Available: http://www.evatronix-ip.com/ip-cores/memory-controllers/nand-flash.html",
        "text": "\"Evatronix NAND Flash controller ip-core.\" {Online}. Available: http://www.evatronix-ip.com/ip-cores/memory-controllers/nand-flash.html"
    },
    "\"Intel, persistent memory file system,\" https://github.com/iinux-pmfs/pmfs.": {
        "acm_key": null,
        "key": "\"Intel, persistent memory file system,\" https://github.com/iinux-pmfs/pmfs.",
        "text": "\"Intel, persistent memory file system,\" https://github.com/iinux-pmfs/pmfs."
    },
    "\"The OpenSSD Project.\" {Online}. Available: http://www.openssd-project.org/wiki/The_OpenSSD_Project": {
        "acm_key": null,
        "key": "\"The OpenSSD Project.\" {Online}. Available: http://www.openssd-project.org/wiki/The_OpenSSD_Project",
        "text": "\"The OpenSSD Project.\" {Online}. Available: http://www.openssd-project.org/wiki/The_OpenSSD_Project"
    },
    "1016755": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1016755",
        "bib_stats": {
            "cites": 3,
            "dl": 297,
            "dl_52": 5,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Wu:2004:EFS:1016720.1016755,\n author = {Wu, Chin-Hsien and Kuo, Tei-Wei and Yang, Chia-Lin},\n title = {Energy-efficient Flash-memory Storage Systems with an Interrupt-emulation Mechanism},\n booktitle = {Proceedings of the 2Nd IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES+ISSS '04},\n year = {2004},\n isbn = {1-58113- 937-3},\n location = {Stockholm, Sweden},\n pages = {134--139},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1016720.1016755},\n doi = {10.1145/1016720.1016755},\n acmid = {1016755},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {embedded systems, energy-efficient, flash memory, interrupt-emulation I/O, programmed I/O, storage systems},\n} \r\n",
        "key": "1016755",
        "pub_year": "2004",
        "text": "Chin-Hsien Wu , Tei-Wei Kuo , Chia-Lin Yang, Energy-efficient flash-memory storage systems with an interrupt-emulation mechanism, Proceedings of the 2nd IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis, September 08-10, 2004, Stockholm, Sweden"
    },
    "1017775": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1017775",
        "bib_stats": {
            "cites": 31,
            "dl": 1,
            "dl_52": 11,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Park:2004:CDP:1017753.1017775,\n author = {Park, Chanik and Lim, Junghee and Kwon, Kiwon and Lee, Jaejin and Min, Sang Lyul},\n title = {Compiler-assisted Demand Paging for Embedded Systems with Flash Memory},\n booktitle = {Proceedings of the 4th ACM International Conference on Embedded Software},\n series = {EMSOFT '04},\n year = {2004},\n isbn = {1-58113-860-1},\n location = {Pisa, Italy},\n pages = {114--124},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/1017753.1017775},\n doi = {10.1145/1017753.1017775},\n acmid = {1017775},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {SRAM, clustering, compilers, embedded systems, flash memory, heterogeneous memory, paging, post-pass optimization},\n} \r\n",
        "key": "1017775",
        "pub_year": "2004",
        "text": "Chanik Park , Junghee Lim , Kiwon Kwon , Jaejin Lee , Sang Lyul Min, Compiler-assisted demand paging for embedded systems with flash memory, Proceedings of the 4th ACM international conference on Embedded software, September 27-29, 2004, Pisa, Italy  \u00a0[doi>"
    },
    "1031516": {
        "abstract": "As the price of cameras and computing elements continue to fall it becomes increasingly feasible to consider the deployment of smart camera networks. Such networks would be composed of small, networked computers equipped with inexpensive image sensors. Consider, for example, the proliferation of camera equipped cell phones. Such camera networks could be used to support a wide variety of applications including environmental modeling, 3D model construction and surveillance. A number of research efforts at a variety of institutions are currently directed towards realizing aspects of this vision. One critical problem that must be addressed in such systems is the issue of localization. That is, in order to take full advantage of the images gathered from multiple vantage points it is helpful to know where the cameras are located with respect to each other. In our system each of the smart cameras is equipped with a co-located controllable light source which it can use to signal other smart cameras in the vicinity. By analyzing the images that it acquires over time, each smart camera is able to locate and identify other smart cameras in the scene. This arrangement makes it possible to directly determine the epipolar geometry of the camera system from image measurements and, hence, recover the relative positions and orientations of the smart camera nodes. We will demonstrate a small scale version of an auto configuring camera network consisting of 3 to 5 smart cameras, we will show how they can accurately localize each other in real time and how they adapt to changes in the configuration.",
        "acm_key": "1031516",
        "bib_stats": {
            "cites": 58,
            "dl": 1,
            "dl_52": 19,
            "dl_6": 2
        },
        "key": "1031516",
        "text": "Hui Dai , Michael Neufeld , Richard Han, ELF: an efficient log-structured flash file system for micro sensor nodes, Proceedings of the 2nd international conference on Embedded networked sensor systems, November 03-05, 2004, Baltimore, MD, USA"
    },
    "1034247": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1034247",
        "bib_stats": {
            "cites": 14,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Edel:2004:MCF:1032659.1034247,\n author = {Edel, Nathan K. and Tuteja, Deepa and Miller, Ethan L. and Brandt, Scott A.},\n title = {MRAMFS: A Compressing File System for Non-Volatile RAM},\n booktitle = {Proceedings of the The IEEE Computer Society's 12th Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems},\n series = {MASCOTS '04},\n year = {2004},\n isbn = {0-7695-2251-3},\n pages = {596--603},\n numpages = {8},\n url = {http://dl.acm.org/citation.cfm?id=1032659.1034247},\n acmid = {1034247},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1034247",
        "pub_year": "2004",
        "text": "Nathan K. Edel , Deepa Tuteja , Ethan L. Miller , Scott A. Brandt, MRAMFS: A Compressing File System for Non-Volatile RAM, Proceedings of the The IEEE Computer Society's 12th Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, p.596-603, October 04-08, 2004"
    },
    "1110668": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1110668",
        "bib_stats": {
            "cites": 22,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Lawton:2006:IFM:1110638.1110668,\n author = {Lawton, George},\n title = {Improved Flash Memory Grows in Popularity},\n journal = {Computer},\n issue_date = {January 2006},\n volume = {39},\n number = {1},\n month = jan,\n year = {2006},\n issn = {0018-9162},\n pages = {16--18},\n numpages = {3},\n url = {http://dx.doi.org/10.1109/MC.2006.22},\n doi = {10.1109/MC.2006.22},\n acmid = {1110668},\n publisher = {IEEE Computer Society Press},\n address = {Los Alamitos, CA, USA},\n keywords = {Flash memory, Flash memory, Storage technology, Storage technology},\n} \r\n",
        "key": "1110668",
        "pub_year": "2006",
        "text": "George Lawton, Improved Flash Memory Grows in Popularity, Computer, v.39 n.1, p.16-18, January 2006  \u00a0[doi>"
    },
    "1111610": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1111610",
        "bib_stats": {
            "cites": 37,
            "dl": 2,
            "dl_52": 43,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Chang:2005:EML:1111609.1111610,\n author = {Chang, Li-Pin and Kuo, Tei-Wei},\n title = {Efficient Management for Large-scale Flash-memory Storage Systems with Resource Conservation},\n journal = {Trans. Storage},\n issue_date = {November 2005},\n volume = {1},\n number = {4},\n month = nov,\n year = {2005},\n issn = {1553-3077},\n pages = {381--418},\n numpages = {38},\n url = {http://doi.acm.org/10.1145/1111609.1111610},\n doi = {10.1145/1111609.1111610},\n acmid = {1111610},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, consumer electronics, embedded systems, memory management, portable devices, storage systems},\n} \r\n",
        "key": "1111610",
        "pub_year": "2005",
        "text": "Li-Pin Chang , Tei-Wei Kuo, Efficient management for large-scale flash-memory storage systems with resource conservation, ACM Transactions on Storage (TOS), v.1 n.4, p.381-418, November 2005"
    },
    "1136532": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1136532",
        "bib_stats": {
            "cites": 9,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wu:2006:SCM:1135776.1136532,\n author = {Wu, Chin-Hsien and Kuo, Tei-Wei and Yang, Chia-Lin},\n title = {A Space-Efficient Caching Mechanism for Flash-Memory Address Translation},\n booktitle = {Proceedings of the Ninth IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing},\n series = {ISORC '06},\n year = {2006},\n isbn = {0-7695-2561-X},\n pages = {64--71},\n numpages = {8},\n url = {https://doi.org/10.1109/ISORC.2006.13},\n doi = {10.1109/ISORC.2006.13},\n acmid = {1136532},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1136532",
        "pub_year": "2006",
        "text": "Chin-Hsien Wu , Tei-Wei Kuo , Chia-Lin Yang, A Space-Efficient Caching Mechanism for Flash-Memory Address Translation, Proceedings of the Ninth IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing, p.64-71, April 24-26, 2006  \u00a0[doi>"
    },
    "1141486": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1141486",
        "bib_stats": {
            "cites": 8,
            "dl": 539,
            "dl_52": 15,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Wu:2006:EIC:1141277.1141486,\n author = {Wu, Chin-Hsien and Kuo, Tei-Wei and Chang, Li-Pin},\n title = {Efficient Initialization and Crash Recovery for Log-based File Systems over Flash Memory},\n booktitle = {Proceedings of the 2006 ACM Symposium on Applied Computing},\n series = {SAC '06},\n year = {2006},\n isbn = {1-59593-108-2},\n location = {Dijon, France},\n pages = {896--900},\n numpages = {5},\n url = {http://doi.acm.org/10.1145/1141277.1141486},\n doi = {10.1145/1141277.1141486},\n acmid = {1141486},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1141486",
        "pub_year": "2006",
        "text": "Chin-Hsien Wu , Tei-Wei Kuo , Li-Pin Chang, Efficient initialization and crash recovery for log-based file systems over flash memory, Proceedings of the 2006 ACM symposium on Applied computing, April 23-27, 2006, Dijon, France"
    },
    "1155411": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1155411",
        "bib_stats": {
            "cites": 40,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Lim:2006:ENF:1155316.1155411,\n author = {Lim, Seung-Ho and Park, Kyu-Ho},\n title = {An Efficient NAND Flash File System for Flash Memory Storage},\n journal = {IEEE Trans. Comput.},\n issue_date = {July 2006},\n volume = {55},\n number = {7},\n month = jul,\n year = {2006},\n issn = {0018-9340},\n pages = {906--912},\n numpages = {7},\n url = {http://dx.doi.org/10.1109/TC.2006.96},\n doi = {10.1109/TC.2006.96},\n acmid = {1155411},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash file system, Flash file system, NAND flash memory, flash translation layer, scan, garbage collection., NAND flash memory, flash translation layer, garbage collection., scan},\n} \r\n",
        "key": "1155411",
        "pub_year": "2006",
        "text": "Seung-Ho Lim , Kyu-Ho Park, An Efficient NAND Flash File System for Flash Memory Storage, IEEE Transactions on Computers, v.55 n.7, p.906-912, July 2006  \u00a0[doi>"
    },
    "1164257": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1164257",
        "bib_stats": {
            "cites": 23,
            "dl": 636,
            "dl_52": 14,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Kim:2006:LSD:1182635.1164257,\n author = {Kim, Gye-Jeong and Baek, Seung-Cheon and Lee, Hyun-Sook and Lee, Han-Deok and Joe, Moon Jeung},\n title = {LGeDBMS: A Small DBMS for Embedded System with Flash Memory},\n booktitle = {Proceedings of the 32Nd International Conference on Very Large Data Bases},\n series = {VLDB '06},\n year = {2006},\n location = {Seoul, Korea},\n pages = {1255--1258},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=1182635.1164257},\n acmid = {1164257},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1164257",
        "pub_year": "2006",
        "text": "Gye-Jeong Kim , Seung-Cheon Baek , Hyun-Sook Lee , Han-Deok Lee , Moon Jeung Joe, LGeDBMS<i>LGeDBMS</i>: a small DBMS for embedded system with flash memory, Proceedings of the 32nd international conference on Very large data bases, September 12-15, 2006, Seoul, Korea : a small DBMS for embedded system with flash memory, Proceedings of the 32nd international conference on Very large data bases, September 12-15, 2006, Seoul, Korea"
    },
    "1165674": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1165674",
        "bib_stats": {
            "cites": 22,
            "dl": 533,
            "dl_52": 11,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chen:2006:STF:1165573.1165674,\n author = {Chen, Feng and Jiang, Song and Zhang, Xiaodong},\n title = {SmartSaver: Turning Flash Drive into a Disk Energy Saver for Mobile Computers},\n booktitle = {Proceedings of the 2006 International Symposium on Low Power Electronics and Design},\n series = {ISLPED '06},\n year = {2006},\n isbn = {1-59593-462-6},\n location = {Tegernsee, Bavaria, Germany},\n pages = {412--417},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1165573.1165674},\n doi = {10.1145/1165573.1165674},\n acmid = {1165674},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy saving, flash drive, hard disk, mobile computer},\n} \r\n",
        "key": "1165674",
        "pub_year": "2006",
        "text": "Feng Chen , Song Jiang , Xiaodong Zhang, SmartSaver: turning flash drive into a disk energy saver for mobile computers, Proceedings of the 2006 international symposium on Low power electronics and design, October 04-06, 2006, Tegernsee, Bavaria, Germany  \u00a0[doi>"
    },
    "1165675": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1165675",
        "bib_stats": {
            "cites": 5,
            "dl": 1,
            "dl_52": 13,
            "dl_6": 6
        },
        "key": "1165675",
        "text": "Hung-Wei Tseng , Han-Lin Li , Chia-Lin Yang, An energy-efficient virtual memory system with flash memory as the secondary storage, Proceedings of the 2006 international symposium on Low power electronics and design, October 04-06, 2006, Tegernsee, Bavaria, Germany"
    },
    "1168914": {
        "abstract": "Rather than adapting existing file system solutions, as in the case of random access memory (RAM) file systems or RAM-based disk emulators, the authors make a case for the need to redesign a file system optimized for persistent RAMs. The Conquest file system has a simpler datapath to small files and metadata in memory that bypasses the I/O buffer and disk management found in conventional disk-based file systems. The performance evaluation of Conquest shows up to a 19-times improvement in memory performance compared to file systems designed for disks, supporting the need for file system redesign to better exploit memory performance.",
        "acm_key": "1168914",
        "bib_stats": {
            "cites": 16,
            "dl": 1,
            "dl_52": 12,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Wang:2006:CFS:1168910.1168914,\n author = {Wang, An-I Andy and Kuenning, Geoff and Reiher, Peter and Popek, Gerald},\n title = {The Conquest File System: Better Performance Through a Disk/persistent-RAM Hybrid Design},\n journal = {Trans. Storage},\n issue_date = {August 2006},\n volume = {2},\n number = {3},\n month = aug,\n year = {2006},\n issn = {1553-3077},\n pages = {309--348},\n numpages = {40},\n url = {http://doi.acm.org/10.1145/1168910.1168914},\n doi = {10.1145/1168910.1168914},\n acmid = {1168914},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Persistent RAM, file systems, performance measurement, storage management},\n} \r\n",
        "key": "1168914",
        "pub_year": "2006",
        "text": "An-I Andy Wang , Geoff Kuenning , Peter Reiher , Gerald Popek, The Conquest<i>Conquest</i> file system: Better performance through a disk/persistent-RAM hybrid design, ACM Transactions on Storage (TOS), v.2 n.3, p.309-348, August 2006&#13;\n\t\t\t\t\t\t file system: Better performance through a disk/persistent-RAM hybrid design, ACM Transactions on Storage (TOS), v.2 n.3, p.309-348, August 2006"
    },
    "1176310": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1176310",
        "bib_stats": {
            "cites": 16,
            "dl": 589,
            "dl_52": 14,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Joo:2006:DPO:1176254.1176310,\n author = {Joo, Yongsoo and Choi, Yongseok and Park, Chanik and Chung, Sung Woo and Chung, EuiYoung and Chang, Naehyuck},\n title = {Demand Paging for OneNAND\\texttrademark Flash eXecute-in-place},\n booktitle = {Proceedings of the 4th International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES+ISSS '06},\n year = {2006},\n isbn = {1-59593-370-0},\n location = {Seoul, Korea},\n pages = {229--234},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1176254.1176310},\n doi = {10.1145/1176254.1176310},\n acmid = {1176310},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, OneNAND, XIP, demand paging, embedded systems, page replacement, virtual memory},\n} \r\n",
        "key": "1176310",
        "pub_year": "2006",
        "text": "Yongsoo Joo , Yongseok Choi , Chanik Park , Sung Woo Chung , EuiYoung Chung , Naehyuck Chang, Demand paging for OneNAND\u2122 Flash eXecute-in-place, Proceedings of the 4th international conference on Hardware/software codesign and system synthesis, October 22-25, 2006, Seoul, Korea"
    },
    "1176774": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1176774",
        "bib_stats": {
            "cites": 43,
            "dl": 1,
            "dl_52": 71,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Kgil:2006:FNF:1176760.1176774,\n author = {Kgil, Taeho and Mudge, Trevor},\n title = {FlashCache: A NAND Flash Memory File Cache for Low Power Web Servers},\n booktitle = {Proceedings of the 2006 International Conference on Compilers, Architecture and Synthesis for Embedded Systems},\n series = {CASES '06},\n year = {2006},\n isbn = {1-59593-543-6},\n location = {Seoul, Korea},\n pages = {103--112},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1176760.1176774},\n doi = {10.1145/1176760.1176774},\n acmid = {1176774},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {application-specific architectures, embedded system, flash memory, full-system, low power, server platforms, simulation, web server},\n} \r\n",
        "key": "1176774",
        "pub_year": "2006",
        "text": "Taeho Kgil , Trevor Mudge, FlashCache: a NAND flash memory file cache for low power web servers, Proceedings of the 2006 international conference on Compilers, architecture and synthesis for embedded systems, October 22-25, 2006, Seoul, Korea  \u00a0[doi>"
    },
    "1176789": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1176789",
        "bib_stats": {
            "cites": 93,
            "dl": 2,
            "dl_52": 186,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Park:2006:CRA:1176760.1176789,\n author = {Park, Seon-yeong and Jung, Dawoon and Kang, Jeong-uk and Kim, Jin-soo and Lee, Joonwon},\n title = {CFLRU: A Replacement Algorithm for Flash Memory},\n booktitle = {Proceedings of the 2006 International Conference on Compilers, Architecture and Synthesis for Embedded Systems},\n series = {CASES '06},\n year = {2006},\n isbn = {1-59593-543-6},\n location = {Seoul, Korea},\n pages = {234--241},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/1176760.1176789},\n doi = {10.1145/1176760.1176789},\n acmid = {1176789},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {embedded storage, flash memory, replacement algorithm},\n} \r\n",
        "key": "1176789",
        "pub_year": "2006",
        "text": "Seon-yeong Park , Dawoon Jung , Jeong-uk Kang , Jin-soo Kim , Joonwon Lee, CFLRU: a replacement algorithm for flash memory, Proceedings of the 2006 international conference on Compilers, architecture and synthesis for embedded systems, October 22-25, 2006, Seoul, Korea  \u00a0[doi>"
    },
    "1176911": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1176911",
        "bib_stats": {
            "cites": 95,
            "dl": 2,
            "dl_52": 131,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Kang:2006:SFT:1176887.1176911,\n author = {Kang, Jeong-Uk and Jo, Heeseung and Kim, Jin-Soo and Lee, Joonwon},\n title = {A Superblock-based Flash Translation Layer for NAND Flash Memory},\n booktitle = {Proceedings of the 6th ACM \\&Amp; IEEE International Conference on Embedded Software},\n series = {EMSOFT '06},\n year = {2006},\n isbn = {1-59593-542-8},\n location = {Seoul, Korea},\n pages = {161--170},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1176887.1176911},\n doi = {10.1145/1176887.1176911},\n acmid = {1176911},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, address translation, flash translation layer (FTL)},\n} \r\n",
        "key": "1176911",
        "pub_year": "2006",
        "text": "Jeong-Uk Kang , Heeseung Jo , Jin-Soo Kim , Joonwon Lee, A superblock-based flash translation layer for NAND flash memory, Proceedings of the 6th ACM & IEEE International conference on Embedded software, October 22-25, 2006, Seoul, Korea  \u00a0[doi>"
    },
    "1182827": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1182827",
        "bib_stats": {
            "cites": 37,
            "dl": 699,
            "dl_52": 19,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Mathur:2006:CEO:1182807.1182827,\n author = {Mathur, Gaurav and Desnoyers, Peter and Ganesan, Deepak and Shenoy, Prashant},\n title = {Capsule: An Energy-optimized Object Storage System for Memory-constrained Sensor Devices},\n booktitle = {Proceedings of the 4th International Conference on Embedded Networked Sensor Systems},\n series = {SenSys '06},\n year = {2006},\n isbn = {1-59593-343-3},\n location = {Boulder, Colorado, USA},\n pages = {195--208},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1182807.1182827},\n doi = {10.1145/1182807.1182827},\n acmid = {1182827},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {embedded systems, energy efficiency, file system, flash memory, objects, sensor network, storage system},\n} \r\n",
        "key": "1182827",
        "pub_year": "2006",
        "text": "Gaurav Mathur , Peter Desnoyers , Deepak Ganesan , Prashant Shenoy, Capsule: an energy-optimized object storage system for memory-constrained sensor devices, Proceedings of the 4th international conference on Embedded networked sensor systems, October 31-November 03, 2006, Boulder, Colorado, USA  \u00a0[doi>"
    },
    "1210600": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1210600",
        "bib_stats": {
            "cites": 18,
            "dl": 1,
            "dl_52": 17,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Wu:2006:DEI:1210596.1210600,\n author = {Wu, Chin-Hsien and Kuo, Tei-Wei and Chang, Li-Pin},\n title = {The Design of Efficient Initialization and Crash Recovery for Log-based File Systems over Flash Memory},\n journal = {Trans. Storage},\n issue_date = {November 2006},\n volume = {2},\n number = {4},\n month = nov,\n year = {2006},\n issn = {1553-3077},\n pages = {449--467},\n numpages = {19},\n url = {http://doi.acm.org/10.1145/1210596.1210600},\n doi = {10.1145/1210596.1210600},\n acmid = {1210600},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, crash recovery, efficient initialization, embedded systems, file systems, storage systems},\n} \r\n",
        "key": "1210600",
        "pub_year": "2006",
        "text": "Chin-Hsien Wu , Tei-Wei Kuo , Li-Pin Chang, The Design of efficient initialization and crash recovery for log-based file systems over flash memory, ACM Transactions on Storage (TOS), v.2 n.4, p.449-467, November 2006"
    },
    "1236412": {
        "abstract": "In this paper, we describe the SMILE (Smart MIddleware, Light Ends) system which is one of the earliest systems built in the area of distributed event stream processing. SMILE unites the \"publish-subscribe\" model of messaging middleware with the \"continuous query\" model of database systems. In SMILE, information producers, which may be sensors, applications, or databases, generate streams of events, such as RFID data, news items or stock trades; consumers specify stateful subscriptions to derived views, such as \"individuals trading top 5 total volume of stock Y within x minutes before a major news story about the same company Y\"; the SMILE system constructs and deploys a dataflow network of computations which process events from producers, compute derived views and deliver continuous and timely updates of subscribed views to consumers. Research challenges addressed by SMILE include: rigorously defining the semantics for correct state delivery; implementing this semantics in the presence of failure; distributing computations optimally over a network of multiple servers; scheduling and controlling message flow in this network; smoothly integrating this technology with other components, e.g., databases, services, user interfaces. SMILE is applicable to any \"sense and respond\" scenario that requires monitoring and processing of events as they are generated. Applications span multiple industries, e.g., monitoring financial opportunities and detecting potential fraud in financial industry, systems management and alerts in data centers, inventory management in RFID applications, and business performance management. In this paper, we describe the SMILE system, its architecture, services supported, and implementation details, and its use in multiple application scenarios.",
        "acm_key": "1236412",
        "bib_stats": {
            "cites": 78,
            "dl": 986,
            "dl_52": 44,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Nath:2007:FDS:1236360.1236412,\n author = {Nath, Suman and Kansal, Aman},\n title = {FlashDB: Dynamic Self-tuning Database for NAND Flash},\n booktitle = {Proceedings of the 6th International Conference on Information Processing in Sensor Networks},\n series = {IPSN '07},\n year = {2007},\n isbn = {978-1-59593-638-7},\n location = {Cambridge, Massachusetts, USA},\n pages = {410--419},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1236360.1236412},\n doi = {10.1145/1236360.1236412},\n acmid = {1236412},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {B<sup>+</sup>-tree, NAND flash, indexing, log-structured index, self-tuning index},\n} \r\n",
        "key": "1236412",
        "pub_year": "2007",
        "text": "Suman Nath , Aman Kansal, FlashDB: dynamic self-tuning database for NAND flash, Proceedings of the 6th international conference on Information processing in sensor networks, April 25-27, 2007, Cambridge, Massachusetts, USA  \u00a0[doi>"
    },
    "1243429": {
        "abstract": "This paper summarizes our experience designing and implementing BitVault: a content-addressable retention platform for large volumes of reference data -- seldom-changing information that needs to be retained for a long time. BitVault uses \"smart bricks\" as the building block to lower the hardware cost. The challenges are to keep management costs low in a system that scales from one brick to tens of thousands, to ensure reliability, and to deliver a simple design. Our design incorporates peer-to-peer (P2P) technologies for self-managing and self-healing and uses massively parallel repair to reduce system vulnerability to data loss. The simplicity of the architecture relies on an eventually reliable membership service provided by a perfect one-hop distributed hash table (DHT). Its object-driven repair model yields last-replica recall guarantee independent of the failure scenario. So long as the last copy of a data object remains in the system, that data can be retrieved and its replication degree can be restored. A prototype has been implemented. Theoretical analysis, simulations and experiments have been conducted to validate the design of BitVault.",
        "acm_key": "1243429",
        "bib_stats": {
            "cites": 56,
            "dl": 1,
            "dl_52": 40,
            "dl_6": 6
        },
        "bibtex": "\r\n@article{Birrell:2007:DHF:1243418.1243429,\n author = {Birrell, Andrew and Isard, Michael and Thacker, Chuck and Wobber, Ted},\n title = {A Design for High-performance Flash Disks},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {April 2007},\n volume = {41},\n number = {2},\n month = apr,\n year = {2007},\n issn = {0163-5980},\n pages = {88--93},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1243418.1243429},\n doi = {10.1145/1243418.1243429},\n acmid = {1243429},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1243429",
        "pub_year": "2007",
        "text": "Andrew Birrell , Michael Isard , Chuck Thacker , Ted Wobber, A design for high-performance flash disks, ACM SIGOPS Operating Systems Review, v.41 n.2, p.88-93, April 2007  \u00a0[doi>"
    },
    "1244248": {
        "abstract": "Research on password authentication systems has repeatedly shown that people choose weak passwords because of the difficulty of remembering random passwords. Moreover, users with multiple passwords for unrelated activities tend to choose almost similar passwords for all of them. Many password schemes have been proposed to alleviate this problem, but they either require modification to the password entry and processing infrastructure (e.g., graphical passwords) or they require the user to have some trusted computing power (e.g., smartcard-like portable devices, browser plugins, etc). We propose a scheme that is applicable to any existing system without any modification, as it does not require any form of involvement from the service provider (e.g., bank, brokerage). Nor does it require the user to have any computing device at hand (not even a calculator). Our approach consists of generating a mnemonic sentence that helps the users remember a multiplicity of truly random passwords, which are independently selected. The scheme is such that changes to passwords do not necessitate a change in the mnemonic sentence that the user memorizes. Hence, passwords can be changed without any additional burden on the memory of the user, thereby increasing the system's security. An adversary who breaks one of the passwords encoded in the mnemonic sentence does not gain information about the other passwords. A key idea is to split a password in two parts: One part is written down on a paper (helper card), another part is encoded in the mnemonic sentence. Both of these two parts are required for successfully reproducing the password, and the password reconstruction from these two parts is done using only simple table lookups. Passwords' renewal requires only the re-generation of the helper card. Our scheme resolves the apparent contradictory requirements from most password policies: That the password should be random, and that it should be memorized and never written down. This makes possible passwords that are more secure against an adversary who illicitly gains access to the password file, as a dictionary attack is now unlikely to succeed (the attacker now needs to carry out a more daunting brute force enumerative attack). Even if the adversary somehow obtains the helper card, it gets quantifiably limited information about the passwords of the user (so the helper card may be lost or stolen without disaster immediately striking the user). We quantify the time period required for this adversary to successfully crack the password.",
        "acm_key": "1244248",
        "bib_stats": {
            "cites": 74,
            "dl": 1,
            "dl_52": 151,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Chang:2007:EWL:1244002.1244248,\n author = {Chang, Li-Pin},\n title = {On Efficient Wear Leveling for Large-scale Flash-memory Storage Systems},\n booktitle = {Proceedings of the 2007 ACM Symposium on Applied Computing},\n series = {SAC '07},\n year = {2007},\n isbn = {1-59593-480-4},\n location = {Seoul, Korea},\n pages = {1126--1130},\n numpages = {5},\n url = {http://doi.acm.org/10.1145/1244002.1244248},\n doi = {10.1145/1244002.1244248},\n acmid = {1244248},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consumer electronics, embedded systems, flash memory, memory management, portable devices, storage systems},\n} \r\n",
        "key": "1244248",
        "pub_year": "2007",
        "text": "Li-Pin Chang, On efficient wear leveling for large-scale flash-memory storage systems, Proceedings of the 2007 ACM symposium on Applied computing, March 11-15, 2007, Seoul, Korea  \u00a0[doi>"
    },
    "1247367": {
        "abstract": "LinuxBIOS is fast becoming a widely accepted alternative to the traditional PC BIOS for cluster computing applications. However, in the process it is gaining attention from developers of Internet appliance, desktop and visualization applications, who also wish to take advantage of the features provided by LinuxBIOS, such as minimizing user interaction, increasing system reliability, and faster boot times. Unlike cluster computing, these applications tend to rely heavily on graphical user interfaces, so it is important that the VGA hardware is correctly initialized early in the boot process in additional to the hardware initialization currently performed by LinuxBIOS. Unfortunately, the open-source nature of LinuxBIOS means that many graphic card vendors are reluctant to expose code relating to the initialization of their hardware in the fear that this might allow competitors access to proprietary chipset information. As a consequence, in many cases the only way to initialize the VGA hardware is to use the vendor provided, proprietary, VGA BIOS. To achieve this it is necessary to provide a compatibility layer that operates between the VGA BIOS and LinuxBIOS in order to simulate the environment that the VGA BIOS assumes is available. In this paper we present our preliminary results on FreeVGA, an x86 emulator based on x86emu that can be used as such a compatibility layer. We will show how we have successfully used FreeVGA to initialize VGA cards from both ATI and Nvidia on a Tyan S2885 platform.",
        "acm_key": "1247367",
        "bib_stats": {
            "cites": 34,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Gal:2005:TFF:1247360.1247367,\n author = {Gal, Eran and Toledo, Sivan},\n title = {A Transactional Flash File System for Microcontrollers},\n booktitle = {Proceedings of the Annual Conference on USENIX Annual Technical Conference},\n series = {ATEC '05},\n year = {2005},\n location = {Anaheim, CA},\n pages = {7--7},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1247360.1247367},\n acmid = {1247367},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1247367",
        "pub_year": "2005",
        "text": "Eran Gal , Sivan Toledo, A transactional flash file system for microcontrollers, Proceedings of the annual conference on USENIX Annual Technical Conference, p.7-7, April 10-15, 2005, Anaheim, CA"
    },
    "1247488": {
        "abstract": "Sketching techniques can provide approximate answers to aggregate queries either for data-streaming or distributed computation. Small space summaries that have linearity properties are required for both types of applications. The prevalent method for analyzing sketches uses moment analysis and distribution independent bounds based on moments. This method produces clean, easy to interpret, theoretical bounds that are especially useful for deriving asymptotic results. However, the theoretical bounds obscure fine details of the behavior of various sketches and they are mostly not indicative of which type of sketches should be used in practice. Moreover, no significant empirical comparison between various sketching techniques has been published, which makes the choice even harder. In this paper, we take a close look at the sketching techniques proposed in the literature from a statistical point of view with the goal of determining properties that indicate the actual behavior and producing tighter confidence bounds. Interestingly, the statistical analysis reveals that two of the techniques, Fast-AGMS and Count-Min, provide results that are in some cases orders of magnitude better than the corresponding theoretical predictions. We conduct an extensive empirical study that compares the different sketching techniques in order to corroborate the statistical analysis with the conclusions we draw from it. The study indicates the expected performance of various sketches, which is crucial if the techniques are to be used by practitioners. The overall conclusion of the study is that Fast-AGMS sketches are, for the full spectrum of problems, either the best, or close to the best, sketching technique. This makes Fast-AGMS sketches the preferred choice irrespective of the situation.",
        "acm_key": "1247488",
        "bib_stats": {
            "cites": 112,
            "dl": 2,
            "dl_52": 129,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Lee:2007:DFD:1247480.1247488,\n author = {Lee, Sang-Won and Moon, Bongki},\n title = {Design of Flash-based DBMS: An In-page Logging Approach},\n booktitle = {Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '07},\n year = {2007},\n isbn = {978-1-59593-686-8},\n location = {Beijing, China},\n pages = {55--66},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1247480.1247488},\n doi = {10.1145/1247480.1247488},\n acmid = {1247488},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-memory database server, in-page logging},\n} \r\n",
        "key": "1247488",
        "pub_year": "2007",
        "text": "Sang-Won Lee , Bongki Moon, Design of flash-based DBMS: an in-page logging approach, Proceedings of the 2007 ACM SIGMOD international conference on Management of data, June 11-14, 2007, Beijing, China  \u00a0[doi>"
    },
    "1251038": {
        "abstract": "Storage servers, as well as storage clients, typically have large memories in which they cache data blocks. This creates a two-tier cache hierarchy in which the presence of a first-tier cache (at the storage client) makes it more difficult to manage the second-tier cache (at the storage server). Many techniques have been proposed for improving the management of second-tier caches, but none of these techniques use the information that is provided by writes of data blocks from the first tier to help manage the second-tier cache. In this paper, we illustrate how the information contained in writes from the first tier can be used to improve the performance of the second-tier cache. In particular, we argue that there are very different reasons why storage clients write data blocks to storage servers (e.g., cleaning dirty blocks vs. limiting the time to recover from failure). These different types of writes can provide strong indications about the current state and future access patterns of a first-tier cache, which can help in managing the second-tier cache. We propose that storage clients inform the storage servers about the types of writes that they perform by passing write hints. These write hints can then be used by the server to manage the second-tier cache. We focus on the common and important case in which the storage client is a database system running a transactional (OLTP) workload. We describe, for this case, the different types of write hints that can be passed to the storage server, and we present several cache management policies that rely on these write hints. We demonstrate using trace driven simulations that these simple and inexpensive write hints can significantly improve the performance of the second-tier cache.",
        "acm_key": "1251038",
        "bib_stats": {
            "cites": 17,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Gill:2005:WWO:1251028.1251038,\n author = {Gill, Binny S. and Modha, Dharmendra S.},\n title = {WOW: Wise Ordering for Writes - Combining Spatial and Temporal Locality in Non-volatile Caches},\n booktitle = {Proceedings of the 4th Conference on USENIX Conference on File and Storage Technologies - Volume 4},\n series = {FAST'05},\n year = {2005},\n location = {San Francisco, CA},\n pages = {10--10},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1251028.1251038},\n acmid = {1251038},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1251038",
        "pub_year": "2005",
        "text": "Binny S. Gill , Dharmendra S. Modha, WOW: wise ordering for writes - combining spatial and temporal locality in non-volatile caches, Proceedings of the 4th conference on USENIX Conference on File and Storage Technologies, p.10-10, December 13-16, 2005, San Francisco, CA"
    },
    "1267309": {
        "abstract": "We present the first peer-to-peer data streaming application that guarantees predictable throughput and low latency in the BAR (Byzantine/Altruistic/Rational) model, in which non-altruistic nodes can behave in ways that are self-serving (rational) or arbitrarily malicious (Byzantine). At the core of our solution is a BAR-tolerant version of gossip, a well-known technique for scalable and reliable data dissemination. BAR Gossip relies on verifiable pseudo-random partner selection to eliminate non-determinism that can be used to game the system while maintaining the robustness and rapid convergence of traditional gossip. A novel fair enough exchange primitive entices cooperation among selfish nodes on short timescales, avoiding the need for long-term node reputations. Our initial experience provides evidence for BAR Gossip's robustness. Our BAR-tolerant streaming application provides over 99% convergence for broadcast updates when all clients are selfish but not colluding, and over 95% convergence when up to 40% of clients collude while the rest follow the protocol. BAR Gossip also performs well when the client population consists of both selfish and Byzantine nodes, achieving over 93% convergence even when 20% of the nodes are Byzantine.",
        "acm_key": "1267309",
        "bib_stats": {
            "cites": 25,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Nightingale:2006:RS:1267308.1267309,\n author = {Nightingale, Edmund B. and Veeraraghavan, Kaushik and Chen, Peter M. and Flinn, Jason},\n title = {Rethink the Sync},\n booktitle = {Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation - Volume 7},\n series = {OSDI '06},\n year = {2006},\n location = {Seattle, WA},\n pages = {1--1},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1267308.1267309},\n acmid = {1267309},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1267309",
        "pub_year": "2006",
        "text": "Edmund B. Nightingale , Kaushik Veeraraghavan , Peter M. Chen , Jason Flinn, Rethink the sync, Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation, p.1-1, November 06-08, 2006, Seattle, WA"
    },
    "1267424": {
        "abstract": "The RAMA file system addresses these problems by providing a massively parallel file system that does not need user hints to provide good performance. RAMA takes advantage of the recent decrease in physical disk size by assuming that each processor in an MPP has one or more disks attached to it. Hashing is then used to pseudo-randomly distribute data to all of these disks, insuring high bandwidth regardless of access pattern. Since MPP programs often have many nodes accessing a single file in parallel, the file system must allow access to different parts of the file without relying on a particular node. In RAMA, a file request involves only two nodes -- the node making the request and the node on whose disk the data is stored. Thus, RAMA scales well to hundreds of processors. Since RAMA needs no layout hints from applications, it fits well into systems where users cannot (or will not) provide such hints. Fortunately, this flexibility does not cause a large loss of performance. RAMA's simulated performance is within 10-15% of the optimum performance of a similarly-sized striped file system, and is a factor of 4 or more better than a striped file system with poorly laid out data.",
        "acm_key": "1267424",
        "bib_stats": {
            "cites": 151,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kawaguchi:1995:FBF:1267411.1267424,\n author = {Kawaguchi, Atsuo and Nishioka, Shingo and Motoda, Hiroshi},\n title = {A Flash-memory Based File System},\n booktitle = {Proceedings of the USENIX 1995 Technical Conference Proceedings},\n series = {TCON'95},\n year = {1995},\n location = {New Orleans, Louisiana},\n pages = {13--13},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1267411.1267424},\n acmid = {1267424},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1267424",
        "pub_year": "1995",
        "text": "Atsuo Kawaguchi , Shingo Nishioka , Hiroshi Motoda, A flash-memory based file system, Proceedings of the USENIX 1995 Technical Conference Proceedings, p.13-13, January 16-20, 1995, New Orleans, Louisiana"
    },
    "1267577": {
        "abstract": "Downloading executable content, which enables principals to run programs from remote sites, is a key technology in a number of emerging applications, including collaborative systems, electronic commerce, and web information services. However, the use of downloaded executable content also presents serious security problems because it enables remote principals to execute programs on behalf of the downloading principal. Unless downloaded executable content is properly controlled, a malicious remote principal may obtain unauthorized access to the downloading principal's resources. Current solutions either attempt to strictly limit the capabilities of downloaded content or require complete trust in the remote principal, so applications which require intermediate amounts of sharing, such as collaborative applications, cannot be constructed over insecure networks. In this paper, we describe an architecture that flexibly controls the access rights of downloaded content by: (1) authenticating content sources; (2) determining content access rights based on its source and the application that it is implementing; and (3) enforcing these access rights over a wide variety of objects and for the entire computation, even if external software is used. We describe the architecture in the context of an infrastructure for supporting collaborative applications.",
        "acm_key": "1267577",
        "bib_stats": {
            "cites": 88,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Gutmann:1996:SDD:1267569.1267577,\n author = {Gutmann, Peter},\n title = {Secure Deletion of Data from Magnetic and Solid-state Memory},\n booktitle = {Proceedings of the 6th Conference on USENIX Security Symposium, Focusing on Applications of Cryptography - Volume 6},\n series = {SSYM'96},\n year = {1996},\n location = {San Jose, California},\n pages = {8--8},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1267569.1267577},\n acmid = {1267577},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1267577",
        "pub_year": "1996",
        "text": "Peter Gutmann, Secure deletion of data from magnetic and solid-state memory, Proceedings of the 6th conference on USENIX Security Symposium, Focusing on Applications of Cryptography, p.8-8, July 22-25, 1996, San Jose, California"
    },
    "1267641": {
        "abstract": "We have used hardware measurements and trace-driven simulation to evaluate each of the alternative storage devices and their related design strategies. Hardware measurements on an HP OmniBook 300 highlight differences in the performance of the three devices as used on the Omnibook, especially the poor performance of version 2.00 of the Microsoft Flash File System [11] when accessing large files. The traces used in our study came from different environments, including mobile computers (Macintosh Power-Books) and desktop computers (running Windows or HPUX), as well as synthetic workloads. Our simulation study shows that flash memory can reduce energy consumption by an order of magnitude, compared to magnetic disk, while providing good read performance and acceptable write performance. These energy savings can translate into a 22% extension of battery life. We also find that the amount of unused memory in a flash memory card has a substantial impact on energy consumption, performance, and endurance: compared to low storage utilizations (40% full), running flash memory near its capacity (95% full) can increase energy consumption by 70-190%, degrade write response time by 30%, and decrease the lifetime of the memory card by up to a third. For flash disks, asynchronous erasure can improve write response time by a factor of 2.5.",
        "acm_key": "1267641",
        "bib_stats": {
            "cites": 93,
            "dl": 234,
            "dl_52": 6,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Douglis:1994:SAM:1267638.1267641,\n author = {Douglis, Fred and C\\'{a}ceres, Ram\\'{o}n and Kaashoek, Frans and Li, Kai and Marsh, Brian and Tauber, Joshua A.},\n title = {Storage Alternatives for Mobile Computers},\n booktitle = {Proceedings of the 1st USENIX Conference on Operating Systems Design and Implementation},\n series = {OSDI '94},\n year = {1994},\n location = {Monterey, California},\n articleno = {3},\n url = {http://dl.acm.org/citation.cfm?id=1267638.1267641},\n acmid = {1267641},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1267641",
        "pub_year": "1994",
        "text": "Fred Douglis , Ram\u00f3n C\u00e1ceres , Frans Kaashoek , Kai Li , Brian Marsh , Joshua A. Tauber, Storage alternatives for mobile computers, Proceedings of the 1st USENIX conference on Operating Systems Design and Implementation, p.3-es, November 14-17, 1994, Monterey, California"
    },
    "1267928": {
        "abstract": "Recently, there has been a growing trend towards designing advanced file system buffer cache replacement algorithms such as ARC [1], PCC [2], and LIRS [3]. These algorithms perform much better than standard caching algorithms available in modern operating system kernels. Given the availability of such advanced caching algorithms and the potential for designing better algorithms, it is highly desirable to replace the standard caching policy. Since the performance of many recently developed replacement algorithms is dependent on the application access patterns, a single caching policy cannot be effective for the wide range of applications that are run on modern operating systems. Furthermore, delegating the responsibility of cache management to the application developers immensely complicates the development process for typical applications. It would be useful to have a repertoire of caching policies in the kernel and to allow the operating system to choose the one that best suits the needs of the currently running applications. In addition, as pointed out in [4], the performance of caching algorithms must be studied in the context of all the kernel storage subsystems. Unfortunately, the intertwined unified page and buffer cache in the Linux kernel makes incorporation of new caching policies an excruciating task, and requires in-depth scrutiny of the code as it may threaten the stability of the kernel. To address these issues, we propose FlexiCache, a flexible interface to the existing page and buffer cache management mechanism. FlexiCache allows easy modification of the replacement policy and provides a simple and powerful means for implementing new caching policies.",
        "acm_key": "1267928",
        "bib_stats": {
            "cites": 26,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Yadgar:2007:KKR:1267903.1267928,\n author = {Yadgar, Gala and Factor, Michael and Schuster, Assaf},\n title = {Karma: Know-it-all Replacement for a Multilevel Cache},\n booktitle = {Proceedings of the 5th USENIX Conference on File and Storage Technologies},\n series = {FAST '07},\n year = {2007},\n location = {San Jose, CA},\n pages = {25--25},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1267903.1267928},\n acmid = {1267928},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1267928",
        "pub_year": "2007",
        "text": "Gala Yadgar , Michael Factor , Assaf Schuster, Karma: know-it-all replacement for a multilevel cache, Proceedings of the 5th USENIX conference on File and Storage Technologies, p.25-25, February 13-16, 2007, San Jose, CA"
    },
    "1268314": {
        "abstract": "In order to reap the benefits of high-speed networks, the performance of the host operating system must at least match that of the underlying network. A barrier to achieving high throughput is the cost of copying data within current host architectures. We present a performance comparison of three styles of network device driver designed for a conventional monolithic UNIX kernel. Each driver performs a different number of copies. The zero-copy driver works by allowing the memory on the network adapter to be mapped directly into user address space. This maximises performance at the cost of: 1) breaking the semantics of existing network APIs such as BSD sockets and SVR4 TLI; 2) pushing responsibility for network buffer management up from the kernel into the application layer. The single-copy driver works by copying data directly between user space and adapter memory obviating the need for an intermediate copy into kernel buffers in main memory. This approach can be made transparent to existing application code but, like the zero-copy case, relies on an adapter with a generous quantity of on-board memory for buffering network data. The two-copy driver is a conventional STREAMS driver. The two-copy approach sacrifices performance for generality. We observe that the STREAMS overhead for small packets is significant. We report on the benefit of the hardware cache in ameliorating the effect of the second copy, although we note that streaming network data through the cache reduces the level of cache residency seen by the rest of the system.",
        "acm_key": "1268314",
        "bib_stats": {
            "cites": 27,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Markatos:1996:IRR:1268299.1268314,\n author = {Markatos, Evangelos P. and Dramitinos, George},\n title = {Implementation of a Reliable Remote Memory Pager},\n booktitle = {Proceedings of the 1996 Annual Conference on USENIX Annual Technical Conference},\n series = {ATEC '96},\n year = {1996},\n location = {San Diego, CA},\n pages = {15--15},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1268299.1268314},\n acmid = {1268314},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1268314",
        "pub_year": "1996",
        "text": "Evangelos P. Markatos , George Dramitinos, Implementation of a reliable remote memory pager, Proceedings of the 1996 annual conference on USENIX Annual Technical Conference, p.15-15, January 22-26, 1996, San Diego, CA"
    },
    "1275990": {
        "abstract": "In this paper, we propose the novel concept of probabilistic design for multimedia embedded systems, which is motivated by the challenge of how to design, but not overdesign, such systems while systematically incorporating performance requirements of multimedia application, uncertainties in execution time, and tolerance for reasonable execution failures. Unlike most present techniques that are based on either worst- or average-case execution times of application tasks, where the former guarantees the completion of each execution, but often leads to overdesigned systems, and the latter fails to provide any completion guarantees, the proposed probabilistic design method takes advantage of unique features mentioned above of multimedia systems to relax the rigid hardware requirements for software implementation and avoid overdesigning the system. In essence, this relaxation expands the design space and we further develop an off-line on-line minimum effort algorithm for quick exploration of the enlarged design space at early design stages. This is the first step toward our goal of bridging the gap between real-time analysis and embedded software implementation for rapid and economic multimedia system design. It is our belief that the proposed method has great potential in reducing system resource while meeting performance requirements. The experimental results confirm this as we achieve significant saving in system's energy consumption to provide a statistical completion ratio guarantee (i.e., the expected number of completions over a large number of iterations is greater than a given value).",
        "acm_key": "1275990",
        "bib_stats": {
            "cites": 195,
            "dl": 4,
            "dl_52": 153,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Lee:2007:LBF:1275986.1275990,\n author = {Lee, Sang-Won and Park, Dong-Joo and Chung, Tae-Sun and Lee, Dong-Ho and Park, Sangwon and Song, Ha-Joo},\n title = {A Log Buffer-based Flash Translation Layer Using Fully-associative Sector Translation},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {July 2007},\n volume = {6},\n number = {3},\n month = jul,\n year = {2007},\n issn = {1539-9087},\n articleno = {18},\n url = {http://doi.acm.org/10.1145/1275986.1275990},\n doi = {10.1145/1275986.1275990},\n acmid = {1275990},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, Flash memory, address translation, associative mapping, log blocks},\n} \r\n",
        "key": "1275990",
        "pub_year": "2007",
        "text": "Sang-Won Lee , Dong-Joo Park , Tae-Sun Chung , Dong-Ho Lee , Sangwon Park , Ha-Joo Song, A log buffer-based flash translation layer using fully-associative sector translation, ACM Transactions on Embedded Computing Systems (TECS), v.6 n.3, p.18-es, July 2007  \u00a0[doi>"
    },
    "1275991": {
        "abstract": "In this paper, we propose the novel concept of probabilistic design for multimedia embedded systems, which is motivated by the challenge of how to design, but not overdesign, such systems while systematically incorporating performance requirements of multimedia application, uncertainties in execution time, and tolerance for reasonable execution failures. Unlike most present techniques that are based on either worst- or average-case execution times of application tasks, where the former guarantees the completion of each execution, but often leads to overdesigned systems, and the latter fails to provide any completion guarantees, the proposed probabilistic design method takes advantage of unique features mentioned above of multimedia systems to relax the rigid hardware requirements for software implementation and avoid overdesigning the system. In essence, this relaxation expands the design space and we further develop an off-line on-line minimum effort algorithm for quick exploration of the enlarged design space at early design stages. This is the first step toward our goal of bridging the gap between real-time analysis and embedded software implementation for rapid and economic multimedia system design. It is our belief that the proposed method has great potential in reducing system resource while meeting performance requirements. The experimental results confirm this as we achieve significant saving in system's energy consumption to provide a statistical completion ratio guarantee (i.e., the expected number of completions over a large number of iterations is greater than a given value).",
        "acm_key": "1275991",
        "bib_stats": {
            "cites": 56,
            "dl": 2,
            "dl_52": 54,
            "dl_6": 7
        },
        "key": "1275991",
        "text": "Chin-Hsien Wu , Tei-Wei Kuo , Li Ping Chang, An efficient B-tree layer implementation for flash-memory storage systems, ACM Transactions on Embedded Computing Systems (TECS), v.6 n.3, p.19-es, July 2007"
    },
    "1276203": {
        "abstract": "We study congestion games where players aim to access a set of resources. Each player has a set of possible strategies and each resource has a function associating the latency it incurs to the players using it. Players are non-cooperative and each wishes to follow strategies that minimize her own latency with no regard to the global optimum. Previous work has studied the impact of this selfish behavior to system performance. In this paper, we study the question of how much the performance can be improved if players are forced to pay taxes for using resources. Our objective is to extend the original game so that selfish behavior does not deteriorate performance. We consider atomic congestion games with linear latency functions and present both negative and positive results. Our negative results show that optimal system performance cannot be achieved even in very simple games. On the positive side, we show that there are ways to assign taxes that can improve the performance of linear congestion games by forcing players to follow strategies where the total latency suffered is within a factor of 2 of the minimum possible; this result is shown to be tight. Furthermore, even in cases where in the absence of taxes the system behavior may be very poor, we show that the total disutility of players (latency plus taxes) is not much larger than the optimal total latency. Besides existential results, we show how to compute taxes in time polynomial in the size of the game by solving convex quadratic programs. Similar questions have been extensively studied in the model of non-atomic congestion games. To the best of our knowledge, this is the first study of the efficiency of taxes in atomic congestion games.",
        "acm_key": "1276203",
        "bib_stats": {
            "cites": 19
        },
        "bibtex": "\r\n@inproceedings{Ben-Aroya:2006:CAF:1276191.1276203,\n author = {Ben-Aroya, Avraham and Toledo, Sivan},\n title = {Competitive Analysis of Flash-memory Algorithms},\n booktitle = {Proceedings of the 14th Conference on Annual European Symposium - Volume 14},\n series = {ESA'06},\n year = {2006},\n isbn = {3-540-38875-3},\n location = {Zurich, Switzerland},\n pages = {100--111},\n numpages = {12},\n url = {http://dx.doi.org/10.1007/11841036_12},\n doi = {10.1007/11841036_12},\n acmid = {1276203},\n publisher = {Springer-Verlag},\n address = {London, UK, UK},\n} \r\n",
        "key": "1276203",
        "pub_year": "2006",
        "text": "Avraham Ben-Aroya , Sivan Toledo, Competitive analysis of flash-memory algorithms, Proceedings of the 14th conference on Annual European Symposium, p.100-111, September 11-13, 2006, Zurich, Switzerland  \u00a0[doi>"
    },
    "1278533": {
        "abstract": "Despite the impressive progress of logic synthesis in the past decade, finding the best architecture for a given circuit still remains an open problem and largely unsolved. In most of the arithmetic circuits the outcome of the synthesis tools depends on the input description of the circuit. In other words, logic synthesis optimisations hardly change the architecture of the given circuit. However, once the input description belongs to the right architecture, logic synthesis does an excellent job in optimising the circuit locally. This is the reason why designers still rely on well studied architectures. The main difficulty in finding the suitable architecture for an arithmetic circuit is the high fan-in dependencies between inputs and outputs (i.e., each output bit depends on a large portion of input bits). Hence, imposing hierarchy and structure is the key to find the best architecture. Although factorisation is one potential solution for this problem, the computational complexity of Boolean factorisation and poor performance of algebraic factorisation make this solution impractical in most cases of interest. In this paper we present a novel approach which progressively decomposes the input circuits into building blocks and constructs hierarchy among these blocks. We show that our approach optimises the critical path delay by 15--30% at the cost of marginal or no area penalty. In some cases, it even improves the area. Qualitatively we observed that our approach found the best known architecture for some circuits without any a priori knowledge about the functionality of the circuit.",
        "acm_key": "1278533",
        "bib_stats": {
            "cites": 64,
            "dl": 1,
            "dl_52": 101,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chang:2007:EEF:1278480.1278533,\n author = {Chang, Yuan-Hao and Hsieh, Jen-Wei and Kuo, Tei-Wei},\n title = {Endurance Enhancement of Flash-memory Storage Systems: An Efficient Static Wear Leveling Design},\n booktitle = {Proceedings of the 44th Annual Design Automation Conference},\n series = {DAC '07},\n year = {2007},\n isbn = {978-1-59593-627-1},\n location = {San Diego, California},\n pages = {212--217},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1278480.1278533},\n doi = {10.1145/1278480.1278533},\n acmid = {1278533},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, flash memory, reliability, wear leveling},\n} \r\n",
        "key": "1278533",
        "pub_year": "2007",
        "text": "Yuan-Hao Chang , Jen-Wei Hsieh , Tei-Wei Kuo, Endurance enhancement of flash-memory storage systems: an efficient static wear leveling design, Proceedings of the 44th annual Design Automation Conference, June 04-08, 2007, San Diego, California"
    },
    "1289953": {
        "abstract": "The increasing levels of system integration in Multi-Processor System-on-Chips (MPSoCs) emphasize the need for new design flows for efficient mapping of multi-task applications onto hardware platforms. Even though data-flow graphs are often used for pure data-streaming, many realistic applications can only be specified as conditional task graphs (CTG). The problem of allocating and scheduling conditional task graphs on processors in a distributed real-time system is NP-hard. The first contribution of this paper is a complete stochastic allocation and scheduling framework, where an MPSoC virtual platform is used to accurately derive input parameters, validate abstract models of system components and assess constraint satisfaction and objective function optimization. The optimizer implements an efficient and exact approach to allocation and scheduling based on problem decomposition. The original contributions of the approach appear both in the allocation and in the scheduling part of the optimizer. For the first, we propose an exact analytic formulation of the stochastic objective function based on the task graph analysis, while for the scheduling part we extend the timetable constraint for conditional activities. The second contribution of this paper is the introduction of a software library and API for the deployment of conditional task graph applications onto Multi-Processor System-on-Chips. With our library support, programmers can quickly develop multi-task applications which will run on a multi-core architecture and can easily apply the optimal solution found by our optimizer. The proposed programming support manages OS-level issues, such as task allocation and scheduling, as well as task-level issues, like inter-task communication and synchronization.",
        "acm_key": "1289953",
        "bib_stats": {
            "cites": 26,
            "dl": 927,
            "dl_52": 24,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Kang:2007:9OI:1289927.1289953,\n author = {Kang, Dongwon and Jung, Dawoon and Kang, Jeong-Uk and Kim, Jin-Soo},\n title = {{\\$\\mu\\$}treee: An Ordered Index Structure for NAND Flash Memory},\n booktitle = {Proceedings of the 7th ACM \\&Amp; IEEE International Conference on Embedded Software},\n series = {EMSOFT '07},\n year = {2007},\n isbn = {978-1-59593-825-1},\n location = {Salzburg, Austria},\n pages = {144--153},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1289927.1289953},\n doi = {10.1145/1289927.1289953},\n acmid = {1289953},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {B+-tree, NAND flash, index structure},\n} \r\n",
        "key": "1289953",
        "pub_year": "2007",
        "text": "Dongwon Kang , Dawoon Jung , Jeong-Uk Kang , Jin-Soo Kim, \u03bc-tree: an ordered index structure for NAND flash memory, Proceedings of the 7th ACM & IEEE international conference on Embedded software, September 30-October 03, 2007, Salzburg, Austria"
    },
    "1289954": {
        "abstract": "The increasing levels of system integration in Multi-Processor System-on-Chips (MPSoCs) emphasize the need for new design flows for efficient mapping of multi-task applications onto hardware platforms. Even though data-flow graphs are often used for pure data-streaming, many realistic applications can only be specified as conditional task graphs (CTG). The problem of allocating and scheduling conditional task graphs on processors in a distributed real-time system is NP-hard. The first contribution of this paper is a complete stochastic allocation and scheduling framework, where an MPSoC virtual platform is used to accurately derive input parameters, validate abstract models of system components and assess constraint satisfaction and objective function optimization. The optimizer implements an efficient and exact approach to allocation and scheduling based on problem decomposition. The original contributions of the approach appear both in the allocation and in the scheduling part of the optimizer. For the first, we propose an exact analytic formulation of the stochastic objective function based on the task graph analysis, while for the scheduling part we extend the timetable constraint for conditional activities. The second contribution of this paper is the introduction of a software library and API for the deployment of conditional task graph applications onto Multi-Processor System-on-Chips. With our library support, programmers can quickly develop multi-task applications which will run on a multi-core architecture and can easily apply the optimal solution found by our optimizer. The proposed programming support manages OS-level issues, such as task allocation and scheduling, as well as task-level issues, like inter-task communication and synchronization.",
        "acm_key": "1289954",
        "bib_stats": {
            "cites": 3,
            "dl": 660,
            "dl_52": 4,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Baek:2007:UIP:1289927.1289954,\n author = {Baek, Seungjae and Ahn, Seongjun and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},\n title = {Uniformity Improving Page Allocation for Flash Memory File Systems},\n booktitle = {Proceedings of the 7th ACM \\&Amp; IEEE International Conference on Embedded Software},\n series = {EMSOFT '07},\n year = {2007},\n isbn = {978-1-59593-825-1},\n location = {Salzburg, Austria},\n pages = {154--163},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1289927.1289954},\n doi = {10.1145/1289927.1289954},\n acmid = {1289954},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {file system, flash memory, implementation, modeling, performance evaluation, uniformity},\n} \r\n",
        "key": "1289954",
        "pub_year": "2007",
        "text": "Seungjae Baek , Seongjun Ahn , Jongmoo Choi , Donghee Lee , Sam H. Noh, Uniformity improving page allocation for flash memory file systems, Proceedings of the 7th ACM & IEEE international conference on Embedded software, September 30-October 03, 2007, Salzburg, Austria"
    },
    "1289955": {
        "abstract": "The increasing levels of system integration in Multi-Processor System-on-Chips (MPSoCs) emphasize the need for new design flows for efficient mapping of multi-task applications onto hardware platforms. Even though data-flow graphs are often used for pure data-streaming, many realistic applications can only be specified as conditional task graphs (CTG). The problem of allocating and scheduling conditional task graphs on processors in a distributed real-time system is NP-hard. The first contribution of this paper is a complete stochastic allocation and scheduling framework, where an MPSoC virtual platform is used to accurately derive input parameters, validate abstract models of system components and assess constraint satisfaction and objective function optimization. The optimizer implements an efficient and exact approach to allocation and scheduling based on problem decomposition. The original contributions of the approach appear both in the allocation and in the scheduling part of the optimizer. For the first, we propose an exact analytic formulation of the stochastic objective function based on the task graph analysis, while for the scheduling part we extend the timetable constraint for conditional activities. The second contribution of this paper is the introduction of a software library and API for the deployment of conditional task graph applications onto Multi-Processor System-on-Chips. With our library support, programmers can quickly develop multi-task applications which will run on a multi-core architecture and can easily apply the optimal solution found by our optimizer. The proposed programming support manages OS-level issues, such as task allocation and scheduling, as well as task-level issues, like inter-task communication and synchronization.",
        "acm_key": "1289955",
        "bib_stats": {
            "cites": 16,
            "dl": 1,
            "dl_52": 35,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Doh:2007:ENR:1289927.1289955,\n author = {Doh, In Hwan and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},\n title = {Exploiting Non-volatile RAM to Enhance Flash File System Performance},\n booktitle = {Proceedings of the 7th ACM \\&Amp; IEEE International Conference on Embedded Software},\n series = {EMSOFT '07},\n year = {2007},\n isbn = {978-1-59593-825-1},\n location = {Salzburg, Austria},\n pages = {164--173},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1289927.1289955},\n doi = {10.1145/1289927.1289955},\n acmid = {1289955},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {experimental evaluation, file system, flash memory, metadata, non-volatile RAM},\n} \r\n",
        "key": "1289955",
        "pub_year": "2007",
        "text": "In Hwan Doh , Jongmoo Choi , Donghee Lee , Sam H. Noh, Exploiting non-volatile RAM to enhance flash file system performance, Proceedings of the 7th ACM & IEEE international conference on Embedded software, September 30-October 03, 2007, Salzburg, Austria"
    },
    "1289956": {
        "abstract": "The increasing levels of system integration in Multi-Processor System-on-Chips (MPSoCs) emphasize the need for new design flows for efficient mapping of multi-task applications onto hardware platforms. Even though data-flow graphs are often used for pure data-streaming, many realistic applications can only be specified as conditional task graphs (CTG). The problem of allocating and scheduling conditional task graphs on processors in a distributed real-time system is NP-hard. The first contribution of this paper is a complete stochastic allocation and scheduling framework, where an MPSoC virtual platform is used to accurately derive input parameters, validate abstract models of system components and assess constraint satisfaction and objective function optimization. The optimizer implements an efficient and exact approach to allocation and scheduling based on problem decomposition. The original contributions of the approach appear both in the allocation and in the scheduling part of the optimizer. For the first, we propose an exact analytic formulation of the stochastic objective function based on the task graph analysis, while for the scheduling part we extend the timetable constraint for conditional activities. The second contribution of this paper is the introduction of a software library and API for the deployment of conditional task graph applications onto Multi-Processor System-on-Chips. With our library support, programmers can quickly develop multi-task applications which will run on a multi-core architecture and can easily apply the optimal solution found by our optimizer. The proposed programming support manages OS-level issues, such as task allocation and scheduling, as well as task-level issues, like inter-task communication and synchronization.",
        "acm_key": "1289956",
        "bib_stats": {
            "cites": 11,
            "dl": 754,
            "dl_52": 8,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Lee:2007:BRS:1289927.1289956,\n author = {Lee, Jongmin and Kim, Sunghoon and Kwon, Hunki and Hyun, Choulseung and Ahn, Seongjun and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},\n title = {Block Recycling Schemes and Their Cost-based Optimization in Nand Flash Memory Based Storage System},\n booktitle = {Proceedings of the 7th ACM \\&Amp; IEEE International Conference on Embedded Software},\n series = {EMSOFT '07},\n year = {2007},\n isbn = {978-1-59593-825-1},\n location = {Salzburg, Austria},\n pages = {174--182},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/1289927.1289956},\n doi = {10.1145/1289927.1289956},\n acmid = {1289956},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL (flash-memory translation layer), flash memory based storage system, merge operation, migration operation},\n} \r\n",
        "key": "1289956",
        "pub_year": "2007",
        "text": "Jongmin Lee , Sunghoon Kim , Hunki Kwon , Choulseung Hyun , Seongjun Ahn , Jongmoo Choi , Donghee Lee , Sam H. Noh, Block recycling schemes and their cost-based optimization in nand flash memory based storage system, Proceedings of the 7th ACM & IEEE international conference on Embedded software, September 30-October 03, 2007, Salzburg, Austria  \u00a0[doi>"
    },
    "1290585": {
        "abstract": "Volume 53 Issue 12, December, 2007 \r\n\r\n",
        "acm_key": "1290585",
        "bib_stats": {
            "cites": 12
        },
        "bibtex": "\r\n@article{Chung:2007:SFD:1290538.1290585,\n author = {Chung, Tae-Sun and Park, Hyung-Seok},\n title = {STAFF: A Flash Driver Algorithm Minimizing Block Erasures},\n journal = {J. Syst. Archit.},\n issue_date = {December, 2007},\n volume = {53},\n number = {12},\n month = dec,\n year = {2007},\n issn = {1383-7621},\n pages = {889--901},\n numpages = {13},\n url = {http://dx.doi.org/10.1016/j.sysarc.2007.02.005},\n doi = {10.1016/j.sysarc.2007.02.005},\n acmid = {1290585},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Embedded system, File system, Flash memory},\n} \r\n",
        "key": "1290585",
        "pub_year": "2007",
        "text": "Tae-Sun Chung , Hyung-Seok Park, STAFF: A flash driver algorithm minimizing block erasures, Journal of Systems Architecture: the EUROMICRO Journal, v.53 n.12, p.889-901, December, 2007  \u00a0[doi>"
    },
    "1298457": {
        "abstract": "This paper presents three policies for effectively utilizing TCP offload network interfaces that support connection handoff. These policies allow connection handoff to reduce the computation and memory bandwidth requirements for packet processing on the host processor without causing the resource constraints on the network interface to limit overall system performance. First, prioritizing packet processing on the network interface ensures that its TCP processing does not harm performance of the connections on the host operating system. Second, dynamically adapting the number of connections on the network interface to the current load avoids overloading the network interface. Third, the operating system can predict connection lifetimes to select long-lived connections for handoff to better utilize the network interface. The use of the first two policies improves web server throughput by 12--31% over the baseline throughput achieved without offload. The third policy helps improve performance when the network interface can only handle a small number of connections at a time. Furthermore, by using a faster offload processor, offloading can improve server throughput by 33--72%.",
        "acm_key": "1298457",
        "bib_stats": {
            "cites": 25,
            "dl": 350,
            "dl_52": 24,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Nightingale:2006:RS:1298455.1298457,\n author = {Nightingale, Edmund B. and Veeraraghavan, Kaushik and Chen, Peter M. and Flinn, Jason},\n title = {Rethink the Sync},\n booktitle = {Proceedings of the 7th Symposium on Operating Systems Design and Implementation},\n series = {OSDI '06},\n year = {2006},\n isbn = {1-931971-47-1},\n location = {Seattle, Washington},\n pages = {1--14},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=1298455.1298457},\n acmid = {1298457},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1298457",
        "pub_year": "2006",
        "text": "Edmund B. Nightingale , Kaushik Veeraraghavan , Peter M. Chen , Jason Flinn, Rethink the sync, Proceedings of the 7th symposium on Operating systems design and implementation, November 06-08, 2006, Seattle, Washington"
    },
    "1314319": {
        "abstract": "This paper introduces a new framework for confidentiality preserving rank-ordered search and retrieval over large document collections. The proposed framework not only protects document/query confidentiality against an outside intruder, but also prevents an untrusted data center from learning information about the query and the document collection. We present practical techniques for proper integration of relevance scoring methods and cryptographic techniques, such as order preserving encryption, to protect data collections and indices and provide efficient and accurate search capabilities to securely rank-order documents in response to a query. Experimental results on the W3C collection show that these techniques have comparable performance to conventional search systems designed for non-encrypted data in terms of search accuracy. The proposed methods thus form the first steps to bring together advanced information retrieval and secure search capabilities for a wide range of applications including managing data in government and business operations, enabling scholarly study of sensitive data, and facilitating the document discovery process in litigation.",
        "acm_key": "1314319",
        "bib_stats": {
            "cites": 3,
            "dl": 341,
            "dl_52": 9,
            "dl_6": 2
        },
        "key": "1314319",
        "text": "Neerja Bhatnagar , Ethan L. Miller, Designing a secure reliable file system for sensor networks, Proceedings of the 2007 ACM workshop on Storage security and survivability, October 29-29, 2007, Alexandria, Virginia, USA"
    },
    "1356908": {
        "abstract": "Horizontally Partitioned Caches (HPCs) are a promising architectural feature to reduce the energy consumption of the memory subsystem. However, the energy reduction obtained using HPC architectures is very sensitive to the HPC parameters. Therefore it is very important to explore the HPC design space and carefully choose the HPC parameters that result in minimum energy consumption for the application. However, since in HPC architectures, the compiler has a significant impact on the energy consumption of the memory subsystem, it is extremely important to include compiler while deciding the HPC design parameters. While there has been no previous approaches to HPC design exploration, existing cache design space exploration methodologies do not include the compiler effects during DSE. In this paper, we present a Compiler-in-the-Loop (CIL) Design Space Exploration (DSE) methodology to explore and decide the HPC design parameters. Our experimental results on HP iPAQ h4300-like memory subsystem running benchmarks from the MiBench suite demonstrate that CIL DSE can discover HPC configurations with up to 80% lesser energy consumption than the HPC configuration in the iPAQ. In contrast, tradition simulation-only exploration can discover HPC design parameters that result in only 57% memory subsystem energy reduction. Finally our hybrid CIL DSE heuristic saves 67% of the exploration time as compared to the exhaustive exploration, while providing maximum possible energy savings on our set of benchmarks.",
        "acm_key": "1356908",
        "bib_stats": {
            "cites": 23,
            "dl": 697,
            "dl_52": 8,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chang:2008:HSD:1356802.1356908,\n author = {Chang, Li-Pin},\n title = {Hybrid Solid-state Disks: Combining Heterogeneous NAND Flash in Large SSDs},\n booktitle = {Proceedings of the 2008 Asia and South Pacific Design Automation Conference},\n series = {ASP-DAC '08},\n year = {2008},\n isbn = {978-1-4244-1922-7},\n location = {Seoul, Korea},\n pages = {428--433},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1356802.1356908},\n acmid = {1356908},\n publisher = {IEEE Computer Society Press},\n address = {Los Alamitos, CA, USA},\n} \r\n",
        "key": "1356908",
        "pub_year": "2008",
        "text": "Li-Pin Chang, Hybrid solid-state disks: combining heterogeneous NAND flash in large SSDs, Proceedings of the 2008 Asia and South Pacific Design Automation Conference, January 21-24, 2008, Seoul, Korea"
    },
    "1363198": {
        "abstract": "Chip multiprocessors (CMPs) present new opportunities for improving database performance on large queries. Because CMPs often share execution, cache, or bandwidth resources among many hardware threads, implementing parallel database operators that efficiently share these resources is key to maximizing performance. A crucial aspect of this parallelism is managing concurrent, shared input and output to the parallel operators. In this paper we propose and evaluate a parallel buffer that enables intra-operator parallelism on CMPs by avoiding contention between hardware threads that need to concurrently read or write to the same buffer. The parallel buffer handles parallel input and output coordination as well as load balancing so individual operators do not need to reimplement that functionality.",
        "acm_key": "1363198",
        "bib_stats": {
            "cites": 32,
            "dl": 857,
            "dl_52": 22,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Graefe:2007:FRT:1363189.1363198,\n author = {Graefe, Goetz},\n title = {The Five-minute Rule Twenty Years Later, and How Flash Memory Changes the Rules},\n booktitle = {Proceedings of the 3rd International Workshop on Data Management on New Hardware},\n series = {DaMoN '07},\n year = {2007},\n isbn = {978-1-59593-772-8},\n location = {Beijing, China},\n pages = {6:1--6:9},\n articleno = {6},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/1363189.1363198},\n doi = {10.1145/1363189.1363198},\n acmid = {1363198},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1363198",
        "pub_year": "2007",
        "text": "Goetz Graefe, The five-minute rule twenty years later, and how flash memory changes the rules, Proceedings of the 3rd international workshop on Data management on new hardware, June 15-15, 2007, Beijing, China  \u00a0[doi>"
    },
    "1364796": {
        "abstract": "The wireless sensor network community approached networking abstractions as an open question, allowing answers to emerge with time and experience. The Trickle algorithm has become a basic mechanism used in numerous protocols and systems. Trickle brings nodes to eventual consistency quickly and efficiently while remaining remarkably robust to variations in network density, topology, and dynamics. Instead of flooding a network with packets, Trickle uses a \"polite gossip\" policy to control send rates so each node hears just enough packets to stay consistent. This simple mechanism enables Trickle to scale to 1000-fold changes in network density, reach consistency in seconds, and require only a few bytes of state yet impose a maintenance cost of a few sends an hour. Originally designed for disseminating new code, experience has shown Trickle to have much broader applicability, including route maintenance and neighbor discovery. This paper provides an overview of the research challenges wireless sensor networks face, describes the Trickle algorithm, and outlines several ways it is used today.",
        "acm_key": "1364796",
        "bib_stats": {
            "cites": 42,
            "dl": 11,
            "dl_52": 232,
            "dl_6": 21
        },
        "bibtex": "\r\n@article{Leventhal:2008:FSM:1364782.1364796,\n author = {Leventhal, Adam},\n title = {Flash Storage Memory},\n journal = {Commun. ACM},\n issue_date = {July 2008},\n volume = {51},\n number = {7},\n month = jul,\n year = {2008},\n issn = {0001-0782},\n pages = {47--51},\n numpages = {5},\n url = {http://doi.acm.org/10.1145/1364782.1364796},\n doi = {10.1145/1364782.1364796},\n acmid = {1364796},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1364796",
        "pub_year": "2008",
        "text": "Adam Leventhal, Flash storage memory, Communications of the ACM, v.51 n.7, July 2008  \u00a0[doi>"
    },
    "1364829": {
        "abstract": "In this paper we develop a recovery conscious framework for multi-core architectures and a suite of techniques for improving the resiliency and recovery efficiency of highly concurrent embedded storage software systems. Our techniques aim at providing continuous availability and performance during recovery while minimizing the time to recovery and the need for rearchitecting the system (legacy code). The main contributions of our recovery conscious framework include (1) a task-level recovery model, which consists of mechanisms for classifying storage tasks into recovery groups and dividing the overall system resources into recovery-oriented resource pools, and (2) the development of recovery-conscious scheduling, which enforces some serializability of failure-dependent tasks in order to reduce the ripple effect of software failure and improve the availability of the system. We present three alternative recovery-conscious scheduling algorithms; each represents one way to trade-off between recovery time and system performance. We have implemented and evaluated these recovery-conscious scheduling algorithms on a real industry-standard storage system. Our experimental evaluation results show that the proposed recovery conscious scheduling algorithms are non-intrusive and can significantly improve (throughput by 16.3% and response time by 22.9%) the performance of the system during failure recovery.",
        "acm_key": "1364829",
        "bib_stats": {
            "cites": 126,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2008:BBM:1364813.1364829,\n author = {Kim, Hyojun and Ahn, Seongjun},\n title = {BPLRU: A Buffer Management Scheme for Improving Random Writes in Flash Storage},\n booktitle = {Proceedings of the 6th USENIX Conference on File and Storage Technologies},\n series = {FAST'08},\n year = {2008},\n location = {San Jose, California},\n pages = {16:1--16:14},\n articleno = {16},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=1364813.1364829},\n acmid = {1364829},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1364829",
        "pub_year": "2008",
        "text": "Hyojun Kim , Seongjun Ahn, BPLRU: a buffer management scheme for improving random writes in flash storage, Proceedings of the 6th USENIX Conference on File and Storage Technologies, p.1-14, February 26-29, 2008, San Jose, California"
    },
    "136555": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "136555",
        "bib_stats": {
            "cites": 32,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Moss:1992:WPO:136554.136555,\n author = {Moss, J. Eliot B.},\n title = {Working with Persistent Objects: To Swizzle or Not to Swizzle},\n journal = {IEEE Trans. Softw. Eng.},\n issue_date = {August 1992},\n volume = {18},\n number = {8},\n month = aug,\n year = {1992},\n issn = {0098-5589},\n pages = {657--673},\n numpages = {17},\n url = {http://dx.doi.org/10.1109/32.153378},\n doi = {10.1109/32.153378},\n acmid = {136555},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {Mneme persistent object store, data structures, database objects, database programming language implementations, direct memory pointers, manipulation, memory resident data, object identifiers, object-oriented databases, persistent object stores, persistent objects, pointer swizzling, quantitative data, software engineering},\n} \r\n",
        "key": "136555",
        "pub_year": "1992",
        "text": "J. Eliot B. Moss, Working with Persistent Objects: To Swizzle or Not to Swizzle, IEEE Transactions on Software Engineering, v.18 n.8, p.657-673, August 1992  \u00a0[doi>"
    },
    "1367830": {
        "abstract": "In this article we survey 415 file system and storage benchmarks from 106 recent papers. We found that most popular benchmarks are flawed and many research papers do not provide a clear indication of true performance. We provide guidelines that we hope will improve future performance evaluations. To show how some widely used benchmarks can conceal or overemphasize overheads, we conducted a set of experiments. As a specific example, slowing down read operations on ext2 by a factor of 32 resulted in only a 2--5&percnt; wall-clock slowdown in a popular compile benchmark. Finally, we discuss future work to improve file system and storage benchmarking.",
        "acm_key": "1367830",
        "bib_stats": {
            "cites": 24,
            "dl": 1,
            "dl_52": 38,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Matthews:2008:ITM:1367829.1367830,\n author = {Matthews, Jeanna and Trika, Sanjeev and Hensgen, Debra and Coulson, Rick and Grimsrud, Knut},\n title = {Intel\\&Reg; Turbo Memory: Nonvolatile Disk Caches in the Storage Hierarchy of Mainstream Computer Systems},\n journal = {Trans. Storage},\n issue_date = {May 2008},\n volume = {4},\n number = {2},\n month = may,\n year = {2008},\n issn = {1553-3077},\n pages = {4:1--4:24},\n articleno = {4},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/1367829.1367830},\n doi = {10.1145/1367829.1367830},\n acmid = {1367830},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND, Nonvolatile memory, disk cache, solid-state disk, write-back},\n} \r\n",
        "key": "1367830",
        "pub_year": "2008",
        "text": "Jeanna Matthews , Sanjeev Trika , Debra Hensgen , Rick Coulson , Knut Grimsrud, Intel\u00ae Turbo Memory: Nonvolatile disk caches in the storage hierarchy of mainstream computer systems, ACM Transactions on Storage (TOS), v.4 n.2, p.1-24, May 2008  \u00a0[doi>"
    },
    "1376723": {
        "abstract": "In this paper, we present Spade - the System S declarative stream processing engine. System S is a large-scale, distributed data stream processing middleware under development at IBM T. J. Watson Research Center. As a front-end for rapid application development for System S, Spade provides (1) an intermediate language for flexible composition of parallel and distributed data-flow graphs, (2) a toolkit of type-generic, built-in stream processing operators, that support scalar as well as vectorized processing and can seamlessly inter-operate with user-defined operators, and (3) a rich set of stream adapters to ingest/publish data from/to outside sources. More importantly, Spade automatically brings performance optimization and scalability to System S applications. To that end, Spade employs a code generation framework to create highly-optimized applications that run natively on the Stream Processing Core (SPC), the execution and communication substrate of System S, and take full advantage of other System S services. Spade allows developers to construct their applications with fine granular stream operators without worrying about the performance implications that might exist, even in a distributed system. Spade's optimizing compiler automatically maps applications into appropriately sized execution units in order to minimize communication overhead, while at the same time exploiting available parallelism. By virtue of the scalability of the System S runtime and Spade's effective code generation and optimization, we can scale applications to a large number of nodes. Currently, we can run Spade jobs on \u2248 500 processors within more than 100 physical nodes in a tightly connected cluster environment. Spade has been in use at IBM Research to create real-world streaming applications, ranging from monitoring financial market feeds to radio telescopes to semiconductor fabrication lines.",
        "acm_key": "1376723",
        "bib_stats": {
            "cites": 92,
            "dl": 3,
            "dl_52": 159,
            "dl_6": 17
        },
        "bibtex": "\r\n@inproceedings{Lee:2008:CFM:1376616.1376723,\n author = {Lee, Sang-Won and Moon, Bongki and Park, Chanik and Kim, Jae-Myung and Kim, Sang-Woo},\n title = {A Case for Flash Memory Ssd in Enterprise Database Applications},\n booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '08},\n year = {2008},\n isbn = {978-1-60558-102-6},\n location = {Vancouver, Canada},\n pages = {1075--1086},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1376616.1376723},\n doi = {10.1145/1376616.1376723},\n acmid = {1376723},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-memory database server, flash-memory ssd},\n} \r\n",
        "key": "1376723",
        "pub_year": "2008",
        "text": "Sang-Won Lee , Bongki Moon , Chanik Park , Jae-Myung Kim , Sang-Woo Kim, A case for flash memory ssd in enterprise database applications, Proceedings of the 2008 ACM SIGMOD international conference on Management of data, June 09-12, 2008, Vancouver, Canada  \u00a0[doi>"
    },
    "1376806": {
        "abstract": "Out-of-memory errors are a serious source of unreliability in most embedded systems. Applications run out of main memory because of the frequent difficulty of estimating the memory requirement before deployment, either because it depends on input data, or because certain language features prevent estimation. The typical lack of disks and virtual memory in embedded systems has a serious consequence when an out-of-memory error occurs. Without swap space, the system crashes if its memory footprint exceeds the available memory by even 1 byte. This work improves reliability for multitasking embedded systems by proposing MTSS, a multitask stack sharing technique. If a task attempts to overflow the bounds of its allocated stack space, MTSS grows its stack into the stack memory space allocated for other tasks. This technique can avoid the out-of-memory error if the extra space recovered is sufficient to complete execution. Experiments show that MTSS is able to recover an average of 54&percnt; of the stack space allocated to the overflowing task in the free space of other tasks. In addition, unlike conventional systems, MTSS detects memory overflows, allowing the possibility of remedial action or a graceful exit if the recovered space is not enough. Alternatively, MTSS can be used for decreasing the required physical memory of an embedded system by reducing the initial memory allocated to each of the tasks and recovering the deficit by sharing stack with other tasks. The overheads of MTSS are low: the runtime and energy overheads are 3.1&percnt; and 3.2&percnt;, on average. These are tolerable given that reliability is the most important concern in virtually all systems, ahead of other concerns, such as runtime and energy.",
        "acm_key": "1376806",
        "bib_stats": {
            "cites": 58,
            "dl": 2,
            "dl_52": 115,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Park:2008:RFA:1376804.1376806,\n author = {Park, Chanik and Cheon, Wonmoon and Kang, Jeonguk and Roh, Kangho and Cho, Wonhee and Kim, Jin-Soo},\n title = {A Reconfigurable FTL (Flash Translation Layer) Architecture for NAND Flash-based Applications},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {July 2008},\n volume = {7},\n number = {4},\n month = aug,\n year = {2008},\n issn = {1539-9087},\n pages = {38:1--38:23},\n articleno = {38},\n numpages = {23},\n url = {http://doi.acm.org/10.1145/1376804.1376806},\n doi = {10.1145/1376804.1376806},\n acmid = {1376806},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, Flash memory, performance analysis, reconfigurable architecture},\n} \r\n",
        "key": "1376806",
        "pub_year": "2008",
        "text": "Chanik Park , Wonmoon Cheon , Jeonguk Kang , Kangho Roh , Wonhee Cho , Jin-Soo Kim, A reconfigurable FTL (flash translation layer) architecture for NAND flash-based applications, ACM Transactions on Embedded Computing Systems (TECS), v.7 n.4, p.1-23, July 2008  \u00a0[doi>"
    },
    "1382149": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1382149",
        "bib_stats": {
            "cites": 66,
            "dl": 1,
            "dl_52": 34,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Kgil:2008:INF:1381306.1382149,\n author = {Kgil, Taeho and Roberts, David and Mudge, Trevor},\n title = {Improving NAND Flash Based Disk Caches},\n booktitle = {Proceedings of the 35th Annual International Symposium on Computer Architecture},\n series = {ISCA '08},\n year = {2008},\n isbn = {978-0-7695-3174-8},\n pages = {327--338},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/ISCA.2008.32},\n doi = {10.1109/ISCA.2008.32},\n acmid = {1382149},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {NAND Flash, Flash, Flash memory controller, disk cache, data center},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1382149&parent_id=1381306&expformat=bibtex&CFID=982041987&CFTOKEN=91171879\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1382149\">\r\n@article{Kgil:2008:INF:1394608.1382149,\n author = {Kgil, Taeho and Roberts, David and Mudge, Trevor},\n title = {Improving NAND Flash Based Disk Caches},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2008},\n volume = {36},\n number = {3},\n month = jun,\n year = {2008},\n issn = {0163-5964},\n pages = {327--338},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1394608.1382149},\n doi = {10.1145/1394608.1382149},\n acmid = {1382149},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND Flash, Flash, Flash memory controller, disk cache, data center},\n} \r\n",
        "key": "1382149",
        "pub_year": "2008",
        "text": "Taeho Kgil , David Roberts , Trevor Mudge, Improving NAND Flash Based Disk Caches, ACM SIGARCH Computer Architecture News, v.36 n.3, p.327-338, June 2008"
    },
    "1391610": {
        "abstract": "Recently, processor power density has been increasing at an alarming rate resulting in high on-chip temperature. Higher temperature increases current leakage and causes poor reliability. In this paper, we propose a Predictive Dynamic Thermal Management (PDTM) based on Application-based Thermal Model (ABTM) and Core-based Thermal Model (CBTM) in the multicore systems. ABTM predicts future temperature based on the application specific thermal behavior, while CBTM estimates core temperature pattern by steady state temperature and workload. The accuracy of our prediction model is 1.6% error in average compared to the model in HybDTM [8], which has at most 5% error. Based on predicted temperature from ABTM and CBTM, the proposed PDTM can maintain the system temperature below a desired level by moving the running application from the possible overheated core to the future coolest core (migration) and reducing the processor resources (priority scheduling) within multicore systems. PDTM enables the exploration of the tradeoff between throughput and fairness in temperature-constrained multicore systems. We implement PDTM on Intel's Quad-Core system with a specific device driver to access Digital Thermal Sensor (DTS). Compared against Linux standard scheduler, PDTM can decrease average temperature about 10%, and peak temperature by 5\u00b0C with negligible impact of performance under 1%, while running single SPEC2006 benchmark. Moreover, our PDTM outperforms HRTM [10] in reducing average temperature by about 7% and peak temperature by about 3\u00b0C with performance overhead by 0.15% when running single benchmark.",
        "acm_key": "1391610",
        "bib_stats": {
            "cites": 69,
            "dl": 712,
            "dl_52": 21,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Dong:2008:CME:1391469.1391610,\n author = {Dong, Xiangyu and Wu, Xiaoxia and Sun, Guangyu and Xie, Yuan and Li, Helen and Chen, Yiran},\n title = {Circuit and Microarchitecture Evaluation of 3D Stacking Magnetic RAM (MRAM) As a Universal Memory Replacement},\n booktitle = {Proceedings of the 45th Annual Design Automation Conference},\n series = {DAC '08},\n year = {2008},\n isbn = {978-1-60558-115-6},\n location = {Anaheim, California},\n pages = {554--559},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1391469.1391610},\n doi = {10.1145/1391469.1391610},\n acmid = {1391610},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3D stacking, MRAM},\n} \r\n",
        "key": "1391610",
        "pub_year": "2008",
        "text": "Xiangyu Dong , Xiaoxia Wu , Guangyu Sun , Yuan Xie , Helen Li , Yiran Chen, Circuit and microarchitecture evaluation of 3D stacking magnetic RAM (MRAM) as a universal memory replacement, Proceedings of the 45th annual Design Automation Conference, June 08-13, 2008, Anaheim, California  \u00a0[doi>"
    },
    "1404019": {
        "abstract": "Despite a low occurrence rate, silent data corruption represents a growing concern for storage systems designers. Throughout the storage hierarchy, from the file system down to the disk drives, various solutions exist to avoid, detect, and correct silent data corruption. Undetected errors during the completion of WRITEs may cause silent data corruption. A portion of the WRITE errors may be detected and corrected successfully by verifying the data written on the disk with the data in the disk cache. Write verification traditionally is scheduled immediately after a WRITE completion (Read After Write - RAW) which is unattractive, because it degrades user performance. To reduce the performance penalty associated with RAW, we propose to retain the written content in the disk cache and verify it once the disk drive becomes idle. Although attractive, this approach (called IRAW - Idle Read After Write) contends for resources, i.e., cache and idle time, with user traffic and other background activities. In this paper, we present a trace-driven evaluation of IRAW and show its feasibility. Our analysis indicates that idleness is present in disk drives and can be utilized for WRITE verification with minimal effect on user performance. IRAW benefits significantly if some amount of cache, i.e., 1 or 2 MB, is dedicated to retain the unverified WRITEs. If the cache is shared with the user requests then a cache retention policy that places both READs and WRITEs upon completion at the most recently used cache segment, yields best IRAW performance without effecting user READs cache hit ratio and overall user performance.",
        "acm_key": "1404019",
        "bib_stats": {
            "cites": 263,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Agrawal:2008:DTS:1404014.1404019,\n author = {Agrawal, Nitin and Prabhakaran, Vijayan and Wobber, Ted and Davis, John D. and Manasse, Mark and Panigrahy, Rina},\n title = {Design Tradeoffs for SSD Performance},\n booktitle = {USENIX 2008 Annual Technical Conference},\n series = {ATC'08},\n year = {2008},\n location = {Boston, Massachusetts},\n pages = {57--70},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=1404014.1404019},\n acmid = {1404019},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1404019",
        "pub_year": "2008",
        "text": "Nitin Agrawal , Vijayan Prabhakaran , Ted Wobber , John D. Davis , Mark Manasse , Rina Panigrahy, Design tradeoffs for SSD performance, USENIX 2008 Annual Technical Conference on Annual Technical Conference, p.57-70, June 22-27, 2008, Boston, Massachusetts"
    },
    "1404889": {
        "abstract": "Periodic broadcast protocols enable efficient streaming of highly popular media files to large numbers of concurrent clients. Most previous periodic broadcast protocols, however, assume that all clients can receive at the same rate, and also assume that reception bandwidth is not time-varying. In this article, we first develop a new periodic broadcast protocol, Optimized Heterogeneous Periodic Broadcast (OHPB), that can be optimized for a given population of clients with heterogeneous reception bandwidths and quality-of-service requirements. The OHPB protocol utilizes an optimized segment size progression determined by solving a linear optimization model that takes as input the client population characteristics and an objective function such as mean client startup delay. We then develop a generalization of the OHPB linear optimization model that allows optimal server bandwidth allocation among multiple concurrent OHPB broadcasts, wherein each media file and its clients may have different characteristics. Finally, we propose complementary client protocols employing work-ahead buffering of data during playback, so as to enable more uniform playback quality when the reception bandwidth is time-varying.",
        "acm_key": "1404889",
        "bib_stats": {
            "cites": 7,
            "dl": 533,
            "dl_52": 19,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Jung:2008:SSL:1404880.1404889,\n author = {Jung, Dawoon and Kim, Jaegeuk and Kim, Jin-Soo and Lee, Joonwon},\n title = {ScaleFFS: A Scalable Log-structured Flash File System for Mobile Multimedia Systems},\n journal = {ACM Trans. Multimedia Comput. Commun. Appl.},\n issue_date = {October 2008},\n volume = {5},\n number = {1},\n month = oct,\n year = {2008},\n issn = {1551-6857},\n pages = {9:1--9:18},\n articleno = {9},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/1404880.1404889},\n doi = {10.1145/1404880.1404889},\n acmid = {1404889},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {File system, NAND, flash memory, storage system},\n} \r\n",
        "key": "1404889",
        "pub_year": "2008",
        "text": "Dawoon Jung , Jaegeuk Kim , Jin-Soo Kim , Joonwon Lee, ScaleFFS: A scalable log-structured flash file system for mobile multimedia systems, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP), v.5 n.1, p.1-18, October 2008"
    },
    "1413261": {
        "abstract": "Volume 6 Issue 4, July/August 2008 \r\n\r\n",
        "acm_key": "1413261",
        "bib_stats": {
            "cites": 33,
            "dl": 11,
            "dl_52": 713,
            "dl_6": 104
        },
        "bibtex": "\r\n@article{Gray:2008:FDO:1413254.1413261,\n author = {Gray, Jim and Fitzgerald, Bob},\n title = {Flash Disk Opportunity for Server Applications},\n journal = {Queue},\n issue_date = {July/August 2008},\n volume = {6},\n number = {4},\n month = jul,\n year = {2008},\n issn = {1542-7730},\n pages = {18--23},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1413254.1413261},\n doi = {10.1145/1413254.1413261},\n acmid = {1413261},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1413261",
        "pub_year": "2008",
        "text": "Jim Gray , Bob Fitzgerald, Flash Disk Opportunity for Server Applications, Queue, v.6 n.4, July/August 2008  \u00a0[doi>"
    },
    "1418664": {
        "abstract": "Due to the complexity of economic system, the interactive effects of economic variables or factors on Chinese foreign trade make the prediction of China's foreign trade extremely difficult. To analyze the relationship between economic variables and foreign trade, this study proposes a novel nonlinear ensemble learning methodology hybridizing nonlinear econometric model and artificial neural networks (ANN) for Chinese foreign trade prediction. In this proposed learning approach, an important econometrical model, the co-integration-based error correction vector auto-regression (EC-VAR) model is first used to capture the impacts of the economic variables on Chinese foreign trade from a multivariate analysis perspective. Then an ANN-based EC-VAR model is used to capture the nonlinear patterns hidden between foreign trade and economic factors. Subsequently, for introducing the effects of irregular events on foreign trade, the text mining and expert's judgmental adjustments are also incorporated into the nonlinear ANN-based EC-VAR model. Finally, all economic variables, the outputs of linear and nonlinear EC-VAR models and judgmental adjustment model are used as another neural network inputs for ensemble prediction purpose. For illustration, the proposed ensemble learning methodology integrating econometric techniques and artificial intelligence (AI) methods is applied to Chinese export trade prediction problem.",
        "acm_key": "1418664",
        "bib_stats": {
            "cites": 1
        },
        "key": "1418664",
        "text": "Ohhoon Kwon , Jaewoo Lee , Kern Koh, EF-Greedy: A Novel Garbage Collection Policy for Flash Memory Based Embedded Systems, Proceedings of the 7th international conference on Computational Science, Part IV: ICCS 2007, p.913-920, May 27-30, 2007, Beijing, China"
    },
    "1434382": {
        "abstract": "The novel and generic meta-interface (MI) paradigm proposed in this paper automates the generation of customized telemedicine software systems (CTSS), directly from the customized application interface (CAI) specifications given. The MI paradigm was tested and verified in the TCM (Traditional Chinese Medicine) telemedicine environment of Nong's Company Limited of the PuraPharm Group, a local Hong Kong TCM telemedicine developer that funded this research. The CAI specification is made by \"gluing\" together icons selected from the enterprise icon library (IL). The CTSS generation, in effect, extracts the corresponding portion of the subsumption hierarchy from the master ontology, an enterprise standard. Since CTSS prototypes were verified in the Nong's TCM telemedicine environment, they were built with the Nong's master TCM ontology core (onto-core) as the basis and reference. In this light, the ontological extraction for a CAI specification is turned into the local TCM onto-core for the CTSS prototype. The enterprise TCM onto-core, the local TCM onto-core, and the icons in IL all contain formal knowledge derived from the enterprise TCM vocabulary. In Nong's case the enterprise vocabulary is the standard of CTSS terminology, gathered from TCM classics, treatises, and case histories by domain experts with consensus certification. Using CAI as the single input to automate the whole CTSS generation process would eliminate MSPM (multi-site project management) problems. Since the Nong's MC (mobile clinics) based telemedicine system is web-based and pervasive, the CTSS is also referred to as the Nong's web-based telemedicine systems (WTS).",
        "acm_key": "1434382",
        "bib_stats": {
            "cites": 0
        },
        "key": "1434382",
        "text": "Adam Ji Dou , Vana Kalogeraki, RG-EDF: An I/O Scheduling Policy for Flash Equipped Sensor Devices, Proceedings of the 6th IFIP WG 10.2 international workshop on Software Technologies for Embedded and Ubiquitous Systems, October 01-03, 2008, Anacarpi, Capri Island, Italy"
    },
    "1450063": {
        "abstract": "A Biomedical Sensor Network (BSN) is a small-size sensor network for medical applications, that may contain tens of sensor nodes. In this paper, we present a formal model for BSNs using timed automata, where the sensor nodes communicate using the Chipcon CC2420 transceiver (developed by Texas Instruments) according to the IEEE 802.15.4 standard. Based on the model, we have used UPPAAL to validate and tune the temporal configuration parameters of a BSN in order to meet desired QoS requirements on network connectivity, packet delivery ratio and end-to-end delay. The network studied allows dynamic reconfigurations of the network topology due to the temporally switching of sensor nodes to power-down mode for energy-saving or their physical movements. Both the simulator and model-checker of UPPAAL are used to analyze the average-case and worst-case behaviors. To enhance the scalability of the tool, we have implemented a (new text-based) version of the UPPAAL simulator optimized for exploring symbolic traces of automata containing large data structures such as matrices. Our experiments show that even though the main feature of the tool is model checking, it is also a promising and competitive tool for efficient simulation and parameter tuning. The simulator scales well; it can easily handle up to 50 nodes in our experiments. The model checker installed on a notebook can also deal with networks with 5 up to 16 nodes within minutes depending on the properties checked; these are BSNs of reasonable size for medical applications. Finally, to study the accuracy of our model and analysis results, we compare simulation results by UPPAAL for two medical scenarios with traditional simulation techniques using OMNeT++, one of the most used simulation tools for wireless sensor networks. The comparison shows that our analysis results coincide with the simulation results by OMNeT++ in most cases although there are some differences caused the simplified wireless channel model in UPPAAL.",
        "acm_key": "1450063",
        "bib_stats": {
            "cites": 20,
            "dl": 666,
            "dl_52": 41,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Lee:2008:9MF:1450058.1450063,\n author = {Lee, Yong-Goo and Jung, Dawoon and Kang, Dongwon and Kim, Jin-Soo},\n title = {{\\$\\mu\\$}FTLL:: A Memory-efficient Flash Translation Layer Supporting Multiple Mapping Granularities},\n booktitle = {Proceedings of the 8th ACM International Conference on Embedded Software},\n series = {EMSOFT '08},\n year = {2008},\n isbn = {978-1-60558-468-3},\n location = {Atlanta, GA, USA},\n pages = {21--30},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1450058.1450063},\n doi = {10.1145/1450058.1450063},\n acmid = {1450063},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, address translation, flash translation layer (FTL)},\n} \r\n",
        "key": "1450063",
        "pub_year": "2008",
        "text": "Yong-Goo Lee , Dawoon Jung , Dongwon Kang , Jin-Soo Kim, \u03bc-FTL:: a memory-efficient flash translation layer supporting multiple mapping granularities, Proceedings of the 8th ACM international conference on Embedded software, October 19-24, 2008, Atlanta, GA, USA  \u00a0[doi>"
    },
    "1450064": {
        "abstract": "A Biomedical Sensor Network (BSN) is a small-size sensor network for medical applications, that may contain tens of sensor nodes. In this paper, we present a formal model for BSNs using timed automata, where the sensor nodes communicate using the Chipcon CC2420 transceiver (developed by Texas Instruments) according to the IEEE 802.15.4 standard. Based on the model, we have used UPPAAL to validate and tune the temporal configuration parameters of a BSN in order to meet desired QoS requirements on network connectivity, packet delivery ratio and end-to-end delay. The network studied allows dynamic reconfigurations of the network topology due to the temporally switching of sensor nodes to power-down mode for energy-saving or their physical movements. Both the simulator and model-checker of UPPAAL are used to analyze the average-case and worst-case behaviors. To enhance the scalability of the tool, we have implemented a (new text-based) version of the UPPAAL simulator optimized for exploring symbolic traces of automata containing large data structures such as matrices. Our experiments show that even though the main feature of the tool is model checking, it is also a promising and competitive tool for efficient simulation and parameter tuning. The simulator scales well; it can easily handle up to 50 nodes in our experiments. The model checker installed on a notebook can also deal with networks with 5 up to 16 nodes within minutes depending on the properties checked; these are BSNs of reasonable size for medical applications. Finally, to study the accuracy of our model and analysis results, we compare simulation results by UPPAAL for two medical scenarios with traditional simulation techniques using OMNeT++, one of the most used simulation tools for wireless sensor networks. The comparison shows that our analysis results coincide with the simulation results by OMNeT++ in most cases although there are some differences caused the simplified wireless channel model in UPPAAL.",
        "acm_key": "1450064",
        "bib_stats": {
            "cites": 23,
            "dl": 1,
            "dl_52": 53,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Kim:2008:PNF:1450058.1450064,\n author = {Kim, Jin Kyu and Lee, Hyung Gyu and Choi, Shinho and Bahng, Kyoung Il},\n title = {A PRAM and NAND Flash Hybrid Architecture for High-performance Embedded Storage Subsystems},\n booktitle = {Proceedings of the 8th ACM International Conference on Embedded Software},\n series = {EMSOFT '08},\n year = {2008},\n isbn = {978-1-60558-468-3},\n location = {Atlanta, GA, USA},\n pages = {31--40},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1450058.1450064},\n doi = {10.1145/1450058.1450064},\n acmid = {1450064},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {file system, flash translation layer (ftl), nand flash, pram},\n} \r\n",
        "key": "1450064",
        "pub_year": "2008",
        "text": "Jin Kyu Kim , Hyung Gyu Lee , Shinho Choi , Kyoung Il Bahng, A PRAM and NAND flash hybrid architecture for high-performance embedded storage subsystems, Proceedings of the 8th ACM international conference on Embedded software, October 19-24, 2008, Atlanta, GA, USA"
    },
    "1450066": {
        "abstract": "A Biomedical Sensor Network (BSN) is a small-size sensor network for medical applications, that may contain tens of sensor nodes. In this paper, we present a formal model for BSNs using timed automata, where the sensor nodes communicate using the Chipcon CC2420 transceiver (developed by Texas Instruments) according to the IEEE 802.15.4 standard. Based on the model, we have used UPPAAL to validate and tune the temporal configuration parameters of a BSN in order to meet desired QoS requirements on network connectivity, packet delivery ratio and end-to-end delay. The network studied allows dynamic reconfigurations of the network topology due to the temporally switching of sensor nodes to power-down mode for energy-saving or their physical movements. Both the simulator and model-checker of UPPAAL are used to analyze the average-case and worst-case behaviors. To enhance the scalability of the tool, we have implemented a (new text-based) version of the UPPAAL simulator optimized for exploring symbolic traces of automata containing large data structures such as matrices. Our experiments show that even though the main feature of the tool is model checking, it is also a promising and competitive tool for efficient simulation and parameter tuning. The simulator scales well; it can easily handle up to 50 nodes in our experiments. The model checker installed on a notebook can also deal with networks with 5 up to 16 nodes within minutes depending on the properties checked; these are BSNs of reasonable size for medical applications. Finally, to study the accuracy of our model and analysis results, we compare simulation results by UPPAAL for two medical scenarios with traditional simulation techniques using OMNeT++, one of the most used simulation tools for wireless sensor networks. The comparison shows that our analysis results coincide with the simulation results by OMNeT++ in most cases although there are some differences caused the simplified wireless channel model in UPPAAL.",
        "acm_key": "1450066",
        "bib_stats": {
            "cites": 7,
            "dl": 519,
            "dl_52": 13,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Sun:2008:LLT:1450058.1450066,\n author = {Sun, Kyoungmoon and Baek, Seungjae and Choi, Jongmoo and Lee, Donghee and Noh, Sam H. and Min, Sang Lyul},\n title = {LTFTL: Lightweight Time-shift Flash Translation Layer for Flash Memory Based Embedded Storage},\n booktitle = {Proceedings of the 8th ACM International Conference on Embedded Software},\n series = {EMSOFT '08},\n year = {2008},\n isbn = {978-1-60558-468-3},\n location = {Atlanta, GA, USA},\n pages = {51--58},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/1450058.1450066},\n doi = {10.1145/1450058.1450066},\n acmid = {1450066},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {fault tolerance, file system, flash memory, ftl (flash translation layer), reliability, time-shift},\n} \r\n",
        "key": "1450066",
        "pub_year": "2008",
        "text": "Kyoungmoon Sun , Seungjae Baek , Jongmoo Choi , Donghee Lee , Sam H. Noh , Sang Lyul Min, LTFTL: lightweight time-shift flash translation layer for flash memory based embedded storage, Proceedings of the 8th ACM international conference on Embedded software, October 19-24, 2008, Atlanta, GA, USA"
    },
    "1453783": {
        "abstract": "Self-managing storage systems have recently received attention from the research community due to their promised ability of continuously adapting to best reflect high-level system goal specifications. However, this eventuality is currently being met by both conceptual and practical challenges that threaten to slow down the pace of innovation. We argue that two fundamental directions will help evolve the state of self-managing storage systems: (i) a standardized development environment for self-management extensions that also addresses ease of deployment, and (ii) a theoretical framework for reasoning about behavioral properties of individual and collective self-management extensions. We propose Active Block Layer Extensions (ABLE), an operating system infrastructure that aids the development and manages the deployed instances of self-management extensions within the storage stack. ABLE develops a theory behind block layer extensions that helps address key questions about overall storage stack behavior, data consistency, and reliability. We exemplify specific storage self-management solutions that can be built as stackable extensions using ABLE. Our initial experience with ABLE and few block layer extensions that we have been building, leads to believe that the ABLE infrastructure can substantially simplify the development and deployment of robust, self-managing, storage systems.",
        "acm_key": "1453783",
        "bib_stats": {
            "cites": 77,
            "dl": 1,
            "dl_52": 135,
            "dl_6": 13
        },
        "bibtex": "\r\n@article{Lee:2008:LLS:1453775.1453783,\n author = {Lee, Sungjin and Shin, Dongkun and Kim, Young-Jin and Kim, Jihong},\n title = {LAST: Locality-aware Sector Translation for NAND Flash Memory-based Storage Systems},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {October 2008},\n volume = {42},\n number = {6},\n month = oct,\n year = {2008},\n issn = {0163-5980},\n pages = {36--42},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/1453775.1453783},\n doi = {10.1145/1453775.1453783},\n acmid = {1453783},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1453783",
        "pub_year": "2008",
        "text": "Sungjin Lee , Dongkun Shin , Young-Jin Kim , Jihong Kim, LAST: locality-aware sector translation for NAND flash memory-based storage systems, ACM SIGOPS Operating Systems Review, v.42 n.6, October 2008"
    },
    "1453913": {
        "abstract": "Content Management Systems (CMS) store enterprise data such as insurance claims, insurance policies, legal documents, patent applications, or archival data like in the case of digital libraries. Search over content allows for information retrieval, but does not provide users with great insight into the data. A more analytical view is needed through analysis, aggregations, groupings, trends, pivot tables or charts, and so on. Multidimensional Content eXploration (MCX) is about effectively analyzing and exploring large amounts of content by combining keyword search with OLAP-style aggregation, navigation, and reporting. We focus on unstructured data or generally speaking documents or content with limited metadata, as it is typically encountered in CMS. We formally present how CMS content and metadata should be organized in a well-defined multidimensional structure, so that sophisticated queries can be expressed and evaluated. The CMS metadata provide traditional OLAP static dimensions that are combined with dynamic dimensions discovered from the analyzed keyword search result, as well as measures for document scores based on the link structure between the documents. In addition, we provide means for multidimensional content exploration through traditional OLAP rollupdrilldown operations on the static and dynamic dimensions, solutions for multi-cube analysis and dynamic navigation of the content. We present our prototype, called DBPubs, which stores research publications as documents that can be searched and -most importantly-- analyzed, and explored. Finally, we present experimental results of the efficiency and effectiveness of our approach.",
        "acm_key": "1453913",
        "bib_stats": {
            "cites": 49,
            "dl": 770,
            "dl_52": 26,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Koltsidas:2008:FUS:1453856.1453913,\n author = {Koltsidas, Ioannis and Viglas, Stratis D.},\n title = {Flashing Up the Storage Layer},\n journal = {Proc. VLDB Endow.},\n issue_date = {August 2008},\n volume = {1},\n number = {1},\n month = aug,\n year = {2008},\n issn = {2150-8097},\n pages = {514--525},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/1453856.1453913},\n doi = {10.14778/1453856.1453913},\n acmid = {1453913},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1453913",
        "pub_year": "2008",
        "text": "Ioannis Koltsidas , Stratis D. Viglas, Flashing up the storage layer, Proceedings of the VLDB Endowment, v.1 n.1, August 2008"
    },
    "1453961": {
        "abstract": "Content Management Systems (CMS) store enterprise data such as insurance claims, insurance policies, legal documents, patent applications, or archival data like in the case of digital libraries. Search over content allows for information retrieval, but does not provide users with great insight into the data. A more analytical view is needed through analysis, aggregations, groupings, trends, pivot tables or charts, and so on. Multidimensional Content eXploration (MCX) is about effectively analyzing and exploring large amounts of content by combining keyword search with OLAP-style aggregation, navigation, and reporting. We focus on unstructured data or generally speaking documents or content with limited metadata, as it is typically encountered in CMS. We formally present how CMS content and metadata should be organized in a well-defined multidimensional structure, so that sophisticated queries can be expressed and evaluated. The CMS metadata provide traditional OLAP static dimensions that are combined with dynamic dimensions discovered from the analyzed keyword search result, as well as measures for document scores based on the link structure between the documents. In addition, we provide means for multidimensional content exploration through traditional OLAP rollupdrilldown operations on the static and dynamic dimensions, solutions for multi-cube analysis and dynamic navigation of the content. We present our prototype, called DBPubs, which stores research publications as documents that can be searched and -most importantly-- analyzed, and explored. Finally, we present experimental results of the efficiency and effectiveness of our approach.",
        "acm_key": "1453961",
        "bib_stats": {
            "cites": 27,
            "dl": 378,
            "dl_52": 3,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Nath:2008:OMV:1453856.1453961,\n author = {Nath, Suman and Gibbons, Phillip B.},\n title = {Online Maintenance of Very Large Random Samples on Flash Storage},\n journal = {Proc. VLDB Endow.},\n issue_date = {August 2008},\n volume = {1},\n number = {1},\n month = aug,\n year = {2008},\n issn = {2150-8097},\n pages = {970--983},\n numpages = {14},\n url = {http://dx.doi.org/10.14778/1453856.1453961},\n doi = {10.14778/1453856.1453961},\n acmid = {1453961},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1453961",
        "pub_year": "2008",
        "text": "Suman Nath , Phillip B. Gibbons, Online maintenance of very large random samples on flash storage, Proceedings of the VLDB Endowment, v.1 n.1, August 2008  \u00a0[doi>"
    },
    "1455235": {
        "abstract": "With increasing design complexity, the gap from ESL (Electronic System Level) design to RTL synthesis becomes more and more crucial to many industrial projects. Although several behavioral synthesis tools exist to automatically generate synthesizable RTL code from C/C++/SystemC-based input descriptions and software generation for embedded processors is automated as well, an efficient ESL synthesis methodology combining both is still missing. This article presents SystemCoDesigner, a novel SystemC-based ESL tool to automatically optimize a hardware/software SoC (System on Chip) implementation with respect to several objectives. Starting from a SystemC behavioral model, SystemCoDesigner automatically extracts the mathematical model, performs a behavioral synthesis step, and explores the multiobjective design space using state-of-the-art multiobjective optimization algorithms. During design space exploration, a single design point is evaluated by simulating highly accurate performance models, which are automatically generated from the SystemC behavioral model and the behavioral synthesis results. Moreover, SystemCoDesigner permits the automatic generation of bit streams for FPGA targets from any previously optimized SoC implementation. Thus SystemCoDesigner is the first fully automated ESL synthesis tool providing a correct-by-construction generation of hardware/software SoC implementations. As a case study, a model of a Motion-JPEG decoder was automatically optimized and implemented using SystemCoDesigner. Several synthesized SoC variants based on this model show different tradeoffs between required hardware costs and achieved system throughput, ranging from software-only solutions to pure hardware implementations that reach real-time performance for QCIF streams on a 50MHz FPGA.",
        "acm_key": "1455235",
        "bib_stats": {
            "cites": 2,
            "dl": 607,
            "dl_52": 6,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Wu:2009:EIR:1455229.1455235,\n author = {Wu, Chin-Hsien},\n title = {An Energy-efficient I/O Request Mechanism for Multi-bank Flash-memory Storage Systems},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {January 2009},\n volume = {14},\n number = {1},\n month = jan,\n year = {2009},\n issn = {1084-4309},\n pages = {6:1--6:25},\n articleno = {6},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/1455229.1455235},\n doi = {10.1145/1455229.1455235},\n acmid = {1455235},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash Memory, embedded systems, energy-efficient, programmed I/O, storage systems},\n} \r\n",
        "key": "1455235",
        "pub_year": "2009",
        "text": "Chin-Hsien Wu, An energy-efficient I/O request mechanism for multi-bank flash-memory storage systems, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.14 n.1, p.1-25, January 2009"
    },
    "1462883": {
        "abstract": "Introducing an application into a data center involves complex interrelated decision-making for the placement of data (where to store it) and resiliency in the event of a disaster (how to protect it). Automated planners can assist administrators in making intelligent placement and resiliency decisions when provisioning for both new and existing applications. Such planners take advantage of recent improvements in storage resource management and provide guided recommendations based on monitored performance data and storage models. For example, the IBM Provisioning Planner provides intelligent decision-making for the steps involved in allocating and assigning storage for workloads. It involves planning for the number, size, and location of volumes on the basis of workload performance requirements and hierarchical constraints, planning for the appropriate number of paths, and enabling access to volumes using zoning, masking, and mapping. The IBM Disaster Recovery (DR) Planner enables administrators to choose and deploy appropriate replication technologies spanning servers, the network, and storage volumes to provide resiliency to the provisioned application. The DR Planner begins with a list of high-level application DR requirements and creates an integrated plan that is optimized on criteria such as cost and solution homogeneity. The Planner deploys the selected plan using orchestrators that are responsible for failover and failback.",
        "acm_key": "1462883",
        "bib_stats": {
            "cites": 54
        },
        "bibtex": "\r\n@article{Freitas:2008:SMN:1462871.1462883,\n author = {Freitas, R. F. and Wilcke, W. W.},\n title = {Storage-class Memory: The Next Storage System Technology},\n journal = {IBM J. Res. Dev.},\n issue_date = {July 2008},\n volume = {52},\n number = {4},\n month = jul,\n year = {2008},\n issn = {0018-8646},\n pages = {439--447},\n numpages = {9},\n url = {http://dx.doi.org/10.1147/rd.524.0439},\n doi = {10.1147/rd.524.0439},\n acmid = {1462883},\n publisher = {IBM Corp.},\n address = {Riverton, NJ, USA},\n} \r\n",
        "key": "1462883",
        "pub_year": "2008",
        "text": "R. F. Freitas , W. W. Wilcke, Storage-class memory: the next storage system technology, IBM Journal of Research and Development, v.52 n.4, p.439-447, July 2008  \u00a0[doi>"
    },
    "1462884": {
        "abstract": "Introducing an application into a data center involves complex interrelated decision-making for the placement of data (where to store it) and resiliency in the event of a disaster (how to protect it). Automated planners can assist administrators in making intelligent placement and resiliency decisions when provisioning for both new and existing applications. Such planners take advantage of recent improvements in storage resource management and provide guided recommendations based on monitored performance data and storage models. For example, the IBM Provisioning Planner provides intelligent decision-making for the steps involved in allocating and assigning storage for workloads. It involves planning for the number, size, and location of volumes on the basis of workload performance requirements and hierarchical constraints, planning for the appropriate number of paths, and enabling access to volumes using zoning, masking, and mapping. The IBM Disaster Recovery (DR) Planner enables administrators to choose and deploy appropriate replication technologies spanning servers, the network, and storage volumes to provide resiliency to the provisioned application. The DR Planner begins with a list of high-level application DR requirements and creates an integrated plan that is optimized on criteria such as cost and solution homogeneity. The Planner deploys the selected plan using orchestrators that are responsible for failover and failback.",
        "acm_key": "1462884",
        "bib_stats": {
            "cites": 41
        },
        "bibtex": "\r\n@article{Burr:2008:OCD:1462871.1462884,\n author = {Burr, G. W. and Kurdi, B. N. and Scott, J. C. and Lam, C. H. and Gopalakrishnan, K. and Shenoy, R. S.},\n title = {Overview of Candidate Device Technologies for Storage-class Memory},\n journal = {IBM J. Res. Dev.},\n issue_date = {July 2008},\n volume = {52},\n number = {4},\n month = jul,\n year = {2008},\n issn = {0018-8646},\n pages = {449--464},\n numpages = {16},\n url = {http://dx.doi.org/10.1147/rd.524.0449},\n doi = {10.1147/rd.524.0449},\n acmid = {1462884},\n publisher = {IBM Corp.},\n address = {Riverton, NJ, USA},\n} \r\n",
        "key": "1462884",
        "pub_year": "2008",
        "text": "G. W. Burr , B. N. Kurdi , J. C. Scott , C. H. Lam , K. Gopalakrishnan , R. S. Shenoy, Overview of candidate device technologies for storage-class memory, IBM Journal of Research and Development, v.52 n.4, p.449-464, July 2008  \u00a0[doi>"
    },
    "1462885": {
        "abstract": "Introducing an application into a data center involves complex interrelated decision-making for the placement of data (where to store it) and resiliency in the event of a disaster (how to protect it). Automated planners can assist administrators in making intelligent placement and resiliency decisions when provisioning for both new and existing applications. Such planners take advantage of recent improvements in storage resource management and provide guided recommendations based on monitored performance data and storage models. For example, the IBM Provisioning Planner provides intelligent decision-making for the steps involved in allocating and assigning storage for workloads. It involves planning for the number, size, and location of volumes on the basis of workload performance requirements and hierarchical constraints, planning for the appropriate number of paths, and enabling access to volumes using zoning, masking, and mapping. The IBM Disaster Recovery (DR) Planner enables administrators to choose and deploy appropriate replication technologies spanning servers, the network, and storage volumes to provide resiliency to the provisioned application. The DR Planner begins with a list of high-level application DR requirements and creates an integrated plan that is optimized on criteria such as cost and solution homogeneity. The Planner deploys the selected plan using orchestrators that are responsible for failover and failback.",
        "acm_key": "1462885",
        "bib_stats": {
            "cites": 108
        },
        "bibtex": "\r\n@article{Raoux:2008:PRA:1462871.1462885,\n author = {Raoux, S. and Burr, G. W. and Breitwisch, M. J. and Rettner, C. T. and Chen, Y.-C. and Shelby, R. M. and Salinga, M. and Krebs, D. and Chen, S.-H. and Lung, H.-L. and Lam, C. H.},\n title = {Phase-change Random Access Memory: A Scalable Technology},\n journal = {IBM J. Res. Dev.},\n issue_date = {July 2008},\n volume = {52},\n number = {4},\n month = jul,\n year = {2008},\n issn = {0018-8646},\n pages = {465--479},\n numpages = {15},\n url = {http://dx.doi.org/10.1147/rd.524.0465},\n doi = {10.1147/rd.524.0465},\n acmid = {1462885},\n publisher = {IBM Corp.},\n address = {Riverton, NJ, USA},\n} \r\n",
        "key": "1462885",
        "pub_year": "2008",
        "text": "S. Raoux , G. W. Burr , M. J. Breitwisch , C. T. Rettner , Y.-C. Chen , R. M. Shelby , M. Salinga , D. Krebs , S.-H. Chen , H.-L. Lung , C. H. Lam, Phase-change random access memory: a scalable technology, IBM Journal of Research and Development, v.52 n.4, p.465-479, July 2008  \u00a0[doi>"
    },
    "1480443": {
        "abstract": "IEEE-1394 is widely adopted in various commercial products for computing, communication, and entertainment. Although many services with Quality-of-Service (QoS) supports are now available in systems over IEEE-1394, little work is done for QoS-based resource allocation. In this article, we aim at the design of a bandwidth reservation mechanism and its policy for isochronous requests, such as those from cameras. We then address the QoS support issue for asynchronous requests, such as those from disks, and an analytic framework for probability-based QoS guarantees. This work is concluded by the proposing of a topology configuration algorithm for IEEE-1394 devices. The capability of the proposed methodology and the analytic framework are evaluated by a series of experiments over a Linux-based system prototype.",
        "acm_key": "1480443",
        "bib_stats": {
            "cites": 20,
            "dl": 1,
            "dl_52": 40,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Choi:2009:JFT:1480439.1480443,\n author = {Choi, Hyun Jin and Lim, Seung-Ho and Park, Kyu Ho},\n title = {JFTL: A Flash Translation Layer Based on a Journal Remapping for Flash Memory},\n journal = {Trans. Storage},\n issue_date = {January 2009},\n volume = {4},\n number = {4},\n month = feb,\n year = {2009},\n issn = {1553-3077},\n pages = {14:1--14:22},\n articleno = {14},\n numpages = {22},\n url = {http://doi.acm.org/10.1145/1480439.1480443},\n doi = {10.1145/1480439.1480443},\n acmid = {1480443},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, flash translation layer, garbage detection, journal remapping, journaling file system},\n} \r\n",
        "key": "1480443",
        "pub_year": "2009",
        "text": "Hyun Jin Choi , Seung-Ho Lim , Kyu Ho Park, JFTL: A flash translation layer based on a journal remapping for flash memory, ACM Transactions on Storage (TOS), v.4 n.4, p.1-22, January 2009"
    },
    "1508270": {
        "abstract": "Recent technological advances in the development of flash-memory based devices have consolidated their leadership position as the preferred storage media in the embedded systems market and opened new vistas for deployment in enterprise-scale storage systems. Unlike hard disks, flash devices are free from any mechanical moving parts, have no seek or rotational delays and consume lower power. However, the internal idiosyncrasies of flash technology make its performance highly dependent on workload characteristics. The poor performance of random writes has been a cause of major concern, which needs to be addressed to better utilize the potential of flash in enterprise-scale environments. We examine one of the important causes of this poor performance: the design of the Flash Translation Layer (FTL), which performs the virtual-to-physical address translations and hides the erase-before-write characteristics of flash. We propose a complete paradigm shift in the design of the core FTL engine from the existing techniques with our Demand-based Flash Translation Layer (DFTL), which selectively caches page-level address mappings. We develop a flash simulation framework called FlashSim. Our experimental evaluation with realistic enterprise-scale workloads endorses the utility of DFTL in enterprise-scale storage systems by demonstrating: (i) improved performance, (ii) reduced garbage collection overhead and (iii) better overload behavior compared to state-of-the-art FTL schemes. For example, a predominantly random-write dominant I/O trace from an OLTP application running at a large financial institution shows a 78% improvement in average response time (due to a 3-fold reduction in operations of the garbage collector), compared to a state-of-the-art FTL scheme. Even for the well-known read-dominant TPC-H benchmark, for which DFTL introduces additional overheads, we improve system response time by 56%.",
        "acm_key": "1508270",
        "bib_stats": {
            "cites": 84,
            "dl": 1,
            "dl_52": 78,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Caulfield:2009:GUF:2528521.1508270,\n author = {Caulfield, Adrian M. and Grupp, Laura M. and Swanson, Steven},\n title = {Gordon: Using Flash Memory to Build Fast, Power-efficient Clusters for Data-intensive Applications},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2009},\n volume = {37},\n number = {1},\n month = mar,\n year = {2009},\n issn = {0163-5964},\n pages = {217--228},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2528521.1508270},\n doi = {10.1145/2528521.1508270},\n acmid = {1508270},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cluster architecture, data centric, flash memory, solid-state storage},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1508270&parent_id=2528521&expformat=bibtex&CFID=982048266&CFTOKEN=55115126\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1508270\">\r\n@article{Caulfield:2009:GUF:1508284.1508270,\n author = {Caulfield, Adrian M. and Grupp, Laura M. and Swanson, Steven},\n title = {Gordon: Using Flash Memory to Build Fast, Power-efficient Clusters for Data-intensive Applications},\n journal = {SIGPLAN Not.},\n issue_date = {March 2009},\n volume = {44},\n number = {3},\n month = mar,\n year = {2009},\n issn = {0362-1340},\n pages = {217--228},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1508284.1508270},\n doi = {10.1145/1508284.1508270},\n acmid = {1508270},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cluster architecture, data centric, flash memory, solid-state storage},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1508270&parent_id=1508284&expformat=bibtex&CFID=982048266&CFTOKEN=55115126\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1508270\">\r\n@inproceedings{Caulfield:2009:GUF:1508244.1508270,\n author = {Caulfield, Adrian M. and Grupp, Laura M. and Swanson, Steven},\n title = {Gordon: Using Flash Memory to Build Fast, Power-efficient Clusters for Data-intensive Applications},\n booktitle = {Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XIV},\n year = {2009},\n isbn = {978-1-60558-406-5},\n location = {Washington, DC, USA},\n pages = {217--228},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1508244.1508270},\n doi = {10.1145/1508244.1508270},\n acmid = {1508270},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cluster architecture, data centric, flash memory, solid-state storage},\n} \r\n",
        "key": "1508270",
        "pub_year": "2009",
        "text": "Adrian M. Caulfield , Laura M. Grupp , Steven Swanson, Gordon: using flash memory to build fast, power-efficient clusters for data-intensive applications, ACM SIGPLAN Notices, v.44 n.3, March 2009"
    },
    "1508271": {
        "abstract": "Recent technological advances in the development of flash-memory based devices have consolidated their leadership position as the preferred storage media in the embedded systems market and opened new vistas for deployment in enterprise-scale storage systems. Unlike hard disks, flash devices are free from any mechanical moving parts, have no seek or rotational delays and consume lower power. However, the internal idiosyncrasies of flash technology make its performance highly dependent on workload characteristics. The poor performance of random writes has been a cause of major concern, which needs to be addressed to better utilize the potential of flash in enterprise-scale environments. We examine one of the important causes of this poor performance: the design of the Flash Translation Layer (FTL), which performs the virtual-to-physical address translations and hides the erase-before-write characteristics of flash. We propose a complete paradigm shift in the design of the core FTL engine from the existing techniques with our Demand-based Flash Translation Layer (DFTL), which selectively caches page-level address mappings. We develop a flash simulation framework called FlashSim. Our experimental evaluation with realistic enterprise-scale workloads endorses the utility of DFTL in enterprise-scale storage systems by demonstrating: (i) improved performance, (ii) reduced garbage collection overhead and (iii) better overload behavior compared to state-of-the-art FTL schemes. For example, a predominantly random-write dominant I/O trace from an OLTP application running at a large financial institution shows a 78% improvement in average response time (due to a 3-fold reduction in operations of the garbage collector), compared to a state-of-the-art FTL scheme. Even for the well-known read-dominant TPC-H benchmark, for which DFTL introduces additional overheads, we improve system response time by 56%.",
        "acm_key": "1508271",
        "bib_stats": {
            "cites": 172,
            "dl": 2,
            "dl_52": 232,
            "dl_6": 23
        },
        "bibtex": "\r\n@inproceedings{Gupta:2009:DFT:1508244.1508271,\n author = {Gupta, Aayush and Kim, Youngjae and Urgaonkar, Bhuvan},\n title = {DFTL: A Flash Translation Layer Employing Demand-based Selective Caching of Page-level Address Mappings},\n booktitle = {Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XIV},\n year = {2009},\n isbn = {978-1-60558-406-5},\n location = {Washington, DC, USA},\n pages = {229--240},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1508244.1508271},\n doi = {10.1145/1508244.1508271},\n acmid = {1508271},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash management, flash translation layer, storage system},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1508271&parent_id=1508244&expformat=bibtex&CFID=982048329&CFTOKEN=63585931\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1508271\">\r\n@article{Gupta:2009:DFT:1508284.1508271,\n author = {Gupta, Aayush and Kim, Youngjae and Urgaonkar, Bhuvan},\n title = {DFTL: A Flash Translation Layer Employing Demand-based Selective Caching of Page-level Address Mappings},\n journal = {SIGPLAN Not.},\n issue_date = {March 2009},\n volume = {44},\n number = {3},\n month = mar,\n year = {2009},\n issn = {0362-1340},\n pages = {229--240},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1508284.1508271},\n doi = {10.1145/1508284.1508271},\n acmid = {1508271},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash management, flash translation layer, storage system},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1508271&parent_id=1508284&expformat=bibtex&CFID=982048329&CFTOKEN=63585931\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1508271\">\r\n@article{Gupta:2009:DFT:2528521.1508271,\n author = {Gupta, Aayush and Kim, Youngjae and Urgaonkar, Bhuvan},\n title = {DFTL: A Flash Translation Layer Employing Demand-based Selective Caching of Page-level Address Mappings},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2009},\n volume = {37},\n number = {1},\n month = mar,\n year = {2009},\n issn = {0163-5964},\n pages = {229--240},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2528521.1508271},\n doi = {10.1145/2528521.1508271},\n acmid = {1508271},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash management, flash translation layer, storage system},\n} \r\n",
        "key": "1508271",
        "pub_year": "2009",
        "text": "Aayush Gupta , Youngjae Kim , Bhuvan Urgaonkar, DFTL: a flash translation layer employing demand-based selective caching of page-level address mappings, Proceedings of the 14th international conference on Architectural support for programming languages and operating systems, March 07-11, 2009, Washington, DC, USA  \u00a0[doi>"
    },
    "1515829": {
        "abstract": "The traditional virtual memory system is designed for decades assuming a magnetic disk as the secondary storage. Recently, flash memory becomes a popular storage alternative for many portable devices with the continuing improvements on its capacity, reliability and much lower power consumption than mechanical hard drives. The characteristics of flash memory are quite different from a magnetic disk. Therefore, in this paper, we revisit virtual memory system design considering limitations imposed by flash memory. In particular, we focus on the energy efficient aspect since power is the first-order design consideration for embedded systems. Due to the write-once feature of flash memory, frequent writes incur frequent garbage collection thereby introducing significant energy overhead. Therefore, in this paper, we propose three methods to reduce writes to flash memory. The HotCache scheme adds an SRAM cache to buffer frequent writes. The subpaging technique partitions a page into subunits, and only dirty subpages are written to flash memory. The duplication-aware garbage collection method exploits data redundancy between the main memory and flash memory to reduce writes incurred by garbage collection. We also identify one type of data locality that is inherent in accesses to flash memory in the virtual memory system, intrapage locality. Intrapage locality needs to be carefully maintained for data allocation in flash memory. Destroying intrapage locality causes noticeable increases in energy consumption. Experimental results show that the average energy reduction of combined subpaging, HotCache, and duplication-aware garbage collection techniques is 42.2%.",
        "acm_key": "1515829",
        "bib_stats": {
            "cites": 7
        },
        "bibtex": "\r\n@article{Li:2008:EFM:1515827.1515829,\n author = {Li, Han-Lin and Yang, Chia-Lin and Tseng, Hung-Wei},\n title = {Energy-aware Flash Memory Management in Virtual Memory System},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {August 2008},\n volume = {16},\n number = {8},\n month = aug,\n year = {2008},\n issn = {1063-8210},\n pages = {952--964},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TVLS1.2008.2000517},\n doi = {10.1109/TVLS1.2008.2000517},\n acmid = {1515829},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n keywords = {<emphasis emphasistype=\"smcaps\">nand</emphasis> flash memory, Embedded systems, NAND flash memory, embedded systems, energy-efficient, virtual memory},\n} \r\n",
        "key": "1515829",
        "pub_year": "2008",
        "text": "Han-Lin Li , Chia-Lin Yang , Hung-Wei Tseng, Energy-aware flash memory management in virtual memory system, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.16 n.8, p.952-964, August 2008"
    },
    "1519081": {
        "abstract": "This paper evaluates pointer tainting, an incarnation of Dynamic Information Flow Tracking (DIFT), which has recently become an important technique in system security. Pointer tainting has been used for two main purposes: detection of privacy-breaching malware (e.g., trojan keyloggers obtaining the characters typed by a user), and detection of memory corruption attacks against non-control data (e.g., a buffer overflow that modifies a user's privilege level). In both of these cases the attacker does not modify control data such as stored branch targets, so the control flow of the target program does not change. Phrased differently, in terms of instructions executed, the program behaves 'normally'. As a result, these attacks are exceedingly difficult to detect. Pointer tainting is considered one of the onlymethods for detecting them in unmodified binaries. Unfortunately, almost all of the incarnations of pointer tainting are flawed. In particular, we demonstrate that the application of pointer tainting to the detection of keyloggers and other privacybreaching malware is problematic. We also discuss whether pointer tainting is able to reliably detect memory corruption attacks against non-control data. Pointer tainting generates itself the conditions for false positives. We analyse the problems in detail and investigate various ways to improve the technique. Most have serious drawbacks in that they are either impractical (and incur many false positives still), and/or cripple the technique's ability to detect attacks. In conclusion, we argue that depending on architecture and operating system, pointer tainting may have some value in detecting memory orruption attacks (albeit with false negatives and not on the popular x86 architecture), but it is fundamentally not suitable for automated detecting of privacy-breaching malware such as keyloggers.",
        "acm_key": "1519081",
        "bib_stats": {
            "cites": 97,
            "dl": 2,
            "dl_52": 114,
            "dl_6": 11
        },
        "key": "1519081",
        "text": "Dushyanth Narayanan , Eno Thereska , Austin Donnelly , Sameh Elnikety , Antony Rowstron, Migrating server storage to SSDs: analysis of tradeoffs, Proceedings of the 4th ACM European conference on Computer systems, April 01-03, 2009, Nuremberg, Germany"
    },
    "1529351": {
        "abstract": "Macromolecules such as proteins and enzymes are responsible for most of cellular functionality. Many molecular interactions, such as protein-protein interactions or protein-ligand binding, occur at what can be defined as the molecular surface. The topology of the molecular surface is often complex, containing various geometric features such as clefts, cavities, tunnels, and flat regions. These geometric features coupled with non-geometric physicochemical properties influence surface-based molecular interactions. Consequently analysis of molecular surfaces is crucial in elucidating structure-property relationships of molecules. In this paper we propose a method for visualizing a molecular surface in a manner that preserves and elucidates salient features. The method involves mapping of a molecular surface to a standard spherical coordinate system. The ability to map arbitrary molecular surfaces to a standard coordinate system aids in comparison of surface features across different molecules. The mapping is accomplished by enclosing the molecular surface by a sphere, and then iteratively deforming the sphere until it converges by wrapping the entire molecular surface. This allows a one-to-one relationship to be established between points on the molecular surface and points on the surface of the sphere. The presence of discontinuities such as tunnels in the molecular surface can be identified by detecting collision between patches of the deforming sphere. Subsequently, the deformable surface is restored back to the sphere, retaining the mapping. Features and properties defined at the molecular surface are then mapped and visualized in the standard spherical coordinate system. The proposed approach has several key advantages. First, it allows a global-to-local visualization of molecular surfaces. Second, it facilitates comparison of specific features as well as collection of features within and across molecules by mapping them to a common coordinate system. Third, the method allows visualization of both geometric and non-geometric surface properties. Fourth, specific molecular characteristics can be visualized individually or in combination on-demand. Finally, and crucially the advantages offered by the proposed visualization do not involve simplification of the surface characteristics thereby ensuring that no loss of potentially important information occurs.",
        "acm_key": "1529351",
        "bib_stats": {
            "cites": 5,
            "dl": 532,
            "dl_52": 27,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Lee:2009:CCA:1529282.1529351,\n author = {Lee, Jongmin and Byun, Eujoon and Park, Hanmook and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},\n title = {CPS-SIM: Configurable and Accurate Clock Precision Solid State Drive Simulator},\n booktitle = {Proceedings of the 2009 ACM Symposium on Applied Computing},\n series = {SAC '09},\n year = {2009},\n isbn = {978-1-60558-166-8},\n location = {Honolulu, Hawaii},\n pages = {318--325},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/1529282.1529351},\n doi = {10.1145/1529282.1529351},\n acmid = {1529351},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL (flash translation layer), NAND flash memory, SSD (solid state drive), clock precision SSD simulator, configurability},\n} \r\n",
        "key": "1529351",
        "pub_year": "2009",
        "text": "Jongmin Lee , Eujoon Byun , Hanmook Park , Jongmoo Choi , Donghee Lee , Sam H. Noh, CPS-SIM: configurable and accurate clock precision solid state drive simulator, Proceedings of the 2009 ACM symposium on Applied Computing, March 08-12, 2009, Honolulu, Hawaii  \u00a0[doi>"
    },
    "1534544": {
        "abstract": "In this study, we consider bytecode optimizations for Python, a programming language which combines object-oriented concepts with features of scripting languages, such as dynamic dictionaries. Due to its design nature, Python is relatively slow compared to other languages. It operates through compiling the code into powerful bytecode instructions that are executed by an interpreter. Python's speed is limited due to its interpreter design, and thus there is a significant need to optimize the language. In this paper, we discuss one possible approach and limitations in optimizing Python based on bytecode transformations. In the first stage of the proposed optimizer, the bytecode is expanded using function inline and loop unrolling. The second stage of transformations simplifies the bytecode by applying a complete set of data-flow optimizations, including constant propagation, algebraic simplifications, dead code elimination, copy propagation, common sub expressions elimination, loop invariant code motion and strength reduction. While these optimizations are known and their implementation mechanism (data flow analysis) is well developed, they have not been successfully implemented in Python due to its dynamic features which prevent their use. In this work we attempt to understand the dynamic features of Python and how these features affect and limit the implementation of these optimizations. In particular, we consider the significant effects of first unrolling and then inlining on the ability to apply the remaining optimizations. The results of our experiments indicate that these optimizations can indeed be implemented and dramatically improve execution times.",
        "acm_key": "1534544",
        "bib_stats": {
            "cites": 65,
            "dl": 1,
            "dl_52": 119,
            "dl_6": 15
        },
        "bibtex": "\r\n@inproceedings{Hu:2009:WAA:1534530.1534544,\n author = {Hu, Xiao-Yu and Eleftheriou, Evangelos and Haas, Robert and Iliadis, Ilias and Pletka, Roman},\n title = {Write Amplification Analysis in Flash-based Solid State Drives},\n booktitle = {Proceedings of SYSTOR 2009: The Israeli Experimental Systems Conference},\n series = {SYSTOR '09},\n year = {2009},\n isbn = {978-1-60558-623-6},\n location = {Haifa, Israel},\n pages = {10:1--10:9},\n articleno = {10},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/1534530.1534544},\n doi = {10.1145/1534530.1534544},\n acmid = {1534544},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, solid state drives, solid state storage systems, write amplification},\n} \r\n",
        "key": "1534544",
        "pub_year": "2009",
        "text": "Xiao-Yu Hu , Evangelos Eleftheriou , Robert Haas , Ilias Iliadis , Roman Pletka, Write amplification analysis in flash-based solid state drives, Proceedings of SYSTOR 2009: The Israeli Experimental Systems Conference, May 04-April 06, 2009, Haifa, Israel"
    },
    "1542324": {
        "abstract": "RAID-6 significantly outperforms the other RAID levels in disk-failure tolerance due to its ability to tolerate arbitrary two concurrent disk failures in a disk array. The underlying parity array codes have a significant impact on RAID-6's performance. In this paper, we propose a new XOR-based RAID-6 code, called the Partition Code (P-Code). P-Code is a very simple and flexible vertical code, making it easy to understand and implement. It works on a group of (prime-1) or (prime) disks, and its coding scheme is based on an equal partition of a specified two-integer-tuple set. P-Code has the following properties: (1) it is a Maximum-Distance-Separable (MDS) code, with optimal storage efficiency; (2) it has optimal construction and reconstruction computational complexity; (3) it has optimal update complexity (i.e., the number of parity blocks affected by a single data-block update is minimal). These optimal properties of P-Code are proven mathematically in this paper. While X-Code is provably optimal and RDP is proven optimal in computational complexity and storage efficiency, the latter in its current form is not optimal in update complexity. We propose a row-parity placement strategy for RDP to help it attain optimal update complexity. P-Code complements the other two optimal RAID-6 codes, X-code and the tweaked RDP, to provide a near-full set of optimal RAID-6 configurations of typical disk-array size (e.g., 4-20 disks). That is, for any prime in a typical array size range, P-code can be deployed for (prime-1) disks optimally, while X-code (or P-Code) and the tweaked RDP can be respectively deployed for (prime) and (prime+1) disks optimally. Moreover, P-code's potentially beneficial properties such as the flexible association between the blocks and their labels may find useful applications in distributed environments.",
        "acm_key": "1542324",
        "bib_stats": {
            "cites": 22,
            "dl": 1,
            "dl_52": 86,
            "dl_6": 10
        },
        "key": "1542324",
        "text": "Ji-Yong Shin , Zeng-Lin Xia , Ning-Yi Xu , Rui Gao , Xiong-Fei Cai , Seungryoul Maeng , Feng-Hsiung Hsu, FTL design exploration in reconfigurable high-performance SSD for server applications, Proceedings of the 23rd international conference on Supercomputing, June 08-12, 2009, Yorktown Heights, NY, USA  \u00a0[doi>"
    },
    "1547510": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1547510",
        "bib_stats": {
            "cites": 33,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2009:TIF:1546683.1547510,\n author = {Li, Yinan and He, Bingsheng and Luo, Qiong and Yi, Ke},\n title = {Tree Indexing on Flash Disks},\n booktitle = {Proceedings of the 2009 IEEE International Conference on Data Engineering},\n series = {ICDE '09},\n year = {2009},\n isbn = {978-0-7695-3545-6},\n pages = {1303--1306},\n numpages = {4},\n url = {http://dx.doi.org/10.1109/ICDE.2009.226},\n doi = {10.1109/ICDE.2009.226},\n acmid = {1547510},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {flash disk, SSD, index, fractional cascading, logarithmic method},\n} \r\n",
        "key": "1547510",
        "pub_year": "2009",
        "text": "Yinan Li , Bingsheng He , Qiong Luo , Ke Yi, Tree Indexing on Flash Disks, Proceedings of the 2009 IEEE International Conference on Data Engineering, p.1303-1306, March 29-April 02, 2009  \u00a0[doi>"
    },
    "1548901": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1548901",
        "bib_stats": {
            "cites": 23,
            "dl": 24,
            "dl_52": 13,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Snider:2008:SLM:1548877.1548901,\n author = {Snider, Greg S.},\n title = {Spike-timing-dependent Learning in Memristive Nanodevices},\n booktitle = {Proceedings of the 2008 IEEE International Symposium on Nanoscale Architectures},\n series = {NANOARCH '08},\n year = {2008},\n isbn = {978-1-4244-2552-5},\n pages = {85--92},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/NANOARCH.2008.4585796},\n doi = {10.1109/NANOARCH.2008.4585796},\n acmid = {1548901},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1548901",
        "pub_year": "2008",
        "text": "Greg S. Snider, Spike-timing-dependent learning in memristive nanodevices, Proceedings of the 2008 IEEE International Symposium on Nanoscale Architectures, p.85-92, June 12-13, 2008  \u00a0[doi>"
    },
    "1550559": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1550559",
        "bib_stats": {
            "cites": 41,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Kang:2009:PTU:1550402.1550559,\n author = {Kang, Sooyong and Park, Sungmin and Jung, Hoyoung and Shim, Hyoki and Cha, Jaehyuk},\n title = {Performance Trade-Offs in Using NVRAM Write Buffer for Flash Memory-Based Storage Devices},\n journal = {IEEE Trans. Comput.},\n issue_date = {June 2009},\n volume = {58},\n number = {6},\n month = jun,\n year = {2009},\n issn = {0018-9340},\n pages = {744--758},\n numpages = {15},\n url = {http://dx.doi.org/10.1109/TC.2008.224},\n doi = {10.1109/TC.2008.224},\n acmid = {1550559},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Nonvolatile RAM, Nonvolatile RAM, flash memory, write buffer, flash translation layer, solid-state disk, storage device., flash memory, flash translation layer, solid-state disk, storage device., write buffer},\n} \r\n",
        "key": "1550559",
        "pub_year": "2009",
        "text": "Sooyong Kang , Sungmin Park , Hoyoung Jung , Hyoki Shim , Jaehyuk Cha, Performance Trade-Offs in Using NVRAM Write Buffer for Flash Memory-Based Storage Devices, IEEE Transactions on Computers, v.58 n.6, p.744-758, June 2009"
    },
    "1551181": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1551181",
        "bib_stats": {
            "cites": 50
        },
        "bibtex": "\r\n@article{Chung:2009:SFT:1550961.1551181,\n author = {Chung, Tae-Sun and Park, Dong-Joo and Park, Sangwon and Lee, Dong-Ho and Lee, Sang-Won and Song, Ha-Joo},\n title = {A Survey of Flash Translation Layer},\n journal = {J. Syst. Archit.},\n issue_date = {May, 2009},\n volume = {55},\n number = {5-6},\n month = may,\n year = {2009},\n issn = {1383-7621},\n pages = {332--343},\n numpages = {12},\n url = {http://dx.doi.org/10.1016/j.sysarc.2009.03.005},\n doi = {10.1016/j.sysarc.2009.03.005},\n acmid = {1551181},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Embedded system, File system, Flash memory},\n} \r\n",
        "key": "1551181",
        "pub_year": "2009",
        "text": "Tae-Sun Chung , Dong-Joo Park , Sangwon Park , Dong-Ho Lee , Sang-Won Lee , Ha-Joo Song, A survey of Flash Translation Layer, Journal of Systems Architecture: the EUROMICRO Journal, v.55 n.5-6, p.332-343, May, 2009"
    },
    "1553708": {
        "abstract": "Under statistical learning framework, the paper focuses on how to use traditional linguistic findings on anaphora resolution as a guide for mining and organizing contextual features for Chinese co-reference resolution. The main achievements are as follows. (1) In order to simulate \"syntactic and semantic parallelism factor\", we extract \"bags of word form and POS\" feature and \"bag of semes\" feature from the contexts of the entity mentions and incorporate them into the baseline feature set. (2) Because it is too coarse to use the feature of bags of word form, POS tag and seme to determine the syntactic and semantic parallelism between two entity mentions, we propose a method for contextual feature reconstruction based on semantic similarity computation, in order that the reconstructed contextual features could better approximate the anaphora resolution factor of \"Syntactic and Semantic Parallelism Preferences\". (3) We use an entity-mention-based contextual feature representation instead of isolated word-based contextual feature representation, and expand the size of the contextual windows in addition, in order to approximately simulate \"the selectional restriction factor\" for anaphora resolution. The experiments show that the multi-level contextual features are useful for co-reference resolution, and the statistical system incorporated with these features performs well on the standard ACE datasets.",
        "acm_key": "1553708",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Lee:2007:NHP:1553705.1553708,\n author = {Lee, Jung-Hoon},\n title = {Next High Performance and Low Power Flash Memory Package Structure},\n journal = {J. Comput. Sci. Technol.},\n issue_date = {July 2007},\n volume = {22},\n number = {4},\n month = jul,\n year = {2007},\n issn = {1000-9000},\n pages = {515--520},\n numpages = {6},\n url = {http://dx.doi.org/10.1007/s11390-007-9068-9},\n doi = {10.1007/s11390-007-9068-9},\n acmid = {1553708},\n publisher = {Institute of Computing Technology},\n address = {Beijing, China},\n keywords = {NAND-type, NOR-type, buffer or cache memory, flash memory, memory localities},\n} \r\n",
        "key": "1553708",
        "pub_year": "2007",
        "text": "Jung-Hoon Lee, Next high performance and low power flash memory package structure, Journal of Computer Science and Technology, v.22 n.4, p.515-520, July 2007"
    },
    "1555371": {
        "abstract": "Traditionally, Internet Service Providers (ISPs) make profit by providing Internet connectivity, while content providers (CPs) play the more lucrative role of delivering content to users. As network connectivity is increasingly a commodity, ISPs have a strong incentive to offer content to their subscribers by deploying their own content distribution infrastructure. Providing content services in an ISP network presents new opportunities for coordination between traffic engineering (to select efficient routes for the traffic) and server selection (to match servers with subscribers). In this work, we develop a mathematical framework that considers three models with an increasing amount of cooperation between the ISP and the CP. We show that separating server selection and traffic engineering leads to sub-optimal equilibria, even when the CP is given accurate and timely information about the ISP's network in a partial cooperation. More surprisingly, extra visibility may result in a less efficient outcome and such performance degradation can be unbounded. Leveraging ideas from cooperative game theory, we propose an architecture based on the concept of Nash bargaining solution. Simulations on realistic backbone topologies are performed to quantify the performance differences among the three models. Our results apply both when a network provider attempts to provide content, and when separate ISP and CP entities wish to cooperate. This study is a step toward a systematic understanding of the interactions between those who provide and operate networks and those who generate and distribute content.",
        "acm_key": "1555371",
        "bib_stats": {
            "cites": 118,
            "dl": 3,
            "dl_52": 237,
            "dl_6": 14
        },
        "bibtex": "\r\n@inproceedings{Chen:2009:UIC:1555349.1555371,\n author = {Chen, Feng and Koufaty, David A. and Zhang, Xiaodong},\n title = {Understanding Intrinsic Characteristics and System Implications of Flash Memory Based Solid State Drives},\n booktitle = {Proceedings of the Eleventh International Joint Conference on Measurement and Modeling of Computer Systems},\n series = {SIGMETRICS '09},\n year = {2009},\n isbn = {978-1-60558-511-6},\n location = {Seattle, WA, USA},\n pages = {181--192},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1555349.1555371},\n doi = {10.1145/1555349.1555371},\n acmid = {1555371},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, hard disk drive, solid state drive},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555371&parent_id=1555349&expformat=bibtex&CFID=982035459&CFTOKEN=93713628\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555371\">\r\n@article{Chen:2009:UIC:2492101.1555371,\n author = {Chen, Feng and Koufaty, David A. and Zhang, Xiaodong},\n title = {Understanding Intrinsic Characteristics and System Implications of Flash Memory Based Solid State Drives},\n journal = {SIGMETRICS Perform. Eval. Rev.},\n issue_date = {June 2009},\n volume = {37},\n number = {1},\n month = jun,\n year = {2009},\n issn = {0163-5999},\n pages = {181--192},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2492101.1555371},\n doi = {10.1145/2492101.1555371},\n acmid = {1555371},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, hard disk drive, solid state drive},\n} \r\n",
        "key": "1555371",
        "pub_year": "2009",
        "text": "Feng Chen , David A. Koufaty , Xiaodong Zhang, Understanding intrinsic characteristics and system implications of flash memory based solid state drives, Proceedings of the eleventh international joint conference on Measurement and modeling of computer systems, June 15-19, 2009, Seattle, WA, USA  \u00a0[doi>"
    },
    "1555758": {
        "abstract": "Caching techniques have been an efficient mechanism for mitigating the effects of the processor-memory speed gap. Traditional multi-level SRAM-based cache hierarchies, especially in the context of chip multiprocessors (CMPs), present many challenges in area requirements, core-to-cache balance, power consumption, and design complexity. New advancements in technology enable caches to be built from other technologies, such as Embedded DRAM (EDRAM), Magnetic RAM (MRAM), and Phase-change RAM (PRAM), in both 2D chips or 3D stacked chips. Caches fabricated in these technologies offer dramatically different power and performance characteristics when compared with SRAM-based caches, particularly in the areas of access latency, cell density, and overall power consumption. In this paper, we propose to take advantage of the best characteristics that each technology offers, through the use of Hybrid Cache Architecture (HCA) designs. We discuss and evaluate two types of hybrid cache architectures: inter cache Level HCA (LHCA), in which the levels in a cache hierarchy can be made of disparate memory technologies; and intra cache level or cache Region based HCA (RHCA), where a single level of cache can be partitioned into multiple regions, each of a different memory technology. We have studied a number of different HCA architectures and explored the potential of hardware support for intra-cache data movement and power consumption management within HCA caches. Utilizing a full-system simulator that has been validated against real hardware, we demonstrate that an LHCA design can provide a geometric mean 7% IPC improvement over a baseline 3-level SRAM cache design under the same area constraint across a collection of 25 workloads. A more aggressive RHCA-based design provides 12% IPC improvement over the baseline. Finally, a 2-layer 3D cache stack (3DHCA) of high density memory technology within the same chip footprint gives 18% IPC improvement over the baseline. Furthermore, up to 70% reduction in power consumption over a baseline SRAM-only design is achieved.",
        "acm_key": "1555758",
        "bib_stats": {
            "cites": 303,
            "dl": 4,
            "dl_52": 449,
            "dl_6": 40
        },
        "bibtex": "\r\n@article{Lee:2009:APC:1555815.1555758,\n author = {Lee, Benjamin C. and Ipek, Engin and Mutlu, Onur and Burger, Doug},\n title = {Architecting Phase Change Memory As a Scalable Dram Alternative},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2009},\n volume = {37},\n number = {3},\n month = jun,\n year = {2009},\n issn = {0163-5964},\n pages = {2--13},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1555815.1555758},\n doi = {10.1145/1555815.1555758},\n acmid = {1555758},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dram alternative, endurance, energy, pcm, performance, phase change memory, power, scalability},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555758&parent_id=1555815&expformat=bibtex&CFID=982050922&CFTOKEN=17085043\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555758\">\r\n@inproceedings{Lee:2009:APC:1555754.1555758,\n author = {Lee, Benjamin C. and Ipek, Engin and Mutlu, Onur and Burger, Doug},\n title = {Architecting Phase Change Memory As a Scalable Dram Alternative},\n booktitle = {Proceedings of the 36th Annual International Symposium on Computer Architecture},\n series = {ISCA '09},\n year = {2009},\n isbn = {978-1-60558-526-0},\n location = {Austin, TX, USA},\n pages = {2--13},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1555754.1555758},\n doi = {10.1145/1555754.1555758},\n acmid = {1555758},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dram alternative, endurance, energy, pcm, performance, phase change memory, power, scalability},\n} \r\n",
        "key": "1555758",
        "pub_year": "2009",
        "text": "Benjamin C. Lee , Engin Ipek , Onur Mutlu , Doug Burger, Architecting phase change memory as a scalable dram alternative, ACM SIGARCH Computer Architecture News, v.37 n.3, June 2009  \u00a0[doi>"
    },
    "1555759": {
        "abstract": "Caching techniques have been an efficient mechanism for mitigating the effects of the processor-memory speed gap. Traditional multi-level SRAM-based cache hierarchies, especially in the context of chip multiprocessors (CMPs), present many challenges in area requirements, core-to-cache balance, power consumption, and design complexity. New advancements in technology enable caches to be built from other technologies, such as Embedded DRAM (EDRAM), Magnetic RAM (MRAM), and Phase-change RAM (PRAM), in both 2D chips or 3D stacked chips. Caches fabricated in these technologies offer dramatically different power and performance characteristics when compared with SRAM-based caches, particularly in the areas of access latency, cell density, and overall power consumption. In this paper, we propose to take advantage of the best characteristics that each technology offers, through the use of Hybrid Cache Architecture (HCA) designs. We discuss and evaluate two types of hybrid cache architectures: inter cache Level HCA (LHCA), in which the levels in a cache hierarchy can be made of disparate memory technologies; and intra cache level or cache Region based HCA (RHCA), where a single level of cache can be partitioned into multiple regions, each of a different memory technology. We have studied a number of different HCA architectures and explored the potential of hardware support for intra-cache data movement and power consumption management within HCA caches. Utilizing a full-system simulator that has been validated against real hardware, we demonstrate that an LHCA design can provide a geometric mean 7% IPC improvement over a baseline 3-level SRAM cache design under the same area constraint across a collection of 25 workloads. A more aggressive RHCA-based design provides 12% IPC improvement over the baseline. Finally, a 2-layer 3D cache stack (3DHCA) of high density memory technology within the same chip footprint gives 18% IPC improvement over the baseline. Furthermore, up to 70% reduction in power consumption over a baseline SRAM-only design is achieved.",
        "acm_key": "1555759",
        "bib_stats": {
            "cites": 210,
            "dl": 3,
            "dl_52": 279,
            "dl_6": 34
        },
        "bibtex": "\r\n@article{Zhou:2009:DEE:1555815.1555759,\n author = {Zhou, Ping and Zhao, Bo and Yang, Jun and Zhang, Youtao},\n title = {A Durable and Energy Efficient Main Memory Using Phase Change Memory Technology},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2009},\n volume = {37},\n number = {3},\n month = jun,\n year = {2009},\n issn = {0163-5964},\n pages = {14--23},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1555815.1555759},\n doi = {10.1145/1555815.1555759},\n acmid = {1555759},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, low power, phase change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555759&parent_id=1555815&expformat=bibtex&CFID=982043795&CFTOKEN=44883123\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555759\">\r\n@inproceedings{Zhou:2009:DEE:1555754.1555759,\n author = {Zhou, Ping and Zhao, Bo and Yang, Jun and Zhang, Youtao},\n title = {A Durable and Energy Efficient Main Memory Using Phase Change Memory Technology},\n booktitle = {Proceedings of the 36th Annual International Symposium on Computer Architecture},\n series = {ISCA '09},\n year = {2009},\n isbn = {978-1-60558-526-0},\n location = {Austin, TX, USA},\n pages = {14--23},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1555754.1555759},\n doi = {10.1145/1555754.1555759},\n acmid = {1555759},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, low power, phase change memory},\n} \r\n",
        "key": "1555759",
        "pub_year": "2009",
        "text": "Ping Zhou , Bo Zhao , Jun Yang , Youtao Zhang, A durable and energy efficient main memory using phase change memory technology, ACM SIGARCH Computer Architecture News, v.37 n.3, June 2009"
    },
    "1555760": {
        "abstract": "Caching techniques have been an efficient mechanism for mitigating the effects of the processor-memory speed gap. Traditional multi-level SRAM-based cache hierarchies, especially in the context of chip multiprocessors (CMPs), present many challenges in area requirements, core-to-cache balance, power consumption, and design complexity. New advancements in technology enable caches to be built from other technologies, such as Embedded DRAM (EDRAM), Magnetic RAM (MRAM), and Phase-change RAM (PRAM), in both 2D chips or 3D stacked chips. Caches fabricated in these technologies offer dramatically different power and performance characteristics when compared with SRAM-based caches, particularly in the areas of access latency, cell density, and overall power consumption. In this paper, we propose to take advantage of the best characteristics that each technology offers, through the use of Hybrid Cache Architecture (HCA) designs. We discuss and evaluate two types of hybrid cache architectures: inter cache Level HCA (LHCA), in which the levels in a cache hierarchy can be made of disparate memory technologies; and intra cache level or cache Region based HCA (RHCA), where a single level of cache can be partitioned into multiple regions, each of a different memory technology. We have studied a number of different HCA architectures and explored the potential of hardware support for intra-cache data movement and power consumption management within HCA caches. Utilizing a full-system simulator that has been validated against real hardware, we demonstrate that an LHCA design can provide a geometric mean 7% IPC improvement over a baseline 3-level SRAM cache design under the same area constraint across a collection of 25 workloads. A more aggressive RHCA-based design provides 12% IPC improvement over the baseline. Finally, a 2-layer 3D cache stack (3DHCA) of high density memory technology within the same chip footprint gives 18% IPC improvement over the baseline. Furthermore, up to 70% reduction in power consumption over a baseline SRAM-only design is achieved.",
        "acm_key": "1555760",
        "bib_stats": {
            "cites": 293,
            "dl": 4,
            "dl_52": 391,
            "dl_6": 35
        },
        "bibtex": "\r\n@inproceedings{Qureshi:2009:SHP:1555754.1555760,\n author = {Qureshi, Moinuddin K. and Srinivasan, Vijayalakshmi and Rivers, Jude A.},\n title = {Scalable High Performance Main Memory System Using Phase-change Memory Technology},\n booktitle = {Proceedings of the 36th Annual International Symposium on Computer Architecture},\n series = {ISCA '09},\n year = {2009},\n isbn = {978-1-60558-526-0},\n location = {Austin, TX, USA},\n pages = {24--33},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1555754.1555760},\n doi = {10.1145/1555754.1555760},\n acmid = {1555760},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dram caching, phase change memory, wear leveling},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555760&parent_id=1555754&expformat=bibtex&CFID=982034103&CFTOKEN=24476294\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555760\">\r\n@article{Qureshi:2009:SHP:1555815.1555760,\n author = {Qureshi, Moinuddin K. and Srinivasan, Vijayalakshmi and Rivers, Jude A.},\n title = {Scalable High Performance Main Memory System Using Phase-change Memory Technology},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2009},\n volume = {37},\n number = {3},\n month = jun,\n year = {2009},\n issn = {0163-5964},\n pages = {24--33},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1555815.1555760},\n doi = {10.1145/1555815.1555760},\n acmid = {1555760},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dram caching, phase change memory, wear leveling},\n} \r\n",
        "key": "1555760",
        "pub_year": "2009",
        "text": "Moinuddin K. Qureshi , Vijayalakshmi Srinivasan , Jude A. Rivers, Scalable high performance main memory system using phase-change memory technology, Proceedings of the 36th annual international symposium on Computer architecture, June 20-24, 2009, Austin, TX, USA  \u00a0[doi>"
    },
    "1555761": {
        "abstract": "Caching techniques have been an efficient mechanism for mitigating the effects of the processor-memory speed gap. Traditional multi-level SRAM-based cache hierarchies, especially in the context of chip multiprocessors (CMPs), present many challenges in area requirements, core-to-cache balance, power consumption, and design complexity. New advancements in technology enable caches to be built from other technologies, such as Embedded DRAM (EDRAM), Magnetic RAM (MRAM), and Phase-change RAM (PRAM), in both 2D chips or 3D stacked chips. Caches fabricated in these technologies offer dramatically different power and performance characteristics when compared with SRAM-based caches, particularly in the areas of access latency, cell density, and overall power consumption. In this paper, we propose to take advantage of the best characteristics that each technology offers, through the use of Hybrid Cache Architecture (HCA) designs. We discuss and evaluate two types of hybrid cache architectures: inter cache Level HCA (LHCA), in which the levels in a cache hierarchy can be made of disparate memory technologies; and intra cache level or cache Region based HCA (RHCA), where a single level of cache can be partitioned into multiple regions, each of a different memory technology. We have studied a number of different HCA architectures and explored the potential of hardware support for intra-cache data movement and power consumption management within HCA caches. Utilizing a full-system simulator that has been validated against real hardware, we demonstrate that an LHCA design can provide a geometric mean 7% IPC improvement over a baseline 3-level SRAM cache design under the same area constraint across a collection of 25 workloads. A more aggressive RHCA-based design provides 12% IPC improvement over the baseline. Finally, a 2-layer 3D cache stack (3DHCA) of high density memory technology within the same chip footprint gives 18% IPC improvement over the baseline. Furthermore, up to 70% reduction in power consumption over a baseline SRAM-only design is achieved.",
        "acm_key": "1555761",
        "bib_stats": {
            "cites": 83,
            "dl": 2,
            "dl_52": 123,
            "dl_6": 15
        },
        "bibtex": "\r\n@inproceedings{Wu:2009:HCA:1555754.1555761,\n author = {Wu, Xiaoxia and Li, Jian and Zhang, Lixin and Speight, Evan and Rajamony, Ram and Xie, Yuan},\n title = {Hybrid Cache Architecture with Disparate Memory Technologies},\n booktitle = {Proceedings of the 36th Annual International Symposium on Computer Architecture},\n series = {ISCA '09},\n year = {2009},\n isbn = {978-1-60558-526-0},\n location = {Austin, TX, USA},\n pages = {34--45},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1555754.1555761},\n doi = {10.1145/1555754.1555761},\n acmid = {1555761},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {hybrid cache architecture, three-dimensional ic},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555761&parent_id=1555754&expformat=bibtex&CFID=982034132&CFTOKEN=15953343\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555761\">\r\n@article{Wu:2009:HCA:1555815.1555761,\n author = {Wu, Xiaoxia and Li, Jian and Zhang, Lixin and Speight, Evan and Rajamony, Ram and Xie, Yuan},\n title = {Hybrid Cache Architecture with Disparate Memory Technologies},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2009},\n volume = {37},\n number = {3},\n month = jun,\n year = {2009},\n issn = {0163-5964},\n pages = {34--45},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1555815.1555761},\n doi = {10.1145/1555815.1555761},\n acmid = {1555761},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {hybrid cache architecture, three-dimensional ic},\n} \r\n",
        "key": "1555761",
        "pub_year": "2009",
        "text": "Xiaoxia Wu , Jian Li , Lixin Zhang , Evan Speight , Ram Rajamony , Yuan Xie, Hybrid cache architecture with disparate memory technologies, Proceedings of the 36th annual international symposium on Computer architecture, June 20-24, 2009, Austin, TX, USA  \u00a0[doi>"
    },
    "1555790": {
        "abstract": "Caching techniques have been an efficient mechanism for mitigating the effects of the processor-memory speed gap. Traditional multi-level SRAM-based cache hierarchies, especially in the context of chip multiprocessors (CMPs), present many challenges in area requirements, core-to-cache balance, power consumption, and design complexity. New advancements in technology enable caches to be built from other technologies, such as Embedded DRAM (EDRAM), Magnetic RAM (MRAM), and Phase-change RAM (PRAM), in both 2D chips or 3D stacked chips. Caches fabricated in these technologies offer dramatically different power and performance characteristics when compared with SRAM-based caches, particularly in the areas of access latency, cell density, and overall power consumption. In this paper, we propose to take advantage of the best characteristics that each technology offers, through the use of Hybrid Cache Architecture (HCA) designs. We discuss and evaluate two types of hybrid cache architectures: inter cache Level HCA (LHCA), in which the levels in a cache hierarchy can be made of disparate memory technologies; and intra cache level or cache Region based HCA (RHCA), where a single level of cache can be partitioned into multiple regions, each of a different memory technology. We have studied a number of different HCA architectures and explored the potential of hardware support for intra-cache data movement and power consumption management within HCA caches. Utilizing a full-system simulator that has been validated against real hardware, we demonstrate that an LHCA design can provide a geometric mean 7% IPC improvement over a baseline 3-level SRAM cache design under the same area constraint across a collection of 25 workloads. A more aggressive RHCA-based design provides 12% IPC improvement over the baseline. Finally, a 2-layer 3D cache stack (3DHCA) of high density memory technology within the same chip footprint gives 18% IPC improvement over the baseline. Furthermore, up to 70% reduction in power consumption over a baseline SRAM-only design is achieved.",
        "acm_key": "1555790",
        "bib_stats": {
            "cites": 52,
            "dl": 2,
            "dl_52": 115,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Dirik:2009:PPS:1555815.1555790,\n author = {Dirik, Cagdas and Jacob, Bruce},\n title = {The Performance of PC Solid-state Disks (SSDs) As a Function of Bandwidth, Concurrency, Device Architecture, and System Organization},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2009},\n volume = {37},\n number = {3},\n month = jun,\n year = {2009},\n issn = {0163-5964},\n pages = {279--289},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/1555815.1555790},\n doi = {10.1145/1555815.1555790},\n acmid = {1555790},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, performance, solid state disks, storage systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1555790&parent_id=1555815&expformat=bibtex&CFID=982052826&CFTOKEN=98875565\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1555790\">\r\n@inproceedings{Dirik:2009:PPS:1555754.1555790,\n author = {Dirik, Cagdas and Jacob, Bruce},\n title = {The Performance of PC Solid-state Disks (SSDs) As a Function of Bandwidth, Concurrency, Device Architecture, and System Organization},\n booktitle = {Proceedings of the 36th Annual International Symposium on Computer Architecture},\n series = {ISCA '09},\n year = {2009},\n isbn = {978-1-60558-526-0},\n location = {Austin, TX, USA},\n pages = {279--289},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/1555754.1555790},\n doi = {10.1145/1555754.1555790},\n acmid = {1555790},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, performance, solid state disks, storage systems},\n} \r\n",
        "key": "1555790",
        "pub_year": "2009",
        "text": "Cagdas Dirik , Bruce Jacob, The performance of PC solid-state disks (SSDs) as a function of bandwidth, concurrency, device architecture, and system organization, ACM SIGARCH Computer Architecture News, v.37 n.3, June 2009"
    },
    "1559854": {
        "abstract": "This demonstration showcases a system for visualizing and analyzing search spaces generated by the SQL Anywhere optimizer during the optimization process of a SQL statement. SQL Anywhere dynamically optimizes each statement every time it is executed. The decisions made by the optimizer during the optimization process are both cost-based and heuristics adapted to the current state of the server and the database instance. Many performance issues can be understood and resolved by analyzing the search space generated when optimizing a certain request. In our experience, there are two main classes of performance issues related to the decisions made by a query optimizer:(1) a request is very slow due to a suboptimal access plan; and (2) a request has a different, less optimal access plan than a previous execution. We have enhanced SQL Anywhere to log, in a very compact format, its search space during the optimization process when tracing mode is on. These search space logs can be used for performance analysis in the absence of the database instances or of extra information about the SQL Anywhere server state at the time the logs were generated. This demonstration introduces the SearchSpaceAnalyzer System, a research prototype used to analyze the search spaces of the SQL Anywhere optimizer. The system visualizes and analyzes (1) a single search space and (2) the differences between two search spaces generated for the same query by two different optimization processes. The SearchSpaceAnalyze System can be used for the analysis of any query optimizer search spaces as long as the logged data is recorded using the syntax understood by the system.",
        "acm_key": "1559854",
        "bib_stats": {
            "cites": 50,
            "dl": 1,
            "dl_52": 58,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Tsirogiannis:2009:QPT:1559845.1559854,\n author = {Tsirogiannis, Dimitris and Harizopoulos, Stavros and Shah, Mehul A. and Wiener, Janet L. and Graefe, Goetz},\n title = {Query Processing Techniques for Solid State Drives},\n booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '09},\n year = {2009},\n isbn = {978-1-60558-551-2},\n location = {Providence, Rhode Island, USA},\n pages = {59--72},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1559845.1559854},\n doi = {10.1145/1559845.1559854},\n acmid = {1559854},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {columnar storage, flash memory, join index, late materialization, semi-join reduction, ssd},\n} \r\n",
        "key": "1559854",
        "pub_year": "2009",
        "text": "Dimitris Tsirogiannis , Stavros Harizopoulos , Mehul A. Shah , Janet L. Wiener , Goetz Graefe, Query processing techniques for solid state drives, Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, June 29-July 02, 2009, Providence, Rhode Island, USA  \u00a0[doi>"
    },
    "1559855": {
        "abstract": "This demonstration showcases a system for visualizing and analyzing search spaces generated by the SQL Anywhere optimizer during the optimization process of a SQL statement. SQL Anywhere dynamically optimizes each statement every time it is executed. The decisions made by the optimizer during the optimization process are both cost-based and heuristics adapted to the current state of the server and the database instance. Many performance issues can be understood and resolved by analyzing the search space generated when optimizing a certain request. In our experience, there are two main classes of performance issues related to the decisions made by a query optimizer:(1) a request is very slow due to a suboptimal access plan; and (2) a request has a different, less optimal access plan than a previous execution. We have enhanced SQL Anywhere to log, in a very compact format, its search space during the optimization process when tracing mode is on. These search space logs can be used for performance analysis in the absence of the database instances or of extra information about the SQL Anywhere server state at the time the logs were generated. This demonstration introduces the SearchSpaceAnalyzer System, a research prototype used to analyze the search spaces of the SQL Anywhere optimizer. The system visualizes and analyzes (1) a single search space and (2) the differences between two search spaces generated for the same query by two different optimization processes. The SearchSpaceAnalyze System can be used for the analysis of any query optimizer search spaces as long as the logged data is recorded using the syntax understood by the system.",
        "acm_key": "1559855",
        "bib_stats": {
            "cites": 38,
            "dl": 946,
            "dl_52": 31,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Chen:2009:FEF:1559845.1559855,\n author = {Chen, Shimin},\n title = {FlashLogging: Exploiting Flash Devices for Synchronous Logging Performance},\n booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '09},\n year = {2009},\n isbn = {978-1-60558-551-2},\n location = {Providence, Rhode Island, USA},\n pages = {73--86},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1559845.1559855},\n doi = {10.1145/1559845.1559855},\n acmid = {1559855},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash devices, flashlogging, near-zero-delay archival disk, online transaction processing, outlier detection and hiding, recovery processing, synchronous logging, unconventional array organization},\n} \r\n",
        "key": "1559855",
        "pub_year": "2009",
        "text": "Shimin Chen, FlashLogging: exploiting flash devices for synchronous logging performance, Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, June 29-July 02, 2009, Providence, Rhode Island, USA"
    },
    "1559937": {
        "abstract": "This demonstration showcases a system for visualizing and analyzing search spaces generated by the SQL Anywhere optimizer during the optimization process of a SQL statement. SQL Anywhere dynamically optimizes each statement every time it is executed. The decisions made by the optimizer during the optimization process are both cost-based and heuristics adapted to the current state of the server and the database instance. Many performance issues can be understood and resolved by analyzing the search space generated when optimizing a certain request. In our experience, there are two main classes of performance issues related to the decisions made by a query optimizer:(1) a request is very slow due to a suboptimal access plan; and (2) a request has a different, less optimal access plan than a previous execution. We have enhanced SQL Anywhere to log, in a very compact format, its search space during the optimization process when tracing mode is on. These search space logs can be used for performance analysis in the absence of the database instances or of extra information about the SQL Anywhere server state at the time the logs were generated. This demonstration introduces the SearchSpaceAnalyzer System, a research prototype used to analyze the search spaces of the SQL Anywhere optimizer. The system visualizes and analyzes (1) a single search space and (2) the differences between two search spaces generated for the same query by two different optimization processes. The SearchSpaceAnalyze System can be used for the analysis of any query optimizer search spaces as long as the logged data is recorded using the syntax understood by the system.",
        "acm_key": "1559937",
        "bib_stats": {
            "cites": 35,
            "dl": 1,
            "dl_52": 93,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Lee:2009:AFM:1559845.1559937,\n author = {Lee, Sang-Won and Moon, Bongki and Park, Chanik},\n title = {Advances in Flash Memory SSD Technology for Enterprise Database Applications},\n booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '09},\n year = {2009},\n isbn = {978-1-60558-551-2},\n location = {Providence, Rhode Island, USA},\n pages = {863--870},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/1559845.1559937},\n doi = {10.1145/1559845.1559937},\n acmid = {1559937},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy, flash-memory ssd, tpc-c benchmark},\n} \r\n",
        "key": "1559937",
        "pub_year": "2009",
        "text": "Sang-Won Lee , Bongki Moon , Chanik Park, Advances in flash memory SSD technology for enterprise database applications, Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, June 29-July 02, 2009, Providence, Rhode Island, USA  \u00a0[doi>"
    },
    "1565698": {
        "abstract": "Database processes must be cache-efficient to effectively utilize modern hardware. In this paper, we analyze the importance of temporal locality and the resultant cache behavior in scheduling database operators for in-memory, block oriented query processing. We demonstrate how the overall performance of a workload of multiple database operators is strongly dependent on how they are interleaved with each other. Longer time slices combined with temporal locality within an operator amortize the effects of the initial compulsory cache misses needed to load the operator's state, such as a hash table, into the cache. Though running an operator to completion over all of its input results in the greatest amortization of cache misses, this is typically infeasible because of the large intermediate storage requirement to materialize all input tuples to an operator. We show experimentally that good cache performance can be obtained with smaller buffers whose size is determined at runtime. We demonstrate a low-overhead method of runtime cache miss sampling using hardware performance counters. Our evaluation considers two common database operators with state: aggregation and hash join. Sampling reveals operator temporal locality and cache miss behavior, and we use those characteristics to choose an appropriate input buffer/block size. The calculated buffer size balances cache miss amortization with buffer memory requirements.",
        "acm_key": "1565698",
        "bib_stats": {
            "cites": 28,
            "dl": 393,
            "dl_52": 18,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Ou:2009:CFR:1565694.1565698,\n author = {Ou, Yi and H\\\"{a}rder, Theo and Jin, Peiquan},\n title = {CFDC: A Flash-aware Replacement Policy for Database Buffer Management},\n booktitle = {Proceedings of the Fifth International Workshop on Data Management on New Hardware},\n series = {DaMoN '09},\n year = {2009},\n isbn = {978-1-60558-701-1},\n location = {Providence, Rhode Island},\n pages = {15--20},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1565694.1565698},\n doi = {10.1145/1565694.1565698},\n acmid = {1565698},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1565698",
        "pub_year": "2009",
        "text": "Yi Ou , Theo H\u00e4rder , Peiquan Jin, CFDC: a flash-aware replacement policy for database buffer management, Proceedings of the Fifth International Workshop on Data Management on New Hardware, June 28-28, 2009, Providence, Rhode Island  \u00a0[doi>"
    },
    "1591039": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1591039",
        "bib_stats": {
            "cites": 8,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{On:2009:LBF:1590953.1591039,\n author = {On, Sai Tung and Hu, Haibo and Li, Yu and Xu, Jianliang},\n title = {Lazy-Update B+-Tree for Flash Devices},\n booktitle = {Proceedings of the 2009 Tenth International Conference on Mobile Data Management: Systems, Services and Middleware},\n series = {MDM '09},\n year = {2009},\n isbn = {978-0-7695-3650-7},\n pages = {323--328},\n numpages = {6},\n url = {http://dx.doi.org/10.1109/MDM.2009.48},\n doi = {10.1109/MDM.2009.48},\n acmid = {1591039},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash Memory, B+-tree, Indexing},\n} \r\n",
        "key": "1591039",
        "pub_year": "2009",
        "text": "Sai Tung On , Haibo Hu , Yu Li , Jianliang Xu, Lazy-Update B+-Tree for Flash Devices, Proceedings of the 2009 Tenth International Conference on Mobile Data Management: Systems, Services and Middleware, p.323-328, May 18-20, 2009  \u00a0[doi>"
    },
    "1594290": {
        "abstract": "Manufactured dies exhibit a large spread of maximum frequency and leakage power due to process variations, which have been increasing with technology scaling. Reducing the spread is very important for maximizing the frequency and the yield of power-constrained designs, because otherwise many dies that do not satisfy frequency or power constraints would be discarded. In this paper, we propose two optimization methods to improve the maximum operating frequency and the yield using power gates that already exist in many power-constrained designs. In the first method, we consider the designs of multiple cores, where each of them can be independently power-gated. When each core shows different frequencies due to within-die variations, the strength of a power gate in each core is adjusted to make their maximum operating frequencies even. This allows faster cores to consume less active leakage power, reducing the total power consumption well below a power constraint in a globally-clocked design. We subsequently increase global supply voltage for higher overall frequency until the power constraint is satisfied. In our experiments assuming multicore processors with 2--16 cores, the maximum operating frequency was improved by 4-23%. In the second method, we take leaky-but-fast dies (which otherwise would be discarded) and adjust the strength of the power gates such that they can operate in an acceptable power and frequency region. The problem is extended to designs employing a frequency binning strategy, where we have an additional objective of maximizing the number of dies for higher frequency bins. In our experiments with ISCAS benchmark circuits, most discarded fast-but leaky dies were recovered using the second method.",
        "acm_key": "1594290",
        "bib_stats": {
            "cites": 7,
            "dl": 545,
            "dl_52": 16,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Xu:2009:DMT:1594233.1594290,\n author = {Xu, Wei and Liu, Jibang and Zhang, Tong},\n title = {Data Manipulation Techniques to Reduce Phase Change Memory Write Energy},\n booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},\n series = {ISLPED '09},\n year = {2009},\n isbn = {978-1-60558-684-7},\n location = {San Fancisco, CA, USA},\n pages = {237--242},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1594233.1594290},\n doi = {10.1145/1594233.1594290},\n acmid = {1594290},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {low power, phase change memory},\n} \r\n",
        "key": "1594290",
        "pub_year": "2009",
        "text": "Wei Xu , Jibang Liu , Tong Zhang, Data manipulation techniques to reduce phase change memory write energy, Proceedings of the 2009 ACM/IEEE international symposium on Low power electronics and design, August 19-21, 2009, San Fancisco, CA, USA  \u00a0[doi>"
    },
    "1596548": {
        "abstract": "As the minimum fabrication technology of CMOS transistor shrink down to 90nm or below, the high standby power has become one of the major critical issues for the SRAM-based FPGA circuit due to the increasing leakage currents in the configuration memory. The integration of MRAM in FPGA instead of SRAM is one of the most promising solutions to overcome this issue, because its nonvolatility and high write/read speed allow to power down completely the logic blocks in \u201cidle\u201d states in the FPGA circuit. MRAM-based FPGA promises as well as some advanced reconfiguration methods such as runtime reconfiguration and multicontext configuration. However, the conventional MRAM technology based on field-induced magnetic switching (FIMS) writing approach consumes very high power, large circuit surface and produces high disturbance between memory cells. These drawbacks prevent FIMS-MRAM's further development in memory and logic circuit. Spin transfer torque (STT)-based MRAM is then evaluated to address these issues, some design techniques and novel computing architecture for FPGA logic circuits based on STT-MRAM technology are presented in this article. By using STMicroelectronics CMOS 90nm technology and a STT-MTJ spice model, some chip characteristic results as the programming latency and power have been calculated and simulated to demonstrate the expected performance of STT-MRAM based FPGA logic circuits.",
        "acm_key": "1596548",
        "bib_stats": {
            "cites": 16,
            "dl": 1,
            "dl_52": 96,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Zhao:2009:STT:1596543.1596548,\n author = {Zhao, Weisheng and Belhaire, Eric and Chappert, Claude and Mazoyer, Pascale},\n title = {Spin Transfer Torque (STT)-MRAM--based Runtime Reconfiguration FPGA Circuit},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {October 2009},\n volume = {9},\n number = {2},\n month = oct,\n year = {2009},\n issn = {1539-9087},\n pages = {14:1--14:16},\n articleno = {14},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/1596543.1596548},\n doi = {10.1145/1596543.1596548},\n acmid = {1596548},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FPGA, MRAM, System on Chip (SOC), architecture, low power, multicontext, nonvolatile, runtime reconfiguration (RTR), spin transfer torque (STT)},\n} \r\n",
        "key": "1596548",
        "pub_year": "2009",
        "text": "Weisheng Zhao , Eric Belhaire , Claude Chappert , Pascale Mazoyer, Spin transfer torque (STT)-MRAM--based runtime reconfiguration FPGA circuit, ACM Transactions on Embedded Computing Systems (TECS), v.9 n.2, p.1-16, October 2009  \u00a0[doi>"
    },
    "1629374": {
        "abstract": "This paper introduces parallelization strategies for the Non-Uniform FFT (NUFFT) data translation on multicore architectures. The NUFFT enables the use of the celebrated FFT with un-equally spaced data in numerous situations in signal and image processing as well as in scientific computing. The critical extension lies at the translation of non-equally spaced or non-uniformly sampled data onto an equally spaced Cartesian grid or vice versa. The data translation can be made sufficiently accurate, with the arithmetic complexity linearly proportional to the size of the data ensemble. For large NUFFTs, however, the data translation is found substantially dominant in computation time on modern computers while it is expected to be dominated by the FFT. In order to match the FFT performance achieved by FFTW, data locality and parallelism in the data translation must be explored and exploited as well. We are concerned with two fundamental issues. First, the data translation can be described as a matrix-vector multiplication with a matrix of irregular sparsity. This is beyond the effective scope of the conventional tiling and parallelization schemes applied by a compiler for performance improvement on computation with dense matrices. Secondly, multicore processors exist and emerge in many different configurations, and are expected to evolve further in architectural variety. This may mean the end of performance tuning on a single type of architecture. In this paper, we introduce an automation tool that takes two specifications as input, one on an application-specific data translation algorithm, the other on a target multicore processor architecture. The tool generates a parallel code that explores the data locality and parallelism by utilizing both geometric structures in data translation and the processor-memory configurations in the target architecture. We present preliminary experimental results on both a simulator and a commercial multicore machine. The results show that our parallelization strategy brings significant performance improvement for the NUFFT data translation by efficiently exploiting the data locality and concurrency in the application.",
        "acm_key": "1629374",
        "bib_stats": {
            "cites": 3,
            "dl": 382,
            "dl_52": 8,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Zuck:2009:NFF:1629335.1629374,\n author = {Zuck, Aviad and Barzilay, Ohad and Toledo, Sivan},\n title = {NANDFS: A Flexible Flash File System for RAM-constrained Systems},\n booktitle = {Proceedings of the Seventh ACM International Conference on Embedded Software},\n series = {EMSOFT '09},\n year = {2009},\n isbn = {978-1-60558-627-4},\n location = {Grenoble, France},\n pages = {285--294},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1629335.1629374},\n doi = {10.1145/1629335.1629374},\n acmid = {1629374},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash, RAM constrained, file system, flash, page mapping},\n} \r\n",
        "key": "1629374",
        "pub_year": "2009",
        "text": "Aviad Zuck , Ohad Barzilay , Sivan Toledo, NANDFS: a flexible flash file system for RAM-constrained systems, Proceedings of the seventh ACM international conference on Embedded software, October 12-16, 2009, Grenoble, France"
    },
    "1629375": {
        "abstract": "This paper introduces parallelization strategies for the Non-Uniform FFT (NUFFT) data translation on multicore architectures. The NUFFT enables the use of the celebrated FFT with un-equally spaced data in numerous situations in signal and image processing as well as in scientific computing. The critical extension lies at the translation of non-equally spaced or non-uniformly sampled data onto an equally spaced Cartesian grid or vice versa. The data translation can be made sufficiently accurate, with the arithmetic complexity linearly proportional to the size of the data ensemble. For large NUFFTs, however, the data translation is found substantially dominant in computation time on modern computers while it is expected to be dominated by the FFT. In order to match the FFT performance achieved by FFTW, data locality and parallelism in the data translation must be explored and exploited as well. We are concerned with two fundamental issues. First, the data translation can be described as a matrix-vector multiplication with a matrix of irregular sparsity. This is beyond the effective scope of the conventional tiling and parallelization schemes applied by a compiler for performance improvement on computation with dense matrices. Secondly, multicore processors exist and emerge in many different configurations, and are expected to evolve further in architectural variety. This may mean the end of performance tuning on a single type of architecture. In this paper, we introduce an automation tool that takes two specifications as input, one on an application-specific data translation algorithm, the other on a target multicore processor architecture. The tool generates a parallel code that explores the data locality and parallelism by utilizing both geometric structures in data translation and the processor-memory configurations in the target architecture. We present preliminary experimental results on both a simulator and a commercial multicore machine. The results show that our parallelization strategy brings significant performance improvement for the NUFFT data translation by efficiently exploiting the data locality and concurrency in the application.",
        "acm_key": "1629375",
        "bib_stats": {
            "cites": 24,
            "dl": 1,
            "dl_52": 73,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Kim:2009:DSS:1629335.1629375,\n author = {Kim, Jaeho and Oh, Yongseok and Kim, Eunsam and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},\n title = {Disk Schedulers for Solid State Drivers},\n booktitle = {Proceedings of the Seventh ACM International Conference on Embedded Software},\n series = {EMSOFT '09},\n year = {2009},\n isbn = {978-1-60558-627-4},\n location = {Grenoble, France},\n pages = {295--304},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1629335.1629375},\n doi = {10.1145/1629335.1629375},\n acmid = {1629375},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Linux, disk scheduler, implementation study, solid state drive},\n} \r\n",
        "key": "1629375",
        "pub_year": "2009",
        "text": "Jaeho Kim , Yongseok Oh , Eunsam Kim , Jongmoo Choi , Donghee Lee , Sam H. Noh, Disk schedulers for solid state drivers, Proceedings of the seventh ACM international conference on Embedded software, October 12-16, 2009, Grenoble, France  \u00a0[doi>"
    },
    "1629376": {
        "abstract": "This paper introduces parallelization strategies for the Non-Uniform FFT (NUFFT) data translation on multicore architectures. The NUFFT enables the use of the celebrated FFT with un-equally spaced data in numerous situations in signal and image processing as well as in scientific computing. The critical extension lies at the translation of non-equally spaced or non-uniformly sampled data onto an equally spaced Cartesian grid or vice versa. The data translation can be made sufficiently accurate, with the arithmetic complexity linearly proportional to the size of the data ensemble. For large NUFFTs, however, the data translation is found substantially dominant in computation time on modern computers while it is expected to be dominated by the FFT. In order to match the FFT performance achieved by FFTW, data locality and parallelism in the data translation must be explored and exploited as well. We are concerned with two fundamental issues. First, the data translation can be described as a matrix-vector multiplication with a matrix of irregular sparsity. This is beyond the effective scope of the conventional tiling and parallelization schemes applied by a compiler for performance improvement on computation with dense matrices. Secondly, multicore processors exist and emerge in many different configurations, and are expected to evolve further in architectural variety. This may mean the end of performance tuning on a single type of architecture. In this paper, we introduce an automation tool that takes two specifications as input, one on an application-specific data translation algorithm, the other on a target multicore processor architecture. The tool generates a parallel code that explores the data locality and parallelism by utilizing both geometric structures in data translation and the processor-memory configurations in the target architecture. We present preliminary experimental results on both a simulator and a commercial multicore machine. The results show that our parallelization strategy brings significant performance improvement for the NUFFT data translation by efficiently exploiting the data locality and concurrency in the application.",
        "acm_key": "1629376",
        "bib_stats": {
            "cites": 12,
            "dl": 344,
            "dl_52": 12,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Kang:2009:AAE:1629335.1629376,\n author = {Kang, Yangwook and Miller, Ethan L.},\n title = {Adding Aggressive Error Correction to a High-performance Compressing Flash File System},\n booktitle = {Proceedings of the Seventh ACM International Conference on Embedded Software},\n series = {EMSOFT '09},\n year = {2009},\n isbn = {978-1-60558-627-4},\n location = {Grenoble, France},\n pages = {305--314},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1629335.1629376},\n doi = {10.1145/1629335.1629376},\n acmid = {1629376},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {compression, file system, nand flash memory, non-volatile memory, reliability},\n} \r\n",
        "key": "1629376",
        "pub_year": "2009",
        "text": "Yangwook Kang , Ethan L. Miller, Adding aggressive error correction to a high-performance compressing flash file system, Proceedings of the seventh ACM international conference on Embedded software, October 12-16, 2009, Grenoble, France  \u00a0[doi>"
    },
    "1629486": {
        "abstract": "Currently, performance analysis of multimedia-MPSoC platforms largely rely on simulation. The execution of one or more applications on such a platform is simulated for a library of test video clips. If all specified performance constraints are satisfied for this library, then the architecture is assumed to be well-designed. This is similar to testing software for functional correctness. However, in contrast to functional testing, simulating a set of video clips for a complex application/architecture is extremely time consuming. In this paper we propose a technique for clustering a library of video clips, such that it is sufficient to simulate only one clip from each cluster rather than the entire library. Our clustering is scalable, i.e., the number of clusters may be determined based on the number of clips that the system designer wishes to simulate (which is independent of the input library size). For each video clip in the library, we perform a fast bitstream analysis from which the workload generated while processing this clip on the given architecture may be estimated. This workload information, in conjunction with a workload model and a performance model of the architecture, is used for the clustering. This entire process does not involve any simulation and is hence extremely fast. We illustrate its utility through a detailed case study using an MPEG-2 decoder application running on an MPSoC platform. As part of validation of our methodology, it was observed that video clips falling into the same cluster exhibit similar worst case buffer backlogs and worst case delays for one macroblock. Overall the results demonstrate that the proposed method provides a very fast and accurate analysis and hence can be of significant benefit to the system designer.",
        "acm_key": "1629486",
        "bib_stats": {
            "cites": 3,
            "dl": 235,
            "dl_52": 5,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Joo:2009:IAL:1629435.1629486,\n author = {Joo, Yongsoo and Cho, Youngjin and Lee, Kyungsoo and Chang, Naehyuck},\n title = {Improving Application Launch Times with Hybrid Disks},\n booktitle = {Proceedings of the 7th IEEE/ACM International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES+ISSS '09},\n year = {2009},\n isbn = {978-1-60558-628-1},\n location = {Grenoble, France},\n pages = {373--382},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1629435.1629486},\n doi = {10.1145/1629435.1629486},\n acmid = {1629486},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {application launch, hybrid disk, pinned set},\n} \r\n",
        "key": "1629486",
        "pub_year": "2009",
        "text": "Yongsoo Joo , Youngjin Cho , Kyungsoo Lee , Naehyuck Chang, Improving application launch times with hybrid disks, Proceedings of the 7th IEEE/ACM international conference on Hardware/software codesign and system synthesis, October 11-16, 2009, Grenoble, France"
    },
    "1629577": {
        "abstract": "Surprisingly, console logs rarely help operators detect problems in large-scale datacenter services, for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We first parse console logs by combining source code analysis with information retrieval to create composite features. We then analyze these features using machine learning to detect operational problems. We show that our method enables analyses that are impossible with previous methods because of its superior ability to create sophisticated features. We also show how to distill the results of our analysis to an operator-friendly one-page decision tree showing the critical messages associated with the detected problems. We validate our approach using the Darkstar online game server and the Hadoop File System, where we detect numerous real problems with high accuracy and few false positives. In the Hadoop case, we are able to analyze 24 million lines of console logs in 3 minutes. Our methodology works on textual console logs of any size and requires no changes to the service software, no human input, and no knowledge of the software's internals.",
        "acm_key": "1629577",
        "bib_stats": {
            "cites": 185,
            "dl": 2,
            "dl_52": 211,
            "dl_6": 5
        },
        "key": "1629577",
        "text": "David G. Andersen , Jason Franklin , Michael Kaminsky , Amar Phanishayee , Lawrence Tan , Vijay Vasudevan, FAWN: a fast array of wimpy nodes, Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, October 11-14, 2009, Big Sky, Montana, USA  \u00a0[doi>"
    },
    "1629936": {
        "abstract": "Exponentially rising cooling/packaging costs due to high power density call for architectural and software-level thermal management. Dynamic thermal management (DTM) techniques continuously monitor the on-chip processor temperature. Appropriate mechanisms (e.g., dynamic voltage or frequency scaling (DVFS), clock gating, fetch gating, etc.) are engaged to lower the temperature if it exceeds a threshold. However, all these mechanisms incur significant performance penalty. We argue that runtime adaptation of micro-architectural parameters, such as instruction window size and issue width, is a more effective mechanism for DTM. If the architectural parameters can be tailored to track the available instruction-level parallelism of the program, the temperature is reduced with minimal performance degradation. Moreover, synergistically combining architectural adaptation with DVFS and fetch gating can achieve the best performance under thermal constraints. The key difficulty in using multiple mechanisms is to select the optimal configuration at runtime for time varying workloads. We present a novel software-level thermal management framework that searches through the configuration space at regular intervals to find the best performing design point that is thermally safe. The central components of our framework are (1) a neural-network based classifier that filters the thermally unsafe configurations, (2) a fast performance prediction model for any configuration, and (3) an efficient configuration space search algorithm. Experimental results indicate that our adaptive scheme achieves 59% reduction in performance overhead compared to DVFS and 39% reduction in overhead compared to DVFS combined with fetch gating.",
        "acm_key": "1629936",
        "bib_stats": {
            "cites": 16,
            "dl": 302,
            "dl_52": 16,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Xu:2009:ISM:1629911.1629936,\n author = {Xu, Wei and Chen, Yiran and Wang, Xiaobin and Zhang, Tong},\n title = {Improving STT MRAM Storage Density Through Smaller-than-worst-case Transistor Sizing},\n booktitle = {Proceedings of the 46th Annual Design Automation Conference},\n series = {DAC '09},\n year = {2009},\n isbn = {978-1-60558-497-3},\n location = {San Francisco, California},\n pages = {87--90},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/1629911.1629936},\n doi = {10.1145/1629911.1629936},\n acmid = {1629936},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT MRAM, defect tolerance, transistor sizing},\n} \r\n",
        "key": "1629936",
        "pub_year": "2009",
        "text": "Wei Xu , Yiran Chen , Xiaobin Wang , Tong Zhang, Improving STT MRAM storage density through smaller-than-worst-case transistor sizing, Proceedings of the 46th Annual Design Automation Conference, July 26-31, 2009, San Francisco, California  \u00a0[doi>"
    },
    "1630086": {
        "abstract": "Exponentially rising cooling/packaging costs due to high power density call for architectural and software-level thermal management. Dynamic thermal management (DTM) techniques continuously monitor the on-chip processor temperature. Appropriate mechanisms (e.g., dynamic voltage or frequency scaling (DVFS), clock gating, fetch gating, etc.) are engaged to lower the temperature if it exceeds a threshold. However, all these mechanisms incur significant performance penalty. We argue that runtime adaptation of micro-architectural parameters, such as instruction window size and issue width, is a more effective mechanism for DTM. If the architectural parameters can be tailored to track the available instruction-level parallelism of the program, the temperature is reduced with minimal performance degradation. Moreover, synergistically combining architectural adaptation with DVFS and fetch gating can achieve the best performance under thermal constraints. The key difficulty in using multiple mechanisms is to select the optimal configuration at runtime for time varying workloads. We present a novel software-level thermal management framework that searches through the configuration space at regular intervals to find the best performing design point that is thermally safe. The central components of our framework are (1) a neural-network based classifier that filters the thermally unsafe configurations, (2) a fast performance prediction model for any configuration, and (3) an efficient configuration space search algorithm. Experimental results indicate that our adaptive scheme achieves 59% reduction in performance overhead compared to DVFS and 39% reduction in overhead compared to DVFS combined with fetch gating.",
        "acm_key": "1630086",
        "bib_stats": {
            "cites": 93,
            "dl": 475,
            "dl_52": 46,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Dhiman:2009:PHP:1629911.1630086,\n author = {Dhiman, Gaurav and Ayoub, Raid and Rosing, Tajana},\n title = {PDRAM: A Hybrid PRAM and DRAM Main Memory System},\n booktitle = {Proceedings of the 46th Annual Design Automation Conference},\n series = {DAC '09},\n year = {2009},\n isbn = {978-1-60558-497-3},\n location = {San Francisco, California},\n pages = {664--469},\n numpages = {-194},\n url = {http://doi.acm.org/10.1145/1629911.1630086},\n doi = {10.1145/1629911.1630086},\n acmid = {1630086},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy efficiency, memory management, phase change memory},\n} \r\n",
        "key": "1630086",
        "pub_year": "2009",
        "text": "Gaurav Dhiman , Raid Ayoub , Tajana Rosing, PDRAM: a hybrid PRAM and DRAM main memory system, Proceedings of the 46th Annual Design Automation Conference, July 26-31, 2009, San Francisco, California  \u00a0[doi>"
    },
    "1637751": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1637751",
        "bib_stats": {
            "cites": 51,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhang:2009:EPC:1636712.1637751,\n author = {Zhang, Wangyuan and Li, Tao},\n title = {Exploring Phase Change Memory and 3D Die-Stacking for Power/Thermal Friendly, Fast and Durable Memory Architectures},\n booktitle = {Proceedings of the 2009 18th International Conference on Parallel Architectures and Compilation Techniques},\n series = {PACT '09},\n year = {2009},\n isbn = {978-0-7695-3771-9},\n pages = {101--112},\n numpages = {12},\n url = {https://doi.org/10.1109/PACT.2009.30},\n doi = {10.1109/PACT.2009.30},\n acmid = {1637751},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1637751",
        "pub_year": "2009",
        "text": "Wangyuan Zhang , Tao Li, Exploring Phase Change Memory and 3D Die-Stacking for Power/Thermal Friendly, Fast and Durable Memory Architectures, Proceedings of the 2009 18th International Conference on Parallel Architectures and Compilation Techniques, p.101-112, September 12-16, 2009  \u00a0[doi>"
    },
    "1638162": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1638162",
        "bib_stats": {
            "cites": 36,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2009:FSN:1637862.1638162,\n author = {Kim, Youngjae and Tauras, Brendan and Gupta, Aayush and Urgaonkar, Bhuvan},\n title = {FlashSim: A Simulator for NAND Flash-Based Solid-State Drives},\n booktitle = {Proceedings of the 2009 First International Conference on Advances in System Simulation},\n series = {SIMUL '09},\n year = {2009},\n isbn = {978-0-7695-3773-3},\n pages = {125--131},\n numpages = {7},\n url = {https://doi.org/10.1109/SIMUL.2009.17},\n doi = {10.1109/SIMUL.2009.17},\n acmid = {1638162},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash Memory, Simulator Design},\n} \r\n",
        "key": "1638162",
        "pub_year": "2009",
        "text": "Youngjae Kim , Brendan Tauras , Aayush Gupta , Bhuvan Urgaonkar, FlashSim: A Simulator for NAND Flash-Based Solid-State Drives, Proceedings of the 2009 First International Conference on Advances in System Simulation, p.125-131, September 20-25, 2009  \u00a0[doi>"
    },
    "1654117": {
        "abstract": "The UNIC code is being developed as part of the DOE's Nuclear Energy Advanced Modeling and Simulation (NEAMS) program. UNIC is an unstructured, deterministic neutron transport code that allows a highly detailed description of a nuclear reactor. The primary goal of our simulation efforts is to reduce the uncertainties and biases in reactor design calculations by progressively replacing existing multilevel averaging (homogenization) techniques with more direct solution methods based on first principles. Since the neutron transport equation is seven dimensional (three in space, two in angle, one in energy, and one in time), these simulations are among the most memory and computationally intensive in all of computational science. In order to model the complex physics of a reactor core, billions of spatial elements, hundreds of angles, and thousands of energy groups are necessary, leading to problem sizes with petascale degrees of freedom. Therefore, these calculations exhaust memory resources on current and even next-generation architectures. In this paper, we present UNIC simulation results for two important representative problems in reactor design and analysis---PHENIX and ZPR-6. In each case, UNIC shows good weak scalability on up to 163,840 cores of Blue Gene/P (Argonne) and 122,800 cores of XT5 (Oak Ridge). While our current per processor performance is less than ideal, we demonstrate a clear ability to effectively utilize the leadership computing platforms. Over the coming months, we aim to improve the per processor performance while maintaining the high parallel efficiency by employing better algorithms such as spatial ",
        "acm_key": "1654117",
        "bib_stats": {
            "cites": 37,
            "dl": 637,
            "dl_52": 45,
            "dl_6": 10
        },
        "bibtex": "\r\n@inproceedings{Dong:2009:LPT:1654059.1654117,\n author = {Dong, Xiangyu and Muralimanohar, Naveen and Jouppi, Norm and Kaufmann, Richard and Xie, Yuan},\n title = {Leveraging 3D PCRAM Technologies to Reduce Checkpoint Overhead for Future Exascale Systems},\n booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},\n series = {SC '09},\n year = {2009},\n isbn = {978-1-60558-744-8},\n location = {Portland, Oregon},\n pages = {57:1--57:12},\n articleno = {57},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1654059.1654117},\n doi = {10.1145/1654059.1654117},\n acmid = {1654117},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1654117",
        "pub_year": "2009",
        "text": "Xiangyu Dong , Naveen Muralimanohar , Norm Jouppi , Richard Kaufmann , Yuan Xie, Leveraging 3D PCRAM technologies to reduce checkpoint overhead for future exascale systems, Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis, November 14-20, 2009, Portland, Oregon  \u00a0[doi>"
    },
    "165907": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "165907",
        "bib_stats": {
            "cites": 11,
            "dl": 265,
            "dl_52": 12,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Hosking:1993:OFH:165854.165907,\n author = {Hosking, Antony L. and Moss, J. Eliot B.},\n title = {Object Fault Handling for Persistent Programming Languages: A Performance Evaluation},\n booktitle = {Proceedings of the Eighth Annual Conference on Object-oriented Programming Systems, Languages, and Applications},\n series = {OOPSLA '93},\n year = {1993},\n isbn = {0-89791-587-9},\n location = {Washington, D.C., USA},\n pages = {288--303},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/165854.165907},\n doi = {10.1145/165854.165907},\n acmid = {165907},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=165907&parent_id=165854&expformat=bibtex&CFID=982034429&CFTOKEN=56822268\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"165907\">\r\n@article{Hosking:1993:OFH:167962.165907,\n author = {Hosking, Antony L. and Moss, J. Eliot B.},\n title = {Object Fault Handling for Persistent Programming Languages: A Performance Evaluation},\n journal = {SIGPLAN Not.},\n issue_date = {Oct. 1, 1993},\n volume = {28},\n number = {10},\n month = oct,\n year = {1993},\n issn = {0362-1340},\n pages = {288--303},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/167962.165907},\n doi = {10.1145/167962.165907},\n acmid = {165907},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "165907",
        "pub_year": "1993",
        "text": "Antony L. Hosking , J. Eliot B. Moss, Object fault handling for persistent programming languages: a performance evaluation, ACM SIGPLAN Notices, v.28 n.10, p.288-303, Oct. 1, 1993  \u00a0[doi>"
    },
    "1669116": {
        "abstract": "Modern DRAM systems rely on memory controllers that employ out-of-order scheduling to maximize row access locality and bank-level parallelism, which in turn maximizes DRAM bandwidth. This is especially important in graphics processing unit (GPU) architectures, where the large quantity of parallelism places a heavy demand on the memory system. The logic needed for out-of-order scheduling can be expensive in terms of area, especially when compared to an in-order scheduling approach. In this paper, we propose a complexity-effective solution to DRAM request scheduling which recovers most of the performance loss incurred by a naive in-order first-in first-out (FIFO) DRAM scheduler compared to an aggressive out-of-order DRAM scheduler. We observe that the memory request stream from individual GPU \"shader cores\" tends to have sufficient row access locality to maximize DRAM efficiency in most applications without significant reordering. However, the interconnection network across which memory requests are sent from the shader cores to the DRAM controller tends to finely interleave the numerous memory request streams in a way that destroys the row access locality of the resultant stream seen at the DRAM controller. To address this, we employ an interconnection network arbitration scheme that preserves the row access locality of individual memory request streams and, in doing so, achieves DRAM efficiency and system performance close to that achievable by using out-of-order memory request scheduling while doing so with a simpler design. We evaluate our interconnection network arbitration scheme using crossbar, mesh, and ring networks for a baseline architecture of 8 memory channels, each controlled by its own DRAM controller and 28 shader cores (224 ALUs), supporting up to 1,792 in-flight memory requests. Our results show that our interconnect arbitration scheme coupled with a banked FIFO in-order scheduler obtains up to 91% of the performance obtainable with an out-of-order memory scheduler for a crossbar network with eight-entry DRAM controller queues.",
        "acm_key": "1669116",
        "bib_stats": {
            "cites": 40,
            "dl": 791,
            "dl_52": 41,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Zhang:2009:CMI:1669112.1669116,\n author = {Zhang, Wangyuan and Li, Tao},\n title = {Characterizing and Mitigating the Impact of Process Variations on Phase Change Based Memory Systems},\n booktitle = {Proceedings of the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO 42},\n year = {2009},\n isbn = {978-1-60558-798-1},\n location = {New York, New York},\n pages = {2--13},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1669112.1669116},\n doi = {10.1145/1669112.1669116},\n acmid = {1669116},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory system, phase change memory, process variation},\n} \r\n",
        "key": "1669116",
        "pub_year": "2009",
        "text": "Wangyuan Zhang , Tao Li, Characterizing and mitigating the impact of process variations on phase change based memory systems, Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, December 12-16, 2009, New York, New York  \u00a0[doi>"
    },
    "1669117": {
        "abstract": "Modern DRAM systems rely on memory controllers that employ out-of-order scheduling to maximize row access locality and bank-level parallelism, which in turn maximizes DRAM bandwidth. This is especially important in graphics processing unit (GPU) architectures, where the large quantity of parallelism places a heavy demand on the memory system. The logic needed for out-of-order scheduling can be expensive in terms of area, especially when compared to an in-order scheduling approach. In this paper, we propose a complexity-effective solution to DRAM request scheduling which recovers most of the performance loss incurred by a naive in-order first-in first-out (FIFO) DRAM scheduler compared to an aggressive out-of-order DRAM scheduler. We observe that the memory request stream from individual GPU \"shader cores\" tends to have sufficient row access locality to maximize DRAM efficiency in most applications without significant reordering. However, the interconnection network across which memory requests are sent from the shader cores to the DRAM controller tends to finely interleave the numerous memory request streams in a way that destroys the row access locality of the resultant stream seen at the DRAM controller. To address this, we employ an interconnection network arbitration scheme that preserves the row access locality of individual memory request streams and, in doing so, achieves DRAM efficiency and system performance close to that achievable by using out-of-order memory request scheduling while doing so with a simpler design. We evaluate our interconnection network arbitration scheme using crossbar, mesh, and ring networks for a baseline architecture of 8 memory channels, each controlled by its own DRAM controller and 28 shader cores (224 ALUs), supporting up to 1,792 in-flight memory requests. Our results show that our interconnect arbitration scheme coupled with a banked FIFO in-order scheduler obtains up to 91% of the performance obtainable with an out-of-order memory scheduler for a crossbar network with eight-entry DRAM controller queues.",
        "acm_key": "1669117",
        "bib_stats": {
            "cites": 147,
            "dl": 1,
            "dl_52": 153,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Qureshi:2009:ELS:1669112.1669117,\n author = {Qureshi, Moinuddin K. and Karidis, John and Franceschini, Michele and Srinivasan, Vijayalakshmi and Lastras, Luis and Abali, Bulent},\n title = {Enhancing Lifetime and Security of PCM-based Main Memory with Start-gap Wear Leveling},\n booktitle = {Proceedings of the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO 42},\n year = {2009},\n isbn = {978-1-60558-798-1},\n location = {New York, New York},\n pages = {14--23},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1669112.1669117},\n doi = {10.1145/1669112.1669117},\n acmid = {1669117},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, phase change memory, wear leveling},\n} \r\n",
        "key": "1669117",
        "pub_year": "2009",
        "text": "Moinuddin K. Qureshi , John Karidis , Michele Franceschini , Vijayalakshmi Srinivasan , Luis Lastras , Bulent Abali, Enhancing lifetime and security of PCM-based main memory with start-gap wear leveling, Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, December 12-16, 2009, New York, New York  \u00a0[doi>"
    },
    "1669118": {
        "abstract": "Modern DRAM systems rely on memory controllers that employ out-of-order scheduling to maximize row access locality and bank-level parallelism, which in turn maximizes DRAM bandwidth. This is especially important in graphics processing unit (GPU) architectures, where the large quantity of parallelism places a heavy demand on the memory system. The logic needed for out-of-order scheduling can be expensive in terms of area, especially when compared to an in-order scheduling approach. In this paper, we propose a complexity-effective solution to DRAM request scheduling which recovers most of the performance loss incurred by a naive in-order first-in first-out (FIFO) DRAM scheduler compared to an aggressive out-of-order DRAM scheduler. We observe that the memory request stream from individual GPU \"shader cores\" tends to have sufficient row access locality to maximize DRAM efficiency in most applications without significant reordering. However, the interconnection network across which memory requests are sent from the shader cores to the DRAM controller tends to finely interleave the numerous memory request streams in a way that destroys the row access locality of the resultant stream seen at the DRAM controller. To address this, we employ an interconnection network arbitration scheme that preserves the row access locality of individual memory request streams and, in doing so, achieves DRAM efficiency and system performance close to that achievable by using out-of-order memory request scheduling while doing so with a simpler design. We evaluate our interconnection network arbitration scheme using crossbar, mesh, and ring networks for a baseline architecture of 8 memory channels, each controlled by its own DRAM controller and 28 shader cores (224 ALUs), supporting up to 1,792 in-flight memory requests. Our results show that our interconnect arbitration scheme coupled with a banked FIFO in-order scheduler obtains up to 91% of the performance obtainable with an out-of-order memory scheduler for a crossbar network with eight-entry DRAM controller queues.",
        "acm_key": "1669118",
        "bib_stats": {
            "cites": 107,
            "dl": 701,
            "dl_52": 26,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Grupp:2009:CFM:1669112.1669118,\n author = {Grupp, Laura M. and Caulfield, Adrian M. and Coburn, Joel and Swanson, Steven and Yaakobi, Eitan and Siegel, Paul H. and Wolf, Jack K.},\n title = {Characterizing Flash Memory: Anomalies, Observations, and Applications},\n booktitle = {Proceedings of the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO 42},\n year = {2009},\n isbn = {978-1-60558-798-1},\n location = {New York, New York},\n pages = {24--33},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1669112.1669118},\n doi = {10.1145/1669112.1669118},\n acmid = {1669118},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {characterization, flash memory, non-volatile},\n} \r\n",
        "key": "1669118",
        "pub_year": "2009",
        "text": "Laura M. Grupp , Adrian M. Caulfield , Joel Coburn , Steven Swanson , Eitan Yaakobi , Paul H. Siegel , Jack K. Wolf, Characterizing flash memory: anomalies, observations, and applications, Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, December 12-16, 2009, New York, New York"
    },
    "1669157": {
        "abstract": "Modern DRAM systems rely on memory controllers that employ out-of-order scheduling to maximize row access locality and bank-level parallelism, which in turn maximizes DRAM bandwidth. This is especially important in graphics processing unit (GPU) architectures, where the large quantity of parallelism places a heavy demand on the memory system. The logic needed for out-of-order scheduling can be expensive in terms of area, especially when compared to an in-order scheduling approach. In this paper, we propose a complexity-effective solution to DRAM request scheduling which recovers most of the performance loss incurred by a naive in-order first-in first-out (FIFO) DRAM scheduler compared to an aggressive out-of-order DRAM scheduler. We observe that the memory request stream from individual GPU \"shader cores\" tends to have sufficient row access locality to maximize DRAM efficiency in most applications without significant reordering. However, the interconnection network across which memory requests are sent from the shader cores to the DRAM controller tends to finely interleave the numerous memory request streams in a way that destroys the row access locality of the resultant stream seen at the DRAM controller. To address this, we employ an interconnection network arbitration scheme that preserves the row access locality of individual memory request streams and, in doing so, achieves DRAM efficiency and system performance close to that achievable by using out-of-order memory request scheduling while doing so with a simpler design. We evaluate our interconnection network arbitration scheme using crossbar, mesh, and ring networks for a baseline architecture of 8 memory channels, each controlled by its own DRAM controller and 28 shader cores (224 ALUs), supporting up to 1,792 in-flight memory requests. Our results show that our interconnect arbitration scheme coupled with a banked FIFO in-order scheduler obtains up to 91% of the performance obtainable with an out-of-order memory scheduler for a crossbar network with eight-entry DRAM controller queues.",
        "acm_key": "1669157",
        "bib_stats": {
            "cites": 113,
            "dl": 560,
            "dl_52": 49,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Cho:2009:FSD:1669112.1669157,\n author = {Cho, Sangyeun and Lee, Hyunjin},\n title = {Flip-N-Write: A Simple Deterministic Technique to Improve PRAM Write Performance, Energy and Endurance},\n booktitle = {Proceedings of the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO 42},\n year = {2009},\n isbn = {978-1-60558-798-1},\n location = {New York, New York},\n pages = {347--357},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/1669112.1669157},\n doi = {10.1145/1669112.1669157},\n acmid = {1669157},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory write performance, phase-change memory},\n} \r\n",
        "key": "1669157",
        "pub_year": "2009",
        "text": "Sangyeun Cho , Hyunjin Lee, Flip-N-Write: a simple deterministic technique to improve PRAM write performance, energy and endurance, Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, December 12-16, 2009, New York, New York  \u00a0[doi>"
    },
    "1685904": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1685904",
        "bib_stats": {
            "cites": 27,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Chang:2010:IFW:1685866.1685904,\n author = {Chang, Yuan-Hao and Hsieh, Jen-Wei and Kuo, Tei-Wei},\n title = {Improving Flash Wear-Leveling by Proactively Moving Static Data},\n journal = {IEEE Trans. Comput.},\n issue_date = {January 2010},\n volume = {59},\n number = {1},\n month = jan,\n year = {2010},\n issn = {0018-9340},\n pages = {53--65},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TC.2009.134},\n doi = {10.1109/TC.2009.134},\n acmid = {1685904},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash memory, Flash memory, wear leveling, endurance, reliability., endurance, reliability., wear leveling},\n} \r\n",
        "key": "1685904",
        "pub_year": "2010",
        "text": "Yuan-Hao Chang , Jen-Wei Hsieh , Tei-Wei Kuo, Improving Flash Wear-Leveling by Proactively Moving Static Data, IEEE Transactions on Computers, v.59 n.1, p.53-65, January 2010  \u00a0[doi>"
    },
    "168631": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "168631",
        "bib_stats": {
            "cites": 37,
            "dl": 926,
            "dl_52": 32,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Satyanarayanan:1993:LRV:168619.168631,\n author = {Satyanarayanan, M. and Mashburn, Henry H. and Kumar, Puneet and Steere, David C. and Kistler, James J.},\n title = {Lightweight Recoverable Virtual Memory},\n booktitle = {Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles},\n series = {SOSP '93},\n year = {1993},\n isbn = {0-89791-632-8},\n location = {Asheville, North Carolina, USA},\n pages = {146--160},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/168619.168631},\n doi = {10.1145/168619.168631},\n acmid = {168631},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=168631&parent_id=168619&expformat=bibtex&CFID=982033868&CFTOKEN=46854995\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"168631\">\r\n@article{Satyanarayanan:1993:LRV:173668.168631,\n author = {Satyanarayanan, M. and Mashburn, Henry H. and Kumar, Puneet and Steere, David C. and Kistler, James J.},\n title = {Lightweight Recoverable Virtual Memory},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 1993},\n volume = {27},\n number = {5},\n month = dec,\n year = {1993},\n issn = {0163-5980},\n pages = {146--160},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/173668.168631},\n doi = {10.1145/173668.168631},\n acmid = {168631},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "168631",
        "pub_year": "1994",
        "text": "M. Satyanarayanan , Henry H. Mashburn , Puneet Kumar , David C. Steere , James J. Kistler, Lightweight recoverable virtual memory, Proceedings of the fourteenth ACM symposium on Operating systems principles, p.146-160, December 05-08, 1993, Asheville, North Carolina, USA"
    },
    "1687448": {
        "abstract": "Accurate and fast estimation of VLSI interconnect thermal profiles has become critically important to estimate their impact on circuit/system performance and reliability, which is necessary for reducing product development time and achieving first-pass silicon success. Present commercial thermal analysis tools are incapable of simulating complex structures, particularly in the 3-D domain and are also difficult to integrate with existing design tools. Existing analytical thermal models are not perfect either: they are either not accurate enough or oversimplified. This paper uses a methodology, which exploits existing electrical resistance solvers for thermal simulation, to allow fast acquisition of thermal profiles of complex interconnect structures with good accuracy and reasonable computation cost. Moreover, for the first time, an accurate closed-form thermal model is developed. The model allows for an equivalent medium with effective thermal conductivity (isotropic or anisotropic) to replace the detailed material information in non-critical regions so that complex interconnect structures can be simulated. Using these techniques, this paper demonstrates the simulation of a very complex interconnect structure (~9000 objects or 15 million meshed unknowns after first order isotropic equivalent medium replacement), which is a first time achievement in the area of interconnect thermal analysis. On the other hand, it is shown that an anisotropic equivalent medium is a much better approximation of real interconnect structures from the point of view of accuracy and computation.",
        "acm_key": "1687448",
        "bib_stats": {
            "cites": 67,
            "dl": 443,
            "dl_52": 54,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Zhou:2009:ERS:1687399.1687448,\n author = {Zhou, Ping and Zhao, Bo and Yang, Jun and Zhang, Youtao},\n title = {Energy Reduction for STT-RAM Using Early Write Termination},\n booktitle = {Proceedings of the 2009 International Conference on Computer-Aided Design},\n series = {ICCAD '09},\n year = {2009},\n isbn = {978-1-60558-800-1},\n location = {San Jose, California},\n pages = {264--268},\n numpages = {5},\n url = {http://doi.acm.org/10.1145/1687399.1687448},\n doi = {10.1145/1687399.1687448},\n acmid = {1687448},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1687448",
        "pub_year": "2009",
        "text": "Ping Zhou , Bo Zhao , Jun Yang , Youtao Zhang, Energy reduction for STT-RAM using early write termination, Proceedings of the 2009 International Conference on Computer-Aided Design, November 02-05, 2009, San Jose, California  \u00a0[doi>"
    },
    "1687491": {
        "abstract": "Accurate and fast estimation of VLSI interconnect thermal profiles has become critically important to estimate their impact on circuit/system performance and reliability, which is necessary for reducing product development time and achieving first-pass silicon success. Present commercial thermal analysis tools are incapable of simulating complex structures, particularly in the 3-D domain and are also difficult to integrate with existing design tools. Existing analytical thermal models are not perfect either: they are either not accurate enough or oversimplified. This paper uses a methodology, which exploits existing electrical resistance solvers for thermal simulation, to allow fast acquisition of thermal profiles of complex interconnect structures with good accuracy and reasonable computation cost. Moreover, for the first time, an accurate closed-form thermal model is developed. The model allows for an equivalent medium with effective thermal conductivity (isotropic or anisotropic) to replace the detailed material information in non-critical regions so that complex interconnect structures can be simulated. Using these techniques, this paper demonstrates the simulation of a very complex interconnect structure (~9000 objects or 15 million meshed unknowns after first order isotropic equivalent medium replacement), which is a first time achievement in the area of interconnect thermal analysis. On the other hand, it is shown that an anisotropic equivalent medium is a much better approximation of real interconnect structures from the point of view of accuracy and computation.",
        "acm_key": "1687491",
        "bib_stats": {
            "cites": 43,
            "dl": 654,
            "dl_52": 101,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Ho:2009:NMM:1687399.1687491,\n author = {Ho, Yenpo and Huang, Garng M. and Li, Peng},\n title = {Nonvolatile Memristor Memory: Device Characteristics and Design Implications},\n booktitle = {Proceedings of the 2009 International Conference on Computer-Aided Design},\n series = {ICCAD '09},\n year = {2009},\n isbn = {978-1-60558-800-1},\n location = {San Jose, California},\n pages = {485--490},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1687399.1687491},\n doi = {10.1145/1687399.1687491},\n acmid = {1687491},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1687491",
        "pub_year": "2009",
        "text": "Yenpo Ho , Garng M. Huang , Peng Li, Nonvolatile memristor memory: device characteristics and design implications, Proceedings of the 2009 International Conference on Computer-Aided Design, November 02-05, 2009, San Jose, California  \u00a0[doi>"
    },
    "1687669": {
        "abstract": "The availability of huge system memory, even on standard servers, generated a lot of interest in main memory database engines. In data warehouse systems, highly compressed column-oriented data structures are quite prominent. In order to scale with the data volume and the system load, many of these systems are highly distributed with a shared-nothing approach. The fundamental principle of all systems is a full table scan over one or multiple compressed columns. Recent research proposed different techniques to speedup table scans like intelligent compression or using an additional hardware such as graphic cards or FPGAs. In this paper, we show that utilizing the embedded Vector Processing Units (VPUs) found in standard superscalar processors can speed up the performance of mainmemory full table scan by factors. This is achieved without changing the hardware architecture and thereby without additional power consumption. Moreover, as on-chip VPUs directly access the system's RAM, no additional costly copy operations are needed for using the new SIMD-scan approach in standard main memory database engines. Therefore, we propose this scan approach to be used as the standard scan operator for compressed column-oriented main memory storage. We then discuss how well our solution scales with the number of processor cores; consequently, to what degree it can be applied in multi-threaded environments. To verify the feasibility of our approach, we implemented the proposed techniques on a modern Intel multi-core processor using Intel\u00ae Streaming SIMD Extensions (Intel\u00ae SSE). In addition, we integrated the new SIMD-scan approach into SAP\u00ae Netweaver\u00ae Business Warehouse Accelerator. We conclude with describing the performance benefits of using our approach for processing and scanning compressed data using VPUs in column-oriented main memory database systems.",
        "acm_key": "1687669",
        "bib_stats": {
            "cites": 57,
            "dl": 439,
            "dl_52": 20,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Agrawal:2009:LTO:1687627.1687669,\n author = {Agrawal, Devesh and Ganesan, Deepak and Sitaraman, Ramesh and Diao, Yanlei and Singh, Shashi},\n title = {Lazy-Adaptive Tree: An Optimized Index Structure for Flash Devices},\n journal = {Proc. VLDB Endow.},\n issue_date = {August 2009},\n volume = {2},\n number = {1},\n month = aug,\n year = {2009},\n issn = {2150-8097},\n pages = {361--372},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/1687627.1687669},\n doi = {10.14778/1687627.1687669},\n acmid = {1687669},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1687669",
        "pub_year": "2009",
        "text": "Devesh Agrawal , Deepak Ganesan , Ramesh Sitaraman , Yanlei Diao , Shashi Singh, Lazy-Adaptive Tree: an optimized index structure for flash devices, Proceedings of the VLDB Endowment, v.2 n.1, August 2009"
    },
    "1694299": {
        "abstract": "MapReduce is a distributed processing algorithm which breaks up large problem sets into small pieces, such that a large cluster of computers can work on those small pieces in an efficient, timely manner. MapReduce was created and popularized by Google, and is widely used as a means of processing large amounts of textual data for the purpose of indexing it for search later on. This paper examines the feasibility of using smart mobile devices in a MapReduce system by exploring several areas, including quantifying the contribution they make to computation throughput, end-user participation, power consumption, and security. The proposed MapReduce System over Heterogeneous Mobile Devices consists of three key components: a server component that coordinates and aggregates results, a mobile device client for iPhone, and a traditional client for reference and to obtain baseline data. A prototypical research implementation demonstrates that it is indeed feasible to leverage smart mobile devices in heterogeneous MapReduce systems, provided certain conditions are understood and accepted. MapReduce systems could see sizable gains of processing throughput by incorporating as many mobile devices as possible in such a heterogeneous environment. Considering the massive number of such devices available and in active use today, this is a reasonably attainable goal and represents an exciting area of study. This paper introduces relevant background material, discusses related work, describes the proposed system, explains obtained results, and finally, discusses topics for further research in this area.",
        "acm_key": "1694299",
        "bib_stats": {
            "cites": 4
        },
        "bibtex": "\r\n@inproceedings{Park:2009:PMS:1694296.1694299,\n author = {Park, Jinha and Yoo, Sungjoo and Lee, Sunggu and Park, Chanik},\n title = {Power Modeling of Solid State Disk for Dynamic Power Management Policy Design in Embedded Systems},\n booktitle = {Proceedings of the 7th IFIP WG 10.2 International Workshop on Software Technologies for Embedded and Ubiquitous Systems},\n series = {SEUS '09},\n year = {2009},\n isbn = {978-3-642-10264-6},\n location = {Newport Beach, CA},\n pages = {24--35},\n numpages = {12},\n url = {http://dx.doi.org/10.1007/978-3-642-10265-3_3},\n doi = {10.1007/978-3-642-10265-3_3},\n acmid = {1694299},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {Solid state disk, dynamic power management, low power states, measurement, power consumption, trace-based simulation},\n} \r\n",
        "key": "1694299",
        "pub_year": "2009",
        "text": "Jinha Park , Sungjoo Yoo , Sunggu Lee , Chanik Park, Power Modeling of Solid State Disk for Dynamic Power Management Policy Design in Embedded Systems, Proceedings of the 7th IFIP WG 10.2 International Workshop on Software Technologies for Embedded and Ubiquitous Systems, p.24-35, November 16-18, 2009, Newport Beach, CA"
    },
    "1698786": {
        "abstract": "We propose a technique that leverages configurable data caches to address the problem of energy inefficiency and intertask interference in multitasking embedded systems. Data caches are often necessary to provide the required memory bandwidth. However, caches introduce two important problems for embedded systems. Caches contribute to a significant amount of power as they typically occupy a large part of the chip and are accessed frequently. In nanometer technologies, such large structures contribute significantly to the total leakage power as well. Additionally, cache outcomes in multitasking environments are notoriously difficult to predict, if not impossible, thus resulting in poor real-time guarantees. We study the effect of multiprogramming workloads on the data cache in a preemptive multitasking environment, and propose a technique which leverages configurable cache architectures to not only eliminate intertask cache interference, but also to significantly reduce both dynamic and leakage power. By mapping tasks to different cache partitions, interference is completely eliminated. Dynamic and leakage power are significantly reduced as only a subset of the cache is active at any moment. We introduce a profile-based, off-line algorithm, which identifies a beneficial cache partitioning. The OS configures the data cache during context-switch by activating the corresponding partition. Our experiments on a large set of multitasking benchmarks demonstrate that our technique not only efficiently eliminates intertask interference, but also significantly reduces both dynamic and leakage power.",
        "acm_key": "1698786",
        "bib_stats": {
            "cites": 1,
            "dl": 358,
            "dl_52": 14,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Cesana:2010:MME:1698772.1698786,\n author = {Cesana, Ulpian and He, Zhen},\n title = {Multi-buffer Manager: Energy-efficient Buffer Manager for Databases on Flash Memory},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {February 2010},\n volume = {9},\n number = {3},\n month = mar,\n year = {2010},\n issn = {1539-9087},\n pages = {28:1--28:36},\n articleno = {28},\n numpages = {36},\n url = {http://doi.acm.org/10.1145/1698772.1698786},\n doi = {10.1145/1698772.1698786},\n acmid = {1698786},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, buffer manager, cache manager, database, embedded device, energy efficiency, flash drive, page replacement},\n} \r\n",
        "key": "1698786",
        "pub_year": "2010",
        "text": "Ulpian Cesana , Zhen He, Multi-buffer manager: Energy-efficient buffer manager for databases on flash memory, ACM Transactions on Embedded Computing Systems (TECS), v.9 n.3, p.1-36, February 2010"
    },
    "1713276": {
        "abstract": "Digital provenance is meta-data that describes the ancestry or history of a digital object. Most work on provenance focuses on how provenance increases the value of data to consumers. However, provenance is also valuable to storage providers. For example, provenance can provide hints on access patterns, detect anomalous behavior, and provide enhanced user search capabilities. As the next generation storage providers, cloud vendors are in the unique position to capitalize on this opportunity to incorporate provenance as a fundamental storage system primitive. To date, cloud offerings have not yet done so. We provide motivation for providers to treat provenance as first class data in the cloud and based on our experience with provenance in a local storage system, suggest a set of requirements that make provenance feasible and attractive.",
        "acm_key": "1713276",
        "bib_stats": {
            "cites": 109,
            "dl": 1,
            "dl_52": 118,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Ousterhout:2010:CRS:1713254.1713276,\n author = {Ousterhout, John and Agrawal, Parag and Erickson, David and Kozyrakis, Christos and Leverich, Jacob and Mazi\\`{e}res, David and Mitra, Subhasish and Narayanan, Aravind and Parulkar, Guru and Rosenblum, Mendel and Rumble, Stephen M. and Stratmann, Eric and Stutsman, Ryan},\n title = {The Case for RAMClouds: Scalable High-performance Storage Entirely in DRAM},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {January 2010},\n volume = {43},\n number = {4},\n month = jan,\n year = {2010},\n issn = {0163-5980},\n pages = {92--105},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1713254.1713276},\n doi = {10.1145/1713254.1713276},\n acmid = {1713276},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1713276",
        "pub_year": "2010",
        "text": "John Ousterhout , Parag Agrawal , David Erickson , Christos Kozyrakis , Jacob Leverich , David Mazi\u00e8res , Subhasish Mitra , Aravind Narayanan , Guru Parulkar , Mendel Rosenblum , Stephen M. Rumble , Eric Stratmann , Ryan Stutsman, The case for RAMClouds: scalable high-performance storage entirely in DRAM, ACM SIGOPS Operating Systems Review, v.43 n.4, January 2010  \u00a0[doi>"
    },
    "1736023": {
        "abstract": "SIMD (Single Instruction, Multiple Data) engines are an essential part of the processors in various computing markets, from servers to the embedded domain. Although SIMD-enabled architectures have the capability of boosting the performance of many application domains by exploiting data-level parallelism, it is very challenging for compilers and also programmers to identify and transform parts of a program that will benefit from a particular SIMD engine. The focus of this paper is on the problem of SIMDization for the growing application domain of streaming. Streaming applications are an ideal solution for targeting multi-core architectures, such as shared/distributed memory systems, tiled architectures, and single-core systems. Since these architectures, in most cases, provide SIMD acceleration units as well, it is highly beneficial to generate SIMD code from streaming programs. Specifically, we introduce MacroSS, which is capable of performing macro-SIMDization on high-level streaming graphs. Macro-SIMDization uses high-level information such as execution rates of actors and communication patterns between them to transform the graph structure, vectorize actors of a streaming program, and generate intermediate code. We also propose low-overhead architectural modifications that accelerate shuffling of data elements between the scalar and vectorized parts of a streaming program. Our experiments show that MacroSS is capable of generating code that, on average, outperforms scalar code compiled with the current state-of-art auto-vectorizing compilers by 54%. Using the low-overhead data shuffling hardware, performance is improved by an additional 8% with less than 1% area overhead.",
        "acm_key": "1736023",
        "bib_stats": {
            "cites": 53,
            "dl": 1,
            "dl_52": 81,
            "dl_6": 9
        },
        "bibtex": "\r\n@article{Ipek:2010:DRM:1735971.1736023,\n author = {Ipek, Engin and Condit, Jeremy and Nightingale, Edmund B. and Burger, Doug and Moscibroda, Thomas},\n title = {Dynamically Replicated Memory: Building Reliable Systems from Nanoscale Resistive Memories},\n journal = {SIGPLAN Not.},\n issue_date = {March 2010},\n volume = {45},\n number = {3},\n month = mar,\n year = {2010},\n issn = {0362-1340},\n pages = {3--14},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1735971.1736023},\n doi = {10.1145/1735971.1736023},\n acmid = {1736023},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {phase-change memory, write endurance},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1736023&parent_id=1735971&expformat=bibtex&CFID=982052882&CFTOKEN=90441668\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1736023\">\r\n@inproceedings{Ipek:2010:DRM:1736020.1736023,\n author = {Ipek, Engin and Condit, Jeremy and Nightingale, Edmund B. and Burger, Doug and Moscibroda, Thomas},\n title = {Dynamically Replicated Memory: Building Reliable Systems from Nanoscale Resistive Memories},\n booktitle = {Proceedings of the Fifteenth Edition of ASPLOS on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XV},\n year = {2010},\n isbn = {978-1-60558-839-1},\n location = {Pittsburgh, Pennsylvania, USA},\n pages = {3--14},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1736020.1736023},\n doi = {10.1145/1736020.1736023},\n acmid = {1736023},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {phase-change memory, write endurance},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1736023&parent_id=1736020&expformat=bibtex&CFID=982052882&CFTOKEN=90441668\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1736023\">\r\n@article{Ipek:2010:DRM:1735970.1736023,\n author = {Ipek, Engin and Condit, Jeremy and Nightingale, Edmund B. and Burger, Doug and Moscibroda, Thomas},\n title = {Dynamically Replicated Memory: Building Reliable Systems from Nanoscale Resistive Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2010},\n volume = {38},\n number = {1},\n month = mar,\n year = {2010},\n issn = {0163-5964},\n pages = {3--14},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1735970.1736023},\n doi = {10.1145/1735970.1736023},\n acmid = {1736023},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {phase-change memory, write endurance},\n} \r\n",
        "key": "1736023",
        "pub_year": "2010",
        "text": "Engin Ipek , Jeremy Condit , Edmund B. Nightingale , Doug Burger , Thomas Moscibroda, Dynamically replicated memory: building reliable systems from nanoscale resistive memories, Proceedings of the fifteenth edition of ASPLOS on Architectural support for programming languages and operating systems, March 13-17, 2010, Pittsburgh, Pennsylvania, USA  \u00a0[doi>"
    },
    "174236": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "174236",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Dipert:1993:FMG:174226.174236,\n author = {Dipert, Brian and Hebert, Lou},\n title = {Flash Memory Goes Mainstream},\n journal = {IEEE Spectr.},\n issue_date = {Oct. 1993},\n volume = {30},\n number = {10},\n month = oct,\n year = {1993},\n issn = {0018-9235},\n pages = {48--52},\n numpages = {5},\n url = {http://dx.doi.org/10.1109/6.237588},\n doi = {10.1109/6.237588},\n acmid = {174236},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "174236",
        "pub_year": "1993",
        "text": "Brian Dipert , Lou Hebert, Flash memory goes mainstream, IEEE Spectrum, v.30 n.10, p.48-52, Oct. 1993  \u00a0[doi>"
    },
    "174238": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "174238",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Eldridge:1993:FF:174226.174238,\n author = {Eldridge, James},\n title = {Filing in a Flash},\n journal = {IEEE Spectr.},\n issue_date = {Oct. 1993},\n volume = {30},\n number = {10},\n month = oct,\n year = {1993},\n issn = {0018-9235},\n pages = {53--54},\n numpages = {2},\n url = {http://dx.doi.org/10.1109/6.237591},\n doi = {10.1109/6.237591},\n acmid = {174238},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "174238",
        "pub_year": "1993",
        "text": "James Eldridge, Filing in a flash, IEEE Spectrum, v.30 n.10, p.53-54, Oct. 1993  \u00a0[doi>"
    },
    "174615": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "174615",
        "bib_stats": {
            "cites": 42,
            "dl": 948,
            "dl_52": 64,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Satyanarayanan:1994:LRV:174613.174615,\n author = {Satyanarayanan, M. and Mashburn, Henry H. and Kumar, Puneet and Steere, David C. and Kistler, James J.},\n title = {Lightweight Recoverable Virtual Memory},\n journal = {ACM Trans. Comput. Syst.},\n issue_date = {Feb. 1994},\n volume = {12},\n number = {1},\n month = feb,\n year = {1994},\n issn = {0734-2071},\n pages = {33--57},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/174613.174615},\n doi = {10.1145/174613.174615},\n acmid = {174615},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Camelot, Coda, RVM, Unix, logging, paging, persistence, scalability, throughput, truncation},\n} \r\n",
        "key": "174615",
        "pub_year": "1994",
        "text": "M. Satyanarayanan , Henry H. Mashburn , Puneet Kumar , David C. Steere , James J. Kistler, Lightweight recoverable virtual memory, ACM Transactions on Computer Systems (TOCS), v.12 n.1, p.33-57, Feb. 1994  \u00a0[doi>"
    },
    "1749491": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1749491",
        "bib_stats": {
            "cites": 51,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Lee:2010:PTF:1749401.1749491,\n author = {Lee, Benjamin C. and Zhou, Ping and Yang, Jun and Zhang, Youtao and Zhao, Bo and Ipek, Engin and Mutlu, Onur and Burger, Doug},\n title = {Phase-Change Technology and the Future of Main Memory},\n journal = {IEEE Micro},\n issue_date = {January 2010},\n volume = {30},\n number = {1},\n month = jan,\n year = {2010},\n issn = {0272-1732},\n pages = {143--143},\n numpages = {1},\n url = {http://dx.doi.org/10.1109/MM.2010.24},\n doi = {10.1109/MM.2010.24},\n acmid = {1749491},\n publisher = {IEEE Computer Society Press},\n address = {Los Alamitos, CA, USA},\n keywords = {DRAM, PCM, energy efficiency, memory architecture, phase-change memory, phase-change memory, PCM, technology scaling, memory architecture, energy efficiency, DRAM, technology scaling},\n} \r\n",
        "key": "1749491",
        "pub_year": "2010",
        "text": "Benjamin C. Lee , Ping Zhou , Jun Yang , Youtao Zhang , Bo Zhao , Engin Ipek , Onur Mutlu , Doug Burger, Phase-Change Technology and the Future of Main Memory, IEEE Micro, v.30 n.1, p.143-143, January 2010  \u00a0[doi>"
    },
    "1784783": {
        "abstract": "We extend Wadler's work that showed duality between call-by-value and call-by-name by giving mutual translations between the \u03bb\u00b5-calculus and the dual calculus. We extend the \u03bb\u00b5-calculus and the dual calculus through two stages. We first add a fixed-point operator and an iteration operator to the call-byname and call-by-value systems respectively. Secondly, we add recursive types, T, and \u22a5 types to these systems. The extended duality between call-byname with recursion and call-by-value with iteration has been suggested by Kakutani. He followed Selinger's category-theoretic approach. We completely follow Wadler's syntactic approach. We give mutual translations between our extended \u03bb\u00b5-calculus and dual calculus by extending Wadler's translations, and also show that our translations form an equational correspondence, which was defined by Sabry and Felleisen. By composing our translations with duality on the dual calculus, we obtain a duality on our extended \u03bb\u00b5-calculus. Wadler's duality on the \u03bb\u00b5-calculus was an involution, and our duality on our extended \u03bb\u00b5-calculus is also an involution.",
        "acm_key": "1784783",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Blaser:2007:POP:1784774.1784783,\n author = {Bl\\\"{a}ser, Luc},\n title = {Persistent Oberon: A Programming Language with Integrated Persistence},\n booktitle = {Proceedings of the 5th Asian Conference on Programming Languages and Systems},\n series = {APLAS'07},\n year = {2007},\n isbn = {3-540-76636-7, 978-3-540-76636-0},\n location = {Singapore},\n pages = {71--85},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=1784774.1784783},\n acmid = {1784783},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n} \r\n",
        "key": "1784783",
        "pub_year": "2007",
        "text": "Luc Bl\u00e4ser, Persistent Oberon: a programming language with integrated persistence, Proceedings of the 5th Asian conference on Programming languages and systems, November 29-December 01, 2007, Singapore"
    },
    "1785503": {
        "abstract": "Optical Lithography is a key to semiconductor device scaling. As technology continues to scale, the fundamental limits of lithography are pushed to an extreme. Today 193nm light is used to print features in 45nm technology node. As the minimum feature size on the mask is less than half the wavelength of light used for the lithography process, diffraction at the mask edges dominates the errors in mask printing. Mask transfer fidelity issues are countered using a number of Resolution Enhancement Techniques (RET) which include Optical Proximity Correction (OPC), Phase Shift Masking (PSM), Sub Resolution Assist Features (SRAF) and Dual Patterning Lithography (DPL). DPL reduces wafer throughput but has become a necessity in current and upcoming technology nodes. It involves splitting patterns in a mask into two masks that are exposed separately. DPL CAD problem is a pattern coloring problem to minimize mask edge placement error (EPE). EPE results from interaction of near field waves and any geometric solution that does not consider interaction of fields, suffers from inaccuracies. Previous publications were mostly focused on a rule based geometric solution. In this paper we investigate a method to implement DPL using fast lithography simulation taking into account not only the bad, but also the beneficial effects of having polygons in the mask close to one another in the final partitioned layout. We present results on metal layer 2 of the ISCAS-85 benchmarks. Results show that even though our model based solution is slower, unlike many previous approaches, the final output meets the objectives of reducing EPE.",
        "acm_key": "1785503",
        "bib_stats": {
            "cites": 17,
            "dl": 315,
            "dl_52": 35,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Shi:2010:WAR:1785481.1785503,\n author = {Shi, Liang and Xue, Chun Jason and Hu, Jingtong and Tseng, Wei-Che and Zhou, Xuehai and Sha, Edwin H.-M.},\n title = {Write Activity Reduction on Flash Main Memory via Smart Victim Cache},\n booktitle = {Proceedings of the 20th Symposium on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '10},\n year = {2010},\n isbn = {978-1-4503-0012-4},\n location = {Providence, Rhode Island, USA},\n pages = {91--94},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/1785481.1785503},\n doi = {10.1145/1785481.1785503},\n acmid = {1785503},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cache, main memory, nand flash memory, victim cache},\n} \r\n",
        "key": "1785503",
        "pub_year": "2010",
        "text": "Liang Shi , Chun Jason Xue , Jingtong Hu , Wei-Che Tseng , Xuehai Zhou , Edwin H.-M. Sha, Write activity reduction on flash main memory via smart victim cache, Proceedings of the 20th symposium on Great lakes symposium on VLSI, May 16-18, 2010, Providence, Rhode Island, USA  \u00a0[doi>"
    },
    "1788904": {
        "abstract": "Initially used in digital audio players, digital cameras, mobile phones, and USB memory sticks, flash memory may become the dominant form of end-user storage in mobile computing, either completely replacing the magnetic hard disks or being an additional secondary storage. We study the design of algorithms and data structures that can exploit the flash memory devices better. For this, we characterize the performance of NAND flash based storage devices, including many solid state disks. We show that these devices have better random read performance than hard disks, but much worse random write performance. We also analyze the effect of misalignments, aging and past I/O patterns etc. on the performance obtained on these devices. We show that despite the similarities between flash memory and RAM (fast random reads) and between flash disk and hard disk (both are block based devices), the algorithms designed in the RAM model or the external memory model do not realize the full potential of the flash memory devices. We later give some broad guidelines for designing algorithms which can exploit the comparative advantages of both a flash memory device and a hard disk, when used together.",
        "acm_key": "1788904",
        "bib_stats": {
            "cites": 16
        },
        "bibtex": "\r\n@inproceedings{Ajwani:2008:CPF:1788888.1788904,\n author = {Ajwani, Deepak and Malinger, Itay and Meyer, Ulrich and Toledo, Sivan},\n title = {Characterizing the Performance of Flash Memory Storage Devices and Its Impact on Algorithm Design},\n booktitle = {Proceedings of the 7th International Conference on Experimental Algorithms},\n series = {WEA'08},\n year = {2008},\n isbn = {3-540-68548-0, 978-3-540-68548-7},\n location = {Provincetown, MA, USA},\n pages = {208--219},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=1788888.1788904},\n acmid = {1788904},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n} \r\n",
        "key": "1788904",
        "pub_year": "2008",
        "text": "Deepak Ajwani , Itay Malinger , Ulrich Meyer , Sivan Toledo, Characterizing the performance of flash memory storage devices and its impact on algorithm design, Proceedings of the 7th international conference on Experimental algorithms, p.208-219, May 30-June 01, 2008, Provincetown, MA, USA"
    },
    "1789988": {
        "abstract": "In this paper, the improvement of an indoor localization using a fingerprint technique is proposed. The Radio Frequency Identification (RFID) system is utilized. In general, the RFID localization can be categorized into two main types: one is the reader localization in which the reader locations will be estimated and one is the tag localization in which the tag locations will be estimation. The selection of these two types depends on the applications. In this paper, the reader localization is considered because of the lower system cost. For the reader localization, although a large number of tags is used, the tag cost is much cheaper than the reader cost. The passive tags are employed as references attached to the ceiling at known locations and the reader carrying on the vehicle of interest is the target to be localized. The basic principle of the fingerprint technique is to find the location of the target by comparing its signal (or information) pattern with a previously recoded database of known signal (or information)-location data. Therefore, there are two main steps to estimate the target location: (i) construction of database containing the signals (or information) and their corresponding locations, and (ii) estimation of the target location. In this paper, firstly, the detected tags found by the reader at each location of interest are collected and from now on the detected tags are called a fingerprint. Secondly, the location of the reader can be estimated using three proposed methods using the intersection between the detected tags and fingerprints. The effectiveness of each method is verified by experiment data. The best result of location estimation error among three proposed methods is less than 35 cm.",
        "acm_key": "1789988",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@inproceedings{Park:2009:RPE:1789954.1789988,\n author = {Park, Kwanghee and Lee, Dong-Hwan and Woo, Youngjoo and Lee, Geunhyung and Lee, Ju-Hong and Kim, Deok-Hwan},\n title = {Reliability and Performance Enhancement Technique for SSD Array Storage System Using RAID Mechanism},\n booktitle = {Proceedings of the 9th International Conference on Communications and Information Technologies},\n series = {ISCIT'09},\n year = {2009},\n isbn = {978-1-4244-4521-9},\n location = {Incheon, Korea},\n pages = {140--145},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1789954.1789988},\n acmid = {1789988},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "1789988",
        "pub_year": "2009",
        "text": "Kwanghee Park , Dong-Hwan Lee , Youngjoo Woo , Geunhyung Lee , Ju-Hong Lee , Deok-Hwan Kim, Reliability and performance enhancement technique for SSD array storage system using RAID mechanism, Proceedings of the 9th international conference on Communications and information technologies, September 28-30, 2009, Incheon, Korea"
    },
    "1801768": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1801768",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Park:2010:BFA:1801035.1801768,\n author = {Park, Hyunchul and Shin, Dongkun},\n title = {Buffer Flush and Address Mapping Scheme for Flash Memory Solid-state Disk},\n journal = {J. Syst. Archit.},\n issue_date = {April, 2010},\n volume = {56},\n number = {4-6},\n month = apr,\n year = {2010},\n issn = {1383-7621},\n pages = {208--220},\n numpages = {13},\n url = {http://dx.doi.org/10.1016/j.sysarc.2010.03.006},\n doi = {10.1016/j.sysarc.2010.03.006},\n acmid = {1801768},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Address mapping, Buffer management, Flash memory, Solid state disk, flash translation layer},\n} \r\n",
        "key": "1801768",
        "pub_year": "2010",
        "text": "Hyunchul Park , Dongkun Shin, Buffer flush and address mapping scheme for flash memory solid-state disk, Journal of Systems Architecture: the EUROMICRO Journal, v.56 n.4-6, p.208-220, April, 2010"
    },
    "1802853": {
        "abstract": "The workflow model has been successively applied to traditional computing environments such as business processes and distributed computing in order to perform service composition, flow management, parallel execution, and time-driven services. Recently, there have been many studies to adopt the workflow model into ubiquitous computing environments for context-aware and autonomous services. A service in ubiquitous computing environments must be executed according to a user's situation information, which is generated dynamically from sensors. Such existing workflow systems as FollowMe and uFlow support context-aware services through workflow models. However, when a user's situation is dynamically changed, the systems don't have a method to immediately adopt the change into an already on-going service workflow. In this paper, we propose a context-aware workflow system, which can apply changes of user's service demand or situation information into an on-going workflow without breaking its operation. The suggested workflow system can re-apply the new services into an initial workflow scenario without interrupting or deleting workflow service. To do this, the proposed system represents contexts described in a workflow as an RDF-based DItree (Document Instance tree). The system uses the tree information to recognize an exact position to be changed in the on-going workflow for the user's situation changes, and to reconstruct only the position under the influence of the changes in the DItree. Therefore, the suggested system can quickly and efficiently apply a change of the user's new situation into an on-going workflow without much loss of time and space, and can offer a context-aware service continuously according to a new workflow.",
        "acm_key": "1802853",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@inproceedings{Kwon:2007:EGC:1802834.1802853,\n author = {Kwon, Ohhoon and Ryu, Yeonseung and Koh, Kern},\n title = {An Efficient Garbage Collection Policy for Flash Memory Based Swap Systems},\n booktitle = {Proceedings of the 2007 International Conference on Computational Science and Its Applications - Volume Part I},\n series = {ICCSA'07},\n year = {2007},\n isbn = {3-540-74468-1, 978-3-540-74468-9},\n location = {Kuala Lumpur, Malaysia},\n pages = {213--223},\n numpages = {11},\n url = {http://dl.acm.org/citation.cfm?id=1802834.1802853},\n acmid = {1802853},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {flash memory, garbage collection, swap systems},\n} \r\n",
        "key": "1802853",
        "pub_year": "2007",
        "text": "Ohhoon Kwon , Yeonseung Ryu , Kern Koh, An efficient garbage collection policy for flash memory based swap systems, Proceedings of the 2007 international conference on Computational science and its applications, August 26-29, 2007, Kuala Lumpur, Malaysia"
    },
    "1802855": {
        "abstract": "The workflow model has been successively applied to traditional computing environments such as business processes and distributed computing in order to perform service composition, flow management, parallel execution, and time-driven services. Recently, there have been many studies to adopt the workflow model into ubiquitous computing environments for context-aware and autonomous services. A service in ubiquitous computing environments must be executed according to a user's situation information, which is generated dynamically from sensors. Such existing workflow systems as FollowMe and uFlow support context-aware services through workflow models. However, when a user's situation is dynamically changed, the systems don't have a method to immediately adopt the change into an already on-going service workflow. In this paper, we propose a context-aware workflow system, which can apply changes of user's service demand or situation information into an on-going workflow without breaking its operation. The suggested workflow system can re-apply the new services into an initial workflow scenario without interrupting or deleting workflow service. To do this, the proposed system represents contexts described in a workflow as an RDF-based DItree (Document Instance tree). The system uses the tree information to recognize an exact position to be changed in the on-going workflow for the user's situation changes, and to reconstruct only the position under the influence of the changes in the DItree. Therefore, the suggested system can quickly and efficiently apply a change of the user's new situation into an on-going workflow without much loss of time and space, and can offer a context-aware service continuously according to a new workflow.",
        "acm_key": "1802855",
        "bib_stats": {
            "cites": 6
        },
        "bibtex": "\r\n@inproceedings{Kim:2007:FHF:1802834.1802855,\n author = {Kim, Eun-ki and Shin, Hyungjong and Jeon, Byung-gil and Han, Seokhee and Jung, Jaemin and Won, Youjip},\n title = {FRASH: Hierarchical File System for FRAM and Flash},\n booktitle = {Proceedings of the 2007 International Conference on Computational Science and Its Applications - Volume Part I},\n series = {ICCSA'07},\n year = {2007},\n isbn = {3-540-74468-1, 978-3-540-74468-9},\n location = {Kuala Lumpur, Malaysia},\n pages = {238--251},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=1802834.1802855},\n acmid = {1802855},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {FRAM, NAND flash memory, NVRAM, file system, hierarchical storage, mounting time},\n} \r\n",
        "key": "1802855",
        "pub_year": "2007",
        "text": "Eun-ki Kim , Hyungjong Shin , Byung-gil Jeon , Seokhee Han , Jaemin Jung , Youjip Won, FRASH: hierarchical file system for FRAM and flash, Proceedings of the 2007 international conference on Computational science and its applications, August 26-29, 2007, Kuala Lumpur, Malaysia"
    },
    "1811089": {
        "abstract": "Dynamic Spectrum Access systems exploit temporarily available spectrum ('white spaces') and can spread transmissions over a number of non-contiguous sub-channels. Such methods are highly beneficial in terms of spectrum utilization. However, excessive fragmentation degrades performance and hence off-sets the benefits. Thus, there is a need to study these processes so as to determine how to ensure acceptable levels of fragmentation. Hence, we present experimental and analytical results derived from a mathematical model. We model a system operating at capacity serving requests for bandwidth by assigning a collection of gaps (sub-channels) with no limitations on the fragment size. Our main theoretical result shows that even if fragments can be arbitrarily small, the system does not degrade with time. Namely, the average total number of fragments remains bounded. Within the very difficult class of dynamic fragmentation models (including models of storage fragmentation), this result appears to be the first of its kind. Extensive experimental results describe behavior, at times unexpected, of fragmentation under different algorithms. Our model also applies to dynamic linked-list storage allocation, and provides a novel analysis in that domain. We prove that, interestingly, the 50% rule of the classical (non-fragmented) allocation model carries over to our model. Overall, the paper provides insights into the potential behavior of practical fragmentation algorithms.",
        "acm_key": "1811089",
        "bib_stats": {
            "cites": 18,
            "dl": 590,
            "dl_52": 58,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Park:2010:CCF:1811039.1811089,\n author = {Park, Dongchul and Debnath, Biplob and Du, David},\n title = {CFTL: A Convertible Flash Translation Layer Adaptive to Data Access Patterns},\n booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},\n series = {SIGMETRICS '10},\n year = {2010},\n isbn = {978-1-4503-0038-4},\n location = {New York, New York, USA},\n pages = {365--366},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/1811039.1811089},\n doi = {10.1145/1811039.1811089},\n acmid = {1811089},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {CFTL, FTL, flash memory, flash translation layer},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1811089&parent_id=1811039&expformat=bibtex&CFID=982049783&CFTOKEN=82820734\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1811089\">\r\n@article{Park:2010:CCF:1811099.1811089,\n author = {Park, Dongchul and Debnath, Biplob and Du, David},\n title = {CFTL: A Convertible Flash Translation Layer Adaptive to Data Access Patterns},\n journal = {SIGMETRICS Perform. Eval. Rev.},\n issue_date = {June 2010},\n volume = {38},\n number = {1},\n month = jun,\n year = {2010},\n issn = {0163-5999},\n pages = {365--366},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/1811099.1811089},\n doi = {10.1145/1811099.1811089},\n acmid = {1811089},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {CFTL, FTL, flash memory, flash translation layer},\n} \r\n",
        "key": "1811089",
        "pub_year": "2010",
        "text": "Dongchul Park , Biplob Debnath , David Du, CFTL: a convertible flash translation layer adaptive to data access patterns, Proceedings of the ACM SIGMETRICS international conference on Measurement and modeling of computer systems, June 14-18, 2010, New York, New York, USA  \u00a0[doi>"
    },
    "1815980": {
        "abstract": "This talk will begin with a description of a cache miss classification scheme for multicores (compulsory, inter-core misses, intra-core misses) that gives insight into the interactions between memory transactions of the different cores on a chip sharing a cache. Ways to improve the on-chip cache performance with architectural enhancements, compiler enhancements, and runtime system enhancements will then be discussed. If the application thread mapping and the on-chip topology is static (i.e., does not change during runtime), then compiler enhancements that support cache topology aware code optimization can be used to significantly improve an application's performance. Results from such an augmented compiler, where the topology is exposed to the compiler and where the compiler also does thread-to-core mapping assignments, will be presented. If the application thread mapping or the on-chip topology is dynamic, then other alternatives exist. For example, a thread scheduler, or allocator, can make decisions about moving threads to different cores during runtime in the hopes of improving overall cache performance. Initial experiments with the REEact system being developed by researchers at Penn State-UPittsburgh-UVirginia that \"reacts\" to hardware conditions (such as cache miss rates, hot-spots, etc.) by reallocating threads at runtime will be outlined. Finally, if the on-chip cache topology itself is dynamic (i.e., is designed to be reconfigurable at runtime), large performance benefits might be obtained. However, both hardware and software design challenges to realizing such a dynamic system abound. Some of these challenges will be briefly discussed.",
        "acm_key": "1815980",
        "bib_stats": {
            "cites": 74,
            "dl": 1,
            "dl_52": 83,
            "dl_6": 15
        },
        "bibtex": "\r\n@article{Schechter:2010:UEE:1816038.1815980,\n author = {Schechter, Stuart and Loh, Gabriel H. and Strauss, Karin and Burger, Doug},\n title = {Use ECP, Not ECC, for Hard Failures in Resistive Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2010},\n volume = {38},\n number = {3},\n month = jun,\n year = {2010},\n issn = {0163-5964},\n pages = {141--152},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1816038.1815980},\n doi = {10.1145/1816038.1815980},\n acmid = {1815980},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {error correction, hard failures, memory, phase change memory, resistive memories},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1815980&parent_id=1816038&expformat=bibtex&CFID=982042394&CFTOKEN=32130760\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1815980\">\r\n@inproceedings{Schechter:2010:UEE:1815961.1815980,\n author = {Schechter, Stuart and Loh, Gabriel H. and Strauss, Karin and Burger, Doug},\n title = {Use ECP, Not ECC, for Hard Failures in Resistive Memories},\n booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},\n series = {ISCA '10},\n year = {2010},\n isbn = {978-1-4503-0053-7},\n location = {Saint-Malo, France},\n pages = {141--152},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1815961.1815980},\n doi = {10.1145/1815961.1815980},\n acmid = {1815980},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {error correction, hard failures, memory, phase change memory, resistive memories},\n} \r\n",
        "key": "1815980",
        "pub_year": "2010",
        "text": "Stuart Schechter , Gabriel H. Loh , Karin Strauss , Doug Burger, Use ECP, not ECC, for hard failures in resistive memories, Proceedings of the 37th annual international symposium on Computer architecture, June 19-23, 2010, Saint-Malo, France  \u00a0[doi>"
    },
    "1815981": {
        "abstract": "This talk will begin with a description of a cache miss classification scheme for multicores (compulsory, inter-core misses, intra-core misses) that gives insight into the interactions between memory transactions of the different cores on a chip sharing a cache. Ways to improve the on-chip cache performance with architectural enhancements, compiler enhancements, and runtime system enhancements will then be discussed. If the application thread mapping and the on-chip topology is static (i.e., does not change during runtime), then compiler enhancements that support cache topology aware code optimization can be used to significantly improve an application's performance. Results from such an augmented compiler, where the topology is exposed to the compiler and where the compiler also does thread-to-core mapping assignments, will be presented. If the application thread mapping or the on-chip topology is dynamic, then other alternatives exist. For example, a thread scheduler, or allocator, can make decisions about moving threads to different cores during runtime in the hopes of improving overall cache performance. Initial experiments with the REEact system being developed by researchers at Penn State-UPittsburgh-UVirginia that \"reacts\" to hardware conditions (such as cache miss rates, hot-spots, etc.) by reallocating threads at runtime will be outlined. Finally, if the on-chip cache topology itself is dynamic (i.e., is designed to be reconfigurable at runtime), large performance benefits might be obtained. However, both hardware and software design challenges to realizing such a dynamic system abound. Some of these challenges will be briefly discussed.",
        "acm_key": "1815981",
        "bib_stats": {
            "cites": 39,
            "dl": 1,
            "dl_52": 63,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Qureshi:2010:MMS:1816038.1815981,\n author = {Qureshi, Moinuddin K. and Franceschini, Michele M. and Lastras-Monta\\~{n}o, Luis A. and Karidis, John P.},\n title = {Morphable Memory System: A Robust Architecture for Exploiting Multi-level Phase Change Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2010},\n volume = {38},\n number = {3},\n month = jun,\n year = {2010},\n issn = {0163-5964},\n pages = {153--162},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1816038.1815981},\n doi = {10.1145/1816038.1815981},\n acmid = {1815981},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {morphable memory, multi-level cell, phase change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1815981&parent_id=1816038&expformat=bibtex&CFID=982042368&CFTOKEN=17804288\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1815981\">\r\n@inproceedings{Qureshi:2010:MMS:1815961.1815981,\n author = {Qureshi, Moinuddin K. and Franceschini, Michele M. and Lastras-Monta\\~{n}o, Luis A. and Karidis, John P.},\n title = {Morphable Memory System: A Robust Architecture for Exploiting Multi-level Phase Change Memories},\n booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},\n series = {ISCA '10},\n year = {2010},\n isbn = {978-1-4503-0053-7},\n location = {Saint-Malo, France},\n pages = {153--162},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1815961.1815981},\n doi = {10.1145/1815961.1815981},\n acmid = {1815981},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {morphable memory, multi-level cell, phase change memory},\n} \r\n",
        "key": "1815981",
        "pub_year": "2010",
        "text": "Moinuddin K. Qureshi , Michele M. Franceschini , Luis A. Lastras-Monta\u00f1o , John P. Karidis, Morphable memory system: a robust architecture for exploiting multi-level phase change memories, ACM SIGARCH Computer Architecture News, v.38 n.3, June 2010  \u00a0[doi>"
    },
    "1816012": {
        "abstract": "This talk will begin with a description of a cache miss classification scheme for multicores (compulsory, inter-core misses, intra-core misses) that gives insight into the interactions between memory transactions of the different cores on a chip sharing a cache. Ways to improve the on-chip cache performance with architectural enhancements, compiler enhancements, and runtime system enhancements will then be discussed. If the application thread mapping and the on-chip topology is static (i.e., does not change during runtime), then compiler enhancements that support cache topology aware code optimization can be used to significantly improve an application's performance. Results from such an augmented compiler, where the topology is exposed to the compiler and where the compiler also does thread-to-core mapping assignments, will be presented. If the application thread mapping or the on-chip topology is dynamic, then other alternatives exist. For example, a thread scheduler, or allocator, can make decisions about moving threads to different cores during runtime in the hopes of improving overall cache performance. Initial experiments with the REEact system being developed by researchers at Penn State-UPittsburgh-UVirginia that \"reacts\" to hardware conditions (such as cache miss rates, hot-spots, etc.) by reallocating threads at runtime will be outlined. Finally, if the on-chip cache topology itself is dynamic (i.e., is designed to be reconfigurable at runtime), large performance benefits might be obtained. However, both hardware and software design challenges to realizing such a dynamic system abound. Some of these challenges will be briefly discussed.",
        "acm_key": "1816012",
        "bib_stats": {
            "cites": 28,
            "dl": 1,
            "dl_52": 151,
            "dl_6": 18
        },
        "bibtex": "\r\n@article{Guo:2010:RCA:1816038.1816012,\n author = {Guo, Xiaochen and Ipek, Engin and Soyata, Tolga},\n title = {Resistive Computation: Avoiding the Power Wall with Low-leakage, STT-MRAM Based Computing},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2010},\n volume = {38},\n number = {3},\n month = jun,\n year = {2010},\n issn = {0163-5964},\n pages = {371--382},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1816038.1816012},\n doi = {10.1145/1816038.1816012},\n acmid = {1816012},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-MRAM, power-efficiency},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1816012&parent_id=1816038&expformat=bibtex&CFID=982033153&CFTOKEN=82410871\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1816012\">\r\n@inproceedings{Guo:2010:RCA:1815961.1816012,\n author = {Guo, Xiaochen and Ipek, Engin and Soyata, Tolga},\n title = {Resistive Computation: Avoiding the Power Wall with Low-leakage, STT-MRAM Based Computing},\n booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},\n series = {ISCA '10},\n year = {2010},\n isbn = {978-1-4503-0053-7},\n location = {Saint-Malo, France},\n pages = {371--382},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1815961.1816012},\n doi = {10.1145/1815961.1816012},\n acmid = {1816012},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-MRAM, power-efficiency},\n} \r\n",
        "key": "1816012",
        "pub_year": "2010",
        "text": "Xiaochen Guo , Engin Ipek , Tolga Soyata, Resistive computation: avoiding the power wall with low-leakage, STT-MRAM based computing, Proceedings of the 37th annual international symposium on Computer architecture, June 19-23, 2010, Saint-Malo, France  \u00a0[doi>"
    },
    "1816014": {
        "abstract": "This talk will begin with a description of a cache miss classification scheme for multicores (compulsory, inter-core misses, intra-core misses) that gives insight into the interactions between memory transactions of the different cores on a chip sharing a cache. Ways to improve the on-chip cache performance with architectural enhancements, compiler enhancements, and runtime system enhancements will then be discussed. If the application thread mapping and the on-chip topology is static (i.e., does not change during runtime), then compiler enhancements that support cache topology aware code optimization can be used to significantly improve an application's performance. Results from such an augmented compiler, where the topology is exposed to the compiler and where the compiler also does thread-to-core mapping assignments, will be presented. If the application thread mapping or the on-chip topology is dynamic, then other alternatives exist. For example, a thread scheduler, or allocator, can make decisions about moving threads to different cores during runtime in the hopes of improving overall cache performance. Initial experiments with the REEact system being developed by researchers at Penn State-UPittsburgh-UVirginia that \"reacts\" to hardware conditions (such as cache miss rates, hot-spots, etc.) by reallocating threads at runtime will be outlined. Finally, if the on-chip cache topology itself is dynamic (i.e., is designed to be reconfigurable at runtime), large performance benefits might be obtained. However, both hardware and software design challenges to realizing such a dynamic system abound. Some of these challenges will be briefly discussed.",
        "acm_key": "1816014",
        "bib_stats": {
            "cites": 60,
            "dl": 1,
            "dl_52": 152,
            "dl_6": 21
        },
        "bibtex": "\r\n@article{Seong:2010:SRP:1816038.1816014,\n author = {Seong, Nak Hee and Woo, Dong Hyuk and Lee, Hsien-Hsin S.},\n title = {Security Refresh: Prevent Malicious Wear-out and Increase Durability for Phase-change Memory with Dynamically Randomized Address Mapping},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2010},\n volume = {38},\n number = {3},\n month = jun,\n year = {2010},\n issn = {0163-5964},\n pages = {383--394},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1816038.1816014},\n doi = {10.1145/1816038.1816014},\n acmid = {1816014},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dynamic address remapping, phase change memory, security, wear leveling},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1816014&parent_id=1816038&expformat=bibtex&CFID=982033310&CFTOKEN=39872190\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1816014\">\r\n@inproceedings{Seong:2010:SRP:1815961.1816014,\n author = {Seong, Nak Hee and Woo, Dong Hyuk and Lee, Hsien-Hsin S.},\n title = {Security Refresh: Prevent Malicious Wear-out and Increase Durability for Phase-change Memory with Dynamically Randomized Address Mapping},\n booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},\n series = {ISCA '10},\n year = {2010},\n isbn = {978-1-4503-0053-7},\n location = {Saint-Malo, France},\n pages = {383--394},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1815961.1816014},\n doi = {10.1145/1815961.1816014},\n acmid = {1816014},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dynamic address remapping, phase change memory, security, wear leveling},\n} \r\n",
        "key": "1816014",
        "pub_year": "2010",
        "text": "Nak Hee Seong , Dong Hyuk Woo , Hsien-Hsin S. Lee, Security refresh: prevent malicious wear-out and increase durability for phase-change memory with dynamically randomized address mapping, Proceedings of the 37th annual international symposium on Computer architecture, June 19-23, 2010, Saint-Malo, France  \u00a0[doi>"
    },
    "1829219": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1829219",
        "bib_stats": {
            "cites": 17,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ferreira:2010:UPN:1828428.1829219,\n author = {Ferreira, Alexandre Peixoto and Childers, Bruce and Melhem, Rami and Moss{\\'e}, Daniel and Yousif, Mazin},\n title = {Using PCM in Next-generation Embedded Space Applications},\n booktitle = {Proceedings of the 2010 16th IEEE Real-Time and Embedded Technology and Applications Symposium},\n series = {RTAS '10},\n year = {2010},\n isbn = {978-0-7695-4001-6},\n pages = {153--162},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/RTAS.2010.40},\n doi = {10.1109/RTAS.2010.40},\n acmid = {1829219},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {embedded, computer architecture, space},\n} \r\n",
        "key": "1829219",
        "pub_year": "2010",
        "text": "Alexandre Peixoto Ferreira , Bruce Childers , Rami Melhem , Daniel Moss\u00e9 , Mazin Yousif, Using PCM in Next-generation Embedded Space Applications, Proceedings of the 2010 16th IEEE Real-Time and Embedded Technology and Applications Symposium, p.153-162, April 12-15, 2010  \u00a0[doi>"
    },
    "1829929": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1829929",
        "bib_stats": {
            "cites": 19,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Park:2010:EIP:1829880.1829929,\n author = {Park, Seon-yeong and Seo, Euiseong and Shin, Ji-Yong and Maeng, Seungryoul and Lee, Joonwon},\n title = {Exploiting Internal Parallelism of Flash-based SSDs},\n journal = {IEEE Comput. Archit. Lett.},\n issue_date = {January 2010},\n volume = {9},\n number = {1},\n month = jan,\n year = {2010},\n issn = {1556-6056},\n pages = {9--12},\n numpages = {4},\n url = {http://dx.doi.org/10.1109/L-CA.2010.3},\n doi = {10.1109/L-CA.2010.3},\n acmid = {1829929},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Input/Output Devices, Input/Output Devices, Storage Management, Secondary storage, Parallel systems, Simulation, Parallel systems, Secondary storage, Simulation, Storage Management},\n} \r\n",
        "key": "1829929",
        "pub_year": "2010",
        "text": "Seon-yeong Park , Euiseong Seo , Ji-Yong Shin , Seungryoul Maeng , Joonwon Lee, Exploiting Internal Parallelism of Flash-based SSDs, IEEE Computer Architecture Letters, v.9 n.1, p.9-12, January 2010  \u00a0[doi>"
    },
    "1837363": {
        "abstract": "Thin-film thermoelectric cooling is a promising technology for mitigating heat dissipation in high performance chips. In this paper, we present an optimization framework for an active cooling system that is comprised of an array of thin-film thermoelectric coolers. We observe a set of constraints of the cooling system design. Firstly, integrating an excessive amount of coolers increases the chip package cost. Moreover, thermoelectric coolers are active devices, which dissipate heat in the chip package when they are in operation. Hence, setting the supply current level to operate the cooler improperly can actually lead to overheating of the chip package. Besides, the supply current needs to be delivered to the integrated cooler devices via dedicated pins. However, extra pins available on high-performance chip packages are limited. Observing these constraints, we propose an optimization framework for configuring the active cooling system, which minimizes the maximum silicon temperature. This includes determining the amount of coolers to deploy and their locations, the mapping of supply pins to the coolers, and determining the current levels of each pin. We propose algorithms to tackle the optimal configuration problem. We found that only a small portion of the silicon die needs to be covered by TEC devices (18% on average). Our experiments show that our algorithms are able to reduce the temperatures of the hot spots by as much as 10.6 \u00b0C (compared to the cases without integrated thermoelectric coolers). The average temperature reduction is 8.6 \u00b0C when 4 dedicated pins are available on the package. The total power consumption of the resulting active cooling system is reasonably small (~ 2 W). Our experiments also reveal that our framework maximizes the efficiency of the cooling devices. In the ideal case where hundreds of pins are available to tune the supply level of each individual cooler, the additional average reduction of the hot spot temperature is only 0.3 \u00b0C.",
        "acm_key": "1837363",
        "bib_stats": {
            "cites": 35,
            "dl": 226,
            "dl_52": 9,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Hu:2010:RWA:1837274.1837363,\n author = {Hu, Jingtong and Xue, Chun Jason and Tseng, Wei-Che and He, Yi and Qiu, Meikang and Sha, Edwin H.-M.},\n title = {Reducing Write Activities on Non-volatile Memories in Embedded CMPs via Data Migration and Recomputation},\n booktitle = {Proceedings of the 47th Design Automation Conference},\n series = {DAC '10},\n year = {2010},\n isbn = {978-1-4503-0002-5},\n location = {Anaheim, California},\n pages = {350--355},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/1837274.1837363},\n doi = {10.1145/1837274.1837363},\n acmid = {1837363},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {CMP, SPM, data migration, data recomputation, flash memory, non-volatile memory, phase change memory},\n} \r\n",
        "key": "1837363",
        "pub_year": "2010",
        "text": "Jingtong Hu , Chun Jason Xue , Wei-Che Tseng , Yi He , Meikang Qiu , Edwin H.-M. Sha, Reducing write activities on non-volatile memories in embedded CMPs via data migration and recomputation, Proceedings of the 47th Design Automation Conference, June 13-18, 2010, Anaheim, California  \u00a0[doi>"
    },
    "1837922": {
        "abstract": "Recently, power has emerged as a critical factor in designing components of storage systems, especially for power-hungry data centers. While there is some research into power-aware storage stack components, there are no systematic studies evaluating each component's impact separately. Various factors like workloads, hardware configurations, and software configurations impact the performance and energy efficiency of the system. This article evaluates the file system's impact on energy consumption and performance. We studied several popular Linux file systems, with various mount and format options, using the FileBench workload generator to emulate four server workloads: Web, database, mail, and fileserver, on two different hardware configurations. The file system design, implementation, and available features have a significant effect on CPU/disk utilization, and hence on performance and power. We discovered that default file system options are often suboptimal, and even poor. In this article we show that a careful matching of expected workloads and hardware configuration to a single software configuration\u2014the file system\u2014can improve power-performance efficiency by a factor ranging from 1.05 to 9.4 times.",
        "acm_key": "1837922",
        "bib_stats": {
            "cites": 30,
            "dl": 1,
            "dl_52": 110,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Josephson:2010:DFS:1837915.1837922,\n author = {Josephson, William K. and Bongo, Lars A. and Li, Kai and Flynn, David},\n title = {DFS: A File System for Virtualized Flash Storage},\n journal = {Trans. Storage},\n issue_date = {September 2010},\n volume = {6},\n number = {3},\n month = sep,\n year = {2010},\n issn = {1553-3077},\n pages = {14:1--14:25},\n articleno = {14},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/1837915.1837922},\n doi = {10.1145/1837915.1837922},\n acmid = {1837922},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, filesystem},\n} \r\n",
        "key": "1837922",
        "pub_year": "2010",
        "text": "William K. Josephson , Lars A. Bongo , Kai Li , David Flynn, DFS: A file system for virtualized flash storage, ACM Transactions on Storage (TOS), v.6 n.3, p.1-25, September 2010"
    },
    "1838588": {
        "abstract": "Climate science educators face great challenges on combining theory with hands-on practices in teaching climate modeling. Typical model runs require large computation and storage resources that may not be available on a campus. Additionally, the training and support required to bring novices up to speed would consume significant class time. The same challenges also exist across many other science and engineering disciplines. The TeraGrid science gateway program is leading the way of a new paradigm in addressing such challenges. As part of the TeraGrid science gateway initiative, The Purdue CCSM portal aims at assisting both research and education users to run Community Climate System Model (CCSM) simulations using the TeraGrid high performance computing resources. It provides a one-stop shop for creating, configuring, running CCSM simulations as well as managing jobs and processing output data. The CCSM portal was used in a Purdue graduate class for students to get hands-on experience with running world class climate simulations and use the results to study climate change impact on political policies. The CCSM portal is based on a service-oriented architecture with multiple interfaces to facilitate training. This paper describes the design of the CCSM portal with the goal of supporting classroom users, the challenges of utilizing the portal in a classroom setting, and the solutions implemented. We present two student projects from the fall 2009 class that successfully used the CCSM portal.",
        "acm_key": "1838588",
        "bib_stats": {
            "cites": 13,
            "dl": 249,
            "dl_52": 24,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Norman:2010:ADS:1838574.1838588,\n author = {Norman, Michael L. and Snavely, Allan},\n title = {Accelerating Data-intensive Science with Gordon and Dash},\n booktitle = {Proceedings of the 2010 TeraGrid Conference},\n series = {TG '10},\n year = {2010},\n isbn = {978-1-60558-818-6},\n location = {Pittsburgh, Pennsylvania},\n pages = {14:1--14:7},\n articleno = {14},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/1838574.1838588},\n doi = {10.1145/1838574.1838588},\n acmid = {1838588},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data mining, predictive science},\n} \r\n",
        "key": "1838588",
        "pub_year": "2010",
        "text": "Michael L. Norman , Allan Snavely, Accelerating data-intensive science with Gordon<i>Gordon</i> and  and Dash<i>Dash</i>, Proceedings of the 2010 TeraGrid Conference, p.1-7, August 02-05, 2010, Pittsburgh, Pennsylvania , Proceedings of the 2010 TeraGrid Conference, p.1-7, August 02-05, 2010, Pittsburgh, Pennsylvania  \u00a0[doi>"
    },
    "1849330": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1849330",
        "bib_stats": {
            "cites": 8,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Andersen:2010:RFD:1849301.1849330,\n author = {Andersen, David G. and Swanson, Steven},\n title = {Rethinking Flash in the Data Center},\n journal = {IEEE Micro},\n issue_date = {July 2010},\n volume = {30},\n number = {4},\n month = jul,\n year = {2010},\n issn = {0272-1732},\n pages = {52--54},\n numpages = {3},\n url = {http://dx.doi.org/10.1109/MM.2010.71},\n doi = {10.1109/MM.2010.71},\n acmid = {1849330},\n publisher = {IEEE Computer Society Press},\n address = {Los Alamitos, CA, USA},\n keywords = {datacenter computing, flash, hardware, memory architectures, memory architectures, datacenter computing, hardware, flash},\n} \r\n",
        "key": "1849330",
        "pub_year": "2010",
        "text": "David G. Andersen , Steven Swanson, Rethinking Flash in the Data Center, IEEE Micro, v.30 n.4, p.52-54, July 2010  \u00a0[doi>"
    },
    "1849834": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1849834",
        "bib_stats": {
            "cites": 9,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lim:2010:FFE:1849414.1849834,\n author = {Lim, Sang-Phil and Lee, Sang-Won and Moon, Bongki},\n title = {FASTer FTL for Enterprise-Class Flash Memory SSDs},\n booktitle = {Proceedings of the 2010 International Workshop on Storage Network Architecture and Parallel I/Os},\n series = {SNAPI '10},\n year = {2010},\n isbn = {978-0-7695-4025-2},\n pages = {3--12},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/SNAPI.2010.9},\n doi = {10.1109/SNAPI.2010.9},\n acmid = {1849834},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash Translation Layer, Full Associativity, OLTP, Hot-cold Separation},\n} \r\n",
        "key": "1849834",
        "pub_year": "2010",
        "text": "Sang-Phil Lim , Sang-Won Lee , Bongki Moon, FASTer FTL for Enterprise-Class Flash Memory SSDs, Proceedings of the 2010 International Workshop on Storage Network Architecture and Parallel I/Os, p.3-12, May 03-03, 2010  \u00a0[doi>"
    },
    "1855518": {
        "abstract": "Data deduplication has become a popular technology for reducing the amount of storage space necessary for backup and archival data. Content defined chunking (CDC) techniques are well established methods of separating a data stream into variable-size chunks such that duplicate content has a good chance of being discovered irrespective of its position in the data stream. Requirements for CDC include fast and scalable operation, as well as achieving good duplicate elimination. While the latter can be achieved by using chunks of small average size, this also increases the amount of metadata necessary to store the relatively more numerous chunks, and impacts negatively the system's performance. We propose a new approach that achieves comparable duplicate elimination while using chunks of larger average size. It involves using two chunk size targets, and mechanisms that dynamically switch between the two based on querying data already stored; we use small chunks in limited regions of transition from duplicate to nonduplicate data, and elsewhere we use large chunks. The algorithms rely on the block store's ability to quickly deliver a high-quality reply to existence queries for already-stored blocks. A chunking decision is made with limited lookahead and number of queries. We present results of running these algorithms on actual backup data, as well as four sets of source code archives. Our algorithms typically achieve similar duplicate elimination to standard algorithms while using chunks 2-4 times as large. Such approaches may be particularly interesting to distributed storage systems that use redundancy techniques (such as error-correcting codes) requiring multiple chunk fragments, for which metadata overheads per stored chunk are high. We find that algorithm variants with more flexibility in location and size of chunks yield better duplicate elimination, at a cost of a higher number of existence queries.",
        "acm_key": "1855518",
        "bib_stats": {
            "cites": 39,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Josephson:2010:DFS:1855511.1855518,\n author = {Josephson, William K. and Bongo, Lars A. and Flynn, David and Li, Kai},\n title = {DFS: A File System for Virtualized Flash Storage},\n booktitle = {Proceedings of the 8th USENIX Conference on File and Storage Technologies},\n series = {FAST'10},\n year = {2010},\n location = {San Jose, California},\n pages = {7--7},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855511.1855518},\n acmid = {1855518},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855518",
        "pub_year": "2010",
        "text": "William K. Josephson , Lars A. Bongo , David Flynn , Kai Li, DFS: a file system for virtualized flash storage, Proceedings of the 8th USENIX conference on File and storage technologies, p.7-7, February 23-26, 2010, San Jose, California"
    },
    "1855519": {
        "abstract": "Data deduplication has become a popular technology for reducing the amount of storage space necessary for backup and archival data. Content defined chunking (CDC) techniques are well established methods of separating a data stream into variable-size chunks such that duplicate content has a good chance of being discovered irrespective of its position in the data stream. Requirements for CDC include fast and scalable operation, as well as achieving good duplicate elimination. While the latter can be achieved by using chunks of small average size, this also increases the amount of metadata necessary to store the relatively more numerous chunks, and impacts negatively the system's performance. We propose a new approach that achieves comparable duplicate elimination while using chunks of larger average size. It involves using two chunk size targets, and mechanisms that dynamically switch between the two based on querying data already stored; we use small chunks in limited regions of transition from duplicate to nonduplicate data, and elsewhere we use large chunks. The algorithms rely on the block store's ability to quickly deliver a high-quality reply to existence queries for already-stored blocks. A chunking decision is made with limited lookahead and number of queries. We present results of running these algorithms on actual backup data, as well as four sets of source code archives. Our algorithms typically achieve similar duplicate elimination to standard algorithms while using chunks 2-4 times as large. Such approaches may be particularly interesting to distributed storage systems that use redundancy techniques (such as error-correcting codes) requiring multiple chunk fragments, for which metadata overheads per stored chunk are high. We find that algorithm variants with more flexibility in location and size of chunks yield better duplicate elimination, at a cost of a higher number of existence queries.",
        "acm_key": "1855519",
        "bib_stats": {
            "cites": 50,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Soundararajan:2010:ESL:1855511.1855519,\n author = {Soundararajan, Gokul and Prabhakaran, Vijayan and Balakrishnan, Mahesh and Wobber, Ted},\n title = {Extending SSD Lifetimes with Disk-based Write Caches},\n booktitle = {Proceedings of the 8th USENIX Conference on File and Storage Technologies},\n series = {FAST'10},\n year = {2010},\n location = {San Jose, California},\n pages = {8--8},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855511.1855519},\n acmid = {1855519},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855519",
        "pub_year": "2010",
        "text": "Gokul Soundararajan , Vijayan Prabhakaran , Mahesh Balakrishnan , Ted Wobber, Extending SSD lifetimes with disk-based write caches, Proceedings of the 8th USENIX conference on File and storage technologies, p.8-8, February 23-26, 2010, San Jose, California"
    },
    "1855520": {
        "abstract": "Data deduplication has become a popular technology for reducing the amount of storage space necessary for backup and archival data. Content defined chunking (CDC) techniques are well established methods of separating a data stream into variable-size chunks such that duplicate content has a good chance of being discovered irrespective of its position in the data stream. Requirements for CDC include fast and scalable operation, as well as achieving good duplicate elimination. While the latter can be achieved by using chunks of small average size, this also increases the amount of metadata necessary to store the relatively more numerous chunks, and impacts negatively the system's performance. We propose a new approach that achieves comparable duplicate elimination while using chunks of larger average size. It involves using two chunk size targets, and mechanisms that dynamically switch between the two based on querying data already stored; we use small chunks in limited regions of transition from duplicate to nonduplicate data, and elsewhere we use large chunks. The algorithms rely on the block store's ability to quickly deliver a high-quality reply to existence queries for already-stored blocks. A chunking decision is made with limited lookahead and number of queries. We present results of running these algorithms on actual backup data, as well as four sets of source code archives. Our algorithms typically achieve similar duplicate elimination to standard algorithms while using chunks 2-4 times as large. Such approaches may be particularly interesting to distributed storage systems that use redundancy techniques (such as error-correcting codes) requiring multiple chunk fragments, for which metadata overheads per stored chunk are high. We find that algorithm variants with more flexibility in location and size of chunks yield better duplicate elimination, at a cost of a higher number of existence queries.",
        "acm_key": "1855520",
        "bib_stats": {
            "cites": 40,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Boboila:2010:WEF:1855511.1855520,\n author = {Boboila, Simona and Desnoyers, Peter},\n title = {Write Endurance in Flash Drives: Measurements and Analysis},\n booktitle = {Proceedings of the 8th USENIX Conference on File and Storage Technologies},\n series = {FAST'10},\n year = {2010},\n location = {San Jose, California},\n pages = {9--9},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855511.1855520},\n acmid = {1855520},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855520",
        "pub_year": "2010",
        "text": "Simona Boboila , Peter Desnoyers, Write endurance in flash drives: measurements and analysis, Proceedings of the 8th USENIX conference on File and storage technologies, p.9-9, February 23-26, 2010, San Jose, California"
    },
    "1855582": {
        "abstract": "Software patches are designed to have a positive effect on the operation of software systems. However, these patches may cause incompatibilities, regressions, and other unintended negative impact on the reliability, performance, and security of software. In this paper, we propose PatchAdvisor, a technique to improve the manageability of the patching process for administrators by automatically inferring the impact of a patch or upgrade. PatchAdvisor inspects a software system and its patch using a combination of static control flow analysis, dynamic execution traces, and ranking heuristics to automatically infer the potential impact of the patch. To evaluate the feasibility of our approach, we implement an initial prototype of PatchAdvisor using the IDA and PaiMei frameworks and demonstrate its effectiveness on a real-world web application stack. Finally, we discuss the challenges and future research directions in this problem domain.",
        "acm_key": "1855582",
        "bib_stats": {
            "cites": 51,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Mogul:2009:OSS:1855568.1855582,\n author = {Mogul, Jeffrey C. and Argollo, Eduardo and Shah, Mehul and Faraboschi, Paolo},\n title = {Operating System Support for NVM+DRAM Hybrid Main Memory},\n booktitle = {Proceedings of the 12th Conference on Hot Topics in Operating Systems},\n series = {HotOS'09},\n year = {2009},\n location = {Monte Verit\\&\\#224;, Switzerland},\n pages = {14--14},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855568.1855582},\n acmid = {1855582},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855582",
        "pub_year": "2009",
        "text": "Jeffrey C. Mogul , Eduardo Argollo , Mehul Shah , Paolo Faraboschi, Operating system support for NVM+DRAM hybrid main memory, Proceedings of the 12th conference on Hot topics in operating systems, p.14-14, May 18-20, 2009, Monte Verit\u00e0, Switzerland"
    },
    "1855752": {
        "abstract": "This paper introduces a new consistency metric, Network Imprecision (NI), to address a central challenge in largescale monitoring systems: safeguarding accuracy despite node and network failures. To implement NI, an overlay that monitors a set of attributes also monitors its own state so that queries return not only attribute values but also information about the stability of the overlay--the number of nodes whose recent updates may be missing and the number of nodes whose inputs may be double counted due to overlay reconfigurations. When NI indicates that the network is stable, query results are guaranteed to reflect the true state of the system. But when the network is unstable, NI puts applications on notice that query results should not be trusted, allowing them to take corrective action such as filtering out inconsistent results. To scalably implement NI's introspection, our prototype introduces a key optimization, dual-tree prefix aggregation, which exploits overlay symmetry to reduce overheads by more than an order of magnitude. Evaluation of three monitoring applications demonstrates that NI flags inaccurate results while incurring low overheads, and monitoring applications that use NI to select good information can improve their accuracy by up to an order of magnitude.",
        "acm_key": "1855752",
        "bib_stats": {
            "cites": 36,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Prabhakaran:2008:TF:1855741.1855752,\n author = {Prabhakaran, Vijayan and Rodeheffer, Thomas L. and Zhou, Lidong},\n title = {Transactional Flash},\n booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},\n series = {OSDI'08},\n year = {2008},\n location = {San Diego, California},\n pages = {147--160},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=1855741.1855752},\n acmid = {1855752},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855752",
        "pub_year": "2008",
        "text": "Vijayan Prabhakaran , Thomas L. Rodeheffer , Lidong Zhou, Transactional flash, Proceedings of the 8th USENIX conference on Operating systems design and implementation, p.147-160, December 08-10, 2008, San Diego, California"
    },
    "1855816": {
        "abstract": "The ability to rapidly deploy new network services, service features and operational tools, without impacting existing services, is a significant challenge for all service providers. In this paper we address this problem by the introduction of a platform called ShadowNet. ShadowNet exploits the strong separation provided by modern computing and network equipment between logical functionality and physical infrastructure. It allows logical topologies of computing servers, network equipment and links to be dynamically created, and then instantiated to and managed on the physical infrastructure. ShadowNet is a sharable, programmable and composable infrastructure, consisting of carrier-grade equipment. Furthermore, it is a fully operational network that is connected to, but functionally separate from the provider production network. By exploiting the strong separation support, ShadowNet allows multiple technology and service trials to be executed in parallel in a realistic operational setting, without impacting the production network. In this paper, we describe the ShadowNet architecture and the control framework designed for its operation and illustrate the utility of the platform. We present our prototype implementation and demonstrate the effectiveness of the platform through extensive evaluation.",
        "acm_key": "1855816",
        "bib_stats": {
            "cites": 19,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lee:2009:FFF:1855807.1855816,\n author = {Lee, Sungjin and Ha, Keonsoo and Zhang, Kangwon and Kim, Jihong and Kim, Junghwan},\n title = {FlexFS: A Flexible Flash File System for MLC NAND Flash Memory},\n booktitle = {Proceedings of the 2009 Conference on USENIX Annual Technical Conference},\n series = {USENIX'09},\n year = {2009},\n location = {San Diego, California},\n pages = {9--9},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855807.1855816},\n acmid = {1855816},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855816",
        "pub_year": "2009",
        "text": "Sungjin Lee , Keonsoo Ha , Kangwon Zhang , Jihong Kim , Junghwan Kim, FlexFS: a flexible flash file system for MLC NAND flash memory, Proceedings of the 2009 conference on USENIX Annual technical conference, p.9-9, June 14-19, 2009, San Diego, California"
    },
    "1855856": {
        "abstract": "Dyson is a new software architecture for building customizable WLANs. While research in wireless networks has made great strides, these advancements have not seen the light of day in real WLAN deployments. One of the key reasons is that today's WLANs are not architected to embrace change. For example, system administrators cannot fine-tune the association policy for their particular environment: an administrator may know certain nodes in certain locations interfere with each other and cause a severe degradation in throughput, and hence, such associations must be avoided in the particular deployment. Dyson defines a set of APIs that allow clients and APs to send pertinent information such as radio channel conditions to a central controller. The central controller processes this information, to form a global view of the network. This global view, combined with historical information about spatial and temporal usage patterns, allows the central controller enact a rich set of policies to control the network's behavior. Dyson provides a Python-based scripting API that allows the central controller's policies to be extended for site-specific customizations and new optimizations that leverage historical knowledge. We have built a prototype implementation of Dyson, which currently runs on a 28-node testbed distributed across one floor of a typical academic building. Using this testbed, we examine various aspects of the architecture in detail, and demonstrate the ease of implementing a wide range of policies. Using Dyson, we demonstrate optimizing associations, handling VoIP clients, reserving airtime for specific users, and optimizing handoffs for mobile clients.",
        "acm_key": "1855856",
        "bib_stats": {
            "cites": 56,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Debnath:2010:CSU:1855840.1855856,\n author = {Debnath, Biplob and Sengupta, Sudipta and Li, Jin},\n title = {ChunkStash: Speeding Up Inline Storage Deduplication Using Flash Memory},\n booktitle = {Proceedings of the 2010 USENIX Conference on USENIX Annual Technical Conference},\n series = {USENIXATC'10},\n year = {2010},\n location = {Boston, MA},\n pages = {16--16},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1855840.1855856},\n acmid = {1855856},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1855856",
        "pub_year": "2010",
        "text": "Biplob Debnath , Sudipta Sengupta , Jin Li, ChunkStash: speeding up inline storage deduplication using flash memory, Proceedings of the 2010 USENIX conference on USENIX annual technical conference, p.16-16, June 23-25, 2010, Boston, MA"
    },
    "1869265": {
        "abstract": "Volume 67 Issue 11, November, 2010 \r\n\r\n",
        "acm_key": "1869265",
        "bib_stats": {
            "cites": 25
        },
        "bibtex": "\r\n@article{Bux:2010:PGG:1869138.1869265,\n author = {Bux, Werner and Iliadis, Ilias},\n title = {Performance of Greedy Garbage Collection in Flash-based Solid-state Drives},\n journal = {Perform. Eval.},\n issue_date = {November, 2010},\n volume = {67},\n number = {11},\n month = nov,\n year = {2010},\n issn = {0166-5316},\n pages = {1172--1186},\n numpages = {15},\n url = {http://dx.doi.org/10.1016/j.peva.2010.07.003},\n doi = {10.1016/j.peva.2010.07.003},\n acmid = {1869265},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Garbage collection, Log-structured systems, Markov chain model, SSD, Stochastic modeling, Write amplification},\n} \r\n",
        "key": "1869265",
        "pub_year": "2010",
        "text": "Werner Bux , Ilias Iliadis, Performance of greedy garbage collection in flash-based solid-state drives, Performance Evaluation, v.67 n.11, p.1172-1186, November, 2010"
    },
    "1870961": {
        "abstract": "As Electronic Control Units (ECUs) and embedded software functions within an automobile keep increasing in number, the scale and complexity of automotive embedded systems is growing at a very rapid pace. Hence, the automotive industry has been developing the Automotive Open System Architecture (AUTOSAR) to harness the reusability of common interfaces to communication buses, real-time operating systems and services. These common interfaces foster ease of adoption, interoperability, maintainability, predictability, and analyzability. However, realizing such standards also requires strong support from end-to-end design tool chains. In this paper, we describe some key analytical components that together characterize the end-to-end timing properties of hierarchical bus structures composed of FlexRay, CANbus and LINbus. Our analysis shows that the practical constraints imposed by standards such as AUTOSAR can lead to higher levels of schedulable resource utilization. This reduces both the overall component count and cost, while facilitating easy enhancements. Our analytical results show (a) how a schedulable utilization of 100% can be obtained for time-triggered FlexRay static segments under AUTOSAR compliance, (b) average-case schedulable utilization of 87% for the event-triggered CAN bus, and (c) similarities between LINbus and FlexRay analyses. We generalize the analytical results from different bus technologies, by exploiting their common underlying structure to enable an integrated end-to-end timing analysis of hierarchical heterogeneous networks. These together yield an end-to-end framework to analyze heterogeneously networked AUTOSAR-compliant automotive systems.",
        "acm_key": "1870961",
        "bib_stats": {
            "cites": 31,
            "dl": 519,
            "dl_52": 23,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Joo:2010:EED:1870926.1870961,\n author = {Joo, Yongsoo and Niu, Dimin and Dong, Xiangyu and Sun, Guangyu and Chang, Naehyuck and Xie, Yuan},\n title = {Energy- and Endurance-aware Design of Phase Change Memory Caches},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '10},\n year = {2010},\n isbn = {978-3-9810801-6-2},\n location = {Dresden, Germany},\n pages = {136--141},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1870926.1870961},\n acmid = {1870961},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1870961",
        "pub_year": "2010",
        "text": "Yongsoo Joo , Dimin Niu , Xiangyu Dong , Guangyu Sun , Naehyuck Chang , Yuan Xie, Energy- and endurance-aware design of phase change memory caches, Proceedings of the Conference on Design, Automation and Test in Europe, March 08-12, 2010, Dresden, Germany"
    },
    "1871147": {
        "abstract": "As Electronic Control Units (ECUs) and embedded software functions within an automobile keep increasing in number, the scale and complexity of automotive embedded systems is growing at a very rapid pace. Hence, the automotive industry has been developing the Automotive Open System Architecture (AUTOSAR) to harness the reusability of common interfaces to communication buses, real-time operating systems and services. These common interfaces foster ease of adoption, interoperability, maintainability, predictability, and analyzability. However, realizing such standards also requires strong support from end-to-end design tool chains. In this paper, we describe some key analytical components that together characterize the end-to-end timing properties of hierarchical bus structures composed of FlexRay, CANbus and LINbus. Our analysis shows that the practical constraints imposed by standards such as AUTOSAR can lead to higher levels of schedulable resource utilization. This reduces both the overall component count and cost, while facilitating easy enhancements. Our analytical results show (a) how a schedulable utilization of 100% can be obtained for time-triggered FlexRay static segments under AUTOSAR compliance, (b) average-case schedulable utilization of 87% for the event-triggered CAN bus, and (c) similarities between LINbus and FlexRay analyses. We generalize the analytical results from different bus technologies, by exploiting their common underlying structure to enable an integrated end-to-end timing analysis of hierarchical heterogeneous networks. These together yield an end-to-end framework to analyze heterogeneously networked AUTOSAR-compliant automotive systems.",
        "acm_key": "1871147",
        "bib_stats": {
            "cites": 42,
            "dl": 513,
            "dl_52": 52,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Ferreira:2010:IPM:1870926.1871147,\n author = {Ferreira, Alexandre P. and Zhou, Miao and Bock, Santiago and Childers, Bruce and Melhem, Rami and Moss{\\'e}, Daniel},\n title = {Increasing PCM Main Memory Lifetime},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '10},\n year = {2010},\n isbn = {978-3-9810801-6-2},\n location = {Dresden, Germany},\n pages = {914--919},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1870926.1871147},\n acmid = {1871147},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1871147",
        "pub_year": "2010",
        "text": "Alexandre P. Ferreira , Miao Zhou , Santiago Bock , Bruce Childers , Rami Melhem , Daniel Moss\u00e9, Increasing PCM main memory lifetime, Proceedings of the Conference on Design, Automation and Test in Europe, March 08-12, 2010, Dresden, Germany"
    },
    "1874715": {
        "abstract": "With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions. With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions.",
        "acm_key": "1874715",
        "bib_stats": {
            "cites": 16,
            "dl": 181,
            "dl_52": 21,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Wu:2009:FFD:1874620.1874715,\n author = {Wu, Po-Liang and Chang, Yuan-Hao and Kuo, Tei-Wei},\n title = {A File-system-aware FTL Design for Flash-memory Storage Systems},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '09},\n year = {2009},\n isbn = {978-3-9810801-5-5},\n location = {Nice, France},\n pages = {393--398},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1874620.1874715},\n acmid = {1874715},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1874715",
        "pub_year": "2009",
        "text": "Po-Liang Wu , Yuan-Hao Chang , Tei-Wei Kuo, A file-system-aware FTL design for flash-memory storage systems, Proceedings of the Conference on Design, Automation and Test in Europe, April 20-24, 2009, Nice, France"
    },
    "1874716": {
        "abstract": "With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions. With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions.",
        "acm_key": "1874716",
        "bib_stats": {
            "cites": 3,
            "dl": 122,
            "dl_52": 13,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Mylavarapu:2009:FFS:1874620.1874716,\n author = {Mylavarapu, Sai Krishna and Choudhuri, Siddharth and Shrivastava, Aviral and Lee, Jongeun and Givargis, Tony},\n title = {FSAF: File System Aware Flash Translation Layer for NAND Flash Memories},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '09},\n year = {2009},\n isbn = {978-3-9810801-5-5},\n location = {Nice, France},\n pages = {399--404},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1874620.1874716},\n acmid = {1874716},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1874716",
        "pub_year": "2009",
        "text": "Sai Krishna Mylavarapu , Siddharth Choudhuri , Aviral Shrivastava , Jongeun Lee , Tony Givargis, FSAF: file system aware flash translation layer for NAND flash memories, Proceedings of the Conference on Design, Automation and Test in Europe, April 20-24, 2009, Nice, France"
    },
    "1874717": {
        "abstract": "With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions. With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions.",
        "acm_key": "1874717",
        "bib_stats": {
            "cites": 12,
            "dl": 117,
            "dl_52": 11,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chu:2009:SMS:1874620.1874717,\n author = {Chu, Yuan-Sheng and Hsieh, Jen-Wei and Chang, Yuan-Hao and Kuo, Tei-Wei},\n title = {A Set-based Mapping Strategy for Flash-memory Reliability Enhancement},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '09},\n year = {2009},\n isbn = {978-3-9810801-5-5},\n location = {Nice, France},\n pages = {405--410},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1874620.1874717},\n acmid = {1874717},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1874717",
        "pub_year": "2009",
        "text": "Yuan-Sheng Chu , Jen-Wei Hsieh , Yuan-Hao Chang , Tei-Wei Kuo, A set-based mapping strategy for flash-memory reliability enhancement, Proceedings of the Conference on Design, Automation and Test in Europe, April 20-24, 2009, Nice, France"
    },
    "1874745": {
        "abstract": "With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions. With the increasing scaling of manufacturing technology, process variation is a phenomenon that has become more prevalent. As a result, in the context of Chip Multiprocessors (CMPs) for example, it is possible that identically-designed processor cores on the chip have non-identical peak frequencies and power consumptions. To cope with such a design, each processor can be assumed to run at the frequency of the slowest processor, resulting in wasted computational capability. This paper considers an alternate approach and proposes an algorithm that intelligently maps (and remaps) computations onto available processors so that each processor runs at its peak frequency. In other words, by dynamically changing the thread-to-processor mapping at runtime, our approach allows each processor to maximize its performance, rather than simply using chip-wide lowest frequency amongst all cores and highest cache latency. Experimental evidence shows that, as compared to a process variation agnostic thread mapping strategy, our proposed scheme achieves as much as 29% improvement in overall execution latency, average improvement being 13% over the benchmarks tested. We also demonstrate in this paper that our savings are consistent across different processor counts, latency maps, and latency distributions.",
        "acm_key": "1874745",
        "bib_stats": {
            "cites": 37,
            "dl": 270,
            "dl_52": 26,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Cho:2009:KKS:1874620.1874745,\n author = {Cho, Hyunjin and Shin, Dongkun and Eom, Young Ik},\n title = {KAST: K-Associative Sector Translation for NAND Flash Memory in Real-time Systems},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '09},\n year = {2009},\n isbn = {978-3-9810801-5-5},\n location = {Nice, France},\n pages = {507--512},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1874620.1874745},\n acmid = {1874745},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "1874745",
        "pub_year": "2009",
        "text": "Hyunjin Cho , Dongkun Shin , Young Ik Eom, KAST: K-Associative Sector Translation for NAND flash memory in real-time systems, Proceedings of the Conference on Design, Automation and Test in Europe, April 20-24, 2009, Nice, France"
    },
    "1878999": {
        "abstract": "With the continuous scaling of semiconductor technology, the life-time of circuit is decreasing so that processor failure becomes an important issue in MPSoC design. A software solution to tolerate run-time processor failure is to migrate tasks from the failed processors to the live processors when failure occurs. Previous works on run-time task migration usually aim to minimize the migration overhead with or without a given latency constraint. For streaming applications, however, it is more important to minimize the throughput degradation than the migration overhead or the latency. Hence, we propose a task remapping technique to minimize the throughput degradation assuming that the migration overhead can be amortized safely. The target multi-core system assumed in this paper consists of processor pools and each pool consists of homogeneous processors. The proposed technique is based on an intensive compile-time analysis for all possible failure scenarios. It involves the following steps; 1) Determine the static mapping of tasks onto the live processors, aiming to minimize the throughput degradation: 2) Find an optimal processor-to-processor mapping to minimize the task migration overhead: and 3) Store the resultant task remapping information that includes task mapping and processor-to-processor mapping results. Since the task remapping information is pre-computed at compile-time for all possible failure scenarios, it should be efficiently represented and stored. At run-time, we simply remap the tasks following the compile-time decision. We examine the scalability of the proposed technique on both space and run-time overhead for compile-time analysis varying the number of failed processors. Through intensive experiments, we show that the proposed technique outperforms the previous works with respect to application throughput.",
        "acm_key": "1878999",
        "bib_stats": {
            "cites": 0,
            "dl": 168,
            "dl_52": 6,
            "dl_6": 2
        },
        "key": "1878999",
        "text": "Kwangyoon Lee , Alex Orailoglu, High durability in NAND flash memory through effective page reuse mechanisms, Proceedings of the eighth IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis, October 24-29, 2010, Scottsdale, Arizona, USA"
    },
    "1879044": {
        "abstract": "Many real-time applications are designed to work in different operating modes each characterized by different functionality and resource demands. With each mode change, resource demands of applications change, and static resource reservations may not be feasible anymore. Dynamic environments where applications may be added and removed online also need to adapt their resource reservations. In such scenarios, resource reconfigurations are needed for changing the resource reservations during runtime and achieve better resource allocations. There are a lot of results in the scientific literature of how to find the optimal amount of resources needed by an application in the different operating modes, or how an application can perform safe mode transitions. However, the problem of resource reconfigurations for systems with reservations has not been addressed. A resource scheduler should be reconfigured online in such a way that it still guarantees a certain amount of resources during the reconfiguration process, otherwise applications may miss deadlines. The paper proposes a framework for scheduling real-time applications through scheduling servers that provide resource reservations, and algorithms for changing the resource reservations online while still guaranteeing the feasibility of the system and the schedulability of applications. The framework analysis is integrated into a well-known modular performance analysis paradigm based on Real-Time Calculus. The results are illustrated with examples and a case study.",
        "acm_key": "1879044",
        "bib_stats": {
            "cites": 8,
            "dl": 563,
            "dl_52": 18,
            "dl_6": 5
        },
        "key": "1879044",
        "text": "Hunki Kwon , Eunsam Kim , Jongmoo Choi , Donghee Lee , Sam H. Noh, Janus-FTL: finding the optimal point on the spectrum between page and block mapping schemes, Proceedings of the tenth ACM international conference on Embedded software, October 24-29, 2010, Scottsdale, Arizona, USA"
    },
    "1881884": {
        "abstract": "Users of content-based publish/subscribe systems (CBPS) are interested in receiving data items with values that satisfy certain conditions. Each user submits a list of subscription specifications to a broker, which routes data items from publishers to users. When a broker receives a notification that contains a value from a publisher, it forwards it only to the subscribers whose requests match the value. However, in many applications, the data published are confidential, and their contents must not be revealed to brokers. Furthermore, a user's subscription may contain sensitive information that must be protected from brokers. Therefore, a difficult challenge arises: how to route publisher data to the appropriate subscribers without the intermediate brokers learning the plain text values of the notifications and subscriptions. To that extent, brokers must be able to perform operations on top of the encrypted contents of subscriptions and notifications. Such operations may be as simple as equality match, but often require more complex operations such as determining inclusion of data in a value interval. Previous work attempted to solve this problem by using one-way data mappings or specialized encryption functions that allow evaluation of conditions on ciphertexts. However, such operations are computationally expensive, and the resulting CBPS lack scalability. As fast dissemination is an important requirement in many applications, we focus on a new data transformation method called Asymmetric Scalar-product Preserving Encryption (ASPE) [1]. We devise methods that build upon ASPE to support private evaluation of several types of conditions. We also suggest techniques for secure aggregation of notifications, supporting functions such as sum, minimum, maximum and count. Our experimental evaluation shows that ASPE-based CBPS incurs 65% less overhead for exact-match filtering and 50% less overhead for range filtering compared to the state-of-the-art.",
        "acm_key": "1881884",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@inproceedings{Ou:2010:PPE:1881867.1881884,\n author = {Ou, Yi and H\\\"{a}rder, Theo and Schall, Daniel},\n title = {Performance and Power Evaluation of Flash-aware Buffer Algorithms},\n booktitle = {Proceedings of the 21st International Conference on Database and Expert Systems Applications: Part I},\n series = {DEXA'10},\n year = {2010},\n isbn = {3-642-15363-1, 978-3-642-15363-1},\n location = {Bilbao, Spain},\n pages = {183--197},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=1881867.1881884},\n acmid = {1881884},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n} \r\n",
        "key": "1881884",
        "pub_year": "2010",
        "text": "Yi Ou , Theo H\u00e4rder , Daniel Schall, Performance and power evaluation of flash-aware buffer algorithms, Proceedings of the 21st international conference on Database and expert systems applications: Part I, August 30-September 03, 2010, Bilbao, Spain"
    },
    "1883714": {
        "abstract": "In the area of highly interactive systems, the use of object databases has significantly grown in the past few years due to the fact that one can, not only persistently store data in the form of objects, but also provide additional functionality in terms of methods defined on these objects. However, a limitation of such a tight coupling of objects and their methods is that parts of the application logic cannot be reused without also having instances of these objects in the new application database. Based on our experience of designing multiple interactive cross-media applications, we propose an approach where we distinguish between regular database objects containing the data and so-called active components storing metadata about specific services. Active components are first class objects which, at activation time, can perform some operations on the server as well as on the client side. Since active components are standalone lightweight components, they can be dynamically bound to single objects or semantically grouped sets of objects and be automatically invoked by different forms of database interactions. The database-driven development of arbitrary client and server-side application functionality not only simplifies the design of highly interactive systems, but also improves the reuse of existing components across different systems.",
        "acm_key": "1883714",
        "bib_stats": {
            "cites": 6
        },
        "bibtex": "\r\n@inproceedings{Dearle:2009:OPR:1883713.1883714,\n author = {Dearle, Alan and Kirby, Graham N. C. and Morrison, Ron},\n title = {Orthogonal Persistence Revisited},\n booktitle = {Proceedings of the Second International Conference on Object Databases},\n series = {ICOODB'09},\n year = {2010},\n isbn = {3-642-14680-5, 978-3-642-14680-0},\n location = {Zurich, Switzerland},\n pages = {1--22},\n numpages = {22},\n url = {http://dl.acm.org/citation.cfm?id=1883713.1883714},\n acmid = {1883714},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n} \r\n",
        "key": "1883714",
        "pub_year": "2009",
        "text": "Alan Dearle , Graham N. C. Kirby , Ron Morrison, Orthogonal persistence revisited, Proceedings of the Second international conference on Object databases, p.1-22, July 01-03, 2009, Zurich, Switzerland"
    },
    "1892715": {
        "abstract": "Address Event Representation (AER) is an emergent technology for assembling modular multiblock bio-inspired sensory and processing systems. Visual sensors (retinae) are among the first AER modules to be reported since the introduction of the technology. Spatial-contrast AER retinae are of special interest since they provide highly compressed data flow without reducing the relevant information required for performing recognition. The reported AER contrast retinae perform a contrast computation based on the ratio between a pixel's local light intensity and a spatially weighted average of its neighborhood. This resulted in compact circuits but with the penalty of all pixels generating output signals even if they sensed no contrast. In this paper, we present a spatial-contrast retina with a signed output: Contrast is computed as the relative difference (not the ratio) between a pixel's local light and its surrounding spatial average and normalized with respect to ambient light. As a result, contrast is ambient light independent, includes a sign, and the output will be zero if there is no contrast. Furthermore, an adjustable thresholding mechanism has been included, such that pixels remain silent until they sense an absolute contrast above the adjustable threshold. The pixel contrast-computation circuit is based on Boahen's biharmonic operator contrast circuit, which has been improved to include mismatch calibration and adaptive-current-based biasing. As a result, the contrast-computation circuit shows much less mismatch, is almost insensitive to ambient light illumination, and biasing is much less critical than in the original voltage biasing scheme. The retina includes an optional global reset mechanism for operation in ambient-light-independent Time-to-First-Spike contrast-computation mode. A 32 \u00d7 32 pixel test prototype has been fabricated in 0.35-\u00b5m CMOS. Experimental results are provided.",
        "acm_key": "1892715",
        "bib_stats": {
            "cites": 13
        },
        "bibtex": "\r\n@article{Dong:2010:UDP:1892701.1892715,\n author = {Dong, Guiqiang and Li, Shu and Zhang, Tong},\n title = {Using Data Postcompensation and Predistortion to Tolerate Cell-to-cell Interference in MLC NAND Flash Memory},\n journal = {Trans. Cir. Sys. Part I},\n issue_date = {October 2010},\n volume = {57},\n number = {10},\n month = oct,\n year = {2010},\n issn = {1549-8328},\n pages = {2718--2728},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/TCSI.2010.2046966},\n doi = {10.1109/TCSI.2010.2046966},\n acmid = {1892715},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {NAND flash memory, cell-to-cell interference, postcompensation, predistortion},\n} \r\n",
        "key": "1892715",
        "pub_year": "2010",
        "text": "Guiqiang Dong , Shu Li , Tong Zhang, Using data postcompensation and predistortion to tolerate cell-to-cell interference in MLC NAND flash memory, IEEE Transactions on Circuits and Systems Part I: Regular Papers, v.57 n.10, p.2718-2728, October 2010"
    },
    "1907850": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1907850",
        "bib_stats": {
            "cites": 24,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Chang:2010:HAN:1907645.1907850,\n author = {Chang, Li-Pin},\n title = {A Hybrid Approach to NAND-Flash-Based Solid-State Disks},\n journal = {IEEE Trans. Comput.},\n issue_date = {October 2010},\n volume = {59},\n number = {10},\n month = oct,\n year = {2010},\n issn = {0018-9340},\n pages = {1337--1349},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TC.2010.14},\n doi = {10.1109/TC.2010.14},\n acmid = {1907850},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash memory, Flash memory, storage systems, file systems, solid-state disks., file systems, solid-state disks., storage systems},\n} \r\n",
        "key": "1907850",
        "pub_year": "2010",
        "text": "Li-Pin Chang, A Hybrid Approach to NAND-Flash-Based Solid-State Disks, IEEE Transactions on Computers, v.59 n.10, p.1337-1349, October 2010  \u00a0[doi>"
    },
    "1914420": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1914420",
        "bib_stats": {
            "cites": 16,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Seppanen:2010:HPS:1913798.1914420,\n author = {Seppanen, Eric and O'Keefe, Matthew T. and Lilja, David J.},\n title = {High Performance Solid State Storage Under Linux},\n booktitle = {Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)},\n series = {MSST '10},\n year = {2010},\n isbn = {978-1-4244-7152-2},\n pages = {1--12},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/MSST.2010.5496976},\n doi = {10.1109/MSST.2010.5496976},\n acmid = {1914420},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1914420",
        "pub_year": "2010",
        "text": "Eric Seppanen , Matthew T. O'Keefe , David J. Lilja, High performance solid state storage under Linux, Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), p.1-12, May 03-07, 2010  \u00a0[doi>"
    },
    "1914429": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1914429",
        "bib_stats": {
            "cites": 9,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wu:2010:BAW:1913798.1914429,\n author = {Wu, Guanying and Eckart, Ben and He, Xubin},\n title = {BPAC: An Adaptive Write Buffer Management Scheme for Flash-based Solid State Drives},\n booktitle = {Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)},\n series = {MSST '10},\n year = {2010},\n isbn = {978-1-4244-7152-2},\n pages = {1--6},\n numpages = {6},\n url = {http://dx.doi.org/10.1109/MSST.2010.5496998},\n doi = {10.1109/MSST.2010.5496998},\n acmid = {1914429},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1914429",
        "pub_year": "2010",
        "text": "Guanying Wu , Ben Eckart , Xubin He, BPAC: An adaptive write buffer management scheme for flash-based Solid State Drives, Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), p.1-6, May 03-07, 2010  \u00a0[doi>"
    },
    "1914433": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1914433",
        "bib_stats": {
            "cites": 18,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Meister:2010:DID:1913798.1914433,\n author = {Meister, Dirk and Brinkmann, Andre},\n title = {Dedupv1: Improving Deduplication Throughput Using Solid State Drives (SSD)},\n booktitle = {Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)},\n series = {MSST '10},\n year = {2010},\n isbn = {978-1-4244-7152-2},\n pages = {1--6},\n numpages = {6},\n url = {http://dx.doi.org/10.1109/MSST.2010.5496992},\n doi = {10.1109/MSST.2010.5496992},\n acmid = {1914433},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1914433",
        "pub_year": "2010",
        "text": "Dirk Meister , Andre Brinkmann, dedupv1: Improving deduplication throughput using solid state drives (SSD), Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), p.1-6, May 03-07, 2010  \u00a0[doi>"
    },
    "1914443": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1914443",
        "bib_stats": {
            "cites": 5,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wongchaowart:2010:CBP:1913798.1914443,\n author = {Wongchaowart, Brian and Iskander, Marian K. and Cho, Sangyeun},\n title = {A Content-aware Block Placement Algorithm for Reducing PRAM Storage Bit Writes},\n booktitle = {Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)},\n series = {MSST '10},\n year = {2010},\n isbn = {978-1-4244-7152-2},\n pages = {1--11},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/MSST.2010.5496996},\n doi = {10.1109/MSST.2010.5496996},\n acmid = {1914443},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1914443",
        "pub_year": "2010",
        "text": "Brian Wongchaowart , Marian K. Iskander , Sangyeun Cho, A content-aware block placement algorithm for reducing PRAM storage bit writes, Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), p.1-11, May 03-07, 2010  \u00a0[doi>"
    },
    "1920119": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1920119",
        "bib_stats": {
            "cites": 16,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Im:2011:FRT:1920045.1920119,\n author = {Im, Soojun and Shin, Dongkun and Shin, Dongkun and Shin, Dongkun and Shin, Dongkun},\n title = {Flash-Aware RAID Techniques for Dependable and High-Performance Flash Memory SSD},\n journal = {IEEE Trans. Comput.},\n issue_date = {January 2011},\n volume = {60},\n number = {1},\n month = jan,\n year = {2011},\n issn = {0018-9340},\n pages = {80--92},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TC.2010.197},\n doi = {10.1109/TC.2010.197},\n acmid = {1920119},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Redundant arrays of inexpensive disks (RAID), Redundant arrays of inexpensive disks (RAID), flash memory, solid-state disk (SSD), reliability, dependability., dependability., flash memory, reliability, solid-state disk (SSD)},\n} \r\n",
        "key": "1920119",
        "pub_year": "2011",
        "text": "Soojun Im , Dongkun Shin , Dongkun Shin , Dongkun Shin , Dongkun Shin, Flash-Aware RAID Techniques for Dependable and High-Performance Flash Memory SSD, IEEE Transactions on Computers, v.60 n.1, p.80-92, January 2011  \u00a0[doi>"
    },
    "1920990": {
        "abstract": "Mobile commerce and location based services (LBS) are some of the fastest growing IT industries in the last five years. Location update of mobile clients is a fundamental capability in mobile commerce and all types of LBS. Higher update frequency leads to higher accuracy, but incurs unacceptably high cost of location management at the location servers. We propose RoadTrack -- a road-network based, query-aware location update framework with two unique features. First, we introduce the concept of precincts to control the granularity of location update resolution for mobile clients that are not of interest to any active location query services. Second, we define query encounter points for mobile objects that are targets of active location query services, and utilize these encounter points to define the adequate location update schedule for each mobile. The RoadTrack framework offers three unique advantages. First, encounter points as a fundamental query awareness mechanism enable us to control and differentiate location update strategies for mobile clients in the vicinity of active location queries, while meeting the needs of location query evaluation. Second, we employ system-defined precincts to manage the desired spatial resolution of location updates for different mobile clients and to control the scope of query awareness to be capitalized by a location update strategy. Third, our road-network based check-free interval optimization further enhances the effectiveness of the Road-Track query-aware location update scheduling algorithm. This optimization provides significant cost reduction for location update management at both mobile clients and location servers. We evaluate the RoadTrack location update approach using a real world road-network based mobility simulator. Our experimental results demonstrate that the RoadTrack query aware location update approach outperforms existing representative location update strategies in terms of both client energy efficiency and server processing load.",
        "acm_key": "1920990",
        "bib_stats": {
            "cites": 47,
            "dl": 479,
            "dl_52": 63,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Li:2010:TIS:1920841.1920990,\n author = {Li, Yinan and He, Bingsheng and Yang, Robin Jun and Luo, Qiong and Yi, Ke},\n title = {Tree Indexing on Solid State Drives},\n journal = {Proc. VLDB Endow.},\n issue_date = {September 2010},\n volume = {3},\n number = {1-2},\n month = sep,\n year = {2010},\n issn = {2150-8097},\n pages = {1195--1206},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/1920841.1920990},\n doi = {10.14778/1920841.1920990},\n acmid = {1920990},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1920990",
        "pub_year": "2010",
        "text": "Yinan Li , Bingsheng He , Robin Jun Yang , Qiong Luo , Ke Yi, Tree indexing on solid state drives, Proceedings of the VLDB Endowment, v.3 n.1-2, September 2010"
    },
    "1921015": {
        "abstract": "Mobile commerce and location based services (LBS) are some of the fastest growing IT industries in the last five years. Location update of mobile clients is a fundamental capability in mobile commerce and all types of LBS. Higher update frequency leads to higher accuracy, but incurs unacceptably high cost of location management at the location servers. We propose RoadTrack -- a road-network based, query-aware location update framework with two unique features. First, we introduce the concept of precincts to control the granularity of location update resolution for mobile clients that are not of interest to any active location query services. Second, we define query encounter points for mobile objects that are targets of active location query services, and utilize these encounter points to define the adequate location update schedule for each mobile. The RoadTrack framework offers three unique advantages. First, encounter points as a fundamental query awareness mechanism enable us to control and differentiate location update strategies for mobile clients in the vicinity of active location queries, while meeting the needs of location query evaluation. Second, we employ system-defined precincts to manage the desired spatial resolution of location updates for different mobile clients and to control the scope of query awareness to be capitalized by a location update strategy. Third, our road-network based check-free interval optimization further enhances the effectiveness of the Road-Track query-aware location update scheduling algorithm. This optimization provides significant cost reduction for location update management at both mobile clients and location servers. We evaluate the RoadTrack location update approach using a real world road-network based mobility simulator. Our experimental results demonstrate that the RoadTrack query aware location update approach outperforms existing representative location update strategies in terms of both client energy efficiency and server processing load.",
        "acm_key": "1921015",
        "bib_stats": {
            "cites": 52,
            "dl": 995,
            "dl_52": 103,
            "dl_6": 9
        },
        "bibtex": "\r\n@article{Debnath:2010:FHT:1920841.1921015,\n author = {Debnath, Biplob and Sengupta, Sudipta and Li, Jin},\n title = {FlashStore: High Throughput Persistent Key-value Store},\n journal = {Proc. VLDB Endow.},\n issue_date = {September 2010},\n volume = {3},\n number = {1-2},\n month = sep,\n year = {2010},\n issn = {2150-8097},\n pages = {1414--1425},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/1920841.1921015},\n doi = {10.14778/1920841.1921015},\n acmid = {1921015},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "1921015",
        "pub_year": "2010",
        "text": "Biplob Debnath , Sudipta Sengupta , Jin Li, FlashStore: high throughput persistent key-value store, Proceedings of the VLDB Endowment, v.3 n.1-2, September 2010"
    },
    "1934984": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1934984",
        "bib_stats": {
            "cites": 82,
            "dl": 1,
            "dl_52": 106,
            "dl_6": 10
        },
        "bibtex": "\r\n@inproceedings{Caulfield:2010:MHS:1934902.1934984,\n author = {Caulfield, Adrian M. and De, Arup and Coburn, Joel and Mollow, Todor I. and Gupta, Rajesh K. and Swanson, Steven},\n title = {Moneta: A High-Performance Storage Array Architecture for Next-Generation, Non-volatile Memories},\n booktitle = {Proceedings of the 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO '43},\n year = {2010},\n isbn = {978-0-7695-4299-7},\n pages = {385--395},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/MICRO.2010.33},\n doi = {10.1109/MICRO.2010.33},\n acmid = {1934984},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {software IO optimizations, non-volatile memories, phase change memories, storage systems},\n} \r\n",
        "key": "1934984",
        "pub_year": "2010",
        "text": "Adrian M. Caulfield , Arup De , Joel Coburn , Todor I. Mollow , Rajesh K. Gupta , Steven Swanson, Moneta: A High-Performance Storage Array Architecture for Next-Generation, Non-volatile Memories, Proceedings of the 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture, p.385-395, December 04-08, 2010"
    },
    "1946062": {
        "abstract": "In this paper, I survey briefly some of the recent and emerging trends in hardware and software features which impact high performance transaction processing and data analytics applications. These features include multicore processor chips, ultra large main memories, flash storage, storage class memories, database appliances, field programmable gate arrays, transactional memory, key-value stores, and cloud computing. While some applications, e.g., Web 2.0 ones, were initially built without traditional transaction processing functionality in mind, slowly system architects and designers are beginning to address such previously ignored issues. The availability, analytics and response time requirements of these applications were initially given more importance than ACID transaction semantics and resource consumption characteristics. A project at IBM Almaden is studying the implications of phase change memory on transaction processing, in the context of a key-value store. Bitemporal data management has also become an important requirement, especially for financial applications. Power consumption and heat dissipation properties are also major considerations in the emergence of modern software and hardware architectural features. Considerations relating to ease of configuration, installation, maintenance and monitoring, and improvement of total cost of ownership have resulted in database appliances becoming very popular. The MapReduce paradigm is now quite popular for large scale data analysis, in spite of the major inefficiencies associated with it.",
        "acm_key": "1946062",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Khessib:2010:USS:1946050.1946062,\n author = {Khessib, Badriddine M. and Vaid, Kushagra and Sankar, Sriram and Zhang, Chengliang},\n title = {Using Solid State Drives As a Mid-tier Cache in Enterprise Database OLTP Applications},\n booktitle = {Proceedings of the Second TPC Technology Conference on Performance Evaluation, Measurement and Characterization of Complex Systems},\n series = {TPCTC'10},\n year = {2011},\n isbn = {978-3-642-18205-1},\n location = {Singapore},\n pages = {153--168},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=1946050.1946062},\n acmid = {1946062},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {DBMS buffer pool management, OLTP performance, SSD caching, solid state disks},\n} \r\n",
        "key": "1946062",
        "pub_year": "2010",
        "text": "Badriddine M. Khessib , Kushagra Vaid , Sriram Sankar , Chengliang Zhang, Using solid state drives as a mid-tier cache in enterprise database OLTP applications, Proceedings of the Second TPC technology conference on Performance evaluation, measurement and characterization of complex systems, p.153-168, September 13-17, 2010, Singapore"
    },
    "1948492": {
        "abstract": "Distributed data and restricted limitations of sensor nodes make doing regression difficult in a wireless sensor network. In conventional methods, gradient descent and Nelder Mead simplex optimization techniques are basically employed to find the model incrementally over a Hamiltonian path among the nodes. Although Nelder Mead simplex based approaches work better than gradient ones, compared to Central approach, their accuracy should be improved even further. Also they all suffer from high latency as all the network nodes should be traversed node by node. In this paper, we propose a two-fold distributed cluster-based approach for spatiotemporal regression over sensor networks. First, the regressor of each cluster is obtained where spatial and temporal parts of the cluster's regressor are learned separately. Within a cluster, the cluster nodes collaborate to compute the temporal part of the cluster's regressor and the cluster head then uses particle swarm optimization to learn the spatial part. Secondly, the cluster heads collaborate to apply weighted combination rule distributively to learn the global model. The evaluation and experimental results show the proposed approach brings lower latency and more energy efficiency compared to its counterparts while its prediction accuracy is considerably acceptable in comparison with the Central approach.",
        "acm_key": "1948492",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Liu:2010:SXS:1948448.1948492,\n author = {Liu, Ji and Chen, Shuyu and Liu, Haozhang},\n title = {A Structure-based XML Storage Method in YAFFS File System},\n booktitle = {Proceedings of the 6th International Conference on Advanced Data Mining and Applications - Volume Part II},\n series = {ADMA'10},\n year = {2010},\n isbn = {3-642-17312-8, 978-3-642-17312-7},\n location = {Chongqing, China},\n pages = {427--434},\n numpages = {8},\n url = {http://dl.acm.org/citation.cfm?id=1948448.1948492},\n acmid = {1948492},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {XML, YAFFS file system, embedded linux, structure-based XML storage},\n} \r\n",
        "key": "1948492",
        "pub_year": "2010",
        "text": "Ji Liu , Shuyu Chen , Haozhang Liu, A structure-based XML storage method in YAFFS file system, Proceedings of the 6th international conference on Advanced data mining and applications, November 19-21, 2010, Chongqing, China"
    },
    "1950379": {
        "abstract": "Graphics processing units (GPUs) provide a low cost platform for accelerating high performance computations. The introduction of new programming languages, such as CUDA and OpenCL, makes GPU programming attractive to a wide variety of programmers. However, programming GPUs is still a cumbersome task for two primary reasons: tedious performance optimizations and lack of portability. First, optimizing an algorithm for a specific GPU is a time-consuming task that requires a thorough understanding of both the algorithm and the underlying hardware. Unoptimized CUDA programs typically only achieve a small fraction of the peak GPU performance. Second, GPU code lacks efficient portability as code written for one GPU can be inefficient when executed on another. Moving code from one GPU to another while maintaining the desired performance is a non-trivial task often requiring significant modifications to account for the hardware differences. In this work, we propose Sponge, a compilation framework for GPUs using synchronous data flow streaming languages. Sponge is capable of performing a wide variety of optimizations to generate efficient code for graphics engines. Sponge alleviates the problems associated with current GPU programming methods by providing portability across different generations of GPUs and CPUs, and a better abstraction of the hardware details, such as the memory hierarchy and threading model. Using streaming, we provide a write-once software paradigm and rely on the compiler to automatically create optimized CUDA code for a wide variety of GPU targets. Sponge's compiler optimizations improve the performance of the baseline CUDA implementations by an average of 3.2x.",
        "acm_key": "1950379",
        "bib_stats": {
            "cites": 117,
            "dl": 1,
            "dl_52": 284,
            "dl_6": 36
        },
        "key": "1950379",
        "text": "Haris Volos , Andres Jaan Tack , Michael M. Swift, Mnemosyne: lightweight persistent memory, Proceedings of the sixteenth international conference on Architectural support for programming languages and operating systems, March 05-11, 2011, Newport Beach, California, USA  \u00a0[doi>"
    },
    "1950380": {
        "abstract": "Graphics processing units (GPUs) provide a low cost platform for accelerating high performance computations. The introduction of new programming languages, such as CUDA and OpenCL, makes GPU programming attractive to a wide variety of programmers. However, programming GPUs is still a cumbersome task for two primary reasons: tedious performance optimizations and lack of portability. First, optimizing an algorithm for a specific GPU is a time-consuming task that requires a thorough understanding of both the algorithm and the underlying hardware. Unoptimized CUDA programs typically only achieve a small fraction of the peak GPU performance. Second, GPU code lacks efficient portability as code written for one GPU can be inefficient when executed on another. Moving code from one GPU to another while maintaining the desired performance is a non-trivial task often requiring significant modifications to account for the hardware differences. In this work, we propose Sponge, a compilation framework for GPUs using synchronous data flow streaming languages. Sponge is capable of performing a wide variety of optimizations to generate efficient code for graphics engines. Sponge alleviates the problems associated with current GPU programming methods by providing portability across different generations of GPUs and CPUs, and a better abstraction of the hardware details, such as the memory hierarchy and threading model. Using streaming, we provide a write-once software paradigm and rely on the compiler to automatically create optimized CUDA code for a wide variety of GPU targets. Sponge's compiler optimizations improve the performance of the baseline CUDA implementations by an average of 3.2x.",
        "acm_key": "1950380",
        "bib_stats": {
            "cites": 113,
            "dl": 1,
            "dl_52": 281,
            "dl_6": 48
        },
        "bibtex": "\r\n@article{Coburn:2011:NMP:1961296.1950380,\n author = {Coburn, Joel and Caulfield, Adrian M. and Akel, Ameen and Grupp, Laura M. and Gupta, Rajesh K. and Jhala, Ranjit and Swanson, Steven},\n title = {NV-Heaps: Making Persistent Objects Fast and Safe with Next-generation, Non-volatile Memories},\n journal = {SIGPLAN Not.},\n issue_date = {March 2011},\n volume = {46},\n number = {3},\n month = mar,\n year = {2011},\n issn = {0362-1340},\n pages = {105--118},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1961296.1950380},\n doi = {10.1145/1961296.1950380},\n acmid = {1950380},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid transactions, memory mangement, non-volatile heap, persistent objects, phase-change memory, pointer safety, spin-torque transfer memory, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1950380&parent_id=1961296&expformat=bibtex&CFID=982037547&CFTOKEN=25880300\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1950380\">\r\n@article{Coburn:2011:NMP:2248487.1950380,\n author = {Coburn, Joel and Caulfield, Adrian M. and Akel, Ameen and Grupp, Laura M. and Gupta, Rajesh K. and Jhala, Ranjit and Swanson, Steven},\n title = {NV-Heaps: Making Persistent Objects Fast and Safe with Next-generation, Non-volatile Memories},\n journal = {SIGPLAN Not.},\n issue_date = {April 2012},\n volume = {47},\n number = {4},\n month = mar,\n year = {2011},\n issn = {0362-1340},\n pages = {105--118},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2248487.1950380},\n doi = {10.1145/2248487.1950380},\n acmid = {1950380},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid transactions, memory mangement, non-volatile heap, persistent objects, phase-change memory, pointer safety, spin-torque transfer memory, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1950380&parent_id=2248487&expformat=bibtex&CFID=982037547&CFTOKEN=25880300\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1950380\">\r\n@inproceedings{Coburn:2011:NMP:1950365.1950380,\n author = {Coburn, Joel and Caulfield, Adrian M. and Akel, Ameen and Grupp, Laura M. and Gupta, Rajesh K. and Jhala, Ranjit and Swanson, Steven},\n title = {NV-Heaps: Making Persistent Objects Fast and Safe with Next-generation, Non-volatile Memories},\n booktitle = {Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XVI},\n year = {2011},\n isbn = {978-1-4503-0266-1},\n location = {Newport Beach, California, USA},\n pages = {105--118},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1950365.1950380},\n doi = {10.1145/1950365.1950380},\n acmid = {1950380},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid transactions, memory mangement, non-volatile heap, persistent objects, phase-change memory, pointer safety, spin-torque transfer memory, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=1950380&parent_id=1950365&expformat=bibtex&CFID=982037547&CFTOKEN=25880300\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"1950380\">\r\n@article{Coburn:2011:NMP:1961295.1950380,\n author = {Coburn, Joel and Caulfield, Adrian M. and Akel, Ameen and Grupp, Laura M. and Gupta, Rajesh K. and Jhala, Ranjit and Swanson, Steven},\n title = {NV-Heaps: Making Persistent Objects Fast and Safe with Next-generation, Non-volatile Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2011},\n volume = {39},\n number = {1},\n month = mar,\n year = {2011},\n issn = {0163-5964},\n pages = {105--118},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/1961295.1950380},\n doi = {10.1145/1961295.1950380},\n acmid = {1950380},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid transactions, memory mangement, non-volatile heap, persistent objects, phase-change memory, pointer safety, spin-torque transfer memory, transactional memory},\n} \r\n",
        "key": "1950380",
        "pub_year": "2011",
        "text": "Joel Coburn , Adrian M. Caulfield , Ameen Akel , Laura M. Grupp , Rajesh K. Gupta , Ranjit Jhala , Steven Swanson, NV-Heaps: making persistent objects fast and safe with next-generation, non-volatile memories, Proceedings of the sixteenth international conference on Architectural support for programming languages and operating systems, March 05-11, 2011, Newport Beach, California, USA  \u00a0[doi>"
    },
    "1950485": {
        "abstract": "Conventional Field Programmable Gate Array (FPGA) architectures leverage on the purely spatial computing model where a design is realized in the form of a small multiple-input single-output lookup tables (LUTs) connected through programmable interconnect switches. However, such a model incorporates an elaborate programmable interconnect network which becomes a major performance bottleneck and leads to poor scalability across process technology nodes. In this paper we evaluate an alternative two-dimensional static random access memory (SRAM) array based reconfigurable computing fabric, referred to as \"Memory Based Computing\" (MBC) that departs from a purely spatial architecture by advocating multi-cycle evaluation at each computational element. Within a computational element, it uses a dense two-dimensional SRAM array to map large multi-input multi-output functions as LUT and evaluate them in time-multiplexed topological fashion. Multi-cycle execution at each computing node is accomplished using a local interconnect architecture. The proposed framework substantially reduces the requirement for global interconnects by folding computational resources onto a single computational element. We explore the design space for MBC to optimize the major design parameters and compare the performance, power dissipation and energy-delay product for benchmark applications between MBC and conventional SRAM-based FPGA. Simulation results show that compared to a clustered FPGA model, the proposed framework achieves 57% improvement in performance, 30% improvement in Energy Delay Product (EDP) and 10% improvement in technological scalability of performance for standard benchmark circuits. Finally, we validate the functionality of MBC framework and timing of different operations by mapping several small applications on a Cyclone III FPGA platform from Altera.",
        "acm_key": "1950485",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Cai:2011:FNF:1950413.1950485,\n author = {Cai, Yu and Haratsch, Erich and McCartney, Mark and Bhargava, Mudit and Mai, Ken},\n title = {FPGA-based Nand Flash Memory Error Characterization and Solid-state Drive Prototyping Platform (Abstract Only)},\n booktitle = {Proceedings of the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays},\n series = {FPGA '11},\n year = {2011},\n isbn = {978-1-4503-0554-9},\n location = {Monterey, CA, USA},\n pages = {284--284},\n numpages = {1},\n url = {http://doi.acm.org/10.1145/1950413.1950485},\n doi = {10.1145/1950413.1950485},\n acmid = {1950485},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash controller, fpga, nand flash, solid state drive},\n} \r\n",
        "key": "1950485",
        "pub_year": "2011",
        "text": "Yu Cai , Erich Haratsch , Mark McCartney , Mudit Bhargava , Ken Mai, FPGA-based nand flash memory error characterization and solid-state drive prototyping platform (abstract only), Proceedings of the 19th ACM/SIGDA international symposium on Field programmable gate arrays, February 27-March 01, 2011, Monterey, CA, USA"
    },
    "1950821": {
        "abstract": "The steeply increasing price and difficulty of masks make the mask-based optical lithography, such as ArF immersion lithography and extreme ultra-violet lithography (EUVL), unaffordable when going beyond the 32-nm half-pitch (HP) node[1]. Electron beam direct writing (EBDW), so called maskless lithography (ML2), provides an ultimate resolution without jeopardy from masks, but the extremely low productivity of the traditional single beam systems made it very laborious for mass manufacturing after over 3 decades of development. Although electron beam lithography has been long used for mask writing, it is yet very slow and typically takes from hours to days to write a complete 6-inch high-end mask. Direct writing a 300-mm wafer definitely would take much longer. Considering production efficiency in the cleanroom, the throughput of lithography tools should be in the order of 10 wafers per hour (WPH) per square meter as compared to that of an ArF scanner. To achieve such a throughput per e-beam column requires an improvement of more than 3-order. Increasing the beam current in the conventional single beam system would induce the space charge effect and thus is not a solution. Several groups [2][3][4][5] have proposed different multiple electron beam maskless lithography (MEBML2) approaches, by multiplying either Gaussian beams, variable shape beams or by using cell projections, to increase the throughput. The maturing MEMS technology and electronic control technology enable precise control of more than ten thousands or even millions of electron beamlets, writing in parallel. Without the mask constraint, the exposure can be made by continuously scanning across the entire wafer diameter as long as the ultra-high speed data rate can be supported. Hence a much slower scan speed is required and therefore a small tool footprint is achievable.",
        "acm_key": "1950821",
        "bib_stats": {
            "cites": 17,
            "dl": 199,
            "dl_52": 8,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Dong:2011:AAM:1950815.1950821,\n author = {Dong, Xiangyu and Xie, Yuan},\n title = {AdaMS: Adaptive MLC/SLC Phase-change Memory Design for File Storage},\n booktitle = {Proceedings of the 16th Asia and South Pacific Design Automation Conference},\n series = {ASPDAC '11},\n year = {2011},\n isbn = {978-1-4244-7516-2},\n location = {Yokohama, Japan},\n pages = {31--36},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1950815.1950821},\n acmid = {1950821},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "1950821",
        "pub_year": "2011",
        "text": "Xiangyu Dong , Yuan Xie, AdaMS: adaptive MLC/SLC phase-change memory design for file storage, Proceedings of the 16th Asia and South Pacific Design Automation Conference, p.31-36, January 25-28, 2011, Yokohama, Japan"
    },
    "1950854": {
        "abstract": "The steeply increasing price and difficulty of masks make the mask-based optical lithography, such as ArF immersion lithography and extreme ultra-violet lithography (EUVL), unaffordable when going beyond the 32-nm half-pitch (HP) node[1]. Electron beam direct writing (EBDW), so called maskless lithography (ML2), provides an ultimate resolution without jeopardy from masks, but the extremely low productivity of the traditional single beam systems made it very laborious for mass manufacturing after over 3 decades of development. Although electron beam lithography has been long used for mask writing, it is yet very slow and typically takes from hours to days to write a complete 6-inch high-end mask. Direct writing a 300-mm wafer definitely would take much longer. Considering production efficiency in the cleanroom, the throughput of lithography tools should be in the order of 10 wafers per hour (WPH) per square meter as compared to that of an ArF scanner. To achieve such a throughput per e-beam column requires an improvement of more than 3-order. Increasing the beam current in the conventional single beam system would induce the space charge effect and thus is not a solution. Several groups [2][3][4][5] have proposed different multiple electron beam maskless lithography (MEBML2) approaches, by multiplying either Gaussian beams, variable shape beams or by using cell projections, to increase the throughput. The maturing MEMS technology and electronic control technology enable precise control of more than ten thousands or even millions of electron beamlets, writing in parallel. Without the mask constraint, the exposure can be made by continuously scanning across the entire wafer diameter as long as the ultra-high speed data rate can be supported. Hence a much slower scan speed is required and therefore a small tool footprint is achievable.",
        "acm_key": "1950854",
        "bib_stats": {
            "cites": 6,
            "dl": 152,
            "dl_52": 6,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Huang:2011:RAW:1950815.1950854,\n author = {Huang, Yazhi and Liu, Tiantian and Xue, Chun Jason},\n title = {Register Allocation for Write Activity Minimization on Non-volatile Main Memory},\n booktitle = {Proceedings of the 16th Asia and South Pacific Design Automation Conference},\n series = {ASPDAC '11},\n year = {2011},\n isbn = {978-1-4244-7516-2},\n location = {Yokohama, Japan},\n pages = {129--134},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=1950815.1950854},\n acmid = {1950854},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "1950854",
        "pub_year": "2011",
        "text": "Yazhi Huang , Tiantian Liu , Chun Jason Xue, Register allocation for write activity minimization on non-volatile main memory, Proceedings of the 16th Asia and South Pacific Design Automation Conference, p.129-134, January 25-28, 2011, Yokohama, Japan"
    },
    "195494": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "195494",
        "bib_stats": {
            "cites": 35,
            "dl": 574,
            "dl_52": 19,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Heinlein:1994:IMP:381792.195494,\n author = {Heinlein, John and Gharachorloo, Kourosh and Dresser, Scott and Gupta, Anoop},\n title = {Integration of Message Passing and Shared Memory in the Stanford FLASH Multiprocessor},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 1994},\n volume = {28},\n number = {5},\n month = nov,\n year = {1994},\n issn = {0163-5980},\n pages = {38--50},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/381792.195494},\n doi = {10.1145/381792.195494},\n acmid = {195494},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195494&parent_id=381792&expformat=bibtex&CFID=982054001&CFTOKEN=60483483\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195494\">\r\n@article{Heinlein:1994:IMP:195470.195494,\n author = {Heinlein, John and Gharachorloo, Kourosh and Dresser, Scott and Gupta, Anoop},\n title = {Integration of Message Passing and Shared Memory in the Stanford FLASH Multiprocessor},\n journal = {SIGPLAN Not.},\n issue_date = {Nov. 1994},\n volume = {29},\n number = {11},\n month = nov,\n year = {1994},\n issn = {0362-1340},\n pages = {38--50},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/195470.195494},\n doi = {10.1145/195470.195494},\n acmid = {195494},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195494&parent_id=195470&expformat=bibtex&CFID=982054001&CFTOKEN=60483483\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195494\">\r\n@inproceedings{Heinlein:1994:IMP:195473.195494,\n author = {Heinlein, John and Gharachorloo, Kourosh and Dresser, Scott and Gupta, Anoop},\n title = {Integration of Message Passing and Shared Memory in the Stanford FLASH Multiprocessor},\n booktitle = {Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS VI},\n year = {1994},\n isbn = {0-89791-660-3},\n location = {San Jose, California, USA},\n pages = {38--50},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/195473.195494},\n doi = {10.1145/195473.195494},\n acmid = {195494},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "195494",
        "pub_year": "1994",
        "text": "John Heinlein , Kourosh Gharachorloo , Scott Dresser , Anoop Gupta, Integration of message passing and shared memory in the Stanford FLASH multiprocessor, Proceedings of the sixth international conference on Architectural support for programming languages and operating systems, p.38-50, October 05-07, 1994, San Jose, California, United States  \u00a0[doi>"
    },
    "195506": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "195506",
        "bib_stats": {
            "cites": 140,
            "dl": 2,
            "dl_52": 220,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Wu:1994:ENM:195470.195506,\n author = {Wu, Michael and Zwaenepoel, Willy},\n title = {eNVy: A Non-volatile, Main Memory Storage System},\n journal = {SIGPLAN Not.},\n issue_date = {Nov. 1994},\n volume = {29},\n number = {11},\n month = nov,\n year = {1994},\n issn = {0362-1340},\n pages = {86--97},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/195470.195506},\n doi = {10.1145/195470.195506},\n acmid = {195506},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195506&parent_id=195470&expformat=bibtex&CFID=982051250&CFTOKEN=67635191\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195506\">\r\n@article{Wu:1994:ENM:381792.195506,\n author = {Wu, Michael and Zwaenepoel, Willy},\n title = {eNVy: A Non-volatile, Main Memory Storage System},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 1994},\n volume = {28},\n number = {5},\n month = nov,\n year = {1994},\n issn = {0163-5980},\n pages = {86--97},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/381792.195506},\n doi = {10.1145/381792.195506},\n acmid = {195506},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195506&parent_id=381792&expformat=bibtex&CFID=982051250&CFTOKEN=67635191\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195506\">\r\n@inproceedings{Wu:1994:ENM:195473.195506,\n author = {Wu, Michael and Zwaenepoel, Willy},\n title = {eNVy: A Non-volatile, Main Memory Storage System},\n booktitle = {Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS VI},\n year = {1994},\n isbn = {0-89791-660-3},\n location = {San Jose, California, USA},\n pages = {86--97},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/195473.195506},\n doi = {10.1145/195473.195506},\n acmid = {195506},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "195506",
        "pub_year": "1994",
        "text": "Michael Wu , Willy Zwaenepoel, eNVy: a non-volatile, main memory storage system, Proceedings of the sixth international conference on Architectural support for programming languages and operating systems, p.86-97, October 05-07, 1994, San Jose, California, USA  \u00a0[doi>"
    },
    "195569": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "195569",
        "bib_stats": {
            "cites": 48,
            "dl": 395,
            "dl_52": 13,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Heinrich:1994:PIF:195470.195569,\n author = {Heinrich, Mark and Kuskin, Jeffrey and Ofelt, David and Heinlein, John and Baxter, Joel and Singh, Jaswinder Pal and Simoni, Richard and Gharachorloo, Kourosh and Nakahira, David and Horowitz, Mark and Gupta, Anoop and Rosenblum, Mendel and Hennessy, John},\n title = {The Performance Impact of Flexibility in the Stanford FLASH Multiprocessor},\n journal = {SIGPLAN Not.},\n issue_date = {Nov. 1994},\n volume = {29},\n number = {11},\n month = nov,\n year = {1994},\n issn = {0362-1340},\n pages = {274--285},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/195470.195569},\n doi = {10.1145/195470.195569},\n acmid = {195569},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195569&parent_id=195470&expformat=bibtex&CFID=982036504&CFTOKEN=53987864\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195569\">\r\n@article{Heinrich:1994:PIF:381792.195569,\n author = {Heinrich, Mark and Kuskin, Jeffrey and Ofelt, David and Heinlein, John and Baxter, Joel and Singh, Jaswinder Pal and Simoni, Richard and Gharachorloo, Kourosh and Nakahira, David and Horowitz, Mark and Gupta, Anoop and Rosenblum, Mendel and Hennessy, John},\n title = {The Performance Impact of Flexibility in the Stanford FLASH Multiprocessor},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 1994},\n volume = {28},\n number = {5},\n month = nov,\n year = {1994},\n issn = {0163-5980},\n pages = {274--285},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/381792.195569},\n doi = {10.1145/381792.195569},\n acmid = {195569},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=195569&parent_id=381792&expformat=bibtex&CFID=982036504&CFTOKEN=53987864\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"195569\">\r\n@inproceedings{Heinrich:1994:PIF:195473.195569,\n author = {Heinrich, Mark and Kuskin, Jeffrey and Ofelt, David and Heinlein, John and Baxter, Joel and Singh, Jaswinder Pal and Simoni, Richard and Gharachorloo, Kourosh and Nakahira, David and Horowitz, Mark and Gupta, Anoop and Rosenblum, Mendel and Hennessy, John},\n title = {The Performance Impact of Flexibility in the Stanford FLASH Multiprocessor},\n booktitle = {Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS VI},\n year = {1994},\n isbn = {0-89791-660-3},\n location = {San Jose, California, USA},\n pages = {274--285},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/195473.195569},\n doi = {10.1145/195473.195569},\n acmid = {195569},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "195569",
        "pub_year": "1994",
        "text": "Mark Heinrich , Jeffrey Kuskin , David Ofelt , John Heinlein , Joel Baxter , Jaswinder Pal Singh , Richard Simoni , Kourosh Gharachorloo , David Nakahira , Mark Horowitz , Anoop Gupta , Mendel Rosenblum , John Hennessy, The performance impact of flexibility in the Stanford FLASH multiprocessor, ACM SIGPLAN Notices, v.29 n.11, p.274-285, Nov. 1994"
    },
    "1957431": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1957431",
        "bib_stats": {
            "cites": 18,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Xie:2011:MAA:1957371.1957431,\n author = {Xie, Yuan},\n title = {Modeling, Architecture, and Applications for Emerging Memory Technologies},\n journal = {IEEE Des. Test},\n issue_date = {January 2011},\n volume = {28},\n number = {1},\n month = jan,\n year = {2011},\n issn = {0740-7475},\n pages = {44--51},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/MDT.2011.20},\n doi = {10.1109/MDT.2011.20},\n acmid = {1957431},\n publisher = {IEEE Computer Society Press},\n address = {Los Alamitos, CA, USA},\n keywords = {NVM, PCRAM, RRAM, SRAM, STT-RAM, design and test, design and test, memory technologies, memory hierarchy, nonvolatile memory, NVM, SRAM, eDRAM, RRAM, STT-RAM, PCRAM, eDRAM, memory hierarchy, memory technologies, nonvolatile memory},\n} \r\n",
        "key": "1957431",
        "pub_year": "2011",
        "text": "Yuan Xie, Modeling, Architecture, and Applications for Emerging Memory Technologies, IEEE Design & Test, v.28 n.1, p.44-51, January 2011  \u00a0[doi>"
    },
    "1960481": {
        "abstract": "This paper advocates a device-aware design strategy to improve various NAND flash memory system performance metrics. It is well known that NAND flash memory program/erase (PE) cycling gradually degrades memory device raw storage reliability, and sufficiently strong error correction codes (ECC) must be used to ensure the PE cycling endurance. Hence, memory manufacturers must fabricate enough number of redundant memory cells geared to the worst-case device reliability at the end of memory lifetime. Given the memory device wear-out dynamics, the existing worst-case oriented ECC redundancy is largely under-utilized over the entire memory lifetime, which can be adaptively traded for improving certain NAND flash memory system performance metrics. This paper explores such device-aware adaptive system design space from two perspectives, including (1) how to improve memory program speed, and (2) how to improve memory defect tolerance and hence enable aggressive fabrication technology scaling. To enable quantitative evaluation, we for the first time develop a NAND flash memory device model to capture the effects of PE cycling from the system level. We carry out simulations using the DiskSim-based SSD simulator and a variety of traces, and the results demonstrate up to 32% SSD average response time reduction. We further demonstrate that the potential on achieving very good defect tolerance, and finally show that these two design approaches can be readily combined together to noticeably improve SSD average response time even in the presence of high memory defect rates.",
        "acm_key": "1960481",
        "bib_stats": {
            "cites": 60,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chen:2011:CCF:1960475.1960481,\n author = {Chen, Feng and Luo, Tian and Zhang, Xiaodong},\n title = {CAFTL: A Content-aware Flash Translation Layer Enhancing the Lifespan of Flash Memory Based Solid State Drives},\n booktitle = {Proceedings of the 9th USENIX Conference on File and Stroage Technologies},\n series = {FAST'11},\n year = {2011},\n isbn = {978-1-931971-82-9},\n location = {San Jose, California},\n pages = {6--6},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1960475.1960481},\n acmid = {1960481},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1960481",
        "pub_year": "2011",
        "text": "Feng Chen , Tian Luo , Xiaodong Zhang, CAFTL: a content-aware flash translation layer enhancing the lifespan of flash memory based solid state drives, Proceedings of the 9th USENIX conference on File and stroage technologies, p.6-6, February 15-17, 2011, San Jose, California"
    },
    "1960482": {
        "abstract": "This paper advocates a device-aware design strategy to improve various NAND flash memory system performance metrics. It is well known that NAND flash memory program/erase (PE) cycling gradually degrades memory device raw storage reliability, and sufficiently strong error correction codes (ECC) must be used to ensure the PE cycling endurance. Hence, memory manufacturers must fabricate enough number of redundant memory cells geared to the worst-case device reliability at the end of memory lifetime. Given the memory device wear-out dynamics, the existing worst-case oriented ECC redundancy is largely under-utilized over the entire memory lifetime, which can be adaptively traded for improving certain NAND flash memory system performance metrics. This paper explores such device-aware adaptive system design space from two perspectives, including (1) how to improve memory program speed, and (2) how to improve memory defect tolerance and hence enable aggressive fabrication technology scaling. To enable quantitative evaluation, we for the first time develop a NAND flash memory device model to capture the effects of PE cycling from the system level. We carry out simulations using the DiskSim-based SSD simulator and a variety of traces, and the results demonstrate up to 32% SSD average response time reduction. We further demonstrate that the potential on achieving very good defect tolerance, and finally show that these two design approaches can be readily combined together to noticeably improve SSD average response time even in the presence of high memory defect rates.",
        "acm_key": "1960482",
        "bib_stats": {
            "cites": 40,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Gupta:2011:LVL:1960475.1960482,\n author = {Gupta, Aayush and Pisolkar, Raghav and Urgaonkar, Bhuvan and Sivasubramaniam, Anand},\n title = {Leveraging Value Locality in Optimizing NAND Flash-based SSDs},\n booktitle = {Proceedings of the 9th USENIX Conference on File and Stroage Technologies},\n series = {FAST'11},\n year = {2011},\n isbn = {978-1-931971-82-9},\n location = {San Jose, California},\n pages = {7--7},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1960475.1960482},\n acmid = {1960482},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1960482",
        "pub_year": "2011",
        "text": "Aayush Gupta , Raghav Pisolkar , Bhuvan Urgaonkar , Anand Sivasubramaniam, Leveraging value locality in optimizing NAND flash-based SSDs, Proceedings of the 9th USENIX conference on File and stroage technologies, p.7-7, February 15-17, 2011, San Jose, California"
    },
    "1960483": {
        "abstract": "This paper advocates a device-aware design strategy to improve various NAND flash memory system performance metrics. It is well known that NAND flash memory program/erase (PE) cycling gradually degrades memory device raw storage reliability, and sufficiently strong error correction codes (ECC) must be used to ensure the PE cycling endurance. Hence, memory manufacturers must fabricate enough number of redundant memory cells geared to the worst-case device reliability at the end of memory lifetime. Given the memory device wear-out dynamics, the existing worst-case oriented ECC redundancy is largely under-utilized over the entire memory lifetime, which can be adaptively traded for improving certain NAND flash memory system performance metrics. This paper explores such device-aware adaptive system design space from two perspectives, including (1) how to improve memory program speed, and (2) how to improve memory defect tolerance and hence enable aggressive fabrication technology scaling. To enable quantitative evaluation, we for the first time develop a NAND flash memory device model to capture the effects of PE cycling from the system level. We carry out simulations using the DiskSim-based SSD simulator and a variety of traces, and the results demonstrate up to 32% SSD average response time reduction. We further demonstrate that the potential on achieving very good defect tolerance, and finally show that these two design approaches can be readily combined together to noticeably improve SSD average response time even in the presence of high memory defect rates.",
        "acm_key": "1960483",
        "bib_stats": {
            "cites": 26,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wei:2011:RED:1960475.1960483,\n author = {Wei, Michael and Grupp, Laura M. and Spada, Frederick E. and Swanson, Steven},\n title = {Reliably Erasing Data from Flash-based Solid State Drives},\n booktitle = {Proceedings of the 9th USENIX Conference on File and Stroage Technologies},\n series = {FAST'11},\n year = {2011},\n isbn = {978-1-931971-82-9},\n location = {San Jose, California},\n pages = {8--8},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1960475.1960483},\n acmid = {1960483},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1960483",
        "pub_year": "2011",
        "text": "Michael Wei , Laura M. Grupp , Frederick E. Spada , Steven Swanson, Reliably erasing data from flash-based solid state drives, Proceedings of the 9th USENIX conference on File and stroage technologies, p.8-8, February 15-17, 2011, San Jose, California"
    },
    "1960494": {
        "abstract": "This paper advocates a device-aware design strategy to improve various NAND flash memory system performance metrics. It is well known that NAND flash memory program/erase (PE) cycling gradually degrades memory device raw storage reliability, and sufficiently strong error correction codes (ECC) must be used to ensure the PE cycling endurance. Hence, memory manufacturers must fabricate enough number of redundant memory cells geared to the worst-case device reliability at the end of memory lifetime. Given the memory device wear-out dynamics, the existing worst-case oriented ECC redundancy is largely under-utilized over the entire memory lifetime, which can be adaptively traded for improving certain NAND flash memory system performance metrics. This paper explores such device-aware adaptive system design space from two perspectives, including (1) how to improve memory program speed, and (2) how to improve memory defect tolerance and hence enable aggressive fabrication technology scaling. To enable quantitative evaluation, we for the first time develop a NAND flash memory device model to capture the effects of PE cycling from the system level. We carry out simulations using the DiskSim-based SSD simulator and a variety of traces, and the results demonstrate up to 32% SSD average response time reduction. We further demonstrate that the potential on achieving very good defect tolerance, and finally show that these two design approaches can be readily combined together to noticeably improve SSD average response time even in the presence of high memory defect rates.",
        "acm_key": "1960494",
        "bib_stats": {
            "cites": 19,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Joo:2011:FQA:1960475.1960494,\n author = {Joo, Yongsoo and Ryu, Junhee and Park, Sangsoo and Shin, Kang G.},\n title = {FAST: Quick Application Launch on Solid-state Drives},\n booktitle = {Proceedings of the 9th USENIX Conference on File and Stroage Technologies},\n series = {FAST'11},\n year = {2011},\n isbn = {978-1-931971-82-9},\n location = {San Jose, California},\n pages = {19--19},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=1960475.1960494},\n acmid = {1960494},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "1960494",
        "pub_year": "2011",
        "text": "Yongsoo Joo , Junhee Ryu , Sangsoo Park , Kang G. Shin, FAST: quick application launch on solid-state drives, Proceedings of the 9th USENIX conference on File and stroage technologies, p.19-19, February 15-17, 2011, San Jose, California"
    },
    "1965751": {
        "abstract": "Windows Error Reporting (WER) is a distributed system that automates the processing of error reports coming from an installed base of a billion machines. WER has collected billions of error reports in 10 years of operation. It collects error data automatically and classifies errors into buckets, which are used to prioritize developer effort and report fixes to users. WER uses a progressive approach to data collection, which minimizes overhead for most reports yet allows developers to collect detailed information when needed. WER takes advantage of its scale to use error statistics as a tool in debugging; this allows developers to isolate bugs that cannot be found at smaller scale. WER has been designed for efficient operation at large scale: one pair of database servers records all the errors that occur on all Windows computers worldwide.",
        "acm_key": "1965751",
        "bib_stats": {
            "cites": 45,
            "dl": 20,
            "dl_52": 1,
            "dl_6": 62
        },
        "bibtex": "\r\n@article{Ousterhout:2011:CR:1965724.1965751,\n author = {Ousterhout, John and Agrawal, Parag and Erickson, David and Kozyrakis, Christos and Leverich, Jacob and Mazi\\`{e}res, David and Mitra, Subhasish and Narayanan, Aravind and Ongaro, Diego and Parulkar, Guru and Rosenblum, Mendel and Rumble, Stephen M. and Stratmann, Eric and Stutsman, Ryan},\n title = {The Case for RAMCloud},\n journal = {Commun. ACM},\n issue_date = {July 2011},\n volume = {54},\n number = {7},\n month = jul,\n year = {2011},\n issn = {0001-0782},\n pages = {121--130},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/1965724.1965751},\n doi = {10.1145/1965724.1965751},\n acmid = {1965751},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "1965751",
        "pub_year": "2011",
        "text": "John Ousterhout , Parag Agrawal , David Erickson , Christos Kozyrakis , Jacob Leverich , David Mazi\u00e8res , Subhasish Mitra , Aravind Narayanan , Diego Ongaro , Guru Parulkar , Mendel Rosenblum , Stephen M. Rumble , Eric Stratmann , Ryan Stutsman, The case for RAMCloud, Communications of the ACM, v.54 n.7, July 2011  \u00a0[doi>"
    },
    "1970387": {
        "abstract": "While multicore processors promise large performance benefits for parallel applications, writing these applications is notoriously difficult. Tuning a parallel application to achieve good performance, also known as performance debugging, is often more challenging than debugging the application for correctness. Parallel programs have many performance-related issues that are not seen in sequential programs. An increase in cache misses is one of the biggest challenges that programmers face. To minimize these misses, programmers must not only identify the source of the extra misses, but also perform the tricky task of determining if the misses are caused by interthread communication (i.e., coherence misses) and if so, whether they are caused by true or false sharing (since the solutions for these two are quite different).",
        "acm_key": "1970387",
        "bib_stats": {
            "cites": 16,
            "dl": 908,
            "dl_52": 38,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Dong:2011:HCU:1970386.1970387,\n author = {Dong, Xiangyu and Xie, Yuan and Muralimanohar, Naveen and Jouppi, Norman P.},\n title = {Hybrid Checkpointing Using Emerging Nonvolatile Memories for Future Exascale Systems},\n journal = {ACM Trans. Archit. Code Optim.},\n issue_date = {July 2011},\n volume = {8},\n number = {2},\n month = jun,\n year = {2011},\n issn = {1544-3566},\n pages = {6:1--6:29},\n articleno = {6},\n numpages = {29},\n url = {http://doi.acm.org/10.1145/1970386.1970387},\n doi = {10.1145/1970386.1970387},\n acmid = {1970387},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Checkpoint, background checkpoint, checkpoint prototype, exascale, hybrid checkpoint, in-disk checkpoint, in-memory checkpoint, incremental checkpoint, optimum checkpoint model, petascale, phase-change memory},\n} \r\n",
        "key": "1970387",
        "pub_year": "2011",
        "text": "Xiangyu Dong , Yuan Xie , Naveen Muralimanohar , Norman P. Jouppi, Hybrid checkpointing using emerging nonvolatile memories for future exascale systems, ACM Transactions on Architecture and Code Optimization (TACO), v.8 n.2, p.1-29, July 2011  \u00a0[doi>"
    },
    "1978457": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1978457",
        "bib_stats": {
            "cites": 14,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Nam:2011:OOF:1978254.1978457,\n author = {Nam, Eyee Hyun and Kim, Bryan Suk Joon and Eom, Hyeonsang and Min, Sang Lyul},\n title = {Ozone (O3): An Out-of-Order Flash Memory Controller Architecture},\n journal = {IEEE Trans. Comput.},\n issue_date = {May 2011},\n volume = {60},\n number = {5},\n month = may,\n year = {2011},\n issn = {0018-9340},\n pages = {653--666},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TC.2010.209},\n doi = {10.1109/TC.2010.209},\n acmid = {1978457},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash memory, Flash memory, flash translation layer (FTL), storage system, solid-state disk (SSD)., flash translation layer (FTL), solid-state disk (SSD)., storage system},\n} \r\n",
        "key": "1978457",
        "pub_year": "2011",
        "text": "Eyee Hyun Nam , Bryan Suk Joon Kim , Hyeonsang Eom , Sang Lyul Min, Ozone (O3): An Out-of-Order Flash Memory Controller Architecture, IEEE Transactions on Computers, v.60 n.5, p.653-666, May 2011  \u00a0[doi>"
    },
    "1978500": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1978500",
        "bib_stats": {
            "cites": 14,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Chiao:2011:RNF:1978257.1978500,\n author = {Chiao, Mong-Ling and Chang, Da-Wei},\n title = {ROSE: A Novel Flash Translation Layer for NAND Flash Memory Based on Hybrid Address Translation},\n journal = {IEEE Trans. Comput.},\n issue_date = {June 2011},\n volume = {60},\n number = {6},\n month = jun,\n year = {2011},\n issn = {0018-9340},\n pages = {753--766},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TC.2011.67},\n doi = {10.1109/TC.2011.67},\n acmid = {1978500},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Storage management, performance, NAND flash memory, flash translation layer (FTL).},\n} \r\n",
        "key": "1978500",
        "pub_year": "2011",
        "text": "Mong-Ling Chiao , Da-Wei Chang, ROSE: A Novel Flash Translation Layer for NAND Flash Memory Based on Hybrid Address Translation, IEEE Transactions on Computers, v.60 n.6, p.753-766, June 2011  \u00a0[doi>"
    },
    "1982311": {
        "abstract": "This paper presents a novel method for integrating swarm intelligence and line-based representation of environment to solve the simultaneous localization and mapping (SLAM) problem of mobile robots. SLAM is a well-studied problem in mobile robotics. Because of stochastic nature of search strategy in swarm intelligence algorithms, they are very successful compared with other techniques in encountering SLAM problem. Line segment based representation of 2D maps is known to have advantages over raw point data or grid based representation gained from laser range scans. It contains higher geometric information that is closer to human insight and conceptual mapping, which is necessary for robust post processing. It also significantly reduces the memory and time complexity. Mobile robot reads raw laser sensor data in each step of its trajectory and converts it to a set of lines which is used to produce the last sensed map. At the next phase, the algorithm utilizes particle swarm optimization (PSO) and introduces a new evaluation function to find the actual state of the last sensed map inside a global map, which is merged into a global map by introducing a new merge method to reconstruct the global map. We use PSO's ability to run away from local extrema and converge towards an optimum point (i.e. best robot status in the map) by utilizing adaptive inertia weight strategy. We also introduce a new criterion to measure the similarity between the line pairs in the map. The experimental results on real datasets and virtual environments exhibit the algorithm's robustness, accuracy and superior performance on problems that are under consideration in SLAM such as loop closing, correspondence problem, curvature of the walls, and sensor uncertainty.",
        "acm_key": "1982311",
        "bib_stats": {
            "cites": 0,
            "dl": 193,
            "dl_52": 13,
            "dl_6": 3
        },
        "key": "1982311",
        "text": "Tae-Sun Chung , Dong-Joo Park , Jongik Kim, LSTAFF*: an efficient flash translation layer for large block flash memory, Proceedings of the 2011 ACM Symposium on Applied Computing, March 21-24, 2011, TaiChung, Taiwan"
    },
    "1982320": {
        "abstract": "This paper presents a novel method for integrating swarm intelligence and line-based representation of environment to solve the simultaneous localization and mapping (SLAM) problem of mobile robots. SLAM is a well-studied problem in mobile robotics. Because of stochastic nature of search strategy in swarm intelligence algorithms, they are very successful compared with other techniques in encountering SLAM problem. Line segment based representation of 2D maps is known to have advantages over raw point data or grid based representation gained from laser range scans. It contains higher geometric information that is closer to human insight and conceptual mapping, which is necessary for robust post processing. It also significantly reduces the memory and time complexity. Mobile robot reads raw laser sensor data in each step of its trajectory and converts it to a set of lines which is used to produce the last sensed map. At the next phase, the algorithm utilizes particle swarm optimization (PSO) and introduces a new evaluation function to find the actual state of the last sensed map inside a global map, which is merged into a global map by introducing a new merge method to reconstruct the global map. We use PSO's ability to run away from local extrema and converge towards an optimum point (i.e. best robot status in the map) by utilizing adaptive inertia weight strategy. We also introduce a new criterion to measure the similarity between the line pairs in the map. The experimental results on real datasets and virtual environments exhibit the algorithm's robustness, accuracy and superior performance on problems that are under consideration in SLAM such as loop closing, correspondence problem, curvature of the walls, and sensor uncertainty.",
        "acm_key": "1982320",
        "bib_stats": {
            "cites": 1,
            "dl": 91,
            "dl_52": 9,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Kim:2011:FEF:1982185.1982320,\n author = {Kim, YoungHwan and Kim, TaeHyoung and Kim, Yuri and Kim, Ah-Reum},\n title = {FMCM: A Efficient Flash Memory Cache Management Scheme for Energy-efficient Disks},\n booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},\n series = {SAC '11},\n year = {2011},\n isbn = {978-1-4503-0113-8},\n location = {TaiChung, Taiwan},\n pages = {625--626},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/1982185.1982320},\n doi = {10.1145/1982185.1982320},\n acmid = {1982320},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cache management scheme, flash memory},\n} \r\n",
        "key": "1982320",
        "pub_year": "2011",
        "text": "YoungHwan Kim , TaeHyoung Kim , Yuri Kim , Ah-Reum Kim, FMCM: a efficient flash memory cache management scheme for energy-efficient disks, Proceedings of the 2011 ACM Symposium on Applied Computing, March 21-24, 2011, TaiChung, Taiwan"
    },
    "1989327": {
        "abstract": "The pace of innovation in data center design has been rapidly accelerating over the last five years, driven by the mega-service operators. I believe we have seen more infrastructure innovation in the last five years than we did in the previous fifteen. Most very large service operators have teams of experts focused on server design, data center power distribution and redundancy, mechanical designs, real estate acquisition, and network hardware and protocols. At low scale, with only a data or center or two, it would be crazy to have all these full time engineers and specialist focused on infrastructural improvements and expansion. But, at high scale with tens of data centers, it would be crazy not to invest deeply in advancing the state of the art. Looking specifically at cloud services, the cost of the infrastructure is the difference between an unsuccessful cloud service and a profitable, self-sustaining business. With continued innovation driving down infrastructure costs, investment capital is available, services can be added and improved, and value can be passed on to customers through price reductions. Amazon Web Services, for example, has had eleven price reductions in four years. I don't recall that happening in my first twenty years working on enterprise software. It really is an exciting time in our industry. I started working on database systems twenty years ago during a period of incredibly rapid change. We improved DB2 performance measured using TPC-A by a factor of ten in a single release. The next release, we made a further four-fold improvement. It's rare to be able to improve a product by forty fold in three years but, admittedly, one of the secrets is to begin from a position where work is truly needed. Back then, the database industry was in its infancy. Customers loved the products and were using them heavily, but we were not anywhere close to delivering on the full promise of the technology. That's exactly where cloud computing is today--just where the database world was twenty years ago. Customers are getting great value from cloud computing but, at the same time, we have much more to do and many of the most interesting problems are yet to be solved. I could easily imagine tenfold improvement across several dimensions in over the next five years. What ties these two problems from different decades together is that some of the biggest problems in cloud computing are problems in persistent state management. What's different is that we now have to tackle these problems in a multi-tenant, high-scale, multi-datacenter environment. It's a new vista for database and storage problems. In this talk, we'll analyze an internet-scale data center looking at the cost of power distribution, servers, storage, networking, and cooling on the belief that understanding what drives cost helps us focus on the most valuable research directions. We'll look at some of the fundamental technology limits approached in cloud database and storage solutions on the belief that, at scale, these limits will constrain practical solutions. And we'll consider existing cloud services since they form the foundation on which future solutions might be built.",
        "acm_key": "1989327",
        "bib_stats": {
            "cites": 46,
            "dl": 764,
            "dl_52": 80,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Debnath:2011:SRS:1989323.1989327,\n author = {Debnath, Biplob and Sengupta, Sudipta and Li, Jin},\n title = {SkimpyStash: RAM Space Skimpy Key-value Store on Flash-based Storage},\n booktitle = {Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '11},\n year = {2011},\n isbn = {978-1-4503-0661-4},\n location = {Athens, Greece},\n pages = {25--36},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1989323.1989327},\n doi = {10.1145/1989323.1989327},\n acmid = {1989327},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, indexing, key-value store, log-structured index., ram space efficient index},\n} \r\n",
        "key": "1989327",
        "pub_year": "2011",
        "text": "Biplob Debnath , Sudipta Sengupta , Jin Li, SkimpyStash: RAM space skimpy key-value store on flash-based storage, Proceedings of the 2011 ACM SIGMOD International Conference on Management of data, June 12-16, 2011, Athens, Greece  \u00a0[doi>"
    },
    "1990165": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1990165",
        "bib_stats": {
            "cites": 7
        },
        "bibtex": "\r\n@inproceedings{Cai:2011:FSD:1989761.1990165,\n author = {Cai, Yu and Haratsch, Erich F. and McCartney, Mark and Mai, Ken},\n title = {FPGA-Based Solid-State Drive Prototyping Platform},\n booktitle = {Proceedings of the 2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines},\n series = {FCCM '11},\n year = {2011},\n isbn = {978-0-7695-4301-7},\n pages = {101--104},\n numpages = {4},\n url = {http://dx.doi.org/10.1109/FCCM.2011.28},\n doi = {10.1109/FCCM.2011.28},\n acmid = {1990165},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {FPGA, NAND flash, Flash controller, Solid state drive},\n} \r\n",
        "key": "1990165",
        "pub_year": "2011",
        "text": "Yu Cai , Erich F. Haratsch , Mark McCartney , Ken Mai, FPGA-Based Solid-State Drive Prototyping Platform, Proceedings of the 2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines, p.101-104, May 01-03, 2011  \u00a0[doi>"
    },
    "1990494": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "1990494",
        "bib_stats": {
            "cites": 13
        },
        "bibtex": "\r\n@inproceedings{Qin:2011:TCM:1989765.1990494,\n author = {Qin, Zhiwei and Wang, Yi and Liu, Duo and Shao, Zili},\n title = {A Two-Level Caching Mechanism for Demand-Based Page-Level Address Mapping in NAND Flash Memory Storage Systems},\n booktitle = {Proceedings of the 2011 17th IEEE Real-Time and Embedded Technology and Applications Symposium},\n series = {RTAS '11},\n year = {2011},\n isbn = {978-0-7695-4344-4},\n pages = {157--166},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/RTAS.2011.23},\n doi = {10.1109/RTAS.2011.23},\n acmid = {1990494},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "1990494",
        "pub_year": "2011",
        "text": "Zhiwei Qin , Yi Wang , Duo Liu , Zili Shao, A Two-Level Caching Mechanism for Demand-Based Page-Level Address Mapping in NAND Flash Memory Storage Systems, Proceedings of the 2011 17th IEEE Real-Time and Embedded Technology and Applications Symposium, p.157-166, April 11-14, 2011  \u00a0[doi>"
    },
    "1993155": {
        "abstract": "As the CMOS semiconductor technology enters nanometer regime, interconnect processes must be compatible with device roadmaps and meet manufacturing targets at the specified wafer size. The resulting ubiquitous process variations cause errors in data delivering through interconnects. This paper proposes an Information Theory based design method to accommodate process variations. Different from the traditional delay based design metric, the current approach uses achievable rate to relate interconnect designs directly to communication applications. More specifically, the data communication over a typical interconnect, a bus, subject to process variations (\"uncertain\" bus), is defined as a communication problem under uncertainty. A data rate, called the achievable rate, is computed for such a bus, which represents the lower bound on the maximal data rate attainable over the bus. When a data rate applied over the bus is smaller than the achievable data rate, a reliable communication can be guaranteed regardless of process variations, i.e., a bit error rate arbitrarily close to zero is achievable. A single communication strategy to combat the process variations is proposed whose code rate is equal to the computed achievable rate. The simulations show that the variations in the interconnect resistivity could have the most harmful effect regarding the achievable rate reduction. Also, the simulations illustrate the importance of taking into account bus parasitic parameters correlations when measuring the influence of the process variations on the achievable rates.",
        "acm_key": "1993155",
        "bib_stats": {
            "cites": 26
        },
        "bibtex": "\r\n@article{Xu:2011:DLO:1993144.1993155,\n author = {Xu, Wei and Sun, Hongbin and Wang, Xiaobin and Chen, Yiran and Zhang, Tong},\n title = {Design of Last-level On-chip Cache Using Spin-torque Transfer RAM (STT RAM)},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {March 2011},\n volume = {19},\n number = {3},\n month = mar,\n year = {2011},\n issn = {1063-8210},\n pages = {483--493},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/TVLSI.2009.2035509},\n doi = {10.1109/TVLSI.2009.2035509},\n acmid = {1993155},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n keywords = {Cache memories, cache memories, magnetic tunneling junction, spin-torque transfer},\n} \r\n",
        "key": "1993155",
        "pub_year": "2011",
        "text": "Wei Xu , Hongbin Sun , Xiaobin Wang , Yiran Chen , Tong Zhang, Design of last-level on-chip cache using spin-torque transfer RAM (STT RAM), IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.19 n.3, p.483-493, March 2011  \u00a0[doi>"
    },
    "1995902": {
        "abstract": "The probability that a failure will occur before the end of the computation increases as the number of processors used in a high performance computing application increases. For long running applications using a large number of processors, it is essential that fault tolerance be used to prevent a total loss of all finished computations after a failure. While checkpointing has been very useful to tolerate failures for a long time, it often introduces a considerable overhead especially when applications modify a large amount of memory between checkpoints and the number of processors is large. In this paper, we propose an algorithm-based recovery scheme for the High Performance Linpack benchmark (which modifies a large amount of memory in each iteration) to tolerate fail-stop failures without checkpointing. It was proved by Huang and Abraham that a checksum added to a matrix will be maintained after the matrix is factored. We demonstrate that, for the right-looking LU factorization algorithm, the checksum is maintained at each step of the computation. Based on this checksum relationship maintained at each step in the middle of the computation, we demonstrate that fail-stop process failures in High Performance Linpack can be tolerated without checkpointing. Because no periodical checkpoint is necessary during computation and no roll-back is necessary during recovery, the proposed recovery scheme is highly scalable and has a good potential to scale to extreme scale computing and beyond. Experimental results on the supercomputer Jaguar demonstrate that the fault tolerance overhead introduced by the proposed recovery scheme is negligible.",
        "acm_key": "1995902",
        "bib_stats": {
            "cites": 36,
            "dl": 1,
            "dl_52": 147,
            "dl_6": 15
        },
        "bibtex": "\r\n@inproceedings{Chen:2011:HMB:1995896.1995902,\n author = {Chen, Feng and Koufaty, David A. and Zhang, Xiaodong},\n title = {Hystor: Making the Best Use of Solid State Drives in High Performance Storage Systems},\n booktitle = {Proceedings of the International Conference on Supercomputing},\n series = {ICS '11},\n year = {2011},\n isbn = {978-1-4503-0102-2},\n location = {Tucson, Arizona, USA},\n pages = {22--32},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/1995896.1995902},\n doi = {10.1145/1995896.1995902},\n acmid = {1995902},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {hard disk drive, hybrid storage system, solid state drive},\n} \r\n",
        "key": "1995902",
        "pub_year": "2011",
        "text": "Feng Chen , David A. Koufaty , Xiaodong Zhang, Hystor: making the best use of solid state drives in high performance storage systems, Proceedings of the international conference on Supercomputing, May 31-June 04, 2011, Tucson, Arizona, USA"
    },
    "1995912": {
        "abstract": "The probability that a failure will occur before the end of the computation increases as the number of processors used in a high performance computing application increases. For long running applications using a large number of processors, it is essential that fault tolerance be used to prevent a total loss of all finished computations after a failure. While checkpointing has been very useful to tolerate failures for a long time, it often introduces a considerable overhead especially when applications modify a large amount of memory between checkpoints and the number of processors is large. In this paper, we propose an algorithm-based recovery scheme for the High Performance Linpack benchmark (which modifies a large amount of memory in each iteration) to tolerate fail-stop failures without checkpointing. It was proved by Huang and Abraham that a checksum added to a matrix will be maintained after the matrix is factored. We demonstrate that, for the right-looking LU factorization algorithm, the checksum is maintained at each step of the computation. Based on this checksum relationship maintained at each step in the middle of the computation, we demonstrate that fail-stop process failures in High Performance Linpack can be tolerated without checkpointing. Because no periodical checkpoint is necessary during computation and no roll-back is necessary during recovery, the proposed recovery scheme is highly scalable and has a good potential to scale to extreme scale computing and beyond. Experimental results on the supercomputer Jaguar demonstrate that the fault tolerance overhead introduced by the proposed recovery scheme is negligible.",
        "acm_key": "1995912",
        "bib_stats": {
            "cites": 43,
            "dl": 1,
            "dl_52": 190,
            "dl_6": 21
        },
        "bibtex": "\r\n@inproceedings{Hu:2011:PII:1995896.1995912,\n author = {Hu, Yang and Jiang, Hong and Feng, Dan and Tian, Lei and Luo, Hao and Zhang, Shuping},\n title = {Performance Impact and Interplay of SSD Parallelism Through Advanced Commands, Allocation Strategy and Data Granularity},\n booktitle = {Proceedings of the International Conference on Supercomputing},\n series = {ICS '11},\n year = {2011},\n isbn = {978-1-4503-0102-2},\n location = {Tucson, Arizona, USA},\n pages = {96--107},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/1995896.1995912},\n doi = {10.1145/1995896.1995912},\n acmid = {1995912},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {advanced commands, nand-flash, parallelism, simulator, ssd},\n} \r\n",
        "key": "1995912",
        "pub_year": "2011",
        "text": "Yang Hu , Hong Jiang , Dan Feng , Lei Tian , Hao Luo , Shuping Zhang, Performance impact and interplay of SSD parallelism through advanced commands, allocation strategy and data granularity, Proceedings of the international conference on Supercomputing, May 31-June 04, 2011, Tucson, Arizona, USA  \u00a0[doi>"
    },
    "1996712": {
        "abstract": "Data Type Definition(DTD) and XML Schema Definition(XSD) are the logical schema of an XML model, but there is no standard format for the conceptual schema of an XML model. Conceptual modeling is a very important first step for constructing a database application. A conceptual model describes a system that is being built. Abstract ideas are made concrete as the ideas are represented in a formal notation. A formal conceptual model has a number of advantages. First, it helps designers understand and document the application under construction. Second, it facilitates development of algorithms that derive the underlying database schemas. In this paper, a real world of interest is described in a conceptual-model Hypergraph, which is a generic conceptual model. It is a Hypergraph because its hyperedges, or simply edges, are not necessarily binary. Its vertices represent sets of objects and its edges represent relationships among the vertices. Edges in a Hypergraph can be directed or undirected, depending on whether the underlying relationships are functional or non-functional. As opposed to relational databases, in this paper we are interested in constructing XML database applications with \"good\" properties. Two properties are particularly outstanding. First, the database should not have redundant data because redundant data lead to multiple-update problem once a single copy is modified. Second, since joins are expensive, the number of generated scheme trees, which are a generic hierarchical storage structure, should be as few as possible in order to reduce the number of joins required to answer a query. Users can draw a Hypergraph as XML conceptual schema with data relationships among elements as a result of specified functional dependency and multivalued dependency.",
        "acm_key": "1996712",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Liang:2011:NME:1996686.1996712,\n author = {Liang, Zhichao and Fan, Yulei and Meng, Xiaofeng},\n title = {A Novel Method to Extend Flash Memory Lifetime in Flash-based DBMS},\n booktitle = {Proceedings of the 16th International Conference on Database Systems for Advanced Applications},\n series = {DASFAA'11},\n year = {2011},\n isbn = {978-3-642-20243-8},\n location = {Hong Kong, China},\n pages = {190--201},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=1996686.1996712},\n acmid = {1996712},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {buffer management, flash-based DBMS, free space management},\n} \r\n",
        "key": "1996712",
        "pub_year": "2011",
        "text": "Zhichao Liang , Yulei Fan , Xiaofeng Meng, A novel method to extend flash memory lifetime in flash-based DBMS, Proceedings of the 16th international conference on Database systems for advanced applications, April 22-25, 2011, Hong Kong, China"
    },
    "1998638": {
        "abstract": "A common application of virtual machines (VM) is to use and then throw away, basically treating a VM like a completely isolated and disposable entity. The disadvantage of this approach is that if there is no malicious activity, the user has to re-do all of the work in her actual workspace since there is no easy way to commit (i.e., merge) only the benign updates within the VM back to the host environment. In this work, we develop a VM commitment system called Secom to automatically eliminate malicious state changes when merging the contents of an OS-level VM to the host. Secom consists of three steps: grouping state changes into clusters, distinguishing between benign and malicious clusters, and committing benign clusters. Secom has three novel features. First, instead of relying on a huge volume of log data, it leverages OS-level information flow and malware behavior information to recognize malicious changes. As a result, the approach imposes a smaller performance overhead. Second, different from existing intrusion detection and recovery systems that detect compromised OS objects one by one, Secom classifies objects into clusters and then identifies malicious objects on a cluster by cluster basis. Third, to reduce the false positive rate when identifying malicious clusters, it simultaneously considers two malware behaviors that are of different types and the origin of the processes that exhibit these behaviors, rather than considers a single behavior alone as done by existing malware detection methods. We have successfully implemented Secom on the Feather-weight Virtual Machine (FVM) system, a Windows-based OS-level virtualization system. Experiments show that the prototype can effectively eliminate malicious state changes while committing a VM with small performance degradation. Moreover, compared with the commercial anti-malware tools, the Secom prototype has a smaller number of false negatives and thus can more thoroughly clean up malware side effects. In addition, the number of false positives of the Secom prototype is also lower than that achieved by the on-line behavior-based approach of the commercial tools.",
        "acm_key": "1998638",
        "bib_stats": {
            "cites": 13,
            "dl": 165,
            "dl_52": 20,
            "dl_6": 4
        },
        "key": "1998638",
        "text": "Arif Merchant , Mustafa Uysal , Pradeep Padala , Xiaoyun Zhu , Sharad Singhal , Kang Shin, Maestro: quality-of-service in large disk arrays, Proceedings of the 8th ACM international conference on Autonomic computing, June 14-18, 2011, Karlsruhe, Germany  \u00a0[doi>"
    },
    "2009820": {
        "abstract": "Volume 84 Issue 9, September, 2011 \r\n\r\n",
        "acm_key": "2009820",
        "bib_stats": {
            "cites": 7
        },
        "bibtex": "\r\n@article{Kwon:2011:FEG:2009733.2009820,\n author = {Kwon, Ohhoon and Koh, Kern and Lee, Jaewoo and Bahn, Hyokyung},\n title = {FeGC: An Efficient Garbage Collection Scheme for Flash Memory Based Storage Systems},\n journal = {J. Syst. Softw.},\n issue_date = {September, 2011},\n volume = {84},\n number = {9},\n month = sep,\n year = {2011},\n issn = {0164-1212},\n pages = {1507--1523},\n numpages = {17},\n url = {http://dx.doi.org/10.1016/j.jss.2011.02.042},\n doi = {10.1016/j.jss.2011.02.042},\n acmid = {2009820},\n publisher = {Elsevier Science Inc.},\n address = {New York, NY, USA},\n keywords = {Embedded systems, Flash memory, Garbage collection, Storage systems},\n} \r\n",
        "key": "2009820",
        "pub_year": "2011",
        "text": "Ohhoon Kwon , Kern Koh , Jaewoo Lee , Hyokyung Bahn, FeGC: An efficient garbage collection scheme for flash memory based storage systems, Journal of Systems and Software, v.84 n.9, p.1507-1523, September, 2011"
    },
    "2014864": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2014864",
        "bib_stats": {
            "cites": 57
        },
        "bibtex": "\r\n@inproceedings{Chen:2011:ERE:2014698.2014864,\n author = {Chen, Feng and Lee, Rubao and Zhang, Xiaodong},\n title = {Essential Roles of Exploiting Internal Parallelism of Flash Memory Based Solid State Drives in High-speed Data Processing},\n booktitle = {Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture},\n series = {HPCA '11},\n year = {2011},\n isbn = {978-1-4244-9432-3},\n pages = {266--277},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2014698.2014864},\n acmid = {2014864},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2014864",
        "pub_year": "2011",
        "text": "Feng Chen , Rubao Lee , Xiaodong Zhang, Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, p.266-277, February 12-16, 2011"
    },
    "2014871": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2014871",
        "bib_stats": {
            "cites": 16
        },
        "bibtex": "\r\n@inproceedings{Joshi:2011:MFE:2014698.2014871,\n author = {Joshi, Madhura and Zhang, Wangyuan and Li, Tao},\n title = {Mercury: A Fast and Energy-efficient Multi-level Cell Based Phase Change Memory System},\n booktitle = {Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture},\n series = {HPCA '11},\n year = {2011},\n isbn = {978-1-4244-9432-3},\n pages = {345--356},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2014698.2014871},\n acmid = {2014871},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2014871",
        "pub_year": "2011",
        "text": "Madhura Joshi , Wangyuan Zhang , Tao Li, Mercury: A fast and energy-efficient multi-level cell based Phase Change Memory system, Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, p.345-356, February 12-16, 2011"
    },
    "2014881": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2014881",
        "bib_stats": {
            "cites": 43
        },
        "bibtex": "\r\n@inproceedings{Yoon:2011:FPN:2014698.2014881,\n author = {Yoon, Doe Hyun and Muralimanohar, Naveen and Chang, Jichuan and Ranganathan, Parthasarathy and Jouppi, Norman P. and Erez, Mattan},\n title = {FREE-p: Protecting Non-volatile Memory Against Both Hard and Soft Errors},\n booktitle = {Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture},\n series = {HPCA '11},\n year = {2011},\n isbn = {978-1-4244-9432-3},\n pages = {466--477},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2014698.2014881},\n acmid = {2014881},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2014881",
        "pub_year": "2011",
        "text": "Doe Hyun Yoon , Naveen Muralimanohar , Jichuan Chang , Parthasarathy Ranganathan , Norman P. Jouppi , Mattan Erez, FREE-p: Protecting non-volatile memory against both hard and soft errors, Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, p.466-477, February 12-16, 2011"
    },
    "2014895": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2014895",
        "bib_stats": {
            "cites": 67
        },
        "bibtex": "\r\n@inproceedings{Smullen:2011:RNF:2014698.2014895,\n author = {Smullen, Clinton W. and Mohan, Vidyabhushan and Nigam, Anurag and Gurumurthi, Sudhanva and Stan, Mircea R.},\n title = {Relaxing Non-volatility for Fast and Energy-efficient STT-RAM Caches},\n booktitle = {Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture},\n series = {HPCA '11},\n year = {2011},\n isbn = {978-1-4244-9432-3},\n pages = {50--61},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2014698.2014895},\n acmid = {2014895},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2014895",
        "pub_year": "2011",
        "text": "Clinton W. Smullen , Vidyabhushan Mohan , Anurag Nigam , Sudhanva Gurumurthi , Mircea R. Stan, Relaxing non-volatility for fast and energy-efficient STT-RAM caches, Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, p.50-61, February 12-16, 2011"
    },
    "2015517": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2015517",
        "bib_stats": {
            "cites": 7
        },
        "key": "2015517",
        "text": "Junghee Lee , Youngjae Kim , Galen M. Shipman , Sarp Oral , Feiyi Wang , Jongman Kim, A semi-preemptive garbage collector for solid state drives, Proceedings of the IEEE International Symposium on Performance Analysis of Systems and Software, p.12-21, April 10-12, 2011  \u00a0[doi>"
    },
    "2016620": {
        "abstract": "Faults are expected to play an increasingly important role in how algorithms and applications are designed to run on future extreme-scale systems. Algorithm-based fault tolerance (ABFT) is a promising approach that involves modifications to the algorithm to recover from faults with lower overheads than replicated storage and a significant reduction in lost work compared to checkpoint-restart techniques. Fault-tolerant linear algebra (FTLA) algorithms employ additional processors that store parities along the dimensions of a matrix to tolerate multiple, simultaneous faults. Existing approaches assume regular data distributions (blocked or block-cyclic) with the failures of each data block being independent. To match the characteristics of failures on parallel computers, we extend these approaches to mapping parity blocks in several important ways. First, we handle parity computation for generalized Cartesian data distributions with each processor holding arbitrary subsets of blocks in a Cartesian-distributed array. Second, techniques to handle correlated failures, i.e., multiple processors that can be expected to fail together, are presented. Third, we handle the colocation of parity blocks with the data blocks and do not require them to be on additional processors. Several alternative approaches, based on graph matching, are presented that attempt to balance the memory overhead on processors while guaranteeing the same fault tolerance properties as existing approaches that assume independent failures on regular blocked data distributions. The evaluation of these algorithms demonstrates that the additional desirable properties are provided by the proposed approach with minimal overhead.",
        "acm_key": "2016620",
        "bib_stats": {
            "cites": 2,
            "dl": 130,
            "dl_52": 3,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Jung:2011:DCP:2016604.2016620,\n author = {Jung, Ju-Young and Cho, Sangyeun},\n title = {Dynamic Co-management of Persistent RAM Main Memory and Storage Resources},\n booktitle = {Proceedings of the 8th ACM International Conference on Computing Frontiers},\n series = {CF '11},\n year = {2011},\n isbn = {978-1-4503-0698-0},\n location = {Ischia, Italy},\n pages = {13:1--13:2},\n articleno = {13},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2016604.2016620},\n doi = {10.1145/2016604.2016620},\n acmid = {2016620},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {PRAM storage device (PSD), performance, persistent RAM (PRAM) main memory, write endurance},\n} \r\n",
        "key": "2016620",
        "pub_year": "2011",
        "text": "Ju-Young Jung , Sangyeun Cho, Dynamic co-management of persistent RAM main memory and storage resources, Proceedings of the 8th ACM International Conference on Computing Frontiers, May 03-05, 2011, Ischia, Italy"
    },
    "2023618": {
        "abstract": "Web 2.0 has enabled Web users to create and share a variety of hyper-text based artifacts including embedded images, sound, and video on the Web. Creating Web-based interactive artifacts such as computer games, however, has remained a challenge: to end users due to the lack of end user programming tools; and to programmers due to the poor interactivity performance of the Web. With the emergence of HTML5 and improving performance of JavaScript engines, professional Web programmers have only just begun to develop Web-native interactive artifacts. Today's standard Web technologies make the Web a hospitable platform for efficient interactive applications both for professional programmers and end-users. With proper support, in tools and languages, end-user programming of interactive applications is feasible. In this paper, we review the current state of Web application development and the possibilities and potential benefits of end-user programming on the Web. We will use a case study, AgentWeb, a Web-based end-user development environment, as a representative of interactive Web applications. It is based completely on open Web technologies, rather than on any proprietary technologies. Given that 2D graphic interactive applications may be developed and efficiently executed on the Web, we discuss some of the potential applications in educational settings, including individual and collaborative learning.",
        "acm_key": "2023618",
        "bib_stats": {
            "cites": 0,
            "dl": 112,
            "dl_52": 9,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Mladenov:2011:SHF:2023607.2023618,\n author = {Mladenov, Radoslav and Ivanov, Sava},\n title = {A Self-tuning Hybrid Flash Translation Layer for Embedded Systems},\n booktitle = {Proceedings of the 12th International Conference on Computer Systems and Technologies},\n series = {CompSysTech '11},\n year = {2011},\n isbn = {978-1-4503-0917-2},\n location = {Vienna, Austria},\n pages = {57--62},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2023607.2023618},\n doi = {10.1145/2023607.2023618},\n acmid = {2023618},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, SSD, address translation, algorithm, block, cache, design, erase, file system, flash, garbage collection, page},\n} \r\n",
        "key": "2023618",
        "pub_year": "2011",
        "text": "Radoslav Mladenov , Sava Ivanov, A self-tuning hybrid flash translation layer for embedded systems, Proceedings of the 12th International Conference on Computer Systems and Technologies, June 16-17, 2011, Vienna, Austria"
    },
    "2024819": {
        "abstract": "As the gap between the lithography wavelength and critical feature size has continued to increase, the semiconductor industry has had to adjust. Previously, scaling along Moore's Law had relied on improvement in lithography equipment, occasionally by reducing the wavelength and frequently by improving the effective numerical aperture. The wavelength used to define critical dimensions during much of the nineties was 248nm, with the industry switching to 193nm in the following decade. After 157nm technology failed to materialize due to technological challenges, the focus of next generation lithography (NGL) research shifted to EUV. Meanwhile, 193nm continued to be the workhorse for the continuation of Moore's Law. The next big equipment advancement came with immersion steppers, which \"increased\" the effective aperture of the lens, thereby capturing more of the diffraction orders in the imaging process. Moore's Law, however requires a significant innovation every two years! With optical lithography wavelength and effective lens aperture stretched to these limits, double patterning came to the rescue. By splitting the pattern into two, the burden on each mask was somewhat reduced, allowing a \"stitched\" pattern to scale. All through these changes, continued scaling also required a tighter co-optimization between process and design. As the image quality became generally weaker, greater restrictions were placed on the diversity of features that could be robustly patterned, leading to the proverbial increase in the heft of design rule manuals.",
        "acm_key": "2024819",
        "bib_stats": {
            "cites": 19,
            "dl": 213,
            "dl_52": 28,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Liu:2011:PVP:2024724.2024819,\n author = {Liu, Tiantian and Zhao, Yingchao and Xue, Chun Jason and Li, Minming},\n title = {Power-aware Variable Partitioning for DSPs with Hybrid PRAM and DRAM Main Memory},\n booktitle = {Proceedings of the 48th Design Automation Conference},\n series = {DAC '11},\n year = {2011},\n isbn = {978-1-4503-0636-2},\n location = {San Diego, California},\n pages = {405--410},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2024724.2024819},\n doi = {10.1145/2024724.2024819},\n acmid = {2024819},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {phase change random access memory, power efficiency, variable partitioning},\n} \r\n",
        "key": "2024819",
        "pub_year": "2011",
        "text": "Tiantian Liu , Yingchao Zhao , Chun Jason Xue , Minming Li, Power-aware variable partitioning for DSPs with hybrid PRAM and DRAM main memory, Proceedings of the 48th Design Automation Conference, June 05-10, 2011, San Diego, California  \u00a0[doi>"
    },
    "2029352": {
        "abstract": "Cloud computing is a paradigm which allows the use of outsourced infrastructures in a \"pay-as-you-go\" basis, thanks to which scalable and customizable infrastructures can be built on demand. The ability to infer the number and type of the Virtual Machines (VM) needed determines the final budget, thus it represents a key in order to efficiently manage a cloud infrastructure. In order to develop new proposals aimed at different topics related to cloud computing (for example, datacenter management, or provision of resources), a lot of work and money is required to set up an adequately sized testbed including different datacenters from different organizations and public cloud providers. Therefore, it is easier to use simulation as a tool for studying complex scenarios. With this in mind, this paper introduces iCanCloud, a novel simulator of cloud infrastructures with remarkable features such as usability, flexibility, performance and scalability. This tool is specially aimed at simulating instance types provided by Amazon, so models of these are included in the simulation framework. Accuracy experiments conducted by means of comparing results obtained using iCanCloud and a validated mathematical model of Amazon in the context of a given application are also presented. These illustrate the efficiency of iCanCloud at reproducing the behavior of Amazon instance types.",
        "acm_key": "2029352",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2029352",
        "text": "Soo-Hyeon Yang , Yeonseung Ryu, An efficient mapping table management in NAND flash-based mobile computers, Proceedings of the 2011 international conference on Computational science and its applications, p.518-527, June 20-23, 2011, Santander, Spain"
    },
    "2039420": {
        "abstract": "Virtual Machines (VMs) allow for platform-independent software development and their use in embedded systems is increasing. In particular, VMs are rewarding in the context of mixed-criticality applications to provide isolation between critical and non-critical tasks running on the same processor. In this paper, we study the design of a real-time system based on a VM monitor/hypervisor that supports multiple VMs/domains. Since each VM in the system runs several real-time tasks, scheduling the VMs leads to a hierarchical scheduling problem. So far, most published techniques for analyzing hierarchical scheduling deal with the schedulability problem, i.e., for a given hierarchical scheduler, testing whether a set of real-time tasks meet their deadlines. In this paper, we are rather concerned with the synthesis of hierarchical/VM schedulers; that is, how to design a scheduler such that all real-time tasks running on the different VMs meet their deadlines. We consider a setup where the tasks are scheduled on multiple VMs under fixed priorities according to the Deadline Monotonic (DM) policy. The VMs are scheduled under fixed priorities on a Rate Monotonic (RM) basis using one or more processors. A partitioned scheduling of VMs is considered, i.e., VMs are not allowed to migrate from one processor to the other. In this context, we propose a method for selecting optimum time slices and periods for each VM in the system. Our goal is to configure the VM scheduler such that not only all tasks are schedulable but also the minimum possible resources are used. Finally, to illustrate the proposed design technique, we present a case study based on automotive control applications.",
        "acm_key": "2039420",
        "bib_stats": {
            "cites": 38,
            "dl": 1,
            "dl_52": 86,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Xue:2011:ENM:2039370.2039420,\n author = {Xue, Chun Jason and Zhang, Youtao and Chen, Yiran and Sun, Guangyu and Yang, J. Jianhua and Li, Hai},\n title = {Emerging Non-volatile Memories: Opportunities and Challenges},\n booktitle = {Proceedings of the Seventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES+ISSS '11},\n year = {2011},\n isbn = {978-1-4503-0715-4},\n location = {Taipei, Taiwan},\n pages = {325--334},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2039370.2039420},\n doi = {10.1145/2039370.2039420},\n acmid = {2039420},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory},\n} \r\n",
        "key": "2039420",
        "pub_year": "2011",
        "text": "Chun Jason Xue , Youtao Zhang , Yiran Chen , Guangyu Sun , J. Jianhua Yang , Hai Li, Emerging non-volatile memories: opportunities and challenges, Proceedings of the seventh IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis, October 09-14, 2011, Taipei, Taiwan  \u00a0[doi>"
    },
    "2042525": {
        "abstract": "Previous research has demonstrated that scratchpad memory(SPM) consumes far less power and on-chip area than the traditional cache. As a software managed memory, SPM has been widely adopted in today's mainstream embedded processors. Traditional SPM allocation strategies depend on either the compiler or the programmer to manage the small memory. The former methods predict the frequently referenced data items before real running by static analysis or profiling, whereas the latter methods require the programmer to manually allocate the SPM space. As for the dynamic heap data allocation, there is no mature allocation scheme for multicore processors with a shared software-managed on-chip memory. This paper presents a novel SPM management framework, for chip multiprocessors (CMP) featuring partitioned global address space (PGAS) SPM memory architecture. The most frequently referenced heap data are maintained in the SPM. This framework mitigates the SPM allocation problem by leveraging the programmer's hints to determine the data items allocated to the SPM. The complex and error-prone allocation procedure is completely handled by an SPM management library (SPMMLIB) without programmer's conscious. The performance is evaluated in a homogenous UltraSPARC multiprocessor using PARSEC and SPLASH2 benchmarks. Experimental results indicate that, on average, the energy consumption is reduced by 22.4% compared with the cache memory architecture.",
        "acm_key": "2042525",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2042525",
        "text": "Xi Zhang , Qian Hu , Dongsheng Wang , Chongmin Li , Haixia Wang, A read-write aware replacement policy for phase change memory, Proceedings of the 9th international conference on Advanced parallel processing technologies, p.31-45, September 26-27, 2011, Shanghai, China"
    },
    "2043558": {
        "abstract": "In this work, we undertake one of the first attempts to conduct a real-world misconfiguration characteristic study. We study a total of 546 real world misconfigurations, including 309 misconfigurations from a commercial storage system deployed at thousands of customers, and 237 from four widely used open source systems (CentOS, MySQL, Apache HTTP Server, and OpenLDAP). Some of our major findings include: (1) A majority of misconfigurations (70.0%~85.5%) are due to mistakes in setting configuration parameters; however, a significant number of misconfigurations are due to compatibility issues or component configurations (i.e., not parameter-related). (2) 38.1%~53.7% of parameter mistakes are caused by illegal parameters that clearly violate some format or rules, motivating the use of an automatic configuration checker to detect these misconfigurations. (3) A significant percentage (12.2%~29.7%) of parameter-based mistakes are due to inconsistencies between different parameter values. (4) 21.7%~57.3% of the misconfigurations involve configurations external to the examined system, some even on entirely different hosts. (5) A significant portion of misconfigurations can cause hard-to-diagnose failures, such as crashes, hangs, or severe performance degradation, indicating that systems should be better-equipped to handle misconfigurations.",
        "acm_key": "2043558",
        "bib_stats": {
            "cites": 72,
            "dl": 1,
            "dl_52": 204,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Lim:2011:SMH:2043556.2043558,\n author = {Lim, Hyeontaek and Fan, Bin and Andersen, David G. and Kaminsky, Michael},\n title = {SILT: A Memory-efficient, High-performance Key-value Store},\n booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},\n series = {SOSP '11},\n year = {2011},\n isbn = {978-1-4503-0977-6},\n location = {Cascais, Portugal},\n pages = {1--13},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2043556.2043558},\n doi = {10.1145/2043556.2043558},\n acmid = {2043558},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {algorithms, design, flash, measurement, memory efficiency, performance},\n} \r\n",
        "key": "2043558",
        "pub_year": "2011",
        "text": "Hyeontaek Lim , Bin Fan , David G. Andersen , Michael Kaminsky, SILT: a memory-efficient, high-performance key-value store, Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, October 23-26, 2011, Cascais, Portugal  \u00a0[doi>"
    },
    "2043560": {
        "abstract": "In this work, we undertake one of the first attempts to conduct a real-world misconfiguration characteristic study. We study a total of 546 real world misconfigurations, including 309 misconfigurations from a commercial storage system deployed at thousands of customers, and 237 from four widely used open source systems (CentOS, MySQL, Apache HTTP Server, and OpenLDAP). Some of our major findings include: (1) A majority of misconfigurations (70.0%~85.5%) are due to mistakes in setting configuration parameters; however, a significant number of misconfigurations are due to compatibility issues or component configurations (i.e., not parameter-related). (2) 38.1%~53.7% of parameter mistakes are caused by illegal parameters that clearly violate some format or rules, motivating the use of an automatic configuration checker to detect these misconfigurations. (3) A significant percentage (12.2%~29.7%) of parameter-based mistakes are due to inconsistencies between different parameter values. (4) 21.7%~57.3% of the misconfigurations involve configurations external to the examined system, some even on entirely different hosts. (5) A significant portion of misconfigurations can cause hard-to-diagnose failures, such as crashes, hangs, or severe performance degradation, indicating that systems should be better-equipped to handle misconfigurations.",
        "acm_key": "2043560",
        "bib_stats": {
            "cites": 94,
            "dl": 1,
            "dl_52": 134,
            "dl_6": 20
        },
        "bibtex": "\r\n@inproceedings{Ongaro:2011:FCR:2043556.2043560,\n author = {Ongaro, Diego and Rumble, Stephen M. and Stutsman, Ryan and Ousterhout, John and Rosenblum, Mendel},\n title = {Fast Crash Recovery in RAMCloud},\n booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},\n series = {SOSP '11},\n year = {2011},\n isbn = {978-1-4503-0977-6},\n location = {Cascais, Portugal},\n pages = {29--41},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2043556.2043560},\n doi = {10.1145/2043556.2043560},\n acmid = {2043560},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash recovery, main memory databases, scalability, storage systems},\n} \r\n",
        "key": "2043560",
        "pub_year": "2011",
        "text": "Diego Ongaro , Stephen M. Rumble , Ryan Stutsman , John Ousterhout , Mendel Rosenblum, Fast crash recovery in RAMCloud, Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, October 23-26, 2011, Cascais, Portugal"
    },
    "2056405": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2056405",
        "bib_stats": {
            "cites": 17
        },
        "bibtex": "\r\n@inproceedings{Zhang:2011:HRD:2056308.2056405,\n author = {Zhang, Wangyuan and Li, Tao},\n title = {Helmet: A Resistance Drift Resilient Architecture for Multi-level Cell Phase Change Memory System},\n booktitle = {Proceedings of the 2011 IEEE/IFIP 41st International Conference on Dependable Systems\\&Networks},\n series = {DSN '11},\n year = {2011},\n isbn = {978-1-4244-9232-9},\n pages = {197--208},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/DSN.2011.5958219},\n doi = {10.1109/DSN.2011.5958219},\n acmid = {2056405},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2056405",
        "pub_year": "2011",
        "text": "Wangyuan Zhang , Tao Li, Helmet: A resistance drift resilient architecture for multi-level cell phase change memory system, Proceedings of the 2011 IEEE/IFIP 41st International Conference on Dependable Systems&Networks, p.197-208, June 27-30, 2011  \u00a0[doi>"
    },
    "2060752": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2060752",
        "bib_stats": {
            "cites": 36
        },
        "bibtex": "\r\n@inproceedings{Murugan:2011:RSW:2060107.2060752,\n author = {Murugan, Muthukumar and Du, David. H. C.},\n title = {Rejuvenator: A Static Wear Leveling Algorithm for NAND Flash Memory with Minimized Overhead},\n booktitle = {Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies},\n series = {MSST '11},\n year = {2011},\n isbn = {978-1-4577-0427-7},\n pages = {1--12},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/MSST.2011.5937225},\n doi = {10.1109/MSST.2011.5937225},\n acmid = {2060752},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2060752",
        "pub_year": "2011",
        "text": "Muthukumar Murugan , David. H. C. Du, Rejuvenator: A static wear leveling algorithm for NAND flash memory with minimized overhead, Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies, p.1-12, May 23-27, 2011  \u00a0[doi>"
    },
    "2060772": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2060772",
        "bib_stats": {
            "cites": 14
        },
        "bibtex": "\r\n@inproceedings{Jiang:2011:SEA:2060107.2060772,\n author = {Jiang, Song and Lei Zhang and XinHao Yuan and Hao Hu and Yu Chen},\n title = {S-FTL: An Efficient Address Translation for Flash Memory by Exploiting Spatial Locality},\n booktitle = {Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies},\n series = {MSST '11},\n year = {2011},\n isbn = {978-1-4577-0427-7},\n pages = {1--12},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/MSST.2011.5937215},\n doi = {10.1109/MSST.2011.5937215},\n acmid = {2060772},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2060772",
        "pub_year": "2011",
        "text": "Song Jiang , Lei Zhang , XinHao Yuan , Hao Hu , Yu Chen, S-FTL: An efficient address translation for flash memory by exploiting spatial locality, Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies, p.1-12, May 23-27, 2011  \u00a0[doi>"
    },
    "2060773": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2060773",
        "bib_stats": {
            "cites": 22
        },
        "bibtex": "\r\n@inproceedings{Park:2011:HDI:2060107.2060773,\n author = {Park, Dongchul and Du, David H. C.},\n title = {Hot Data Identification for Flash-based Storage Systems Using Multiple Bloom Filters},\n booktitle = {Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies},\n series = {MSST '11},\n year = {2011},\n isbn = {978-1-4577-0427-7},\n pages = {1--11},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/MSST.2011.5937216},\n doi = {10.1109/MSST.2011.5937216},\n acmid = {2060773},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2060773",
        "pub_year": "2011",
        "text": "Dongchul Park , David H. C. Du, Hot data identification for flash-based storage systems using multiple bloom filters, Proceedings of the 2011 IEEE 27th Symposium on Mass Storage Systems and Technologies, p.1-11, May 23-27, 2011"
    },
    "2060904": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2060904",
        "bib_stats": {
            "cites": 8
        },
        "key": "2060904",
        "text": "Soyoon Lee , Hyokyung Bahn , Sam H. Noh, Characterizing Memory Write References for Efficient Management of Hybrid PCM and DRAM Memory, Proceedings of the 2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems, p.168-175, July 25-27, 2011  \u00a0[doi>"
    },
    "2060909": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2060909",
        "bib_stats": {
            "cites": 22
        },
        "bibtex": "\r\n@inproceedings{Kim:2011:HCH:2060110.2060909,\n author = {Kim, Youngjae and Gupta, Aayush and Urgaonkar, Bhuvan and Berman, Piotr and Sivasubramaniam, Anand},\n title = {HybridStore: A Cost-Efficient, High-Performance Storage System Combining SSDs and HDDs},\n booktitle = {Proceedings of the 2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems},\n series = {MASCOTS '11},\n year = {2011},\n isbn = {978-0-7695-4430-4},\n pages = {227--236},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/MASCOTS.2011.64},\n doi = {10.1109/MASCOTS.2011.64},\n acmid = {2060909},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Flash Memory, Storage Systems, Modeling, Capacity Planning},\n} \r\n",
        "key": "2060909",
        "pub_year": "2011",
        "text": "Youngjae Kim , Aayush Gupta , Bhuvan Urgaonkar , Piotr Berman , Anand Sivasubramaniam, HybridStore: A Cost-Efficient, High-Performance Storage System Combining SSDs and HDDs, Proceedings of the 2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems, p.227-236, July 25-27, 2011  \u00a0[doi>"
    },
    "2062959": {
        "abstract": "Google Android is a popular software stack for smart phone, where the user experience is critical to its success. The pause time of its garbage collection in DalvikVM should not be too long to stutter the game animation or webpage scrolling. Generational collection or concurrent collection can be the effective approaches to reducing GC pause time. As of version 2.2, Android implements a non-generational stop-the-world (STW) mark-sweep algorithm. In this paper we present an enhancement called Regional GC for Android that can effectively improve its user experience. During the system bootup period, Android preloads the common runtime classes and data structures in order to save the user applications' startup time. When Android launches a user application the first time, it starts a new process with a new DalvikVM instance to run the application code. Every application process has its separate managed heap; while the system preloaded data space is shared across all the application processes. The Regional GC we propose is similar to a generational GC but actually partitions the heap according to regions instead of generations. One region (called the class region) is for the preloaded data, and the other region (called the user region) is for runtime dynamic data. A major collection of regional GC is the same as DalvikVM's normal STW collection, while a minor collection only marks and sweeps the user region. In this way, the regional GC effectively improves Android in both application performance and user experience. In the evaluation of an Android workload suite (AWS), 2D graphic workload Album Slideshow is improved by 28%, and its average pause time is reduced by 73%. The average pause time reduction across all the AWS applications is 55%. The regional GC can be combined with a concurrent GC to further reduce the pause time. This paper also describes two alternative write barrier designs in the Regional GC. One uses page fault to catch the reference writes on the fly; the other one scans the page table entries to discover the dirty pages. We evaluate the two approaches with the AWS applications, and discuss their respective pros and cons.",
        "acm_key": "2062959",
        "bib_stats": {
            "cites": 3,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Yimo:2011:WSR:2062932.2062959,\n author = {Yimo, Du and Fang, Liu and Zhiguang, Chen and Xin, Ma},\n title = {WeLe-RAID: A SSD-based RAID for System Endurance and Performance},\n booktitle = {Proceedings of the 8th IFIP International Conference on Network and Parallel Computing},\n series = {NPC'11},\n year = {2011},\n isbn = {978-3-642-24402-5},\n location = {Changsha, China},\n pages = {248--262},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=2062932.2062959},\n acmid = {2062959},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {RAID, SSD, endurance, performance, reliability, wear-leveling},\n} \r\n",
        "key": "2062959",
        "pub_year": "2011",
        "text": "Du Yimo , Liu Fang , Chen Zhiguang , Ma Xin, WeLe-RAID: a SSD-based RAID for system endurance and performance, Proceedings of the 8th IFIP international conference on Network and parallel computing, October 21-23, 2011, Changsha, China"
    },
    "2063436": {
        "abstract": "In this paper we present a precise data race detection technique for distributed memory parallel programs. Our technique, which we call Active Testing, builds on our previous work on race detection for shared memory Java and C programs and it handles programs written using shared memory approaches as well as bulk communication. Active testing works in two phases: in the first phase, it performs an imprecise dynamic analysis of an execution of the program and finds potential data races that could happen if the program is executed with a different thread schedule. In the second phase, active testing re-executes the program by actively controlling the thread schedule so that the data races reported in the first phase can be confirmed. A key highlight of our technique is that it can scalably handle distributed programs with bulk communication and single- and splitphase barriers. Another key feature of our technique is that it is precise---a data race confirmed by active testing is an actual data race present in the program; however, being a testing approach, our technique can miss actual data races. We implement the framework for the UPC programming language and demonstrate scalability up to a thousand cores for programs with both fine-grained and bulk (MPI style) communication. The tool confirms previously known bugs and uncovers several unknown ones. Our extensions capture constructs proposed in several modern programming languages for High Performance Computing, most notably non-blocking barriers and collectives.",
        "acm_key": "2063436",
        "bib_stats": {
            "cites": 44,
            "dl": 872,
            "dl_52": 108,
            "dl_6": 14
        },
        "bibtex": "\r\n@inproceedings{Wu:2011:SFS:2063384.2063436,\n author = {Wu, Xiaojian and Reddy, A. L. Narasimha},\n title = {SCMFS: A File System for Storage Class Memory},\n booktitle = {Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},\n series = {SC '11},\n year = {2011},\n isbn = {978-1-4503-0771-0},\n location = {Seattle, Washington},\n pages = {39:1--39:11},\n articleno = {39},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2063384.2063436},\n doi = {10.1145/2063384.2063436},\n acmid = {2063436},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2063436",
        "pub_year": "2011",
        "text": "Xiaojian Wu , A. L. Narasimha Reddy, SCMFS: a file system for storage class memory, Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis, November 12-18, 2011, Seattle, Washington"
    },
    "2063977": {
        "abstract": "Search over enterprise data is essential to every aspect of an enterprise because it helps users fulfill their information needs. Similar to Web search, most queries in enterprise search are keyword queries. However, enterprise search is a unique research problem because, compared with the data in traditional IR applications (e.g., text data), enterprise data includes information stored in different formats. In particular, enterprise data include both unstructured and structured information, and all the data center around a particular enterprise. As a result, the relevant information from these two data sources could be complementary to each other. Intuitively, such integrated data could be exploited to improve the enterprise search quality. Despite its importance, this problem has received little attention so far. In this paper, we demonstrate the feasibility of leveraging the integrated information in enterprise data to improve search quality through a case study, i.e., finding relevant information of certain types from enterprise data. Enterprise search users often look for different types of relevant information other than documents, e.g., the contact information of per- sons working on a product. When formulating a keyword query, search users may specify both content requirements, i.e., what kind of information is relevant, and type requirements, i.e., what type of information is relevant. Thus, the goal is to find information relevant to both requirements specified in the query. Specifically, we formulate the problem as keyword search over structured or semistructured data, and then propose to leverage the complementary unstructured information in the enterprise data to solve the problem. Experiment results over real world enterprise data and simulated data show that the proposed methods can effectively exploit the unstructured information to find relevant information of certain types from structured and semistructured information in enterprise data.",
        "acm_key": "2063977",
        "bib_stats": {
            "cites": 18,
            "dl": 382,
            "dl_52": 33,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Gao:2011:PRT:2063576.2063977,\n author = {Gao, Shen and Xu, Jianliang and He, Bingsheng and Choi, Byron and Hu, Haibo},\n title = {PCMLogging: Reducing Transaction Logging Overhead with PCM},\n booktitle = {Proceedings of the 20th ACM International Conference on Information and Knowledge Management},\n series = {CIKM '11},\n year = {2011},\n isbn = {978-1-4503-0717-8},\n location = {Glasgow, Scotland, UK},\n pages = {2401--2404},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/2063576.2063977},\n doi = {10.1145/2063576.2063977},\n acmid = {2063977},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database recovery, logging, pcm, transaction management},\n} \r\n",
        "key": "2063977",
        "pub_year": "2011",
        "text": "Shen Gao , Jianliang Xu , Bingsheng He , Byron Choi , Haibo Hu, PCMLogging: reducing transaction logging overhead with PCM, Proceedings of the 20th ACM international conference on Information and knowledge management, October 24-28, 2011, Glasgow, Scotland, UK  \u00a0[doi>"
    },
    "2076150": {
        "abstract": "Volume 37 Issue 6, November, 2011 \r\n\r\n",
        "acm_key": "2076150",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Lim:2011:DDF:2076029.2076150,\n author = {Lim, Seung-Ho},\n title = {DeFFS: Duplication-eliminated Flash File System},\n journal = {Comput. Electr. Eng.},\n issue_date = {November, 2011},\n volume = {37},\n number = {6},\n month = nov,\n year = {2011},\n issn = {0045-7906},\n pages = {1122--1136},\n numpages = {15},\n url = {http://dx.doi.org/10.1016/j.compeleceng.2011.06.007},\n doi = {10.1016/j.compeleceng.2011.06.007},\n acmid = {2076150},\n publisher = {Pergamon Press, Inc.},\n address = {Tarrytown, NY, USA},\n} \r\n",
        "key": "2076150",
        "pub_year": "2011",
        "text": "Seung-Ho Lim, DeFFS: Duplication-eliminated flash file system, Computers and Electrical Engineering, v.37 n.6, p.1122-1136, November, 2011"
    },
    "2097588": {
        "abstract": "Transmission over wireless ad hoc networks is a challenging problem, because the wireless channel is characterized by limited bandwidth, multi-hop connectivity, mobility of nodes, and dynamically varying network topology. Current unipath routing protocols result in performance degradation in mobile networks due to unreliability of the wireless infrastructure and mobility of nodes. Multipath routing is an attractive alternative for scalable and multiple sub-streamable multimedia traffic under highly error-prone and resourcedepleted network environments. However, existing multipath-capable routing protocols cannot split a single data flow into several sub-flows over a multipath, because these routing protocols use, mostly, an alternate path scheme that provides a secondary path in the event of link failure of the primary path. The Split Multipath Routing (SMR) protocol, which is a major multipath routing protocol based on Dynamic Source Routing (DSR) and uses decentralized transmission over multipath. In enhanced performance, Split Equal-cost Multipath Routing (SEMR) based on SMR is proposed, by introducing \u2018congestion path metric' as a novel metric, which can identify whether the path contains a bottleneck node and guide the selection of other non-congested paths in the path-selecting process. In using proposed concept, superior performance in comparison with SMR and DSR, can be achieved",
        "acm_key": "2097588",
        "bib_stats": {
            "cites": 39,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chung:2006:SSF:2097538.2097588,\n author = {Chung, Tae-Sun and Park, Dong-Joo and Park, Sangwon and Lee, Dong-Ho and Lee, Sang-Won and Song, Ha-Joo},\n title = {System Software for Flash Memory: A Survey},\n booktitle = {Proceedings of the 2006 International Conference on Embedded and Ubiquitous Computing},\n series = {EUC'06},\n year = {2006},\n isbn = {3-540-36679-2, 978-3-540-36679-9},\n location = {Seoul, Korea},\n pages = {394--404},\n numpages = {11},\n url = {http://dx.doi.org/10.1007/11802167_41},\n doi = {10.1007/11802167_41},\n acmid = {2097588},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {embedded system, file system, flash memory},\n} \r\n",
        "key": "2097588",
        "pub_year": "2006",
        "text": "Tae-Sun Chung , Dong-Joo Park , Sangwon Park , Dong-Ho Lee , Sang-Won Lee , Ha-Joo Song, System software for flash memory: a survey, Proceedings of the 2006 international conference on Embedded and Ubiquitous Computing, August 01-04, 2006, Seoul, Korea"
    },
    "2113527": {
        "abstract": "We consider broadcast protocols in wireless networks that have limited energy and computation resources. The well-known algorithm, DBIP (Directional Broadcast Incremental Power), which exploits \u201cIncremental Power\u201d philosophy for wireless networks with directional antenna to construct broadcasting tree, provides very good results in terms of energy savings. Unfortunately, its computation is centralized, as the source node needs to know the entire topology of the network. Mobility of nodes or frequent changes in the node activity status (from \u201cactive\u201d to \u201cpassive\u201d and vice-versa) may cause global changes in topology which must be propagated throughout the network for any centralized solution. This may results in extreme and un-acceptable communication overhead. In this paper, we propose and evaluate a localized energy-efficient broadcast protocol, Localized Directional Broadcast Incremental Power Protocol (LDBIP), which employs distributed location information and computation to construct broadcast trees. In the proposed method, a source node sets up spanning tree with its local neighborhood position information and includes certain hops relay information in packet. Directional antennas are used for transmitting broadcast packet, and the transmission power is adjusted for each transmission to the minimal necessary for reaching the particular neighbor. Relay nodes will consider relay instructions received to compute their own local neighborhood spanning tree and then rebroadcasts. Experimental results verify that this new protocol shows similar performance with DBIP in static wireless networks, and better performance in mobile scenarios.",
        "acm_key": "2113527",
        "bib_stats": {
            "cites": 3,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ryu:2005:ISU:2113438.2113527,\n author = {Ryu, Yeonseung and Lee, Kangsun},\n title = {Improvement of Space Utilization in NAND Flash Memory Storages},\n booktitle = {Proceedings of the Second International Conference on Embedded Software and Systems},\n series = {ICESS'05},\n year = {2005},\n isbn = {3-540-30881-4, 978-3-540-30881-2},\n location = {Xi'an, China},\n pages = {766--775},\n numpages = {10},\n url = {http://dx.doi.org/10.1007/11599555_74},\n doi = {10.1007/11599555_74},\n acmid = {2113527},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n keywords = {flash memory, flash translation layer, space utilization},\n} \r\n",
        "key": "2113527",
        "pub_year": "2005",
        "text": "Yeonseung Ryu , Kangsun Lee, Improvement of space utilization in NAND flash memory storages, Proceedings of the Second international conference on Embedded Software and Systems, December 16-18, 2005, Xi'an, China"
    },
    "2118362": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2118362",
        "bib_stats": {
            "cites": 14
        },
        "bibtex": "\r\n@inproceedings{Wang:2011:EMC:2117685.2118362,\n author = {Wang, Jue and Dong, Xiangyu and Sun, Guangyu and Niu, Dimin and Xie, Yuan},\n title = {Energy-efficient Multi-level Cell Phase-change Memory System with Data Encoding},\n booktitle = {Proceedings of the 2011 IEEE 29th International Conference on Computer Design},\n series = {ICCD '11},\n year = {2011},\n isbn = {978-1-4577-1953-0},\n pages = {175--182},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/ICCD.2011.6081394},\n doi = {10.1109/ICCD.2011.6081394},\n acmid = {2118362},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2118362",
        "pub_year": "2011",
        "text": "Jue Wang , Xiangyu Dong , Guangyu Sun , Dimin Niu , Yuan Xie, Energy-efficient multi-level cell phase-change memory system with data encoding, Proceedings of the 2011 IEEE 29th International Conference on Computer Design, p.175-182, October 09-12, 2011  \u00a0[doi>"
    },
    "2118492": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2118492",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@inproceedings{Lee:2011:BCS:2117686.2118492,\n author = {Lee, Eunji and Jin, Daeja and Koh, Kern and Bahn, Hyokyung},\n title = {Is Buffer Cache Still Effective for High Speed PCM (Phase Change Memory) Storage?},\n booktitle = {Proceedings of the 2011 IEEE 17th International Conference on Parallel and Distributed Systems},\n series = {ICPADS '11},\n year = {2011},\n isbn = {978-0-7695-4576-9},\n pages = {356--363},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/ICPADS.2011.74},\n doi = {10.1109/ICPADS.2011.74},\n acmid = {2118492},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Phase Change Memory, Buffer Cache, File Systmes},\n} \r\n",
        "key": "2118492",
        "pub_year": "2011",
        "text": "Eunji Lee , Daeja Jin , Kern Koh , Hyokyung Bahn, Is Buffer Cache Still Effective for High Speed PCM (Phase Change Memory) Storage?, Proceedings of the 2011 IEEE 17th International Conference on Parallel and Distributed Systems, p.356-363, December 07-09, 2011  \u00a0[doi>"
    },
    "2121147": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2121147",
        "bib_stats": {
            "cites": 20
        },
        "bibtex": "\r\n@inproceedings{Liu:2011:PWN:2120959.2121147,\n author = {Liu, Duo and Wang, Tianzheng and Wang, Yi and Qin, Zhiwei and Shao, Zili},\n title = {PCM-FTL: A Write-Activity-Aware NAND Flash Memory Management Scheme for PCM-Based Embedded Systems},\n booktitle = {Proceedings of the 2011 IEEE 32Nd Real-Time Systems Symposium},\n series = {RTSS '11},\n year = {2011},\n isbn = {978-0-7695-4591-2},\n pages = {357--366},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/RTSS.2011.40},\n doi = {10.1109/RTSS.2011.40},\n acmid = {2121147},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {NAND flash memory, phase change memory, endurance, flash translation layer},\n} \r\n",
        "key": "2121147",
        "pub_year": "2011",
        "text": "Duo Liu , Tianzheng Wang , Yi Wang , Zhiwei Qin , Zili Shao, PCM-FTL: A Write-Activity-Aware NAND Flash Memory Management Scheme for PCM-Based Embedded Systems, Proceedings of the 2011 IEEE 32nd Real-Time Systems Symposium, p.357-366, November 29-December 02, 2011  \u00a0[doi>"
    },
    "2121467": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2121467",
        "bib_stats": {
            "cites": 8
        },
        "key": "2121467",
        "text": "Kun Fang , Long Chen , Zhao Zhang , Zhichun Zhu, Memory Architecture for Integrating Emerging Memory Technologies, Proceedings of the 2011 International Conference on Parallel Architectures and Compilation Techniques, p.403-412, October 10-14, 2011  \u00a0[doi>"
    },
    "2151017": {
        "abstract": "The performance of modern many-core platforms strongly depends on the effectiveness of using their complex cache and memory structures. This indicates the need for a memory-centric approach to platform scheduling, in which it is the locations of memory blocks in caches rather than CPU idleness that determines where application processes are run. Using the term 'memory region' to denote the current set of physical memory pages actively used by an application, this paper presents and evaluates region-based scheduling methods for multicore platforms. This involves (i) continuously and at runtime identifying the memory regions used by executable entities, and their sizes, (ii) mapping these regions to caches to match performance goals, and (iii) maintaining region to cache mappings by ensuring that entities run on processors with direct access to the caches containing their regions. Region scheduling can implement policies that (i) offer improved performance to applications by 'unifying' the multiple caches present on the underlying physical machine and/or by 'balancing' cache usage to take maximum advantage of available cache space, (ii) better isolate applications from each other, particularly when their performance is strongly affected by cache availability, and also (iii) take advantage of standard scheduling and CPU-based load balancing when regioning is ineffective. The paper describes region scheduling and its system-level implementation and evaluates its performance with micro-benchmarks and representative multi-core applications. Single applications see performance improvements of up to 15% with region scheduling, and we observe 40% latency improvements when a platform is shared by multiple applications. Superior isolation is shown to be particularly important for cache-sensitive or real-time codes.",
        "acm_key": "2151017",
        "bib_stats": {
            "cites": 47,
            "dl": 757,
            "dl_52": 77,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Caulfield:2012:PSU:2189750.2151017,\n author = {Caulfield, Adrian M. and Mollov, Todor I. and Eisner, Louis Alex and De, Arup and Coburn, Joel and Swanson, Steven},\n title = {Providing Safe, User Space Access to Fast, Solid State Disks},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2012},\n volume = {40},\n number = {1},\n month = mar,\n year = {2012},\n issn = {0163-5964},\n pages = {387--400},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2189750.2151017},\n doi = {10.1145/2189750.2151017},\n acmid = {2151017},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O performance, file systems, non-volatile memory, storage systems, virtualization},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2151017&parent_id=2189750&expformat=bibtex&CFID=982051094&CFTOKEN=83751426\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2151017\">\r\n@inproceedings{Caulfield:2012:PSU:2150976.2151017,\n author = {Caulfield, Adrian M. and Mollov, Todor I. and Eisner, Louis Alex and De, Arup and Coburn, Joel and Swanson, Steven},\n title = {Providing Safe, User Space Access to Fast, Solid State Disks},\n booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XVII},\n year = {2012},\n isbn = {978-1-4503-0759-8},\n location = {London, England, UK},\n pages = {387--400},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2150976.2151017},\n doi = {10.1145/2150976.2151017},\n acmid = {2151017},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O performance, file systems, non-volatile memory, storage systems, virtualization},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2151017&parent_id=2150976&expformat=bibtex&CFID=982051094&CFTOKEN=83751426\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2151017\">\r\n@article{Caulfield:2012:PSU:2248487.2151017,\n author = {Caulfield, Adrian M. and Mollov, Todor I. and Eisner, Louis Alex and De, Arup and Coburn, Joel and Swanson, Steven},\n title = {Providing Safe, User Space Access to Fast, Solid State Disks},\n journal = {SIGPLAN Not.},\n issue_date = {April 2012},\n volume = {47},\n number = {4},\n month = mar,\n year = {2012},\n issn = {0362-1340},\n pages = {387--400},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2248487.2151017},\n doi = {10.1145/2248487.2151017},\n acmid = {2151017},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O performance, file systems, non-volatile memory, storage systems, virtualization},\n} \r\n",
        "key": "2151017",
        "pub_year": "2012",
        "text": "Adrian M. Caulfield , Todor I. Mollov , Louis Alex Eisner , Arup De , Joel Coburn , Steven Swanson, Providing safe, user space access to fast, solid state disks, Proceedings of the seventeenth international conference on Architectural Support for Programming Languages and Operating Systems, March 03-07, 2012, London, England, UK"
    },
    "2151018": {
        "abstract": "The performance of modern many-core platforms strongly depends on the effectiveness of using their complex cache and memory structures. This indicates the need for a memory-centric approach to platform scheduling, in which it is the locations of memory blocks in caches rather than CPU idleness that determines where application processes are run. Using the term 'memory region' to denote the current set of physical memory pages actively used by an application, this paper presents and evaluates region-based scheduling methods for multicore platforms. This involves (i) continuously and at runtime identifying the memory regions used by executable entities, and their sizes, (ii) mapping these regions to caches to match performance goals, and (iii) maintaining region to cache mappings by ensuring that entities run on processors with direct access to the caches containing their regions. Region scheduling can implement policies that (i) offer improved performance to applications by 'unifying' the multiple caches present on the underlying physical machine and/or by 'balancing' cache usage to take maximum advantage of available cache space, (ii) better isolate applications from each other, particularly when their performance is strongly affected by cache availability, and also (iii) take advantage of standard scheduling and CPU-based load balancing when regioning is ineffective. The paper describes region scheduling and its system-level implementation and evaluates its performance with micro-benchmarks and representative multi-core applications. Single applications see performance improvements of up to 15% with region scheduling, and we observe 40% latency improvements when a platform is shared by multiple applications. Superior isolation is shown to be particularly important for cache-sensitive or real-time codes.",
        "acm_key": "2151018",
        "bib_stats": {
            "cites": 55,
            "dl": 1,
            "dl_52": 166,
            "dl_6": 19
        },
        "bibtex": "\r\n@article{Narayanan:2012:WP:2248487.2151018,\n author = {Narayanan, Dushyanth and Hodson, Orion},\n title = {Whole-system Persistence},\n journal = {SIGPLAN Not.},\n issue_date = {April 2012},\n volume = {47},\n number = {4},\n month = mar,\n year = {2012},\n issn = {0362-1340},\n pages = {401--410},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2248487.2151018},\n doi = {10.1145/2248487.2151018},\n acmid = {2151018},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVRAM, persistence},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2151018&parent_id=2248487&expformat=bibtex&CFID=982051064&CFTOKEN=40092356\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2151018\">\r\n@inproceedings{Narayanan:2012:WP:2150976.2151018,\n author = {Narayanan, Dushyanth and Hodson, Orion},\n title = {Whole-system Persistence},\n booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS XVII},\n year = {2012},\n isbn = {978-1-4503-0759-8},\n location = {London, England, UK},\n pages = {401--410},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2150976.2151018},\n doi = {10.1145/2150976.2151018},\n acmid = {2151018},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVRAM, persistence},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2151018&parent_id=2150976&expformat=bibtex&CFID=982051064&CFTOKEN=40092356\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2151018\">\r\n@article{Narayanan:2012:WP:2189750.2151018,\n author = {Narayanan, Dushyanth and Hodson, Orion},\n title = {Whole-system Persistence},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2012},\n volume = {40},\n number = {1},\n month = mar,\n year = {2012},\n issn = {0163-5964},\n pages = {401--410},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2189750.2151018},\n doi = {10.1145/2189750.2151018},\n acmid = {2151018},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVRAM, persistence},\n} \r\n",
        "key": "2151018",
        "pub_year": "2012",
        "text": "Dushyanth Narayanan , Orion Hodson, Whole-system persistence, ACM SIGARCH Computer Architecture News, v.40 n.1, March 2012"
    },
    "2155642": {
        "abstract": "Spin-transfer torque random access memory (STT-RAM) has received increasing attention because of its attractive features: good scalability, zero standby power, non-volatility and radiation hardness. The use of STT-RAM technology in the last level on-chip caches has been proposed as it minimizes cache leakage power with technology scaling down. Furthermore, the cell area of STT-RAM is only 1/9 ~ 1/3 that of SRAM. This allows for a much larger cache with the same die footprint, improving overall system performance through reducing cache misses. However, deploying STT-RAM technology in L1 caches is challenging because of the long and power-consuming write operations. In this paper, we propose both L1 and lower level cache designs that use STT-RAM. In particular, our designs use STT-RAM cells with various data retention time and write performances, made possible by different magnetic tunneling junction (MTJ) designs. For the fast STT-RAM bits with reduced data retention time, a counter controlled dynamic refresh scheme is proposed to maintain the data validity. Our dynamic scheme saves more than 80% refresh energy compared to the simple refresh scheme proposed in previous works. A L1 cache built with ultra low retention STT-RAM coupled with our proposed dynamic refresh scheme can achieve 9.2% in performance improvement, and saves up to 30% of the total energy when compared to one that uses traditional SRAM. For lower level caches with relative large cache capacity, we propose a data migration scheme that moves data between portions of the cache with different retention characteristics so as to maximize the performance and power benefits. Our experiments show that on the average, our proposed multi retention level STT-RAM cache reduces 30 ~ 70% of the total energy compared to previous works, while improving IPC performance for both 2-level and 3-level cache hierarchy.",
        "acm_key": "2155642",
        "bib_stats": {
            "cites": 25,
            "dl": 357,
            "dl_52": 34,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Hay:2011:PPB:2155620.2155642,\n author = {Hay, Andrew and Strauss, Karin and Sherwood, Timothy and Loh, Gabriel H. and Burger, Doug},\n title = {Preventing PCM Banks from Seizing Too Much Power},\n booktitle = {Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO-44},\n year = {2011},\n isbn = {978-1-4503-1053-6},\n location = {Porto Alegre, Brazil},\n pages = {186--195},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2155620.2155642},\n doi = {10.1145/2155620.2155642},\n acmid = {2155642},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory, performance, phase-change memory, power, resistive memories, tokens, write throughput},\n} \r\n",
        "key": "2155642",
        "pub_year": "2011",
        "text": "Andrew Hay , Karin Strauss , Timothy Sherwood , Gabriel H. Loh , Doug Burger, Preventing PCM banks from seizing too much power, Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, December 03-07, 2011, Porto Alegre, Brazil  \u00a0[doi>"
    },
    "2155659": {
        "abstract": "Spin-transfer torque random access memory (STT-RAM) has received increasing attention because of its attractive features: good scalability, zero standby power, non-volatility and radiation hardness. The use of STT-RAM technology in the last level on-chip caches has been proposed as it minimizes cache leakage power with technology scaling down. Furthermore, the cell area of STT-RAM is only 1/9 ~ 1/3 that of SRAM. This allows for a much larger cache with the same die footprint, improving overall system performance through reducing cache misses. However, deploying STT-RAM technology in L1 caches is challenging because of the long and power-consuming write operations. In this paper, we propose both L1 and lower level cache designs that use STT-RAM. In particular, our designs use STT-RAM cells with various data retention time and write performances, made possible by different magnetic tunneling junction (MTJ) designs. For the fast STT-RAM bits with reduced data retention time, a counter controlled dynamic refresh scheme is proposed to maintain the data validity. Our dynamic scheme saves more than 80% refresh energy compared to the simple refresh scheme proposed in previous works. A L1 cache built with ultra low retention STT-RAM coupled with our proposed dynamic refresh scheme can achieve 9.2% in performance improvement, and saves up to 30% of the total energy when compared to one that uses traditional SRAM. For lower level caches with relative large cache capacity, we propose a data migration scheme that moves data between portions of the cache with different retention characteristics so as to maximize the performance and power benefits. Our experiments show that on the average, our proposed multi retention level STT-RAM cache reduces 30 ~ 70% of the total energy compared to previous works, while improving IPC performance for both 2-level and 3-level cache hierarchy.",
        "acm_key": "2155659",
        "bib_stats": {
            "cites": 38,
            "dl": 861,
            "dl_52": 84,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Sun:2011:MRL:2155620.2155659,\n author = {Sun, Zhenyu and Bi, Xiuyuan and Li, Hai (Helen) and Wong, Weng-Fai and Ong, Zhong-Liang and Zhu, Xiaochun and Wu, Wenqing},\n title = {Multi Retention Level STT-RAM Cache Designs with a Dynamic Refresh Scheme},\n booktitle = {Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO-44},\n year = {2011},\n isbn = {978-1-4503-1053-6},\n location = {Porto Alegre, Brazil},\n pages = {329--338},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2155620.2155659},\n doi = {10.1145/2155620.2155659},\n acmid = {2155659},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2155659",
        "pub_year": "2011",
        "text": "Zhenyu Sun , Xiuyuan Bi , Hai (Helen) Li , Weng-Fai Wong , Zhong-Liang Ong , Xiaochun Zhu , Wenqing Wu, Multi retention level STT-RAM cache designs with a dynamic refresh scheme, Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, December 03-07, 2011, Porto Alegre, Brazil  \u00a0[doi>"
    },
    "2168863": {
        "abstract": "Interest has been growing in powering datacenters (at least partially) with renewable or \"green\" sources of energy, such as solar or wind. However, it is challenging to use these sources because, unlike the \"brown\" (carbon-intensive) energy drawn from the electrical grid, they are not always available. This means that energy demand and supply must be matched, if we are to take full advantage of the green energy to minimize brown energy consumption. In this paper, we investigate how to manage a datacenter's computational workload to match the green energy supply. In particular, we consider data-processing frameworks, in which many background computations can be delayed by a bounded amount of time. We propose GreenHadoop, a MapReduce framework for a datacenter powered by a photovoltaic solar array and the electrical grid (as a backup). GreenHadoop predicts the amount of solar energy that will be available in the near future, and schedules the MapReduce jobs to maximize the green energy consumption within the jobs' time bounds. If brown energy must be used to avoid time bound violations, GreenHadoop selects times when brown energy is cheap, while also managing the cost of peak brown power consumption. Our experimental results demonstrate that GreenHadoop can significantly increase green energy consumption and decrease electricity cost, compared to Hadoop.",
        "acm_key": "2168863",
        "bib_stats": {
            "cites": 45,
            "dl": 870,
            "dl_52": 66,
            "dl_6": 4
        },
        "key": "2168863",
        "text": "Mohit Saxena , Michael M. Swift , Yiying Zhang, FlashTier: a lightweight, consistent and durable storage cache, Proceedings of the 7th ACM european conference on Computer Systems, April 10-13, 2012, Bern, Switzerland"
    },
    "2178512": {
        "abstract": "Visualization techniques increase the user involvement in the interactive process of data mining and querying of spatio-temporal data. This paper describes a novel geometric approach to clustering and querying of spatio-temporal data. We propose the uniform geometric model based on function representation of solids to cluster and query time-dependent data. Clustering and querying are integrated with visualization techniques in one GUI. First, visual clustering with blobby model allows the user to see the result of clustering on the screen for different time points and/or time intervals and set the appropriate parameters interactively. After that, the user gets the data of clusters for the chosen time frames. Then, the user can visually query the cluster/clusters he/she is interested in with geometric primitive solids which currently are cubes, spheres/ellipsoids, cylinders, etc. Geometric operations of union, intersection and/or subtraction can be performed over the geometric primitive solids to get the final query shape. The user visually clusters spatio-temporal data and queries the clusters with geometric shapes through graphics interface accessing dynamically 3D projections of multidimensional points from database, warehouses or files.With the uniform geometric model of the clustering and querying of spatio-temporal data, 3D visualization tools can be naturally incorporated in one system to allow the user to visualize and query clusters changing over time.",
        "acm_key": "2178512",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Ryu:2005:SFM:2178501.2178512,\n author = {Ryu, Yeonseung and Chung, Tae-sun and Lee, Myungho},\n title = {A Space-efficient Flash Memory Software for Mobile Devices},\n booktitle = {Proceedings of the 2005 International Conference on Computational Science and Its Applications - Volume Part IV},\n series = {ICCSA'05},\n year = {2005},\n isbn = {3-540-25863-9, 978-3-540-25863-6},\n location = {Singapore},\n pages = {72--78},\n numpages = {7},\n url = {http://dx.doi.org/10.1007/11424925_9},\n doi = {10.1007/11424925_9},\n acmid = {2178512},\n publisher = {Springer-Verlag},\n address = {Berlin, Heidelberg},\n} \r\n",
        "key": "2178512",
        "pub_year": "2005",
        "text": "Yeonseung Ryu , Tae-sun Chung , Myungho Lee, A space-efficient flash memory software for mobile devices, Proceedings of the 2005 international conference on Computational Science and Its Applications, May 09-12, 2005, Singapore"
    },
    "2180908": {
        "abstract": "NAND flash memory has gained its popularity in a variety of applications as a storage medium due to its low power consumption, nonvolatility, high performance, physical stability, and portability. In particular, Multi-Level Cell (MLC) flash memory, which provides a lower cost and higher density solution, has occupied the largest part of NAND flash-memory market share. However, MLC flash memory also introduces new challenges: (1) Pages in a block must be written sequentially. (2) Information to indicate a page being obsoleted cannot be recorded in its spare area due to the limitation on the number of partial programming. Since most of applications access NAND flash memory under FAT file system, this article designs an MLC Flash Translation Layer (MFTL) for flash-memory storage systems which takes constraints of MLC flash memory and access behaviors of FAT file system into consideration. A series of trace-driven simulations was conducted to evaluate the performance of the proposed scheme. Although MFTL is designed for MLC flash memory and FAT file system, it is applicable to SLC flash memory and other file systems as well. Our experiment results show that the proposed MFTL could achieve a good performance for various access patterns even on SLC flash memory.",
        "acm_key": "2180908",
        "bib_stats": {
            "cites": 2,
            "dl": 564,
            "dl_52": 24,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Hsieh:2012:MDI:2180905.2180908,\n author = {Hsieh, Jen-Wei and Wu, Chung-Hsien and Chiu, Ge-Ming},\n title = {MFTL: A Design and Implementation for MLC Flash Memory Storage Systems},\n journal = {Trans. Storage},\n issue_date = {May 2012},\n volume = {8},\n number = {2},\n month = may,\n year = {2012},\n issn = {1553-3077},\n pages = {7:1--7:29},\n articleno = {7},\n numpages = {29},\n url = {http://doi.acm.org/10.1145/2180905.2180908},\n doi = {10.1145/2180905.2180908},\n acmid = {2180908},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FAT file system, Multi-level cell flash memory, storage management},\n} \r\n",
        "key": "2180908",
        "pub_year": "2012",
        "text": "Jen-Wei Hsieh , Chung-Hsien Wu , Ge-Ming Chiu, MFTL: A Design and Implementation for MLC Flash Memory Storage Systems, ACM Transactions on Storage (TOS), v.8 n.2, p.1-29, May 2012"
    },
    "2192670": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2192670",
        "bib_stats": {
            "cites": 18
        },
        "bibtex": "\r\n@inproceedings{Awasthi:2012:ESM:2192603.2192670,\n author = {Awasthi, Manu and Shevgoor, Manjunath and Sudan, Kshitij and Rajendran, Bipin and Balasubramonian, Rajeev and Srinivasan, Viii},\n title = {Efficient Scrub Mechanisms for Error-prone Emerging Memories},\n booktitle = {Proceedings of the 2012 IEEE 18th International Symposium on High-Performance Computer Architecture},\n series = {HPCA '12},\n year = {2012},\n isbn = {978-1-4673-0827-4},\n pages = {1--12},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/HPCA.2012.6168941},\n doi = {10.1109/HPCA.2012.6168941},\n acmid = {2192670},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2192670",
        "pub_year": "2012",
        "text": "Manu Awasthi , Manjunath Shevgoor , Kshitij Sudan , Bipin Rajendran , Rajeev Balasubramonian , Viii Srinivasan, Efficient scrub mechanisms for error-prone emerging memories, Proceedings of the 2012 IEEE 18th International Symposium on High-Performance Computer Architecture, p.1-12, February 25-29, 2012  \u00a0[doi>"
    },
    "2192684": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2192684",
        "bib_stats": {
            "cites": 43
        },
        "bibtex": "\r\n@inproceedings{Jiang:2012:IWO:2192603.2192684,\n author = {Jiang, Lei and Zhao, Bo and Zhang, Youtao and Yang, Jun and Childers, Bruce R.},\n title = {Improving Write Operations in MLC Phase Change Memory},\n booktitle = {Proceedings of the 2012 IEEE 18th International Symposium on High-Performance Computer Architecture},\n series = {HPCA '12},\n year = {2012},\n isbn = {978-1-4673-0827-4},\n pages = {1--10},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/HPCA.2012.6169027},\n doi = {10.1109/HPCA.2012.6169027},\n acmid = {2192684},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2192684",
        "pub_year": "2012",
        "text": "Lei Jiang , Bo Zhao , Youtao Zhang , Jun Yang , Bruce R. Childers, Improving write operations in MLC phase change memory, Proceedings of the 2012 IEEE 18th International Symposium on High-Performance Computer Architecture, p.1-10, February 25-29, 2012  \u00a0[doi>"
    },
    "2208008": {
        "abstract": "As conventional memory technologies such as DRAM and Flash run into scaling challenges, architects and system designers are forced to look at alternative technologies for building future computer systems. This synthesis lecture begins by listing the requirements for a next generation memory technology and briefly surveying the landscape of novel non-volatile memories. Among these, Phase Change Memory (PCM) is emerging as a leading contender, and the authors discuss the material, device, and circuit advances underlying this exciting technology. The lecture then describes architectural solutions to enable PCM for main memories. Finally, the authors explore the impact of such byte-addressable non-volatile memories on future storage and system designs. Table of Contents: Next Generation Memory Technologies / Architecting PCM for Main Memories / Tolerating Slow Writes in PCM / Wear Leveling for Durability / Wear Leveling Under Adversarial Settings / Error Resilience in Phase Change Memories / Storage and System Design With Emerging Non-Volatile Memories",
        "acm_key": "2208008",
        "bib_stats": {
            "cites": 18
        },
        "bibtex": "\r\n@book{Qureshi:2011:PCM:2208008,\n author = {Qureshi, Moinuddin K. and Gurumurthi, Sudhanva and Rajendran, Bipin},\n title = {Phase Change Memory: From Devices to Systems},\n year = {2011},\n isbn = {160845665X, 9781608456659},\n edition = {1st},\n publisher = {Morgan \\& Claypool Publishers},\n} \r\n",
        "key": "2208008",
        "pub_year": null,
        "text": "Moinuddin K. Qureshi , Sudhanva Gurumurthi , Bipin Rajendran, Phase Change Memory: From Devices to Systems, Morgan & Claypool Publishers, 2011"
    },
    "2208462": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208462",
        "bib_stats": {
            "cites": 36,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhang:2012:DFS:2208461.2208462,\n author = {Zhang, Yiying and Arulraj, Leo Prasath and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},\n title = {De-indirection for Flash-based SSDs with Nameless Writes},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {1--1},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208462},\n acmid = {2208462},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208462",
        "pub_year": "2012",
        "text": "Yiying Zhang , Leo Prasath Arulraj , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-Dusseau, De-indirection for flash-based SSDs with nameless writes, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.1-1, February 14-17, 2012, San Jose, CA"
    },
    "2208463": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208463",
        "bib_stats": {
            "cites": 74,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Grupp:2012:BFN:2208461.2208463,\n author = {Grupp, Laura M. and Davis, John D. and Swanson, Steven},\n title = {The Bleak Future of NAND Flash Memory},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {2--2},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208463},\n acmid = {2208463},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208463",
        "pub_year": "2012",
        "text": "Laura M. Grupp , John D. Davis , Steven Swanson, The bleak future of NAND flash memory, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.2-2, February 14-17, 2012, San Jose, CA"
    },
    "2208464": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208464",
        "bib_stats": {
            "cites": 39,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Yang:2012:PBI:2208461.2208464,\n author = {Yang, Jisoo and Minturn, Dave B. and Hady, Frank},\n title = {When Poll is Better Than Interrupt},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {3--3},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208464},\n acmid = {2208464},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208464",
        "pub_year": "2012",
        "text": "Jisoo Yang , Dave B. Minturn , Frank Hady, When poll is better than interrupt, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.3-3, February 14-17, 2012, San Jose, CA"
    },
    "2208472": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208472",
        "bib_stats": {
            "cites": 29,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Liu:2012:ONF:2208461.2208472,\n author = {Liu, Ren-Shuo and Yang, Chia-Lin and Wu, Wei},\n title = {Optimizing NAND Flash-based SSDs via Retention Relaxation},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {11--11},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208472},\n acmid = {2208472},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208472",
        "pub_year": "2012",
        "text": "Ren-Shuo Liu , Chia-Lin Yang , Wei Wu, Optimizing NAND flash-based SSDs via retention relaxation, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.11-11, February 14-17, 2012, San Jose, CA"
    },
    "2208473": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208473",
        "bib_stats": {
            "cites": 42,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Min:2012:SRW:2208461.2208473,\n author = {Min, Changwoo and Kim, Kangnyeon and Cho, Hyunjin and Lee, Sang-Won and Eom, Young Ik},\n title = {SFS: Random Write Considered Harmful in Solid State Drives},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {12--12},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208473},\n acmid = {2208473},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208473",
        "pub_year": "2012",
        "text": "Changwoo Min , Kangnyeon Kim , Hyunjin Cho , Sang-Won Lee , Young Ik Eom, SFS: random write considered harmful in solid state drives, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.12-12, February 14-17, 2012, San Jose, CA"
    },
    "2208474": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208474",
        "bib_stats": {
            "cites": 28,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Park:2012:FFE:2208461.2208474,\n author = {Park, Stan and Shen, Kai},\n title = {FIOS: A Fair, Efficient Flash I/O Scheduler},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {13--13},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208474},\n acmid = {2208474},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208474",
        "pub_year": "2012",
        "text": "Stan Park , Kai Shen, FIOS: a fair, efficient flash I/O scheduler, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.13-13, February 14-17, 2012, San Jose, CA"
    },
    "2208478": {
        "abstract": "Redundancy elimination using data deduplication and incremental data processing has emerged as an important technique to minimize storage and computation requirements in data center computing. In this paper, we present the design, implementation and evaluation of Shredder, a high performance content-based chunking framework for supporting incremental storage and computation systems. Shredder exploits the massively parallel processing power of GPUs to overcome the CPU bottlenecks of content-based chunking in a cost-effective manner. Unlike previous uses of GPUs, which have focused on applications where computation costs are dominant, Shredder is designed to operate in both compute-and dataintensive environments. To allow this, Shredder provides several novel optimizations aimed at reducing the cost of transferring data between host (CPU) and GPU, fully utilizing the multicore architecture at the host, and reducing GPU memory access latencies. With our optimizations, Shredder achieves a speedup of over 5X for chunking bandwidth compared to our optimized parallel implementation without a GPU on the same host system. Furthermore, we present two real world applications of Shredder: an extension to HDFS, which serves as a basis for incremental MapReduce computations, and an incremental cloud backup system. In both contexts, Shredder detects redundancies in the input data across successive runs, leading to significant savings in storage, computation, and end-to-end completion times.",
        "acm_key": "2208478",
        "bib_stats": {
            "cites": 45,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2012:RSS:2208461.2208478,\n author = {Kim, Hyojun and Agrawal, Nitin and Ungureanu, Cristian},\n title = {Revisiting Storage for Smartphones},\n booktitle = {Proceedings of the 10th USENIX Conference on File and Storage Technologies},\n series = {FAST'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {17--17},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2208461.2208478},\n acmid = {2208478},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2208478",
        "pub_year": "2012",
        "text": "Hyojun Kim , Nitin Agrawal , Cristian Ungureanu, Revisiting storage for smartphones, Proceedings of the 10th USENIX conference on File and Storage Technologies, p.17-17, February 14-17, 2012, San Jose, CA"
    },
    "2228300": {
        "abstract": "Diagnosis and correction of performance issues in modern, large-scale distributed systems can be a daunting task, since a single developer is unlikely to be familiar with the entire system and it is hard to characterize the behavior of a software system without completely understanding its internal components. This paper describes DISTALYZER, an automated tool to support developer investigation of performance issues in distributed systems. We aim to leverage the vast log data available from large scale systems, while reducing the level of knowledge required for a developer to use our tool. Specifically, given two sets of logs, one with good and one with bad performance, DISTALYZER uses machine learning techniques to compare system behaviors extracted from the logs and automatically infer the strongest associations between system components and performance. The tool outputs a set of inter-related event occurrences and variable values that exhibit the largest divergence across the logs sets and most directly affect the overall performance of the system. These patterns are presented to the developer for inspection, to help them understand which system component(s) likely contain the root cause of the observed performance issue, thus alleviating the need for many human hours of manual inspection. We demonstrate the generality and effectiveness of DISTALYZER on three real distributed systems by showing how it discovers and highlights the root cause of six performance issues across the systems. DISTALYZER has broad applicability to other systems since it is dependent only on the logs for input, and not on the source code.",
        "acm_key": "2228300",
        "bib_stats": {
            "cites": 25,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Balakrishnan:2012:CSL:2228298.2228300,\n author = {Balakrishnan, Mahesh and Malkhi, Dahlia and Prabhakaran, Vijayan and Wobber, Ted and Wei, Michael and Davis, John D.},\n title = {CORFU: A Shared Log Design for Flash Clusters},\n booktitle = {Proceedings of the 9th USENIX Conference on Networked Systems Design and Implementation},\n series = {NSDI'12},\n year = {2012},\n location = {San Jose, CA},\n pages = {1--1},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2228298.2228300},\n acmid = {2228300},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2228300",
        "pub_year": "2012",
        "text": "Mahesh Balakrishnan , Dahlia Malkhi , Vijayan Prabhakaran , Ted Wobber , Michael Wei , John D. Davis, CORFU: a shared log design for flash clusters, Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation, April 25-27, 2012, San Jose, CA"
    },
    "2228374": {
        "abstract": "In the quest to understand and cure genetic diseases such as cancer, the fundamental approach being taken is undergoing a gradual change. It is becoming more acceptable to view these diseases as an engineering problem, and systems engineering approaches are becoming more accepted as a means to tackle genetic diseases. In this light, we believe that logic synthesis techniques can play a very important role. Several techniques from the field of logic synthesis can be adapted to assist in the arguably huge effort of modeling and controlling such diseases. The set of genes that control a particular genetic disease can be modeled as a Finite State Machine (FSM) called the Gene Regulatory Network (GRN). Important problems include (i) inferring the GRN from observed gene expression data from patients and (ii) assuming that such a GRN exists, determining the \"best\" set of drugs so that the disease is \"maximally\" cured. In this paper, we report initial results on the application of logic synthesis techniques that we have developed to address both these problems. In the first technique, we present Boolean Satisfiability (SAT) based approaches to infer the logical support of each gene that regulates melanoma, using gene expression data from patients of the disease. From the output of such a tool, biologists can construct targeted experiments to understand the logic functions that regulate a particular gene. The second technique assumes that the GRN is known, and uses a weighted partial Max-SAT formulation to find the set of drugs with the least side-effects, that steer the GRN state towards one that is closest to that of a healthy individual, in the context of colon cancer. Our group is currently exploring the application of several other logic techniques to a variety of related problems in this domain.",
        "acm_key": "2228374",
        "bib_stats": {
            "cites": 8,
            "dl": 803,
            "dl_52": 43,
            "dl_6": 22
        },
        "bibtex": "\r\n@inproceedings{Mirhoseini:2012:CEM:2228360.2228374,\n author = {Mirhoseini, Azalia and Potkonjak, Miodrag and Koushanfar, Farinaz},\n title = {Coding-based Energy Minimization for Phase Change Memory},\n booktitle = {Proceedings of the 49th Annual Design Automation Conference},\n series = {DAC '12},\n year = {2012},\n isbn = {978-1-4503-1199-1},\n location = {San Francisco, California},\n pages = {68--76},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/2228360.2228374},\n doi = {10.1145/2228360.2228374},\n acmid = {2228374},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy efficient coding, phase change memory},\n} \r\n",
        "key": "2228374",
        "pub_year": "2012",
        "text": "Azalia Mirhoseini , Miodrag Potkonjak , Farinaz Koushanfar, Coding-based energy minimization for phase change memory, Proceedings of the 49th Annual Design Automation Conference, June 03-07, 2012, San Francisco, California"
    },
    "2228406": {
        "abstract": "In the quest to understand and cure genetic diseases such as cancer, the fundamental approach being taken is undergoing a gradual change. It is becoming more acceptable to view these diseases as an engineering problem, and systems engineering approaches are becoming more accepted as a means to tackle genetic diseases. In this light, we believe that logic synthesis techniques can play a very important role. Several techniques from the field of logic synthesis can be adapted to assist in the arguably huge effort of modeling and controlling such diseases. The set of genes that control a particular genetic disease can be modeled as a Finite State Machine (FSM) called the Gene Regulatory Network (GRN). Important problems include (i) inferring the GRN from observed gene expression data from patients and (ii) assuming that such a GRN exists, determining the \"best\" set of drugs so that the disease is \"maximally\" cured. In this paper, we report initial results on the application of logic synthesis techniques that we have developed to address both these problems. In the first technique, we present Boolean Satisfiability (SAT) based approaches to infer the logical support of each gene that regulates melanoma, using gene expression data from patients of the disease. From the output of such a tool, biologists can construct targeted experiments to understand the logic functions that regulate a particular gene. The second technique assumes that the GRN is known, and uses a weighted partial Max-SAT formulation to find the set of drugs with the least side-effects, that steer the GRN state towards one that is closest to that of a healthy individual, in the context of colon cancer. Our group is currently exploring the application of several other logic techniques to a variety of related problems in this domain.",
        "acm_key": "2228406",
        "bib_stats": {
            "cites": 40,
            "dl": 797,
            "dl_52": 109,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Jog:2012:CRA:2228360.2228406,\n author = {Jog, Adwait and Mishra, Asit K. and Xu, Cong and Xie, Yuan and Narayanan, Vijaykrishnan and Iyer, Ravishankar and Das, Chita R.},\n title = {Cache Revive: Architecting Volatile STT-RAM Caches for Enhanced Performance in CMPs},\n booktitle = {Proceedings of the 49th Annual Design Automation Conference},\n series = {DAC '12},\n year = {2012},\n isbn = {978-1-4503-1199-1},\n location = {San Francisco, California},\n pages = {243--252},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2228360.2228406},\n doi = {10.1145/2228360.2228406},\n acmid = {2228406},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-RAM, heterogeneous (hybrid) systems},\n} \r\n",
        "key": "2228406",
        "pub_year": "2012",
        "text": "Adwait Jog , Asit K. Mishra , Cong Xu , Yuan Xie , Vijaykrishnan Narayanan , Ravishankar Iyer , Chita R. Das, Cache revive: architecting volatile STT-RAM caches for enhanced performance in CMPs, Proceedings of the 49th Annual Design Automation Conference, June 03-07, 2012, San Francisco, California  \u00a0[doi>"
    },
    "2228439": {
        "abstract": "In the quest to understand and cure genetic diseases such as cancer, the fundamental approach being taken is undergoing a gradual change. It is becoming more acceptable to view these diseases as an engineering problem, and systems engineering approaches are becoming more accepted as a means to tackle genetic diseases. In this light, we believe that logic synthesis techniques can play a very important role. Several techniques from the field of logic synthesis can be adapted to assist in the arguably huge effort of modeling and controlling such diseases. The set of genes that control a particular genetic disease can be modeled as a Finite State Machine (FSM) called the Gene Regulatory Network (GRN). Important problems include (i) inferring the GRN from observed gene expression data from patients and (ii) assuming that such a GRN exists, determining the \"best\" set of drugs so that the disease is \"maximally\" cured. In this paper, we report initial results on the application of logic synthesis techniques that we have developed to address both these problems. In the first technique, we present Boolean Satisfiability (SAT) based approaches to infer the logical support of each gene that regulates melanoma, using gene expression data from patients of the disease. From the output of such a tool, biologists can construct targeted experiments to understand the logic functions that regulate a particular gene. The second technique assumes that the GRN is known, and uses a weighted partial Max-SAT formulation to find the set of drugs with the least side-effects, that steer the GRN state towards one that is closest to that of a healthy individual, in the context of colon cancer. Our group is currently exploring the application of several other logic techniques to a variety of related problems in this domain.",
        "acm_key": "2228439",
        "bib_stats": {
            "cites": 19,
            "dl": 438,
            "dl_52": 47,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Chen:2012:APW:2228360.2228439,\n author = {Chen, Chi-Hao and Hsiu, Pi-Cheng and Kuo, Tei-Wei and Yang, Chia-Lin and Wang, Cheng-Yuan Michael},\n title = {Age-based PCM Wear Leveling with Nearly Zero Search Cost},\n booktitle = {Proceedings of the 49th Annual Design Automation Conference},\n series = {DAC '12},\n year = {2012},\n isbn = {978-1-4503-1199-1},\n location = {San Francisco, California},\n pages = {453--458},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2228360.2228439},\n doi = {10.1145/2228360.2228439},\n acmid = {2228439},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, memory management, phase change memory, wear-leveling},\n} \r\n",
        "key": "2228439",
        "pub_year": "2012",
        "text": "Chi-Hao Chen , Pi-Cheng Hsiu , Tei-Wei Kuo , Chia-Lin Yang , Cheng-Yuan Michael Wang, Age-based PCM wear leveling with nearly zero search cost, Proceedings of the 49th Annual Design Automation Conference, June 03-07, 2012, San Francisco, California  \u00a0[doi>"
    },
    "2232028": {
        "abstract": "We consider the problem of constructing efficient P2P overlays for sensornets providing \"Energy-Level Application and Services\". In this context, assuming that a sensor is responsible for executing some program task but unfortunately it's energy-level is lower than a pre-defined threshold. Then, this sensor should be able to introduce a query to the whole system in order to discover efficiently another sensor with the desired energy level, in which the task overhead must be eventually forwarded. In this way, the \"Life-Expectancy\" of the whole network could be increased. Sensor nodes are mapped to peers based on their energy level. As the energy levels change, the sensor nodes would have to move from one peer to another and this operation is very crucial for the efficient scalability of the proposed system. Similarly, as the energy level of a sensor node becomes extremely low, that node may want to forward it's task to another node with the desired energy level. The method presented in [10] presents a novel P2P overlay for Energy Level discovery in a sensornet. However, this solution is not dynamic, since requires periodical restructuring. In particular, it is not able to support neither join of sensor_nodes with energy level out of the ranges supported by the existing p2p overlay nor leave of empty overlay_peers to which no sensor_nodes are currently associated. On this purpose and based on the efficient P2P method presented in [11], we design a dynamic P2P overlay for Energy Level discovery in a sensornet, the so-called SART (Sensors' Autonomous Range Tree). The adaptation of the P2P index presented in [11] guarantees the best-known dynamic query performance of the above operation. We experimentally verify this performance, via the D-P2P-Sim simulator.",
        "acm_key": "2232028",
        "bib_stats": {
            "cites": 2,
            "dl": 164,
            "dl_52": 23,
            "dl_6": 2
        },
        "key": "2232028",
        "text": "Huan Li , Dong Liang , Lihui Xie , Gong Zhang , Krithi Ramamritham, TL-Tree: flash-optimized storage for time-series sensing data on sensor platforms, Proceedings of the 27th Annual ACM Symposium on Applied Computing, March 26-30, 2012, Trento, Italy"
    },
    "2236589": {
        "abstract": "Deployments of networked sensors fuel online applications that feed on real-time sensor data. This scenario calls for techniques that support the management of workloads that contain queries as well as very frequent updates. This paper compares two well-chosen approaches to exploiting the parallelism offered by modern processors for supporting such workloads. A general approach to avoiding contention among parallel hardware threads and thus exploiting the parallelism available in processors is to maintain two copies, or snapshots, of the data: one for the relatively long-duration queries and one for the frequent and very localized updates. The snapshot that receives the updates is frequently made available to queries, so that queries see up-to-date data. The snapshots may be physical or virtual. Physical snapshots are created using the C library memcpy function. Virtual snapshots are created by the fork system function that creates a new process that initially has the same data snapshot as the process it was forked from. When the new process carries out updates, this triggers the actual memory copying in a copy-on-write manner at memory page granularity. This paper characterizes the circumstances under which each technique is preferable. The use of physical snapshots is surprisingly efficient.",
        "acm_key": "2236589",
        "bib_stats": {
            "cites": 6,
            "dl": 240,
            "dl_52": 17,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Saxena:2012:HDT:2236584.2236589,\n author = {Saxena, Mohit and Shah, Mehul A. and Harizopoulos, Stavros and Swift, Michael M. and Merchant, Arif},\n title = {Hathi: Durable Transactions for Memory Using Flash},\n booktitle = {Proceedings of the Eighth International Workshop on Data Management on New Hardware},\n series = {DaMoN '12},\n year = {2012},\n isbn = {978-1-4503-1445-9},\n location = {Scottsdale, Arizona},\n pages = {33--38},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2236584.2236589},\n doi = {10.1145/2236584.2236589},\n acmid = {2236589},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2236589",
        "pub_year": "2012",
        "text": "Mohit Saxena , Mehul A. Shah , Stavros Harizopoulos , Michael M. Swift , Arif Merchant, Hathi: durable transactions for memory using flash, Proceedings of the Eighth International Workshop on Data Management on New Hardware, p.33-38, May 21-21, 2012, Scottsdale, Arizona"
    },
    "225263": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "225263",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Niijima:1995:DSF:225261.225263,\n author = {Niijima, H.},\n title = {Design of a Solid-state File Using Flash EEPROM},\n journal = {IBM J. Res. Dev.},\n issue_date = {Sept. 1995},\n volume = {39},\n number = {5},\n month = sep,\n year = {1995},\n issn = {0018-8646},\n pages = {531--545},\n numpages = {15},\n url = {http://dx.doi.org/10.1147/rd.395.0531},\n doi = {10.1147/rd.395.0531},\n acmid = {225263},\n publisher = {IBM Corp.},\n address = {Riverton, NJ, USA},\n} \r\n",
        "key": "225263",
        "pub_year": "1995",
        "text": "H. Niijima, Design of a solid-state file using flash EEPROM, IBM Journal of Research and Development, v.39 n.5, p.531-545, Sept. 1995  \u00a0[doi>"
    },
    "2254786": {
        "abstract": "Multi-banked embedded DRAM (eDRAM) has become increasingly popular in high-performance systems. However, the data retention problem of eDRAM is exacerbated by the larger number of banks and the high-performance environment in which it is deployed: The data retention time of each memory cell decreases while the number of cells to be refreshed increases. For this, multi-bank designs offer a concurrent refresh mode, where idle banks can be refreshed concurrently during read and write operations. However, conventional techniques such as periodically scheduling refreshes---with priority given to refreshes in case of conflicts with reads or writes---have variable performance, increase read latency, and can perform poorly in worst case memory access patterns. We propose a novel refresh scheduling algorithm that is low-complexity, produces near-optimal throughput with universal guarantees, and is tolerant to bursty memory access patterns. The central idea is to decouple the scheduler into two simple-to-implement modules: one determines which cell to refresh next and the other determines when to force an idle cycle in all banks. We derive necessary and sufficient conditions to guarantee data integrity for all access patterns, with any given number of banks, rows per bank, read/write ports and data retention time. Our analysis shows that there is a tradeoff between refresh overhead and burst tolerance and characterizes this tradeoff precisely. The algorithm is shown to be near-optimal and achieves, for instance, 76.6% reduction in worst-case refresh overhead from the periodic refresh algorithm for a 250MHz eDRAM with 10us retention time and 16 banks each with 128 rows. Simulations with Apex-Map synthetic benchmarks and switch lookup table traffic show that VR can almost completely hide the refresh overhead for memory accesses with moderate-to-high multiplexing across memory banks.",
        "acm_key": "2254786",
        "bib_stats": {
            "cites": 6,
            "dl": 702,
            "dl_52": 25,
            "dl_6": 5
        },
        "key": "2254786",
        "text": "Hyojun Kim , Moonkyung Ryu , Umakishore Ramachandran, What is a good buffer cache replacement scheme for mobile flash storage?, ACM SIGMETRICS Performance Evaluation Review, v.40 n.1, June 2012  \u00a0[doi>"
    },
    "2276906": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2276906",
        "bib_stats": {
            "cites": 205
        },
        "bibtex": "\r\n@article{Kim:2002:SFT:2275633.2276906,\n author = {Kim, Jesung and Kim, Jong Min and Noh, S. H. and Min, Sang Lyul and Cho, Yookun},\n title = {A Space-efficient Flash Translation Layer for CompactFlash Systems},\n journal = {IEEE Trans. on Consum. Electron.},\n issue_date = {May 2002},\n volume = {48},\n number = {2},\n month = may,\n year = {2002},\n issn = {0098-3063},\n pages = {366--375},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/TCE.2002.1010143},\n doi = {10.1109/TCE.2002.1010143},\n acmid = {2276906},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2276906",
        "pub_year": "2002",
        "text": "Jesung Kim , Jong Min Kim , S. H. Noh , Sang Lyul Min , Yookun Cho, A space-efficient flash translation layer for CompactFlash systems, IEEE Transactions on Consumer Electronics, v.48 n.2, p.366-375, May 2002  \u00a0[doi>"
    },
    "2278037": {
        "abstract": "Volume 52 Issue 2, September 2006 \r\n\r\n",
        "acm_key": "2278037",
        "bib_stats": {
            "cites": 64
        },
        "bibtex": "\r\n@article{Jo:2006:FFB:2275657.2278037,\n author = {Jo, Heeseung and Kang, Jeong-Uk and Park, Seon-Yeong and Kim, Jin-Soo and Lee, Joonwon},\n title = {FAB: Flash-aware Buffer Management Policy for Portable Media Players},\n journal = {IEEE Trans. on Consum. Electron.},\n issue_date = {September 2006},\n volume = {52},\n number = {2},\n month = sep,\n year = {2006},\n issn = {0098-3063},\n pages = {485--493},\n numpages = {9},\n url = {http://dx.doi.org/10.1109/TCE.2006.1649669},\n doi = {10.1109/TCE.2006.1649669},\n acmid = {2278037},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2278037",
        "pub_year": "2006",
        "text": "Heeseung Jo , Jeong-Uk Kang , Seon-Yeong Park , Jin-Soo Kim , Joonwon Lee, FAB: flash-aware buffer management policy for portable media players, IEEE Transactions on Consumer Electronics, v.52 n.2, p.485-493, September 2006  \u00a0[doi>"
    },
    "2279736": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2279736",
        "bib_stats": {
            "cites": 25
        },
        "bibtex": "\r\n@article{Jung:2008:LIL:2275721.2279736,\n author = {Jung, Hoyoung and Shim, Hyoki and Park, Sungmin and Kang, Sooyong and Cha, Jaehyuk},\n title = {LRU-WSR: Integration of LRU and Writes Sequence Reordering for Flash Memory},\n journal = {IEEE Trans. on Consum. Electron.},\n issue_date = {August 2008},\n volume = {54},\n number = {3},\n month = aug,\n year = {2008},\n issn = {0098-3063},\n pages = {1215--1223},\n numpages = {9},\n url = {http://dx.doi.org/10.1109/TCE.2008.4637609},\n doi = {10.1109/TCE.2008.4637609},\n acmid = {2279736},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {flash memory, buffer replacement, storage system},\n} \r\n",
        "key": "2279736",
        "pub_year": "2008",
        "text": "Hoyoung Jung , Hyoki Shim , Sungmin Park , Sooyong Kang , Jaehyuk Cha, LRU-WSR: integration of LRU and writes sequence reordering for flash memory, IEEE Transactions on Consumer Electronics, v.54 n.3, p.1215-1223, August 2008"
    },
    "2279738": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2279738",
        "bib_stats": {
            "cites": 22
        },
        "bibtex": "\r\n@article{Seo:2008:RBR:2275721.2279738,\n author = {Seo, Dongyoung and Shin, Dongkun},\n title = {Recently-evicted-first Buffer Replacement Policy for Flash Storage Devices},\n journal = {IEEE Trans. on Consum. Electron.},\n issue_date = {August 2008},\n volume = {54},\n number = {3},\n month = aug,\n year = {2008},\n issn = {0098-3063},\n pages = {1228--1235},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/TCE.2008.4637611},\n doi = {10.1109/TCE.2008.4637611},\n acmid = {2279738},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {flash memory, buffer management, page replacement, flash translation layer, embedded storage},\n} \r\n",
        "key": "2279738",
        "pub_year": "2008",
        "text": "Dongyoung Seo , Dongkun Shin, Recently-evicted-first buffer replacement policy for flash storage devices, IEEE Transactions on Consumer Electronics, v.54 n.3, p.1228-1235, August 2008"
    },
    "2280072": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2280072",
        "bib_stats": {
            "cites": 18
        },
        "bibtex": "\r\n@article{Li:2009:CNB:2275727.2280072,\n author = {Li, Zhi and Jin, Peiquan and Su, Xuan and Cui, Kai and Yue, Lihua},\n title = {CCF-LRU: A New Buffer Replacement Algorithm for Flash Memory},\n journal = {IEEE Trans. on Consum. Electron.},\n issue_date = {August 2009},\n volume = {55},\n number = {3},\n month = aug,\n year = {2009},\n issn = {0098-3063},\n pages = {1351--1359},\n numpages = {9},\n url = {http://dx.doi.org/10.1109/TCE.2009.5277999},\n doi = {10.1109/TCE.2009.5277999},\n acmid = {2280072},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {LRU, buffer replacement algorithm, flash memory},\n} \r\n",
        "key": "2280072",
        "pub_year": "2009",
        "text": "Zhi Li , Peiquan Jin , Xuan Su , Kai Cui , Lihua Yue, CCF-LRU: a new buffer replacement algorithm for flash memory, IEEE Transactions on Consumer Electronics, v.55 n.3, p.1351-1359, August 2009"
    },
    "2302224": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2302224",
        "bib_stats": {
            "cites": 15
        },
        "bibtex": "\r\n@article{Hu:2011:WAM:2298601.2302224,\n author = {Hu, Jingtong and Tseng, Wei-Che and Xue, C. J. and Zhuge, Qingfeng and Zhao, Yingchao and Sha, E. H.-M.},\n title = {Write Activity Minimization for Nonvolatile Main Memory Via Scheduling and Recomputation},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {April 2011},\n volume = {30},\n number = {4},\n month = apr,\n year = {2011},\n issn = {0278-0070},\n pages = {584--592},\n numpages = {9},\n url = {http://dx.doi.org/10.1109/TCAD.2010.2097307},\n doi = {10.1109/TCAD.2010.2097307},\n acmid = {2302224},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {Data recomputation, MRAM, SPM, flash memory, nonvolatile memory, phase change memory, scheduling},\n} \r\n",
        "key": "2302224",
        "pub_year": "2011",
        "text": "Jingtong Hu , Wei-Che Tseng , C. J. Xue , Qingfeng Zhuge , Yingchao Zhao , E. H.-M. Sha, Write Activity Minimization for Nonvolatile Main Memory Via Scheduling and Recomputation, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.30 n.4, p.584-592, April 2011  \u00a0[doi>"
    },
    "232991": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "232991",
        "bib_stats": {
            "cites": 44,
            "dl": 653,
            "dl_52": 20,
            "dl_6": 2
        },
        "key": "232991",
        "text": "Yiming Hu , Qing Yang, DCD<italic>DCD</italic>&#8212;disk caching disk: a new approach for boosting I/O performance, ACM SIGARCH Computer Architecture News, v.24 n.2, p.169-178, May 1996&#13;\n\t\t\t\t\t\t\u2014disk caching disk: a new approach for boosting I/O performance, ACM SIGARCH Computer Architecture News, v.24 n.2, p.169-178, May 1996"
    },
    "2333672": {
        "abstract": "The \"power wall\" has forced chip and system architects to design with smaller margins between nominal and worst-case operating points. Localized hot spots and temperature gradients exacerbate lifetime reliability problems. Smaller voltage margins make processors more vulnerable to inductive noise on the voltage rails, as well as soft errors induced by high energy particle incidence. The problem of process variation presents another obstacle to sustained performance growth in the late CMOS design era. At the same time, the emerging phase change memory (a promising technology for future low power, dense storage in systems) is vulnerable to malicious attacks that can reduce the lifetime of an already wear-out prone technology. These issues have all led to R&D in \"better than worst-case\" design principles. Dynamic power and thermal management control loops have already become an integral part of chip and system design. New research in wearout and general reliability management have recently been published. These new generation management protocols have, however, opened up other sources of concern: e.g. potential security holes exposed by the integrated control loops and system safety issues triggered by potential violations of power or thermal limits imposed by the original specification. We coin the term \"Energy-Secure System Architectures\" to cover the range of research being pursued within industry and academia in order to ensure robust and secure functionality, while meeting the energy-related constraints of the emerging \"green computing\" era. This keynote speech attempts to provide a summary overview of the problem and solution spaces around the theme of energy-secure computing -- with a special focus on servers and extreme-scale systems.",
        "acm_key": "2333672",
        "bib_stats": {
            "cites": 13,
            "dl": 336,
            "dl_52": 34,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Jiang:2012:EER:2333660.2333672,\n author = {Jiang, Lei and Zhang, Youtao and Yang, Jun},\n title = {ER: Elastic RESET for Low Power and Long Endurance MLC Based Phase Change Memory},\n booktitle = {Proceedings of the 2012 ACM/IEEE International Symposium on Low Power Electronics and Design},\n series = {ISLPED '12},\n year = {2012},\n isbn = {978-1-4503-1249-3},\n location = {Redondo Beach, California, USA},\n pages = {39--44},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2333660.2333672},\n doi = {10.1145/2333660.2333672},\n acmid = {2333672},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {multi-level cell, phase change memory},\n} \r\n",
        "key": "2333672",
        "pub_year": "2012",
        "text": "Lei Jiang , Youtao Zhang , Jun Yang, ER: elastic RESET for low power and long endurance MLC based phase change memory, Proceedings of the 2012 ACM/IEEE international symposium on Low power electronics and design, July 30-August 01, 2012, Redondo Beach, California, USA"
    },
    "2334281": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2334281",
        "bib_stats": {
            "cites": 5
        },
        "bibtex": "\r\n@article{WeiXu:2011:TFT:2334215.2334281,\n author = {Wei Xu and Tong Zhang},\n title = {A Time-Aware Fault Tolerance Scheme to Improve Reliability of Multilevel Phase-Change Memory in the Presence of Significant Resistance Drift},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {August 2011},\n volume = {19},\n number = {8},\n month = aug,\n year = {2011},\n issn = {1063-8210},\n pages = {1357--1367},\n numpages = {11},\n url = {http://dx.doi.org/10.1109/TVLSI.2010.2052640},\n doi = {10.1109/TVLSI.2010.2052640},\n acmid = {2334281},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2334281",
        "pub_year": "2011",
        "text": "Wei Xu , Tong Zhang, A Time-Aware Fault Tolerance Scheme to Improve Reliability of Multilevel Phase-Change Memory in the Presence of Significant Resistance Drift, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.19 n.8, p.1357-1367, August 2011  \u00a0[doi>"
    },
    "2337203": {
        "abstract": "Single-Instruction Multiple-Thread (SIMT) micro-architectures implemented in Graphics Processing Units (GPUs) run fine-grained threads in lockstep by grouping them into units, referred to as warps, to amortize the cost of instruction fetch, decode and control logic over multiple execution units. As individual threads take divergent execution paths, their processing takes place sequentially, defeating part of the efficiency advantage of SIMD execution. We present two complementary techniques that mitigate the impact of thread divergence on SIMT micro-architectures. Both techniques relax the SIMD execution model by allowing two distinct instructions to be scheduled to disjoint subsets of the the same row of execution units, instead of one single instruction. They increase flexibility by providing more thread grouping opportunities than SIMD, while preserving the affinity between threads to avoid introducing extra memory divergence. We consider (1) co-issuing instructions from different divergent paths of the same warp and (2) co-issuing instructions from different warps. To support (1), we introduce a novel thread reconvergence technique that ensures threads are run back in lockstep at control-flow reconvergence points without hindering their ability to run branches in parallel. We propose a lane shuffling technique to allow solution (2) to benefit from inter-warp correlations in divergence patterns. The combination of all these techniques improves performance by 23% on a set of regular GPGPU applications and by 40% on irregular applications, while maintaining the same instruction-fetch and processing-unit resource requirements as the contemporary Fermi GPU architecture.",
        "acm_key": "2337203",
        "bib_stats": {
            "cites": 46,
            "dl": 441,
            "dl_52": 58,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Qureshi:2012:PIP:2366231.2337203,\n author = {Qureshi, Moinuddin K. and Franceschini, Michele M. and Jagmohan, Ashish and Lastras, Luis A.},\n title = {PreSET: Improving Performance of Phase Change Memories by Exploiting Asymmetry in Write Times},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2012},\n volume = {40},\n number = {3},\n month = jun,\n year = {2012},\n issn = {0163-5964},\n pages = {380--391},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2366231.2337203},\n doi = {10.1145/2366231.2337203},\n acmid = {2337203},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2337203&parent_id=2366231&expformat=bibtex&CFID=982050282&CFTOKEN=80176767\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2337203\">\r\n@inproceedings{Qureshi:2012:PIP:2337159.2337203,\n author = {Qureshi, Moinuddin K. and Franceschini, Michele M. and Jagmohan, Ashish and Lastras, Luis A.},\n title = {PreSET: Improving Performance of Phase Change Memories by Exploiting Asymmetry in Write Times},\n booktitle = {Proceedings of the 39th Annual International Symposium on Computer Architecture},\n series = {ISCA '12},\n year = {2012},\n isbn = {978-1-4503-1642-2},\n location = {Portland, Oregon},\n pages = {380--391},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2337159.2337203},\n acmid = {2337203},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2337203",
        "pub_year": "2012",
        "text": "Moinuddin K. Qureshi , Michele M. Franceschini , Ashish Jagmohan , Luis A. Lastras, PreSET: improving performance of phase change memories by exploiting asymmetry in write times, Proceedings of the 39th Annual International Symposium on Computer Architecture, June 09-13, 2012, Portland, Oregon"
    },
    "2358563": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2358563",
        "bib_stats": {
            "cites": 15
        },
        "bibtex": "\r\n@inproceedings{Li:2012:IOB:2357496.2358563,\n author = {Li, Dong and Vetter, Jeffrey S. and Marin, Gabriel and McCurdy, Collin and Cira, Cristian and Liu, Zhuo and Yu, Weikuan},\n title = {Identifying Opportunities for Byte-Addressable Non-Volatile Memory in Extreme-Scale Scientific Applications},\n booktitle = {Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium},\n series = {IPDPS '12},\n year = {2012},\n isbn = {978-0-7695-4675-9},\n pages = {945--956},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/IPDPS.2012.89},\n doi = {10.1109/IPDPS.2012.89},\n acmid = {2358563},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2358563",
        "pub_year": "2012",
        "text": "Dong Li , Jeffrey S. Vetter , Gabriel Marin , Collin McCurdy , Cristian Cira , Zhuo Liu , Weikuan Yu, Identifying Opportunities for Byte-Addressable Non-Volatile Memory in Extreme-Scale Scientific Applications, Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium, p.945-956, May 21-25, 2012  \u00a0[doi>"
    },
    "2358570": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2358570",
        "bib_stats": {
            "cites": 13
        },
        "bibtex": "\r\n@inproceedings{Wang:2012:NEA:2357496.2358570,\n author = {Wang, Chao and Vazhkudai, Sudharshan S. and Ma, Xiaosong and Meng, Fei and Kim, Youngjae and Engelmann, Christian},\n title = {NVMalloc: Exposing an Aggregate SSD Store As a Memory Partition in Extreme-Scale Machines},\n booktitle = {Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium},\n series = {IPDPS '12},\n year = {2012},\n isbn = {978-0-7695-4675-9},\n pages = {957--968},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/IPDPS.2012.90},\n doi = {10.1109/IPDPS.2012.90},\n acmid = {2358570},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2358570",
        "pub_year": "2012",
        "text": "Chao Wang , Sudharshan S. Vazhkudai , Xiaosong Ma , Fei Meng , Youngjae Kim , Christian Engelmann, NVMalloc: Exposing an Aggregate SSD Store as a Memory Partition in Extreme-Scale Machines, Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium, p.957-968, May 21-25, 2012  \u00a0[doi>"
    },
    "2362810": {
        "abstract": "An electronic vehicle immobilizer is an anti-theft device which prevents the engine of the vehicle from starting unless the corresponding transponder is present. Such a transponder is a passive RFID tag which is embedded in the car key and wirelessly authenticates to the vehicle. It prevents a perpetrator from hot-wiring the vehicle or starting the car by forcing the mechanical lock. Having such an immobilizer is required by law in several countries. Hitag2, introduced in 1996, is currently the most widely used transponder in the car immobilizer industry. It is used by at least 34 car makes and fitted in more than 200 different car models. Hitag2 uses a proprietary stream cipher with 48-bit keys for authentication and confidentiality. This article reveals several weaknesses in the design of the cipher and presents three practical attacks that recover the secret key using only wireless communication. The most serious attack recovers the secret key from a car in less than six minutes using ordinary hardware. This attack allows an adversary to bypass the cryptographic authentication, leaving only the mechanical key as safeguard. This is even more sensitive on vehicles where the physical key has been replaced by a keyless entry system based on Hitag2. During our experiments we managed to recover the secret key and start the engine of many vehicles from various makes using our transponder emulating device. These experiments also revealed several implementation weaknesses in the immobilizer units.",
        "acm_key": "2362810",
        "bib_stats": {
            "cites": 15,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Reardon:2012:DNE:2362793.2362810,\n author = {Reardon, Joel and Capkun, Srdjan and Basin, David},\n title = {Data Node Encrypted File System: Efficient Secure Deletion for Flash Memory},\n booktitle = {Proceedings of the 21st USENIX Conference on Security Symposium},\n series = {Security'12},\n year = {2012},\n location = {Bellevue, WA},\n pages = {17--17},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2362793.2362810},\n acmid = {2362810},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2362810",
        "pub_year": "2012",
        "text": "Joel Reardon , Srdjan Capkun , David Basin, Data node encrypted file system: efficient secure deletion for flash memory, Proceedings of the 21st USENIX conference on Security symposium, p.17-17, August 08-10, 2012, Bellevue, WA"
    },
    "2367603": {
        "abstract": "Time-traveling ability, which enables storage state to be reverted to any previous timepoints, is a highly desirable functionality in modern storage systems to ensure storage continuity. Continuous Data Protection (CDP) is a typical time-traveling implementation mechanism. CDP can guard well against software bugs, unintentional errors, malicious attacks, all of which are often beyond the capabilities of traditional periodical backup schemes. Broadly speaking, CDP can be implemented in two different ways, i.e., either integrate it seamlessly to the target file systems or more generally make it sit at the device block level. However, the state-of-the-art CDP implementations suffer from various limitations, e.g., huge implementation complexity, non-trivial performance interference. In this study, we introduce BVSSD, a new block level versioning system specifically designed for the emerging flash-based SSD. BVSSD realizes CDP functionality through positively and usefully exploiting the inherent idiosyncrasies of flash, which is the well-known \"no-overwritten\" property. Specifically, BVSSD simply keeps track of the SSD FTL metadata changes, which essentially represent the dynamics of the SSD storage state, and restores them to past timepoints to perform recoveries. Compared with existing block-level CDP schemes, BVSSD is much more light-weight, less performance-interfering, easier to realize, and more importantly, it requires no intrusive modifications to the upper file systems and applications. Our trace-driven simulation results with a number of different realistic enterprise-scale workload traces have shown that BVSSD only incurs marginal performance overheads, somewhere between 3% and 8% performance degradation, while with minimum additional RAM requirement, which is an acceptable price for the high reliability that BVSSD can provide. Furthermore, given most of the typcial SSDs deployment scenarios and their ever-increasing capacity trend, BVSSD is realistically poised to be feasible to be deployed in actual situations.",
        "acm_key": "2367603",
        "bib_stats": {
            "cites": 26,
            "dl": 447,
            "dl_52": 102,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Desnoyers:2012:AMS:2367589.2367603,\n author = {Desnoyers, Peter},\n title = {Analytic Modeling of SSD Write Performance},\n booktitle = {Proceedings of the 5th Annual International Systems and Storage Conference},\n series = {SYSTOR '12},\n year = {2012},\n isbn = {978-1-4503-1448-0},\n location = {Haifa, Israel},\n pages = {12:1--12:10},\n articleno = {12},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2367589.2367603},\n doi = {10.1145/2367589.2367603},\n acmid = {2367603},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, solid state drives, solid state storage systems, write amplification},\n} \r\n",
        "key": "2367603",
        "pub_year": "2012",
        "text": "Peter Desnoyers, Analytic modeling of SSD write performance, Proceedings of the 5th Annual International Systems and Storage Conference, June 04-06, 2012, Haifa, Israel"
    },
    "2376111": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2376111",
        "bib_stats": {
            "cites": 17
        },
        "bibtex": "\r\n@inproceedings{Poremba:2012:NAM:2374491.2376111,\n author = {Poremba, Matt and Xie, Yuan},\n title = {NVMain: An Architectural-Level Main Memory Simulator for Emerging Non-volatile Memories},\n booktitle = {Proceedings of the 2012 IEEE Computer Society Annual Symposium on VLSI},\n series = {ISVLSI '12},\n year = {2012},\n isbn = {978-0-7695-4767-1},\n pages = {392--397},\n numpages = {6},\n url = {http://dx.doi.org/10.1109/ISVLSI.2012.82},\n doi = {10.1109/ISVLSI.2012.82},\n acmid = {2376111},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {emerging memory technology, memory architecture},\n} \r\n",
        "key": "2376111",
        "pub_year": "2012",
        "text": "Matt Poremba , Yuan Xie, NVMain: An Architectural-Level Main Memory Simulator for Emerging Non-volatile Memories, Proceedings of the 2012 IEEE Computer Society Annual Symposium on VLSI, p.392-397, August 19-21, 2012  \u00a0[doi>"
    },
    "2376582": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2376582",
        "bib_stats": {
            "cites": 8
        },
        "bibtex": "\r\n@inproceedings{Liu:2012:PDW:2376360.2376582,\n author = {Liu, Zhuo and Wang, Bin and Carpenter, Patrick and Li, Dong and Vetter, Jeffrey S. and Yu, Weikuan},\n title = {PCM-Based Durable Write Cache for Fast Disk I/O},\n booktitle = {Proceedings of the 2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},\n series = {MASCOTS '12},\n year = {2012},\n isbn = {978-0-7695-4793-0},\n pages = {451--458},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/MASCOTS.2012.57},\n doi = {10.1109/MASCOTS.2012.57},\n acmid = {2376582},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Phase change memory (PCM), write cache, wear leveling},\n} \r\n",
        "key": "2376582",
        "pub_year": "2012",
        "text": "Zhuo Liu , Bin Wang , Patrick Carpenter , Dong Li , Jeffrey S. Vetter , Weikuan Yu, PCM-Based Durable Write Cache for Fast Disk I/O, Proceedings of the 2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems, p.451-458, August 07-09, 2012  \u00a0[doi>"
    },
    "2385607": {
        "abstract": "Conventional wisdom holds that storage is not a big contributor to application performance on mobile devices. Flash storage (the type most commonly used today) draws little power, and its performance is thought to exceed that of the network subsystem. In this article, we present evidence that storage performance does indeed affect the performance of several common applications such as Web browsing, maps, application install, email, and Facebook. For several Android smartphones, we find that just by varying the underlying flash storage, performance over WiFi can typically vary between 100&percnt; and 300&percnt; across applications; in one extreme scenario, the variation jumped to over 2000&percnt;. With a faster network (set up over USB), the performance variation rose even further. We identify the reasons for the strong correlation between storage and application performance to be a combination of poor flash device performance, random I/O from application databases, and heavy-handed use of synchronous writes. Based on our findings, we implement and evaluate a set of pilot solutions to address the storage performance deficiencies in smartphones.",
        "acm_key": "2385607",
        "bib_stats": {
            "cites": 26,
            "dl": 1,
            "dl_52": 152,
            "dl_6": 15
        },
        "bibtex": "\r\n@article{Kim:2012:RSS:2385603.2385607,\n author = {Kim, Hyojun and Agrawal, Nitin and Ungureanu, Cristian},\n title = {Revisiting Storage for Smartphones},\n journal = {Trans. Storage},\n issue_date = {November 2012},\n volume = {8},\n number = {4},\n month = dec,\n year = {2012},\n issn = {1553-3077},\n pages = {14:1--14:25},\n articleno = {14},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2385603.2385607},\n doi = {10.1145/2385603.2385607},\n acmid = {2385607},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Android, Storage systems, mobile, mobile storage, smartphones},\n} \r\n",
        "key": "2385607",
        "pub_year": "2012",
        "text": "Hyojun Kim , Nitin Agrawal , Cristian Ungureanu, Revisiting storage for smartphones, ACM Transactions on Storage (TOS), v.8 n.4, p.1-25, November 2012  \u00a0[doi>"
    },
    "2401689": {
        "abstract": "In this paper, we are concerned with optimization of Context FCM-based RBF neural network realized with the aid of information granulation using clustering techniques that is based on K-Means clustering and Context-based FCM clustering. The objective of this paper is to investigate and compare alternative design models, present an organization of the overall optimization process, and come up with a specification of evaluation mechanisms of the performance of the model. The underlying design tool guiding the development of Context FCM-based RBF neural networks revolves around a certain reconstructability criterion. The design process comprised several main focuses such as: 1) The output space is granulated making use of the K-Means clustering while the input space is clustered with the aid of a context-based fuzzy clustering. 2) The number of information granules produced for each context is adjusted so that we satisfy a certain reconstructability criterion that helps us minimize an error between the original data and the ones resulting from their reconstruction involving prototypes of the clusters and the corresponding membership values. 3) The output neuron of the network exhibits a certain functional nature as its connections are realized as local linear function whose location is determined by the values of the context and the experiments that lead to some design guidelines of the models. Numeric examples involve low dimensional synthetic data and nonlinear process datasets.",
        "acm_key": "2401689",
        "bib_stats": {
            "cites": 7,
            "dl": 271,
            "dl_52": 42,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Shin:2012:APG:2401603.2401689,\n author = {Shin, Dong-Jae and Park, Sung Kyu and Kim, Seong Min and Park, Kyu Ho},\n title = {Adaptive Page Grouping for Energy Efficiency in Hybrid PRAM-DRAM Main Memory},\n booktitle = {Proceedings of the 2012 ACM Research in Applied Computation Symposium},\n series = {RACS '12},\n year = {2012},\n isbn = {978-1-4503-1492-3},\n location = {San Antonio, Texas},\n pages = {395--402},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2401603.2401689},\n doi = {10.1145/2401603.2401689},\n acmid = {2401689},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {PCM, PRAM, main memory, power management},\n} \r\n",
        "key": "2401689",
        "pub_year": "2012",
        "text": "Dong-Jae Shin , Sung Kyu Park , Seong Min Kim , Kyu Ho Park, Adaptive page grouping for energy efficiency in hybrid PRAM-DRAM main memory, Proceedings of the 2012 ACM Research in Applied Computation Symposium, October 23-26, 2012, San Antonio, Texas"
    },
    "2417550": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2417550",
        "bib_stats": {
            "cites": 23
        },
        "bibtex": "\r\n@inproceedings{Yoon:2012:RBL:2417497.2417550,\n author = {Yoon, HanBin},\n title = {Row Buffer Locality Aware Caching Policies for Hybrid Memories},\n booktitle = {Proceedings of the 2012 IEEE 30th International Conference on Computer Design (ICCD 2012)},\n series = {ICCD '12},\n year = {2012},\n isbn = {978-1-4673-3051-0},\n pages = {337--344},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/ICCD.2012.6378661},\n doi = {10.1109/ICCD.2012.6378661},\n acmid = {2417550},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Random access memory,Phase change materials,Arrays,Memory management,Microprocessors,Heuristic algorithms},\n} \r\n",
        "key": "2417550",
        "pub_year": "2012",
        "text": "HanBin Yoon, Row buffer locality aware caching policies for hybrid memories, Proceedings of the 2012 IEEE 30th International Conference on Computer Design (ICCD 2012), p.337-344, September 30-October 03, 2012  \u00a0[doi>"
    },
    "2417574": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2417574",
        "bib_stats": {
            "cites": 4
        },
        "key": "2417574",
        "text": "Jing Li, A case for small row buffers in non-volatile main memories, Proceedings of the 2012 IEEE 30th International Conference on Computer Design (ICCD 2012), p.484-485, September 30-October 03, 2012  \u00a0[doi>"
    },
    "2417614": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2417614",
        "bib_stats": {
            "cites": 15
        },
        "bibtex": "\r\n@inproceedings{Cristal:2012:FCR:2417497.2417614,\n author = {Cristal, Adrian},\n title = {Flash Correct-and-refresh: Retention-aware Error Management for Increased Flash Memory Lifetime},\n booktitle = {Proceedings of the 2012 IEEE 30th International Conference on Computer Design (ICCD 2012)},\n series = {ICCD '12},\n year = {2012},\n isbn = {978-1-4673-3051-0},\n pages = {94--101},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/ICCD.2012.6378623},\n doi = {10.1109/ICCD.2012.6378623},\n acmid = {2417614},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Error correction codes,Flash memory,Bit error rate,Threshold voltage,Nonvolatile memory,Programming,multi-level cell (MLC),NAND Flash,reliability,error correction},\n} \r\n",
        "key": "2417614",
        "pub_year": "2012",
        "text": "Adrian Cristal, Flash correct-and-refresh: Retention-aware error management for increased flash memory lifetime, Proceedings of the 2012 IEEE 30th International Conference on Computer Design (ICCD 2012), p.94-101, September 30-October 03, 2012  \u00a0[doi>"
    },
    "2420697": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2420697",
        "bib_stats": {
            "cites": 23
        },
        "bibtex": "\r\n@article{Meza:2012:EES:2420620.2420697,\n author = {Meza, Justin and Chang, Jichuan and Yoon, HanBin and Mutlu, Onur and Ranganathan, Parthasarathy},\n title = {Enabling Efficient and Scalable Hybrid Memories Using Fine-Granularity DRAM Cache Management},\n journal = {IEEE Comput. Archit. Lett.},\n issue_date = {July 2012},\n volume = {11},\n number = {2},\n month = jul,\n year = {2012},\n issn = {1556-6056},\n pages = {61--64},\n numpages = {4},\n url = {http://dx.doi.org/10.1109/L-CA.2012.2},\n doi = {10.1109/L-CA.2012.2},\n acmid = {2420697},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Random access memory,Phase change materials,System-on-a-chip,Buffer storage,Bandwidth,Memory management,Cache memory,non-volatile memories,Random access memory,Phase change materials,System-on-a-chip,Buffer storage,Bandwidth,Memory management,Indexes,hybrid main memories,Cache memories,tag storage},\n} \r\n",
        "key": "2420697",
        "pub_year": "2012",
        "text": "Justin Meza , Jichuan Chang , HanBin Yoon , Onur Mutlu , Parthasarathy Ranganathan, Enabling Efficient and Scalable Hybrid Memories Using Fine-Granularity DRAM Cache Management, IEEE Computer Architecture Letters, v.11 n.2, p.61-64, July 2012  \u00a0[doi>"
    },
    "2458046": {
        "abstract": "The Joint Collaborative Team on Video Decoding is developing a new standard named High Efficiency Video Coding (HEVC) that aims at reducing the bitrate of H.264/AVC by another 50 %. In order to fulfill the computational demands of the new standard, in particular for high resolutions and at low power budgets, exploiting parallelism is no longer an option but a requirement. Therefore, HEVC includes several coding tools that allows to divide each picture into several partitions that can be processed in parallel, without degrading the quality nor the bitrate. In this paper we adapt one of these approaches, the Wavefront Parallel Processing (WPP) coding, and show how it can be implemented on multi- and many-core processors. Our approach, named Overlapped Wavefront (OWF), processes several partitions as well as several pictures in parallel. This has the advantage that the amount of (thread-level) parallelism stays constant during execution. In addition, performance and power results are provided for three platforms: a server Intel CPU with 8 cores, a laptop Intel CPU with 4 cores, and a TILE-Gx36 with 36 cores from Tilera. The results show that our parallel HEVC decoder is capable of achieving an average frame rate of 116 fps for 4k resolution on a standard multicore CPU. The results also demonstrate that exploiting more parallelism by increasing the number of cores can improve the energy efficiency measured in terms of Joules per frame substantially.",
        "acm_key": "2458046",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Du:2013:ELS:2458016.2458046,\n author = {Du, Jiayi and Wang, Yan and Zhuge, Qingfeng and Hu, Jingtong and Sha, Edwin H.},\n title = {Efficient Loop Scheduling for Chip Multiprocessors with Non-Volatile Main Memory},\n journal = {J. Signal Process. Syst.},\n issue_date = {June      2013},\n volume = {71},\n number = {3},\n month = jun,\n year = {2013},\n issn = {1939-8018},\n pages = {261--273},\n numpages = {13},\n url = {http://dx.doi.org/10.1007/s11265-012-0703-5},\n doi = {10.1007/s11265-012-0703-5},\n acmid = {2458046},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Chip multiprocessor, Loop scheduling algorithm, Non-volatile memory},\n} \r\n",
        "key": "2458046",
        "pub_year": "2013",
        "text": "Jiayi Du , Yan Wang , Qingfeng Zhuge , Jingtong Hu , Edwin H. Sha, Efficient Loop Scheduling for Chip Multiprocessors with Non-Volatile Main Memory, Journal of Signal Processing Systems, v.71 n.3, p.261-273, June      2013"
    },
    "2462171": {
        "abstract": "Among techniques for parallelizing sequential codes, privatization is a common and significant transformation performed by both compilers and runtime parallelizing systems. Without privatization, repetitive updates to the same data structures often introduce spurious data dependencies that hide the inherent parallelism. Unfortunately, it remains a significant challenge to compilers to automatically privatize dynamic and recursive data structures which appear frequently in real applications written in languages such as C/C++. This is because such languages lack a naming mechanism to define the address range of a pointer-based data structure, in contrast to arrays with explicitly declared bounds. In this paper we present a novel solution to this difficult problem by expanding general data structures such that memory accesses issued from different threads to contentious data structures are directed to different data fields. Based on compile-time type checking and a data dependence graph, this aggressive extension to the traditional scalar and array expansion isolates the address ranges among different threads, without struggling with privatization based on thread-private stacks, such that the targeted loop can be effectively parallelized. With this method fully implemented in GCC, experiments are conducted on a set of programs from well-known benchmark suites such as Mibench, MediaBench II and SPECint. Results show that the new approach can lead to a high speedup when executing the transformed code on multiple cores.",
        "acm_key": "2462171",
        "bib_stats": {
            "cites": 1,
            "dl": 202,
            "dl_52": 17,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Gao:2013:UMR:2499370.2462171,\n author = {Gao, Tiejun and Strauss, Karin and Blackburn, Stephen M. and McKinley, Kathryn S. and Burger, Doug and Larus, James},\n title = {Using Managed Runtime Systems to Tolerate Holes in Wearable Memories},\n journal = {SIGPLAN Not.},\n issue_date = {June 2013},\n volume = {48},\n number = {6},\n month = jun,\n year = {2013},\n issn = {0362-1340},\n pages = {297--308},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2499370.2462171},\n doi = {10.1145/2499370.2462171},\n acmid = {2462171},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {failure tolerance, memory management, phase-change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2462171&parent_id=2499370&expformat=bibtex&CFID=982028483&CFTOKEN=74492710\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2462171\">\r\n@inproceedings{Gao:2013:UMR:2491956.2462171,\n author = {Gao, Tiejun and Strauss, Karin and Blackburn, Stephen M. and McKinley, Kathryn S. and Burger, Doug and Larus, James},\n title = {Using Managed Runtime Systems to Tolerate Holes in Wearable Memories},\n booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},\n series = {PLDI '13},\n year = {2013},\n isbn = {978-1-4503-2014-6},\n location = {Seattle, Washington, USA},\n pages = {297--308},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2491956.2462171},\n doi = {10.1145/2491956.2462171},\n acmid = {2462171},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {failure tolerance, memory management, phase-change memory},\n} \r\n",
        "key": "2462171",
        "pub_year": "2013",
        "text": "Tiejun Gao , Karin Strauss , Stephen M. Blackburn , Kathryn S. McKinley , Doug Burger , James Larus, Using managed runtime systems to tolerate holes in wearable memories, ACM SIGPLAN Notices, v.48 n.6, June 2013"
    },
    "2463587": {
        "abstract": "The memory capacity, computational power, communication bandwidth, energy consumption, and physical size of the brain all tend to scale with the number of synapses, which outnumber neurons by a factor of 10,000. Although progress in cortical simulations using modern digital computers has been rapid, the essential disparity between the classical von Neumann computer architecture and the computational fabric of the nervous system makes large-scale simulations expensive, power hungry, and time consuming. Over the last three decades, CMOS-based neuromorphic implementations of \u201celectronic cortex\u201d have emerged as an energy efficient alternative for modeling neuronal behavior. However, the key ingredient for electronic implementation of any self-learning system\u2014programmable, plastic Hebbian synapses scalable to biological densities\u2014has remained elusive. We demonstrate the viability of implementing such electronic synapses using nanoscale phase change devices. We introduce novel programming schemes for modulation of device conductance to closely mimic the phenomenon of Spike Timing Dependent Plasticity (STDP) observed biologically, and verify through simulations that such plastic phase change devices should support simple correlative learning in networks of spiking neurons. Our devices, when arranged in a crossbar array architecture, could enable the development of synaptronic systems that approach the density (\u223c10",
        "acm_key": "2463587",
        "bib_stats": {
            "cites": 6,
            "dl": 764,
            "dl_52": 66,
            "dl_6": 5
        },
        "key": "2463587",
        "text": "J. Joshua Yang , R. Stanley Williams, Memristive devices in computing system: Promises and challenges, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.9 n.2, p.1-20, May 2013  \u00a0[doi>"
    },
    "2463589": {
        "abstract": "The memory capacity, computational power, communication bandwidth, energy consumption, and physical size of the brain all tend to scale with the number of synapses, which outnumber neurons by a factor of 10,000. Although progress in cortical simulations using modern digital computers has been rapid, the essential disparity between the classical von Neumann computer architecture and the computational fabric of the nervous system makes large-scale simulations expensive, power hungry, and time consuming. Over the last three decades, CMOS-based neuromorphic implementations of \u201celectronic cortex\u201d have emerged as an energy efficient alternative for modeling neuronal behavior. However, the key ingredient for electronic implementation of any self-learning system\u2014programmable, plastic Hebbian synapses scalable to biological densities\u2014has remained elusive. We demonstrate the viability of implementing such electronic synapses using nanoscale phase change devices. We introduce novel programming schemes for modulation of device conductance to closely mimic the phenomenon of Spike Timing Dependent Plasticity (STDP) observed biologically, and verify through simulations that such plastic phase change devices should support simple correlative learning in networks of spiking neurons. Our devices, when arranged in a crossbar array architecture, could enable the development of synaptronic systems that approach the density (\u223c10",
        "acm_key": "2463589",
        "bib_stats": {
            "cites": 17,
            "dl": 2,
            "dl_52": 494,
            "dl_6": 47
        },
        "bibtex": "\r\n@article{Apalkov:2013:STM:2463585.2463589,\n author = {Apalkov, Dmytro and Khvalkovskiy, Alexey and Watts, Steven and Nikitin, Vladimir and Tang, Xueti and Lottis, Daniel and Moon, Kiseok and Luo, Xiao and Chen, Eugene and Ong, Adrian and Driskill-Smith, Alexander and Krounbi, Mohamad},\n title = {Spin-transfer Torque Magnetic Random Access Memory (STT-MRAM)},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {May 2013},\n volume = {9},\n number = {2},\n month = may,\n year = {2013},\n issn = {1550-4832},\n pages = {13:1--13:35},\n articleno = {13},\n numpages = {35},\n url = {http://doi.acm.org/10.1145/2463585.2463589},\n doi = {10.1145/2463585.2463589},\n acmid = {2463589},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MRAM, magnetic memory, magnetic tunneling junction, spin polarization, spin transfer torque, tunneling magnetoresistance},\n} \r\n",
        "key": "2463589",
        "pub_year": "2013",
        "text": "Dmytro Apalkov , Alexey Khvalkovskiy , Steven Watts , Vladimir Nikitin , Xueti Tang , Daniel Lottis , Kiseok Moon , Xiao Luo , Eugene Chen , Adrian Ong , Alexander Driskill-Smith , Mohamad Krounbi, Spin-transfer torque magnetic random access memory (STT-MRAM), ACM Journal on Emerging Technologies in Computing Systems (JETC), v.9 n.2, p.1-35, May 2013  \u00a0[doi>"
    },
    "2463636": {
        "abstract": "\r\n                          How close to optimal can you even get with the existing filesystem APIs at the application level? That seems like an even more fundamental limitation that you can't address by getting rid of the FTL. An application using typical user-level filesystem APIs currently has no good way to tell the system that it expects to be doing a lot of random-access writes or even, to use one example from the article here, that the write it's doing is actually just an unmodified copy of a portion of another file.",
        "acm_key": "2463636",
        "bib_stats": {
            "cites": 0,
            "dl": 97,
            "dl_52": 2,
            "dl_6": 202
        },
        "bibtex": "\r\n@article{Leventhal:2013:FSO:2460276.2463636,\n author = {Leventhal, Adam H.},\n title = {A File System All Its Own},\n journal = {Queue},\n issue_date = {March 2013},\n volume = {11},\n number = {3},\n month = mar,\n year = {2013},\n issn = {1542-7730},\n pages = {30:30--30:35},\n articleno = {30},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2460276.2463636},\n doi = {10.1145/2460276.2463636},\n acmid = {2463636},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2463636",
        "pub_year": "2013",
        "text": "Adam H. Leventhal, A File System All Its Own, Queue, v.11 n.3, March 2013"
    },
    "2465326": {
        "abstract": "Recently, parallel search engines have been implemented based on scalable distributed file systems such as Google File System. However, we claim that building a massively-parallel search engine using a parallel DBMS can be an attractive alternative since it supports a higher-level (i.e., SQL-level) interface than that of a distributed file system for easy and less error-prone application development while providing scalability. Regarding higher-level functionality, we can draw a parallel with the traditional O/S file system vs. DBMS. In this paper, we propose a new approach of building a massively-parallel search engine using a DB-IR tightly-integrated parallel DBMS. To estimate the performance, we propose a hybrid (i.e., analytic and experimental) performance model for the parallel search engine. We argue that the model can accurately estimate the performance of a massively-parallel (e.g., 300-node) search engine using the experimental results obtained from a small-scale (e.g., 5-node) one. We show that the estimation error between the model and the actual experiment is less than 2.13% by observing that the bulk of the query processing time is spent at the slave (vs. at the master and network) and by estimating the time spent at the slave based on actual measurement. Using our model, we demonstrate a commercial-level scalability and performance of our architecture. Our proposed system ODYS is capable of handling 1 billion queries per day (81 queries/sec) for 30 billion Web pages by using only 43,472 nodes with an average query response time of 194 ms. By using twice as many (86,944) nodes, ODYS can provide an average query response time of 148 ms. These results show that building a massively-parallel search engine using a parallel DBMS is a viable approach with advantages of supporting the high-level (i.e., DBMS-level), SQL-like programming interface.",
        "acm_key": "2465326",
        "bib_stats": {
            "cites": 14,
            "dl": 988,
            "dl_52": 90,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Kang:2013:XTF:2463676.2465326,\n author = {Kang, Woon-Hak and Lee, Sang-Won and Moon, Bongki and Oh, Gi-Hwan and Min, Changwoo},\n title = {X-FTL: Transactional FTL for SQLite Databases},\n booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '13},\n year = {2013},\n isbn = {978-1-4503-2037-5},\n location = {New York, New York, USA},\n pages = {97--108},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2463676.2465326},\n doi = {10.1145/2463676.2465326},\n acmid = {2465326},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {copy-on-write, flash storage devices, flash translation layer, sqlite, transactional atomicity},\n} \r\n",
        "key": "2465326",
        "pub_year": "2013",
        "text": "Woon-Hak Kang , Sang-Won Lee , Bongki Moon , Gi-Hwan Oh , Changwoo Min, X-FTL: transactional FTL for SQLite databases, Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, June 22-27, 2013, New York, New York, USA  \u00a0[doi>"
    },
    "2465543": {
        "abstract": "There is growing interest to replace traditional servers with low-power multicore systems such as ARM Cortex-A9. However, such systems are typically provisioned for mobile applications that have lower memory and I/O requirements than server application. Thus, the impact and extent of the imbalance between application and system resources in exploiting energy efficient execution of server workloads is unclear. This paper proposes a trace-driven analytical model for understanding the energy performance of server workloads on ARM Cortex-A9 multicore systems. Key to our approach is the modeling of the degrees of CPU core, memory and I/O resource overlap, and in estimating the number of cores and clock frequency that optimizes energy performance without compromising execution time. Since energy usage is the product of utilized power and execution time, the model first estimates the execution time of a program. CPU time, which accounts for both cores and memory response time, is modeled as an M/G/1 queuing system. Workload characterization of high performance computing, web hosting and financial computing applications shows that bursty memory traffic fits a Pareto distribution, and non-bursty memory traffic is exponentially distributed. Our analysis using these server workloads reveals that not all server workloads might benefit from higher number of cores or clock frequencies. Applying our model, we predict the configurations that increase energy efficiency by 10% without turning off cores, and up to one third with shutting down unutilized cores. For memory-bounded programs, we show that the limited memory bandwidth might increase both execution time and energy usage, to the point where energy cost might be higher than on a typical x64 multicore system. Lastly, we show that increasing memory and I/O bandwidth can improve both the execution time and the energy usage of server workloads on ARM Cortex-A9 systems.",
        "acm_key": "2465543",
        "bib_stats": {
            "cites": 20,
            "dl": 248,
            "dl_52": 36,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{VanHoudt:2013:MFM:2465529.2465543,\n author = {Van Houdt, Benny},\n title = {A Mean Field Model for a Class of Garbage Collection Algorithms in Flash-based Solid State Drives},\n booktitle = {Proceedings of the ACM SIGMETRICS/International Conference on Measurement and Modeling of Computer Systems},\n series = {SIGMETRICS '13},\n year = {2013},\n isbn = {978-1-4503-1900-3},\n location = {Pittsburgh, PA, USA},\n pages = {191--202},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2465529.2465543},\n doi = {10.1145/2465529.2465543},\n acmid = {2465543},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-based solid state drives, garbage collection, mean field, write amplification},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2465543&parent_id=2465529&expformat=bibtex&CFID=982039290&CFTOKEN=22043349\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2465543\">\r\n@article{VanHoudt:2013:MFM:2494232.2465543,\n author = {Van Houdt, Benny},\n title = {A Mean Field Model for a Class of Garbage Collection Algorithms in Flash-based Solid State Drives},\n journal = {SIGMETRICS Perform. Eval. Rev.},\n issue_date = {June 2013},\n volume = {41},\n number = {1},\n month = jun,\n year = {2013},\n issn = {0163-5999},\n pages = {191--202},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2494232.2465543},\n doi = {10.1145/2494232.2465543},\n acmid = {2465543},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-based solid state drives, garbage collection, mean field, write amplification},\n} \r\n",
        "key": "2465543",
        "pub_year": "2013",
        "text": "Benny Van Houdt, A mean field model for a class of garbage collection algorithms in flash-based solid state drives, Proceedings of the ACM SIGMETRICS/international conference on Measurement and modeling of computer systems, June 17-21, 2013, Pittsburgh, PA, USA  \u00a0[doi>"
    },
    "2480639": {
        "abstract": "It is well-known that the web contains many duplicate and near-duplicate documents. Despite the efforts that have been put towards equipping search engines with duplicate detection algorithms, still there are cases where the documents retrieved in response to web queries contain redundant information. In this paper, we are concerned with effectively identifying and reducing redundant information in search results. In particular, we describe how we automatically detect content that is lexically and/or semantically duplicated across search results and we introduce a novel algorithm that upon the detection of significant (i.e., above a given threshold) content duplication, it filters out redundant information. Information filtering takes place in two-steps depending on whether we are dealing with documents of (nearly) identical lexical content or with documents of lexically distinct but semantically equivalent content. In the first case, our algorithm retains in the result list the document that is the most relevant to the query intention and removes duplicates. In the second case, our algorithm merges into a single text, which we call SuperText, the documents of redundant information in a way that every document contributes diverse semantic content to the generated SuperText. Additionally, the algorithm re-ranks the remaining documents based on their contextual relevance to the query intention. The experimental evaluation of our approach demonstrates that it is very effective in identifying lexical and semantic information redundancy across search results. In addition, we have found that our algorithm manages to filter out successfully content duplication from the results list and the SuperTexts it generates for reducing information redundancy are syntactically and semantically coherent texts.",
        "acm_key": "2480639",
        "bib_stats": {
            "cites": 3,
            "dl": 229,
            "dl_52": 33,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Jung:2013:LPA:2480362.2480639,\n author = {Jung, Sanghyuk and Song, Yong Ho},\n title = {LINK-GC: A Preemptive Approach for Garbage Collection in NAND Flash Storages},\n booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},\n series = {SAC '13},\n year = {2013},\n isbn = {978-1-4503-1656-9},\n location = {Coimbra, Portugal},\n pages = {1478--1484},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2480362.2480639},\n doi = {10.1145/2480362.2480639},\n acmid = {2480639},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash storage management, garbage collection, solid state drives},\n} \r\n",
        "key": "2480639",
        "pub_year": "2013",
        "text": "Sanghyuk Jung , Yong Ho Song, LINK-GC: a preemptive approach for garbage collection in NAND flash storages, Proceedings of the 28th Annual ACM Symposium on Applied Computing, March 18-22, 2013, Coimbra, Portugal"
    },
    "2480648": {
        "abstract": "It is well-known that the web contains many duplicate and near-duplicate documents. Despite the efforts that have been put towards equipping search engines with duplicate detection algorithms, still there are cases where the documents retrieved in response to web queries contain redundant information. In this paper, we are concerned with effectively identifying and reducing redundant information in search results. In particular, we describe how we automatically detect content that is lexically and/or semantically duplicated across search results and we introduce a novel algorithm that upon the detection of significant (i.e., above a given threshold) content duplication, it filters out redundant information. Information filtering takes place in two-steps depending on whether we are dealing with documents of (nearly) identical lexical content or with documents of lexically distinct but semantically equivalent content. In the first case, our algorithm retains in the result list the document that is the most relevant to the query intention and removes duplicates. In the second case, our algorithm merges into a single text, which we call SuperText, the documents of redundant information in a way that every document contributes diverse semantic content to the generated SuperText. Additionally, the algorithm re-ranks the remaining documents based on their contextual relevance to the query intention. The experimental evaluation of our approach demonstrates that it is very effective in identifying lexical and semantic information redundancy across search results. In addition, we have found that our algorithm manages to filter out successfully content duplication from the results list and the SuperTexts it generates for reducing information redundancy are syntactically and semantically coherent texts.",
        "acm_key": "2480648",
        "bib_stats": {
            "cites": 0,
            "dl": 170,
            "dl_52": 29,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Fang:2013:MLR:2480362.2480648,\n author = {Fang, Hua-Wei and Yeh, Mi-Yen and Kuo, Tei-Wei},\n title = {MLC-flash-friendly Logging and Recovery for Databases},\n booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},\n series = {SAC '13},\n year = {2013},\n isbn = {978-1-4503-1656-9},\n location = {Coimbra, Portugal},\n pages = {1541--1546},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2480362.2480648},\n doi = {10.1145/2480362.2480648},\n acmid = {2480648},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-memory storage systems, logging, performance, transaction recovery},\n} \r\n",
        "key": "2480648",
        "pub_year": "2013",
        "text": "Hua-Wei Fang , Mi-Yen Yeh , Tei-Wei Kuo, MLC-flash-friendly logging and recovery for databases, Proceedings of the 28th Annual ACM Symposium on Applied Computing, March 18-22, 2013, Coimbra, Portugal"
    },
    "2482793": {
        "abstract": "The general-purpose computing on graphics processing units (GPGPUs) are increasingly used to accelerate parallel applications. This makes reliability a growing concern in GPUs as they are originally designed for graphics processing with relaxed requirements for execution correctness. With CMOS processing technologies continuously scaling down to the nano-scale, on-chip soft error rate (SER) has been predicted to increase exponentially. GPGPUs with hundreds of cores integrated into a single chip are prone to manifest high SER. This paper aims to enhance the GPGPU reliability in light of soft errors. We leverage the GPGPU microarchitecture characteristics, and propose energy-efficient protection mechanisms for two typical SRAM-based structures (i.e. instruction buffer and registers) which suffer high susceptibility. We develop Similarity-AWare Protection (SAWP) scheme that leverages the instruction similarity to provide the near-full ECC protection to the instruction buffer with quite little area and power overhead. Based on the observation that shared memory usually exhibits low utilization, we propose SHAred memory to Register Protection (SHARP) scheme, it intelligently leverages shared memory to hold the ECCs of registers. Experimental results show that our techniques have the strong capability of substantially improving the structure vulnerability, and significantly reducing the power consumption compared to the full ECC protection mechanism.",
        "acm_key": "2482793",
        "bib_stats": {
            "cites": 4,
            "dl": 578,
            "dl_52": 33,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Jeon:2013:IHS:2482767.2482793,\n author = {Jeon, Hyeran and El Maghraoui, Kaoutar and Kandiraju, Gokul B.},\n title = {Investigating Hybrid SSD FTL Schemes for Hadoop Workloads},\n booktitle = {Proceedings of the ACM International Conference on Computing Frontiers},\n series = {CF '13},\n year = {2013},\n isbn = {978-1-4503-2053-5},\n location = {Ischia, Italy},\n pages = {20:1--20:10},\n articleno = {20},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2482767.2482793},\n doi = {10.1145/2482767.2482793},\n acmid = {2482793},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2482793",
        "pub_year": "2013",
        "text": "Hyeran Jeon , Kaoutar El Maghraoui , Gokul B. Kandiraju, Investigating hybrid SSD FTL schemes for Hadoop workloads, Proceedings of the ACM International Conference on Computing Frontiers, May 14-16, 2013, Ischia, Italy"
    },
    "2485497": {
        "abstract": "Parallel programming requires the definition of shared-memory semantics by means of a consistency model, which affects how the parallel hardware is designed. Therefore, verifying the hardware compliance with a consistency model is a relevant problem, whose complexity depends on the observability of memory events. Post-silicon checkers analyze a single sequence of events per core and so do most pre-silicon checkers, although one reported method samples two sequences per core. Besides, most are post-mortem checkers requiring the whole sequence of events to be available prior to verification. On the contrary, this paper describes a novel on-the-fly technique for verifying memory consistency from an executable representation of a multicore system. To increase efficiency without hampering verification guarantees, three points are monitored per core. The sampling points are selected to be largely independent from the core's microarchitecture. The technique relies on concurrent relaxed scoreboards to check for consistency violations in each core. To check for global violations, it employs a linear order of events induced by a given test case. We prove that the technique neither indicates false negatives nor false positives when the test case exposes an error that affects the sampled sequences, making it the first on-the-fly checker with full guarantees. We compare our technique with two post-mortem checkers under 2400 scenarios for platforms with 2 to 8 cores. The results show that our technique is at least 100 times faster than a checker sampling a single sequence per processor and it needs approximately 1/4 to 3/4 of the overall verification effort required by a post-mortem checker sampling two sequences per processor.",
        "acm_key": "2485497",
        "bib_stats": {
            "cites": 2,
            "dl": 66,
            "dl_52": 6,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhou:2013:DSW:2485288.2485497,\n author = {Zhou, Ping and Zhang, Youtao and Yang, Jun},\n title = {The Design of Sustainable Wireless Sensor Network Node Using Solar Energy and Phase Change Memory},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '13},\n year = {2013},\n isbn = {978-1-4503-2153-2},\n location = {Grenoble, France},\n pages = {869--872},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2485288.2485497},\n acmid = {2485497},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2485497",
        "pub_year": "2013",
        "text": "Ping Zhou , Youtao Zhang , Jun Yang, The design of sustainable wireless sensor network node using solar energy and phase change memory, Proceedings of the Conference on Design, Automation and Test in Europe, March 18-22, 2013, Grenoble, France"
    },
    "2488935": {
        "abstract": "Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements, but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application, and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition, data mining, and search. Based on this analysis, we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis, we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing, while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.",
        "acm_key": "2488935",
        "bib_stats": {
            "cites": 2,
            "dl": 97,
            "dl_52": 13,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Tseng:2013:UNF:2463209.2488935,\n author = {Tseng, Hung-Wei and Grupp, Laura M. and Swanson, Steven},\n title = {Underpowering NAND Flash: Profits and Perils},\n booktitle = {Proceedings of the 50th Annual Design Automation Conference},\n series = {DAC '13},\n year = {2013},\n isbn = {978-1-4503-2071-9},\n location = {Austin, Texas},\n pages = {162:1--162:6},\n articleno = {162},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2463209.2488935},\n doi = {10.1145/2463209.2488935},\n acmid = {2488935},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2488935",
        "pub_year": "2013",
        "text": "Hung-Wei Tseng , Laura M. Grupp , Steven Swanson, Underpowering NAND flash: profits and perils, Proceedings of the 50th Annual Design Automation Conference, May 29-June 07, 2013, Austin, Texas  \u00a0[doi>"
    },
    "2488936": {
        "abstract": "Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements, but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application, and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition, data mining, and search. Based on this analysis, we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis, we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing, while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.",
        "acm_key": "2488936",
        "bib_stats": {
            "cites": 3,
            "dl": 254,
            "dl_52": 38,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Yang:2013:NEN:2463209.2488936,\n author = {Yang, Ming-Chang and Chang, Yuan-Hao and Tsao, Che-Wei and Huang, Po-Chun},\n title = {New ERA: New Efficient Reliability-aware Wear Leveling for Endurance Enhancement of Flash Storage Devices},\n booktitle = {Proceedings of the 50th Annual Design Automation Conference},\n series = {DAC '13},\n year = {2013},\n isbn = {978-1-4503-2071-9},\n location = {Austin, Texas},\n pages = {163:1--163:6},\n articleno = {163},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2463209.2488936},\n doi = {10.1145/2463209.2488936},\n acmid = {2488936},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, flash memory, reliability, wear leveling},\n} \r\n",
        "key": "2488936",
        "pub_year": "2013",
        "text": "Ming-Chang Yang , Yuan-Hao Chang , Che-Wei Tsao , Po-Chun Huang, New ERA: new efficient reliability-aware wear leveling for endurance enhancement of flash storage devices, Proceedings of the 50th Annual Design Automation Conference, May 29-June 07, 2013, Austin, Texas"
    },
    "2488937": {
        "abstract": "Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements, but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application, and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition, data mining, and search. Based on this analysis, we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis, we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing, while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.",
        "acm_key": "2488937",
        "bib_stats": {
            "cites": 2,
            "dl": 180,
            "dl_52": 24,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Wang:2013:SSW:2463209.2488937,\n author = {Wang, Chundong and Wong, Weng-Fai},\n title = {SAW: System-assisted Wear Leveling on the Write Endurance of NAND Flash Devices},\n booktitle = {Proceedings of the 50th Annual Design Automation Conference},\n series = {DAC '13},\n year = {2013},\n isbn = {978-1-4503-2071-9},\n location = {Austin, Texas},\n pages = {164:1--164:9},\n articleno = {164},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/2463209.2488937},\n doi = {10.1145/2463209.2488937},\n acmid = {2488937},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2488937",
        "pub_year": "2013",
        "text": "Chundong Wang , Weng-Fai Wong, SAW: system-assisted wear leveling on the write endurance of NAND flash devices, Proceedings of the 50th Annual Design Automation Conference, May 29-June 07, 2013, Austin, Texas"
    },
    "2488938": {
        "abstract": "Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements, but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application, and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition, data mining, and search. Based on this analysis, we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis, we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing, while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.",
        "acm_key": "2488938",
        "bib_stats": {
            "cites": 5,
            "dl": 272,
            "dl_52": 44,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Tsao:2013:PEG:2463209.2488938,\n author = {Tsao, Che-Wei and Chang, Yuan-Hao and Yang, Ming-Chang},\n title = {Performance Enhancement of Garbage Collection for Flash Storage Devices: An Efficient Victim Block Selection Design},\n booktitle = {Proceedings of the 50th Annual Design Automation Conference},\n series = {DAC '13},\n year = {2013},\n isbn = {978-1-4503-2071-9},\n location = {Austin, Texas},\n pages = {165:1--165:6},\n articleno = {165},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2463209.2488938},\n doi = {10.1145/2463209.2488938},\n acmid = {2488938},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, performance, reliability},\n} \r\n",
        "key": "2488938",
        "pub_year": "2013",
        "text": "Che-Wei Tsao , Yuan-Hao Chang , Ming-Chang Yang, Performance enhancement of garbage collection for flash storage devices: an efficient victim block selection design, Proceedings of the 50th Annual Design Automation Conference, May 29-June 07, 2013, Austin, Texas"
    },
    "2488939": {
        "abstract": "Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements, but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application, and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition, data mining, and search. Based on this analysis, we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis, we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing, while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.",
        "acm_key": "2488939",
        "bib_stats": {
            "cites": 3,
            "dl": 612,
            "dl_52": 74,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Liu:2013:DDS:2463209.2488939,\n author = {Liu, Ren-Shuo and Yang, Chia-Lin and Li, Cheng-Hsuan and Chen, Geng-You},\n title = {DuraCache: A Durable SSD Cache Using MLC NAND Flash},\n booktitle = {Proceedings of the 50th Annual Design Automation Conference},\n series = {DAC '13},\n year = {2013},\n isbn = {978-1-4503-2071-9},\n location = {Austin, Texas},\n pages = {166:1--166:6},\n articleno = {166},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2463209.2488939},\n doi = {10.1145/2463209.2488939},\n acmid = {2488939},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MLC, NAND flash, SSD, cache, endurance},\n} \r\n",
        "key": "2488939",
        "pub_year": "2013",
        "text": "Ren-Shuo Liu , Chia-Lin Yang , Cheng-Hsuan Li , Geng-You Chen, DuraCache: a durable SSD cache using MLC NAND flash, Proceedings of the 50th Annual Design Automation Conference, May 29-June 07, 2013, Austin, Texas"
    },
    "2490404": {
        "abstract": "Singular value decomposition (SVD) is an optimal method to obtain spatial multiplexing gain in multi-input multi-output (MIMO) channels. However, the high cost of implementation and high decomposing latency of the SVD restricts its usage in current wireless communication applications. In this paper, we present a complete adaptive SVD algorithm and a reconfigurable architecture for high-throughput MIMO-orthogonal frequency division multiplexing systems. There are several proposed architectural design techniques: reconfigurable scheme, division-free adaptive step size scheme, early termination scheme, and data interleaving scheme. The reconfigurable scheme can support all antenna configurations in a MIMO system. The division-free adaptive step size and early termination schemes are used to effectively reduce the decomposing latency and improve hardware utilization. The data interleaving scheme helps to deal with several channel matrices concurrently. Besides, we propose an orthogonal reconstruction scheme to obtain more accurate SVD outputs, and then the system performance will be greatly enhanced. We apply our SVD design to the IEEE 802.11n applications. This design is implemented and fabricated in UMC 90 nm 1P9M CMOS technology. The maximum operating frequency is measured to be at 101.2 MHz, and the corresponding power dissipation is at 125 mW. The core size is 2.17 mm",
        "acm_key": "2490404",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Shi:2013:CVM:2490394.2490404,\n author = {Shi, Liang and Li, Jianhua and Xue, Chun Jason and Zhou, Xuehai},\n title = {Cooperating Virtual Memory and Write Buffer Management for Flash-based Storage Systems},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {April 2013},\n volume = {21},\n number = {4},\n month = apr,\n year = {2013},\n issn = {1063-8210},\n pages = {706--719},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TVLSI.2012.2193909},\n doi = {10.1109/TVLSI.2012.2193909},\n acmid = {2490404},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n keywords = {NAND flash memory, adaptive partition cluster least recently used (APCLRU), flash translation layer (FTL), virtual memory, write buffer, write-buffer-aware least recently used (WBLRU)},\n} \r\n",
        "key": "2490404",
        "pub_year": "2013",
        "text": "Liang Shi , Jianhua Li , Chun Jason Xue , Xuehai Zhou, Cooperating virtual memory and write buffer management for flash-based storage systems, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.21 n.4, p.706-719, April 2013"
    },
    "2492838": {
        "abstract": "This paper is the first to present an efficient charge management algorithm focusing on extending the cycle life of battery elements in hybrid electrical energy storage (HEES) systems while simultaneously improving the overall cycle efficiency. In particular, it proposes to apply a crossover filter to the power source and load profiles. The goal of this filtering technique is to allow the battery banks to stably (i.e., with low variation) receive energy from the power source and/or provide energy to the load device, while leaving the spiky (i.e., with high variation) power supply or demand to be dealt with by the supercapacitor banks. To maximize the HEES system cycle efficiency, a mathematical problem is formulated and solved to determine the optimal charging/discharging current profiles and charge transfer interconnect voltage, taking into account the power loss of the EES elements and power converters. To minimize the state of health (SoH) degradation of the battery array in the HEES system, we make use of two facts: the SoH of battery is better maintained if (i) the SoC swing is smaller, and (ii) the same SoC swing occurs at lower average SoC. Now then using the supercapacitor bank to deal with the high-frequency component of the power supply or demand, we can reduce the SoC swing for the battery array and lower the SoC of the array. A secondary helpful effect is that, for fixed and given amount of energy delivered to the load device, an improvement in the overall charge cycle efficiency of the HEES system translates into a further reduction in both the average SoC and the SoC swing of the battery array. The proposed charge management algorithm for a Li-ion battery -- supercapacitor bank HEES system is simulated and compared to a homogeneous EES system comprised of Li-ion batteries only. Experimental results show significant performance enhancements for the HEES system, an increase of up to 21.9% and 4.82x in terms of the cycle efficiency and cycle life, respectively.",
        "acm_key": "2492838",
        "bib_stats": {
            "cites": 49,
            "dl": 211,
            "dl_52": 113,
            "dl_6": 22
        },
        "bibtex": "\r\n@inproceedings{Cai:2012:EPM:2492708.2492838,\n author = {Cai, Yu and Haratsch, Erich F. and Mutlu, Onur and Mai, Ken},\n title = {Error Patterns in MLC NAND Flash Memory: Measurement, Characterization, and Analysis},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '12},\n year = {2012},\n isbn = {978-3-9810801-8-6},\n location = {Dresden, Germany},\n pages = {521--526},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2492708.2492838},\n acmid = {2492838},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {NAND flash, endurance, error correction, error patterns, reliability},\n} \r\n",
        "key": "2492838",
        "pub_year": "2012",
        "text": "Yu Cai , Erich F. Haratsch , Onur Mutlu , Ken Mai, Error patterns in MLC NAND flash memory: measurement, characterization, and analysis, Proceedings of the Conference on Design, Automation and Test in Europe, March 12-16, 2012, Dresden, Germany"
    },
    "2493062": {
        "abstract": "This paper is the first to present an efficient charge management algorithm focusing on extending the cycle life of battery elements in hybrid electrical energy storage (HEES) systems while simultaneously improving the overall cycle efficiency. In particular, it proposes to apply a crossover filter to the power source and load profiles. The goal of this filtering technique is to allow the battery banks to stably (i.e., with low variation) receive energy from the power source and/or provide energy to the load device, while leaving the spiky (i.e., with high variation) power supply or demand to be dealt with by the supercapacitor banks. To maximize the HEES system cycle efficiency, a mathematical problem is formulated and solved to determine the optimal charging/discharging current profiles and charge transfer interconnect voltage, taking into account the power loss of the EES elements and power converters. To minimize the state of health (SoH) degradation of the battery array in the HEES system, we make use of two facts: the SoH of battery is better maintained if (i) the SoC swing is smaller, and (ii) the same SoC swing occurs at lower average SoC. Now then using the supercapacitor bank to deal with the high-frequency component of the power supply or demand, we can reduce the SoC swing for the battery array and lower the SoC of the array. A secondary helpful effect is that, for fixed and given amount of energy delivered to the load device, an improvement in the overall charge cycle efficiency of the HEES system translates into a further reduction in both the average SoC and the SoC swing of the battery array. The proposed charge management algorithm for a Li-ion battery -- supercapacitor bank HEES system is simulated and compared to a homogeneous EES system comprised of Li-ion batteries only. Experimental results show significant performance enhancements for the HEES system, an increase of up to 21.9% and 4.82x in terms of the cycle efficiency and cycle life, respectively.",
        "acm_key": "2493062",
        "bib_stats": {
            "cites": 6,
            "dl": 161,
            "dl_52": 17,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Liu:2012:BFM:2492708.2493062,\n author = {Liu, Duo and Wang, Tianzheng and Wang, Yi and Qin, Zhiwei and Shao, Zili},\n title = {A Block-level Flash Memory Management Scheme for Reducing Write Activities in PCM-based Embedded Systems},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '12},\n year = {2012},\n isbn = {978-3-9810801-8-6},\n location = {Dresden, Germany},\n pages = {1447--1450},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2492708.2493062},\n acmid = {2493062},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {NAND flash memory, endurance, flash translation layer, phase change memory, write activity},\n} \r\n",
        "key": "2493062",
        "pub_year": "2012",
        "text": "Duo Liu , Tianzheng Wang , Yi Wang , Zhiwei Qin , Zili Shao, A block-level flash memory management scheme for reducing write activities in PCM-based embedded systems, Proceedings of the Conference on Design, Automation and Test in Europe, March 12-16, 2012, Dresden, Germany"
    },
    "2493080": {
        "abstract": "This paper is the first to present an efficient charge management algorithm focusing on extending the cycle life of battery elements in hybrid electrical energy storage (HEES) systems while simultaneously improving the overall cycle efficiency. In particular, it proposes to apply a crossover filter to the power source and load profiles. The goal of this filtering technique is to allow the battery banks to stably (i.e., with low variation) receive energy from the power source and/or provide energy to the load device, while leaving the spiky (i.e., with high variation) power supply or demand to be dealt with by the supercapacitor banks. To maximize the HEES system cycle efficiency, a mathematical problem is formulated and solved to determine the optimal charging/discharging current profiles and charge transfer interconnect voltage, taking into account the power loss of the EES elements and power converters. To minimize the state of health (SoH) degradation of the battery array in the HEES system, we make use of two facts: the SoH of battery is better maintained if (i) the SoC swing is smaller, and (ii) the same SoC swing occurs at lower average SoC. Now then using the supercapacitor bank to deal with the high-frequency component of the power supply or demand, we can reduce the SoC swing for the battery array and lower the SoC of the array. A secondary helpful effect is that, for fixed and given amount of energy delivered to the load device, an improvement in the overall charge cycle efficiency of the HEES system translates into a further reduction in both the average SoC and the SoC swing of the battery array. The proposed charge management algorithm for a Li-ion battery -- supercapacitor bank HEES system is simulated and compared to a homogeneous EES system comprised of Li-ion batteries only. Experimental results show significant performance enhancements for the HEES system, an increase of up to 21.9% and 4.82x in terms of the cycle efficiency and cycle life, respectively.",
        "acm_key": "2493080",
        "bib_stats": {
            "cites": 7,
            "dl": 89,
            "dl_52": 16,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Wang:2012:CAR:2492708.2493080,\n author = {Wang, Yiqun and Liu, Yongpan and Liu, Yumeng and Zhang, Daming and Li, Shuangchen and Sai, Baiko and Chiang, Mei-Fang and Yang, Huazhong},\n title = {A Compression-based Area-efficient Recovery Architecture for Nonvolatile Processors},\n booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},\n series = {DATE '12},\n year = {2012},\n isbn = {978-3-9810801-8-6},\n location = {Dresden, Germany},\n pages = {1519--1524},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2492708.2493080},\n acmid = {2493080},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2493080",
        "pub_year": "2012",
        "text": "Yiqun Wang , Yongpan Liu , Yumeng Liu , Daming Zhang , Shuangchen Li , Baiko Sai , Mei-Fang Chiang , Huazhong Yang, A compression-based area-efficient recovery architecture for nonvolatile processors, Proceedings of the Conference on Design, Automation and Test in Europe, March 12-16, 2012, Dresden, Germany"
    },
    "2493505": {
        "abstract": "Based on an 18-month qualitative study that included the creation and testing of design considerations and a prototype location-based information system (LBIS), this research provides empirical insight into the daily practices of a wide variety of individuals working to address food insecurity in one U.S. county. Qualitative fieldwork reveals that nonprofit organizations in the food assistance ecology engage in location-based information practices that could be enhanced by the design of a LBIS. Two practices that would benefit from a collaborative LBIS are 1) practices of matching in which nonprofit workers help individuals who are seeking assistance to food resources and 2) practices of distribution in which nonprofit workers help organizations access and deliver food resources to clients. In order to support such practices across organizations the cooperative design component of this research suggests that an LIBS should: support the role of intermediaries who engage in practices of matching and distribution; provide interactive mapping tools that match resources to need; enable organizations to control visibility over specific data; and document work and impact. This research further suggests that designers should explore the wide variety of spatial patterns that must align and overlap such that ecologies of nonprofit organizations might synergistically work together to address pressing social needs.",
        "acm_key": "2493505",
        "bib_stats": {
            "cites": 6,
            "dl": 551,
            "dl_52": 62,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Nguyen:2013:SSE:2493432.2493505,\n author = {Nguyen, David T. and Zhou, Gang and Qi, Xin and Peng, Ge and Zhao, Jianing and Nguyen, Tommy and Le, Duy},\n title = {Storage-aware Smartphone Energy Savings},\n booktitle = {Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing},\n series = {UbiComp '13},\n year = {2013},\n isbn = {978-1-4503-1770-2},\n location = {Zurich, Switzerland},\n pages = {677--686},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2493432.2493505},\n doi = {10.1145/2493432.2493505},\n acmid = {2493505},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {smartphone energy-efficient system},\n} \r\n",
        "key": "2493505",
        "pub_year": "2013",
        "text": "David T. Nguyen , Gang Zhou , Xin Qi , Ge Peng , Jianing Zhao , Tommy Nguyen , Duy Le, Storage-aware smartphone energy savings, Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing, September 08-12, 2013, Zurich, Switzerland"
    },
    "2495493": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2495493",
        "bib_stats": {
            "cites": 13
        },
        "bibtex": "\r\n@inproceedings{Jacobvitz:2013:CCE:2495252.2495493,\n author = {Jacobvitz, Adam N. and Calderbank, Robert and Sorin, Daniel J.},\n title = {Coset Coding to Extend the Lifetime of Memory},\n booktitle = {Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)},\n series = {HPCA '13},\n year = {2013},\n isbn = {978-1-4673-5585-8},\n pages = {222--233},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/HPCA.2013.6522321},\n doi = {10.1109/HPCA.2013.6522321},\n acmid = {2495493},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2495493",
        "pub_year": "2013",
        "text": "Adam N. Jacobvitz , Robert Calderbank , Daniel J. Sorin, Coset coding to extend the lifetime of memory, Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA), p.222-233, February 23-27, 2013"
    },
    "2495496": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2495496",
        "bib_stats": {
            "cites": 23
        },
        "bibtex": "\r\n@inproceedings{Yue:2013:AWE:2495252.2495496,\n author = {Yue, Jianhui and Zhu, Yifeng},\n title = {Accelerating Write by Exploiting PCM Asymmetries},\n booktitle = {Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)},\n series = {HPCA '13},\n year = {2013},\n isbn = {978-1-4673-5585-8},\n pages = {282--293},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/HPCA.2013.6522326},\n doi = {10.1109/HPCA.2013.6522326},\n acmid = {2495496},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2495496",
        "pub_year": "2013",
        "text": "Jianhui Yue , Yifeng Zhu, Accelerating write by exploiting PCM asymmetries, Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA), p.282-293, February 23-27, 2013  \u00a0[doi>"
    },
    "2495506": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2495506",
        "bib_stats": {
            "cites": 13
        },
        "bibtex": "\r\n@inproceedings{Wang:2013:IIN:2495252.2495506,\n author = {Wang, Jue and Dong, Xiangyu and Xie, Yuan and Jouppi, Norman P.},\n title = {I2WAP: Improving Non-volatile Cache Lifetime by Reducing Inter- and Intra-set Write Variations},\n booktitle = {Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)},\n series = {HPCA '13},\n year = {2013},\n isbn = {978-1-4673-5585-8},\n pages = {234--245},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/HPCA.2013.6522322},\n doi = {10.1109/HPCA.2013.6522322},\n acmid = {2495506},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2495506",
        "pub_year": "2013",
        "text": "Jue Wang , Xiangyu Dong , Yuan Xie , Norman P. Jouppi, i2WAP: Improving non-volatile cache lifetime by reducing inter- and intra-set write variations, Proceedings of the 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA), p.234-245, February 23-27, 2013  \u00a0[doi>"
    },
    "2496690": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2496690",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@inproceedings{Motwani:2013:DLC:2496025.2496690,\n author = {Motwani, Ravi and Ong, Chong},\n title = {Design of LDPC Coding Schemes for Exploitation of Bit Error Rate Diversity Across Dies in NAND Flash Memory},\n booktitle = {Proceedings of the 2013 International Conference on Computing, Networking and Communications (ICNC)},\n series = {ICNC '13},\n year = {2013},\n isbn = {978-1-4673-5287-1},\n pages = {950--954},\n numpages = {5},\n url = {http://dx.doi.org/10.1109/ICCNC.2013.6504218},\n doi = {10.1109/ICCNC.2013.6504218},\n acmid = {2496690},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2496690",
        "pub_year": "2013",
        "text": "Ravi Motwani , Chong Ong, Design of LDPC coding schemes for exploitation of bit error rate diversity across dies in NAND flash memory, Proceedings of the 2013 International Conference on Computing, Networking and Communications (ICNC), p.950-954, January 28-31, 2013  \u00a0[doi>"
    },
    "2496691": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2496691",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@inproceedings{Kong:2013:MCF:2496025.2496691,\n author = {Kong, Jun Jin and Son, Hongrak and Lee, Jaejin and Kim, Jaehong and Cho, Kyoung Lae and Vijaya Kumar, B. V.  K. and Kim, Yongjune},\n title = {Modulation Coding for Flash Memories},\n booktitle = {Proceedings of the 2013 International Conference on Computing, Networking and Communications (ICNC)},\n series = {ICNC '13},\n year = {2013},\n isbn = {978-1-4673-5287-1},\n pages = {961--967},\n numpages = {7},\n url = {http://dx.doi.org/10.1109/ICCNC.2013.6504220},\n doi = {10.1109/ICCNC.2013.6504220},\n acmid = {2496691},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {runlength limited (RLL) code,Cell-to-cell interference,flash memory,lateral charge spreading,modulation coding},\n} \r\n",
        "key": "2496691",
        "pub_year": "2013",
        "text": "Jun Jin Kong , Hongrak Son , Jaejin Lee , Jaehong Kim , Kyoung Lae Cho , B. V.  K. Vijaya Kumar , Yongjune Kim, Modulation coding for flash memories, Proceedings of the 2013 International Conference on Computing, Networking and Communications (ICNC), p.961-967, January 28-31, 2013  \u00a0[doi>"
    },
    "2503221": {
        "abstract": "Soaring energy consumption, accompanied by declining reliability, together loom as the biggest hurdles for the next generation of supercomputers. Recent reports have expressed concern that reliability at exascale level could degrade to the point where failures become a norm rather than an exception. HPC researchers are focusing on improving existing fault tolerance protocols to address these concerns. Research on improving hardware reliability, i.e., machine component reliability, has also been making progress independently. In this paper, we try to bridge this gap and explore the potential of combining both software and hardware aspects towards improving reliability of HPC machines. Fault rates are known to double for every 10\u00b0C rise in core temperature. We leverage this notion to experimentally demonstrate the potential of restraining core temperatures and load balancing to achieve two-fold benefits: improving reliability of parallel machines and reducing total execution time required by applications. Our experimental results show that we can improve the reliability of a machine by a factor of 2.3 and reduce the execution time by 12%. In addition, our scheme can also reduce machine energy consumption by as much as 25%. For a 350K socket machine, regular checkpoint/restart fails to make progress (less than 1% efficiency), whereas our validated model predicts an efficiency of 20% by improving the machine reliability by a factor of up to 2.29.",
        "acm_key": "2503221",
        "bib_stats": {
            "cites": 3,
            "dl": 411,
            "dl_52": 41,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Yoon:2013:PNM:2503210.2503221,\n author = {Yoon, Doe Hyun and Chang, Jichuan and Schreiber, Robert S. and Jouppi, Norman P.},\n title = {Practical Nonvolatile Multilevel-cell Phase Change Memory},\n booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},\n series = {SC '13},\n year = {2013},\n isbn = {978-1-4503-2378-9},\n location = {Denver, Colorado},\n pages = {21:1--21:12},\n articleno = {21},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2503210.2503221},\n doi = {10.1145/2503210.2503221},\n acmid = {2503221},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory, multilevel cell, nonvolatility, phase change},\n} \r\n",
        "key": "2503221",
        "pub_year": "2013",
        "text": "Doe Hyun Yoon , Jichuan Chang , Robert S. Schreiber , Norman P. Jouppi, Practical nonvolatile multilevel-cell phase change memory, Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis, November 17-21, 2013, Denver, Colorado  \u00a0[doi>"
    },
    "2505066": {
        "abstract": "Efficient multimedia and specifically image authentication is critical and in demand to protect data vulnerability in wireless multimedia sensor networks (WMSN). This is to prevent malicious intruders from modifying and forging image contents over a network. Watermarking technique has been widely used to assert an image data authentication over wired networks; however, resource constraints (e.g. processing power, communication energy) in small sensors and the state of error-prone wireless channels result in fundamental challenges for developing efficient watermarking schemes in WMSN. These challenges include how to embed/protect/extract watermark efficiently and robustly in low-cost sensors and how to transmit authenticated image and multimedia with high energy efficiency. In this paper, we propose a communication-resource-aware and adaptive watermarking scheme for multimedia authentication in WMSN. Our contribution is two folds. First, the transmission quality for the watermark as well as watermarked multimedia authenticity by embedding watermark with adaptive coding redundancies, and by unequally allocating network resources to protect the image and multimedia packets with the watermark information. Second, communication energy efficiency and real time performance are achieved with the watermark being adaptive to the network condition and the processing delay reduced due to the exploited inter-frame correlation. The simulation and experimental results demonstrate that the proposed adaptive watermarking system can achieve considerable gains in terms of energy saving, image transmission quality and multimedia authentication performance.",
        "acm_key": "2505066",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Li:2013:EIM:2505058.2505066,\n author = {Li, Guohui and Zhao, Pei and Yuan, Ling and Gao, Sheng},\n title = {Efficient Implementation of a Multi-dimensional Index Structure over Flash Memory Storage Systems},\n journal = {J. Supercomput.},\n issue_date = {June      2013},\n volume = {64},\n number = {3},\n month = jun,\n year = {2013},\n issn = {0920-8542},\n pages = {1055--1074},\n numpages = {20},\n url = {http://dx.doi.org/10.1007/s11227-011-0679-0},\n doi = {10.1007/s11227-011-0679-0},\n acmid = {2505066},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {3-competitive online algorithm, K-D-B-tree, Logging entry, Node translate table, Replacement policy},\n} \r\n",
        "key": "2505066",
        "pub_year": "2013",
        "text": "Guohui Li , Pei Zhao , Ling Yuan , Sheng Gao, Efficient implementation of a multi-dimensional index structure over flash memory storage systems, The Journal of Supercomputing, v.64 n.3, p.1055-1074, June      2013"
    },
    "2507545": {
        "abstract": "Tree index structures are crucial components in data management systems. Existing tree index structure are designed with the implicit assumption that the underlying external memory storage is the conventional magnetic hard disk drives. This assumption is going to be invalid soon, as flash memory storage is increasingly adopted as the main storage media in mobile devices, digital cameras, embedded sensors, and notebooks. Though it is direct and simple to port existing tree index structures on the flash memory storage, that direct approach does not consider the unique characteristics of flash memory, i.e., slow write operations, and erase-before-update property, which would result in a sub optimal performance. In this paper, we introduce FAST (i.e., Flash-Aware Search Trees) as a generic framework for flash-aware tree index structures. FAST distinguishes itself from all previous attempts of flash memory indexing in two aspects: (1) FAST is a generic framework that can be applied to a wide class of data partitioning tree structures including R-tree and its variants, and (2) FAST achieves both ",
        "acm_key": "2507545",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Sarwat:2013:GEF:2507519.2507545,\n author = {Sarwat, Mohamed and Mokbel, Mohamed F. and Zhou, Xun and Nath, Suman},\n title = {Generic and Efficient Framework for Search Trees on Flash Memory Storage Systems},\n journal = {Geoinformatica},\n issue_date = {July      2013},\n volume = {17},\n number = {3},\n month = jul,\n year = {2013},\n issn = {1384-6175},\n pages = {417--448},\n numpages = {32},\n url = {http://dx.doi.org/10.1007/s10707-012-0164-9},\n doi = {10.1007/s10707-012-0164-9},\n acmid = {2507545},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Data, Flash memory, Index structure, Multi-dimensional, Spatial, Storage, System, Tree},\n} \r\n",
        "key": "2507545",
        "pub_year": "2013",
        "text": "Mohamed Sarwat , Mohamed F. Mokbel , Xun Zhou , Suman Nath, Generic and efficient framework for search trees on flash memory storage systems, Geoinformatica, v.17 n.3, p.417-448, July      2013"
    },
    "2508783": {
        "abstract": "Storage and retrieval of data in Wireless Sensor Networks (WSNs) have been found to be challenging issues in recent studies. The two principal approaches used in almost all proposed schemes in this field are Centralized and Decentralized. Many investigations have considered the security and communication issues in centralized schemes where a central node exists as the sink and all collected data are sent to it to be processed or the central node provides access to the possible users. In decentralized systems, all nodes are equally responsible for the duties of the central node in centralized approaches. In cases where sensors cannot transmit data immediately, which is usually the case in distributed approaches, in-network storage and retrieval is an alternative with its own security and communication issues stemming from the properties of energy sensitive sensors. In this paper, a semi-centralized scheme is introduced that is based on a number of traditional techniques, namely, clustering, symmetric and asymmetric key-management, and threshold secret sharing. The proposed scheme provides an energy-efficient and secure in-network storage and retrieval that could be applied to WSNs. A predictive method is proposed to adaptively determine the proper parameters for the threshold secret sharing technique. Confidentiality, dependability, and integrity of the sensed data are enhanced in a distributed manner with fairly low communication and computation costs. Simulations were utilized to illustrate the effect of several network parameters on energy consumption and to come up with optimization recommendations for the parameters of the proposed secret sharing scheme.",
        "acm_key": "2508783",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Lee:2013:MGP:2508762.2508783,\n author = {Lee, Yangsun and Barolli, Leonard and Lim, Seung-Ho},\n title = {Mapping Granularity and Performance Tradeoffs for Solid State Drive},\n journal = {J. Supercomput.},\n issue_date = {August    2013},\n volume = {65},\n number = {2},\n month = aug,\n year = {2013},\n issn = {0920-8542},\n pages = {507--523},\n numpages = {17},\n url = {http://dx.doi.org/10.1007/s11227-012-0798-2},\n doi = {10.1007/s11227-012-0798-2},\n acmid = {2508783},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Flash translation layer, Mapping unit, Page mapping, Solid state drives},\n} \r\n",
        "key": "2508783",
        "pub_year": "2013",
        "text": "Yangsun Lee , Leonard Barolli , Seung-Ho Lim, Mapping granularity and performance tradeoffs for solid state drive, The Journal of Supercomputing, v.65 n.2, p.507-523, August    2013"
    },
    "2511418": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2511418",
        "bib_stats": {
            "cites": 18
        },
        "bibtex": "\r\n@inproceedings{Kannan:2013:OCU:2510661.2511418,\n author = {Kannan, Sudarsun and Gavrilovska, Ada and Schwan, Karsten and Milojicic, Dejan},\n title = {Optimizing Checkpoints Using NVM As Virtual Memory},\n booktitle = {Proceedings of the 2013 IEEE 27th International Symposium on Parallel and Distributed Processing},\n series = {IPDPS '13},\n year = {2013},\n isbn = {978-0-7695-4971-2},\n pages = {29--40},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/IPDPS.2013.69},\n doi = {10.1109/IPDPS.2013.69},\n acmid = {2511418},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Non volatile memory (NVM), PCM, Checkpointing, Memory bandwidth, Pre-Copy},\n} \r\n",
        "key": "2511418",
        "pub_year": "2013",
        "text": "Sudarsun Kannan , Ada Gavrilovska , Karsten Schwan , Dejan Milojicic, Optimizing Checkpoints Using NVM as Virtual Memory, Proceedings of the 2013 IEEE 27th International Symposium on Parallel and Distributed Processing, p.29-40, May 20-24, 2013  \u00a0[doi>"
    },
    "2512961": {
        "abstract": "Online portfolio selection is a fundamental problem in computational finance, which has been extensively studied across several research communities, including finance, statistics, artificial intelligence, machine learning, and data mining. This article aims to provide a comprehensive survey and a structural understanding of online portfolio selection techniques published in the literature. From an online machine learning perspective, we first formulate online portfolio selection as a sequential decision problem, and then we survey a variety of state-of-the-art approaches, which are grouped into several major categories, including benchmarks, Follow-the-Winner approaches, Follow-the-Loser approaches, Pattern-Matching--based approaches, and Meta-Learning Algorithms. In addition to the problem formulation and related algorithms, we also discuss the relationship of these algorithms with the capital growth theory so as to better understand the similarities and differences of their underlying trading ideas. This article aims to provide a timely and comprehensive survey for both machine learning and data mining researchers in academia and quantitative portfolio managers in the financial industry to help them understand the state of the art and facilitate their research and practical applications. We also discuss some open issues and evaluate some emerging new trends for future research.",
        "acm_key": "2512961",
        "bib_stats": {
            "cites": 6,
            "dl": 1,
            "dl_52": 136,
            "dl_6": 6
        },
        "bibtex": "\r\n@article{Ma:2014:SAT:2578702.2512961,\n author = {Ma, Dongzhe and Feng, Jianhua and Li, Guoliang},\n title = {A Survey of Address Translation Technologies for Flash Memories},\n journal = {ACM Comput. Surv.},\n issue_date = {January 2014},\n volume = {46},\n number = {3},\n month = jan,\n year = {2014},\n issn = {0360-0300},\n pages = {36:1--36:39},\n articleno = {36},\n numpages = {39},\n url = {http://doi.acm.org/10.1145/2512961},\n doi = {10.1145/2512961},\n acmid = {2512961},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, flash translation layer, garbage collection, wear leveling},\n} \r\n",
        "key": "2512961",
        "pub_year": "2014",
        "text": "Dongzhe Ma , Jianhua Feng , Guoliang Li, A survey of address translation technologies for flash memories, ACM Computing Surveys (CSUR), v.46 n.3, p.1-39, January 2014"
    },
    "2522724": {
        "abstract": "Providing consistent response times to users of mobile applications is challenging because there are several variable delays between the start of a user's request and the completion of the response. These delays include location lookup, sensor data acquisition, radio wake-up, network transmissions, and processing on both the client and server. To allow applications to achieve consistent response times in the face of these variable delays, this paper presents the design, implementation, and evaluation of the Timecard system. Timecard provides two abstractions: the first returns the time elapsed since the user started the request, and the second returns an estimate of the time it would take to transmit the response from the server to the client and process the response at the client. With these abstractions, the server can adapt its processing time to control the end-to-end delay for the request. Implementing these abstractions requires Timecard to track delays across multiple asynchronous activities, handle time skew between client and server, and estimate network transfer times. Experiments with Timecard incorporated into two mobile applications show that the end-to-end delay is within 50 ms of the target delay of 1200 ms over 90% of the time.",
        "acm_key": "2522724",
        "bib_stats": {
            "cites": 21,
            "dl": 1,
            "dl_52": 208,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Coburn:2013:AMT:2517349.2522724,\n author = {Coburn, Joel and Bunker, Trevor and Schwarz, Meir and Gupta, Rajesh and Swanson, Steven},\n title = {From ARIES to MARS: Transaction Support for Next-generation, Solid-state Drives},\n booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},\n series = {SOSP '13},\n year = {2013},\n isbn = {978-1-4503-2388-8},\n location = {Farminton, Pennsylvania},\n pages = {197--212},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2517349.2522724},\n doi = {10.1145/2517349.2522724},\n acmid = {2522724},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2522724",
        "pub_year": "2013",
        "text": "Joel Coburn , Trevor Bunker , Meir Schwarz , Rajesh Gupta , Steven Swanson, From ARIES to MARS: transaction support for next-generation, solid-state drives, Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles, November 03-06, 2013, Farminton, Pennsylvania"
    },
    "2522732": {
        "abstract": "Providing consistent response times to users of mobile applications is challenging because there are several variable delays between the start of a user's request and the completion of the response. These delays include location lookup, sensor data acquisition, radio wake-up, network transmissions, and processing on both the client and server. To allow applications to achieve consistent response times in the face of these variable delays, this paper presents the design, implementation, and evaluation of the Timecard system. Timecard provides two abstractions: the first returns the time elapsed since the user started the request, and the second returns an estimate of the time it would take to transmit the response from the server to the client and process the response at the client. With these abstractions, the server can adapt its processing time to control the end-to-end delay for the request. Implementing these abstractions requires Timecard to track delays across multiple asynchronous activities, handle time skew between client and server, and estimate network transfer times. Experiments with Timecard incorporated into two mobile applications show that the end-to-end delay is within 50 ms of the target delay of 1200 ms over 90% of the time.",
        "acm_key": "2522732",
        "bib_stats": {
            "cites": 27,
            "dl": 3,
            "dl_52": 356,
            "dl_6": 31
        },
        "bibtex": "\r\n@inproceedings{Balakrishnan:2013:TDD:2517349.2522732,\n author = {Balakrishnan, Mahesh and Malkhi, Dahlia and Wobber, Ted and Wu, Ming and Prabhakaran, Vijayan and Wei, Michael and Davis, John D. and Rao, Sriram and Zou, Tao and Zuck, Aviad},\n title = {Tango: Distributed Data Structures over a Shared Log},\n booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},\n series = {SOSP '13},\n year = {2013},\n isbn = {978-1-4503-2388-8},\n location = {Farminton, Pennsylvania},\n pages = {325--340},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2517349.2522732},\n doi = {10.1145/2517349.2522732},\n acmid = {2522732},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2522732",
        "pub_year": "2013",
        "text": "Mahesh Balakrishnan , Dahlia Malkhi , Ted Wobber , Ming Wu , Vijayan Prabhakaran , Michael Wei , John D. Davis , Sriram Rao , Tao Zou , Aviad Zuck, Tango: distributed data structures over a shared log, Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles, November 03-06, 2013, Farminton, Pennsylvania"
    },
    "2534393": {
        "abstract": "Complex thermal behavior inhibits the advancement of three-dimensional (3D) very-large-scale-integration (VLSI) system designs, as it could lead to ultra-high temperature hotspots and permanent silicon device damage. This article introduces a new runtime thermal management strategy to effectively diffuse and manage heat throughout 3D chip geometry for a better throughput performance in networks on chip (NoC). This strategy employs a dynamic programming-based runtime thermal management (DPRTM) policy to provide online thermal regulation. Reactive and proactive adaptive schemes are integrated to optimize the routing pathways depending on the critical temperature thresholds and traffic developments. Also, when the critical system thermal limit is violated, an urgent throttling will take place. The proposed DPRTM is rigorously evaluated through cycle-accurate simulations, and results show that the proposed approach outperforms conventional approaches in terms of computational efficiency and thermal stability. For example, the system throughput using the DPRTM approach can be improved by 33&percnt; when compared to other adaptive routing strategies for a given thermal constraint. Moreover, the DPRTM implementation presented in this article demonstrates that the hardware overhead is insignificant. This work opens a new avenue for exploring the on-chip adaptability and thermal regulation for future large-scale and 3D many-core integrations.",
        "acm_key": "2534393",
        "bib_stats": {
            "cites": 6,
            "dl": 346,
            "dl_52": 33,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Li:2013:LVS:2558148.2534393,\n author = {Li, Jianhua and Shi, Liang and Li, Qingan and Xue, Chun Jason and Chen, Yiran and Xu, Yinlong and Wang, Wei},\n title = {Low-energy Volatile STT-RAM Cache Design Using Cache-coherence-enabled Adaptive Refresh},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {December 2013},\n volume = {19},\n number = {1},\n month = dec,\n year = {2013},\n issn = {1084-4309},\n pages = {5:1--5:23},\n articleno = {5},\n numpages = {23},\n url = {http://doi.acm.org/10.1145/2534393},\n doi = {10.1145/2534393},\n acmid = {2534393},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Spin-torque transfer RAM, cache coherence, embedded DRAM, energy efficiency, nonvolatile memory, refresh},\n} \r\n",
        "key": "2534393",
        "pub_year": "2013",
        "text": "Jianhua Li , Liang Shi , Qingan Li , Chun Jason Xue , Yiran Chen , Yinlong Xu , Wei Wang, Low-energy volatile STT-RAM cache design using cache-coherence-enabled adaptive refresh, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.19 n.1, p.1-23, December 2013  \u00a0[doi>"
    },
    "2535477": {
        "abstract": "Breaking up the OS in many small components is attractive from a dependability point of view. If one of the components crashes or needs an update, we can replace it on the fly without taking down the system. The question is how to achieve this without sacrificing performance and without wasting resources unnecessarily. In this paper, we show that heterogeneous multicore architectures allow us to run OS code efficiently by executing each of the OS components on the most suitable core. Thus, components that require high single-thread performance run on (expensive) high-performance cores, while components that are less performance critical run on wimpy cores. Moreover, as current trends suggest that there will be no shortage of cores, we can give each component its own dedicated core when performance is of the essence, and consolidate multiple functions on a single core (saving power and resources) when performance is less critical for these components. Using frequency scaling to emulate different \u00d786 cores, we evaluate our design on the most demanding subsystem of our operating system--the network stack. We show that less is sometimes more and that we can deliver better throughput with slower and, likely, less power hungry cores. For instance, we support network processing at close to 10 Gbps (the maximum speed of our NIC), while using an average of just 60% of the core speeds. Moreover, even if we scale all the cores of the network stack down to as little as 200 MHz, we still achieve 1.8 Gbps, which may be enough for many applications.",
        "acm_key": "2535477",
        "bib_stats": {
            "cites": 13,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Holland:2013:FCS:2535461.2535477,\n author = {Holland, David A. and Angelino, Elaine and Wald, Gideon and Seltzer, Margo I.},\n title = {Flash Caching on the Storage Client},\n booktitle = {Proceedings of the 2013 USENIX Conference on Annual Technical Conference},\n series = {USENIX ATC'13},\n year = {2013},\n location = {San Jose, CA},\n pages = {127--138},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2535461.2535477},\n acmid = {2535477},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2535477",
        "pub_year": "2013",
        "text": "David A. Holland , Elaine Angelino , Gideon Wald , Margo I. Seltzer, Flash caching on the storage client, Proceedings of the 2013 USENIX conference on Annual Technical Conference, June 26-28, 2013, San Jose, CA"
    },
    "2536372": {
        "abstract": "Web service providers have been using NoSQL datastores to provide scalability and availability for globally distributed data at the cost of sacrificing transactional guarantees. Recently, major web service providers like Google have moved towards building storage systems that provide ACID transactional guarantees for globally distributed data. For example, the newly published system, Spanner, uses Two-Phase Commit and Two-Phase Locking to provide atomicity and isolation for globally distributed data, running on top of Paxos to provide fault-tolerant log replication. We show in this paper that it is possible to provide the same ACID transactional guarantees for multi-datacenter databases with fewer cross-datacenter communication trips, compared to replicated logging. Instead of replicating the transactional log, we replicate the commit operation itself, by running Two-Phase Commit multiple times in different datacenters and using Paxos to reach consensus among datacenters as to whether the transaction should commit. Doing so not only replaces several inter-datacenter communication trips with intra-datacenter communication trips, but also allows us to integrate atomic commitment and isolation protocols with consistent replication protocols to further reduce the number of cross-datacenter communication trips needed for consistent replication; for example, by eliminating the need for an election phase in Paxos. We analyze our approach in terms of communication trips to compare it against the log replication approach, then we conduct an extensive experimental study to compare the performance and scalability of both approaches under various multi-datacenter setups.",
        "acm_key": "2536372",
        "bib_stats": {
            "cites": 10,
            "dl": 138,
            "dl_52": 13,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Stoica:2013:IFW:2536360.2536372,\n author = {Stoica, Radu and Ailamaki, Anastasia},\n title = {Improving Flash Write Performance by Using Update Frequency},\n journal = {Proc. VLDB Endow.},\n issue_date = {July 2013},\n volume = {6},\n number = {9},\n month = jul,\n year = {2013},\n issn = {2150-8097},\n pages = {733--744},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/2536360.2536372},\n doi = {10.14778/2536360.2536372},\n acmid = {2536372},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "2536372",
        "pub_year": "2013",
        "text": "Radu Stoica , Anastasia Ailamaki, Improving flash write performance by using update frequency, Proceedings of the VLDB Endowment, v.6 n.9, p.733-744, July 2013"
    },
    "2537546": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2537546",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Lim:2013:AIP:2537181.2537546,\n author = {Lim, Seung-Ho and Lee, Seongwoo and Ahn, Woo Hyun},\n title = {Applications IO Profiling and Analysis for Smart Devices},\n journal = {J. Syst. Archit.},\n issue_date = {October, 2013},\n volume = {59},\n number = {9},\n month = oct,\n year = {2013},\n issn = {1383-7621},\n pages = {740--747},\n numpages = {8},\n url = {http://dx.doi.org/10.1016/j.sysarc.2013.02.005},\n doi = {10.1016/j.sysarc.2013.02.005},\n acmid = {2537546},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Android, IO profiling, Storage component, Storage traffic analysis},\n} \r\n",
        "key": "2537546",
        "pub_year": "2013",
        "text": "Seung-Ho Lim , Seongwoo Lee , Woo Hyun Ahn, Applications IO profiling and analysis for smart devices, Journal of Systems Architecture: the EUROMICRO Journal, v.59 n.9, p.740-747, October, 2013"
    },
    "2540712": {
        "abstract": "Modern GPUs share limited hardware resources, such as register files, among a large number of concurrently executing threads. For efficient resource sharing, several buffering and collision avoidance stages are inserted in the GPU pipeline. These additional stages increase the read-after-write (RAW) latencies of instructions. Since GPUs are often architected to hide RAW latencies through extensive multithreading, they typically do not employ power-hungry data-forwarding networks (DFNs). However, we observe that many GPGPU applications do not have enough active threads that are ready to issue instructions to hide these RAW latencies. In this paper, we first demonstrate that DFNs can considerably improve the performance of many compute-intensive GPGPU applications and then propose most recent result forwarding (MoRF) as a low-power alternative to the DFN. Second, for floating-point (FP) operations, we exploit a high-throughput fused multiply-add (HFMA) unit to further reduce both RAW latencies and the number of FMA units in the GPU without impacting instruction throughput. MoRF and HFMA together provide a geometric mean performance improvement of 18% and 29% for integer/single-precision and double-precision GPGPU applications, respectively. Finally, both MoRF and HFMA allow the GPU to effectively mimic a shallower pipeline for a large percentage of instructions. Exploiting such a benefit, we propose low-power pipelines that can reduce peak power consumption by 14% without affecting the performance or increasing the complexity of the forwarding network. The peak power reduction allows GPUs to operate more cores within the same power budget, achieving a geometric mean performance improvement of 33% for double-precision GPGPU applications.",
        "acm_key": "2540712",
        "bib_stats": {
            "cites": 50,
            "dl": 732,
            "dl_52": 75,
            "dl_6": 16
        },
        "bibtex": "\r\n@inproceedings{Sampson:2013:ASS:2540708.2540712,\n author = {Sampson, Adrian and Nelson, Jacob and Strauss, Karin and Ceze, Luis},\n title = {Approximate Storage in Solid-state Memories},\n booktitle = {Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO-46},\n year = {2013},\n isbn = {978-1-4503-2638-4},\n location = {Davis, California},\n pages = {25--36},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2540708.2540712},\n doi = {10.1145/2540708.2540712},\n acmid = {2540712},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {approximate computing, error tolerance, phase-change memory, storage},\n} \r\n",
        "key": "2540712",
        "pub_year": "2013",
        "text": "Adrian Sampson , Jacob Nelson , Karin Strauss , Luis Ceze, Approximate storage in solid-state memories, Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, December 07-11, 2013, Davis, California"
    },
    "2540744": {
        "abstract": "Modern GPUs share limited hardware resources, such as register files, among a large number of concurrently executing threads. For efficient resource sharing, several buffering and collision avoidance stages are inserted in the GPU pipeline. These additional stages increase the read-after-write (RAW) latencies of instructions. Since GPUs are often architected to hide RAW latencies through extensive multithreading, they typically do not employ power-hungry data-forwarding networks (DFNs). However, we observe that many GPGPU applications do not have enough active threads that are ready to issue instructions to hide these RAW latencies. In this paper, we first demonstrate that DFNs can considerably improve the performance of many compute-intensive GPGPU applications and then propose most recent result forwarding (MoRF) as a low-power alternative to the DFN. Second, for floating-point (FP) operations, we exploit a high-throughput fused multiply-add (HFMA) unit to further reduce both RAW latencies and the number of FMA units in the GPU without impacting instruction throughput. MoRF and HFMA together provide a geometric mean performance improvement of 18% and 29% for integer/single-precision and double-precision GPGPU applications, respectively. Finally, both MoRF and HFMA allow the GPU to effectively mimic a shallower pipeline for a large percentage of instructions. Exploiting such a benefit, we propose low-power pipelines that can reduce peak power consumption by 14% without affecting the performance or increasing the complexity of the forwarding network. The peak power reduction allows GPUs to operate more cores within the same power budget, achieving a geometric mean performance improvement of 33% for double-precision GPGPU applications.",
        "acm_key": "2540744",
        "bib_stats": {
            "cites": 34,
            "dl": 781,
            "dl_52": 90,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Zhao:2013:KCP:2540708.2540744,\n author = {Zhao, Jishen and Li, Sheng and Yoon, Doe Hyun and Xie, Yuan and Jouppi, Norman P.},\n title = {Kiln: Closing the Performance Gap Between Systems with and Without Persistence Support},\n booktitle = {Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO-46},\n year = {2013},\n isbn = {978-1-4503-2638-4},\n location = {Davis, California},\n pages = {421--432},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2540708.2540744},\n doi = {10.1145/2540708.2540744},\n acmid = {2540744},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory, persistent memory},\n} \r\n",
        "key": "2540744",
        "pub_year": "2013",
        "text": "Jishen Zhao , Sheng Li , Doe Hyun Yoon , Yuan Xie , Norman P. Jouppi, Kiln: closing the performance gap between systems with and without persistence support, Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, December 07-11, 2013, Davis, California"
    },
    "2540745": {
        "abstract": "Modern GPUs share limited hardware resources, such as register files, among a large number of concurrently executing threads. For efficient resource sharing, several buffering and collision avoidance stages are inserted in the GPU pipeline. These additional stages increase the read-after-write (RAW) latencies of instructions. Since GPUs are often architected to hide RAW latencies through extensive multithreading, they typically do not employ power-hungry data-forwarding networks (DFNs). However, we observe that many GPGPU applications do not have enough active threads that are ready to issue instructions to hide these RAW latencies. In this paper, we first demonstrate that DFNs can considerably improve the performance of many compute-intensive GPGPU applications and then propose most recent result forwarding (MoRF) as a low-power alternative to the DFN. Second, for floating-point (FP) operations, we exploit a high-throughput fused multiply-add (HFMA) unit to further reduce both RAW latencies and the number of FMA units in the GPU without impacting instruction throughput. MoRF and HFMA together provide a geometric mean performance improvement of 18% and 29% for integer/single-precision and double-precision GPGPU applications, respectively. Finally, both MoRF and HFMA allow the GPU to effectively mimic a shallower pipeline for a large percentage of instructions. Exploiting such a benefit, we propose low-power pipelines that can reduce peak power consumption by 14% without affecting the performance or increasing the complexity of the forwarding network. The peak power reduction allows GPUs to operate more cores within the same power budget, achieving a geometric mean performance improvement of 33% for double-precision GPGPU applications.",
        "acm_key": "2540745",
        "bib_stats": {
            "cites": 4,
            "dl": 322,
            "dl_52": 33,
            "dl_6": 8
        },
        "key": "2540745",
        "text": "Jie Fan , Song Jiang , Jiwu Shu , Youhui Zhang , Weimin Zhen, Aegis: partitioning data block for efficient recovery of stuck-at-faults in phase change memory, Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, December 07-11, 2013, Davis, California  \u00a0[doi>"
    },
    "2541957": {
        "abstract": "While there has been prior work to underprovision the power distribution infrastructure for a datacenter to save costs, the ability to underprovision the backup power infrastructure, which contributes significantly to capital costs, is little explored. There are two main components in the backup infrastructure - Diesel Generators (DGs) and UPS units - which can both be underprovisioned (or even removed) in terms of their power and/or energy capacities. However, embarking on such underprovisioning mandates studying several ramifications - the resulting cost savings, the lower availability, and the performance and state loss consequences on individual applications - concurrently. This paper presents the first such study, considering cost, availability, performance and application consequences of underprovisioning the backup power infrastructure. We present a framework to quantify the cost of backup capacity that is provisioned, and implement techniques leveraging existing software and hardware mechanisms to provide as seamless an operation as possible for an application within the provisioned backup capacity during a power outage. We evaluate the cost-performance-availability trade-offs for different levels of backup underprovisioning for applications with diverse reliance on the backup infrastructure. Our results show that one may be able to completely do away with DGs, compensating for it with additional UPS energy capacities, to significantly cut costs and still be able to handle power outages lasting as high as 40 minutes (which constitute bulk of the outages). Further, we can push the limits of outage duration that can be handled in a cost-effective manner, if applications are willing to tolerate degraded performance during the outage. Our evaluations also show that different applications react differently to the outage handling mechanisms, and that the efficacy of the mechanisms is sensitive to the outage duration. The insights from this paper can spur new opportunities for future work on backup power infrastructure optimization.",
        "acm_key": "2541957",
        "bib_stats": {
            "cites": 17,
            "dl": 2,
            "dl_52": 336,
            "dl_6": 23
        },
        "key": "2541957",
        "text": "Ren-Shuo Liu , De-Yu Shen , Chia-Lin Yang , Shun-Chih Yu , Cheng-Yuan Michael Wang, NVM duet: unified working memory and persistent store architecture, Proceedings of the 19th international conference on Architectural support for programming languages and operating systems, March 01-05, 2014, Salt Lake City, Utah, USA  \u00a0[doi>"
    },
    "2554871": {
        "abstract": "Web applications are notoriously vulnerable to code injection attacks. Given that, practitioners need to assess the risk posed by applications due to code injection attacks to plan ahead on employing necessary mitigation approaches. This paper proposes a risk assessment approach for code injection vulnerability in web applications. We are motivated by the observation that traditional risk assessment approaches work well when quantitative values of specific parameters of the risk computation model is known in advance. In practice, they are difficult to predict correctly. Moreover, one specific code injection vulnerabilities can be exploited in different ways that may result in different types of severity level. Further, diverse types of injection vulnerabilities and their implications cannot be combined in existing approaches. To address these limitations, we propose a Fuzzy Logic-based System (FLS) to assess the risk due to different types of code injection vulnerabilities. Our further contribution is a set of proposed code-level metrics that can be used to establish the linguistic terms to express vulnerability levels and their impact subjectively. We apply nested FLS to combine risk from multiple vulnerabilities to assess a single value representing the overall risk. We evaluate our approach with three real-world web applications implemented in PHP, and apply for SQL Injection (SQLI) and Cross-Site Scripting (XSS), the two most widely reported vulnerabilities in today's web applications. The initial results indicate that the proposed approach can effectively assess high risks present in vulnerable applications.",
        "acm_key": "2554871",
        "bib_stats": {
            "cites": 1,
            "dl": 89,
            "dl_52": 19,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Lo:2014:INF:2554850.2554871,\n author = {Lo, Shi-wu and Chen, Bo-Hong and Chen, Yu-Wei and Shen, Tzu-Chieh and Lin, You-Ching},\n title = {ICAP, a New Flash Wear-leveling Algorithm Inspired by Locality},\n booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},\n series = {SAC '14},\n year = {2014},\n isbn = {978-1-4503-2469-4},\n location = {Gyeongju, Republic of Korea},\n pages = {1478--1483},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2554850.2554871},\n doi = {10.1145/2554850.2554871},\n acmid = {2554871},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {fast mounting, flash, flash translation layer, wear-leveling},\n} \r\n",
        "key": "2554871",
        "pub_year": "2014",
        "text": "Shi-wu Lo , Bo-Hong Chen , Yu-Wei Chen , Tzu-Chieh Shen , You-Ching Lin, ICAP, a new flash wear-leveling algorithm inspired by locality, Proceedings of the 29th Annual ACM Symposium on Applied Computing, March 24-28, 2014, Gyeongju, Republic of Korea"
    },
    "2554939": {
        "abstract": "Web applications are notoriously vulnerable to code injection attacks. Given that, practitioners need to assess the risk posed by applications due to code injection attacks to plan ahead on employing necessary mitigation approaches. This paper proposes a risk assessment approach for code injection vulnerability in web applications. We are motivated by the observation that traditional risk assessment approaches work well when quantitative values of specific parameters of the risk computation model is known in advance. In practice, they are difficult to predict correctly. Moreover, one specific code injection vulnerabilities can be exploited in different ways that may result in different types of severity level. Further, diverse types of injection vulnerabilities and their implications cannot be combined in existing approaches. To address these limitations, we propose a Fuzzy Logic-based System (FLS) to assess the risk due to different types of code injection vulnerabilities. Our further contribution is a set of proposed code-level metrics that can be used to establish the linguistic terms to express vulnerability levels and their impact subjectively. We apply nested FLS to combine risk from multiple vulnerabilities to assess a single value representing the overall risk. We evaluate our approach with three real-world web applications implemented in PHP, and apply for SQL Injection (SQLI) and Cross-Site Scripting (XSS), the two most widely reported vulnerabilities in today's web applications. The initial results indicate that the proposed approach can effectively assess high risks present in vulnerable applications.",
        "acm_key": "2554939",
        "bib_stats": {
            "cites": 0,
            "dl": 177,
            "dl_52": 59,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chang:2014:OFM:2554850.2554939,\n author = {Chang, Li-Pin and Huang, Sheng-Min and Li, Wen-Ping},\n title = {Optimizing FTL Mapping Cache for Random-write Workloads Using Adaptive Block Partitioning},\n booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},\n series = {SAC '14},\n year = {2014},\n isbn = {978-1-4503-2469-4},\n location = {Gyeongju, Republic of Korea},\n pages = {1504--1510},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2554850.2554939},\n doi = {10.1145/2554850.2554939},\n acmid = {2554939},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, SSD, flash storage},\n} \r\n",
        "key": "2554939",
        "pub_year": "2014",
        "text": "Li-Pin Chang , Sheng-Min Huang , Wen-Ping Li, Optimizing FTL mapping cache for random-write workloads using adaptive block partitioning, Proceedings of the 29th Annual ACM Symposium on Applied Computing, March 24-28, 2014, Gyeongju, Republic of Korea"
    },
    "2555699": {
        "abstract": "It is estimated that the human brain consumes a mere 20 watts of power as it perceives and comprehends the complex natural world. While the capability and efficiency of the human brain is indisputable, there are many perspectives on how to translate these efficiencies to algorithmic models and computational structures that are realizable on embedded platforms. Certainly, as advancements are made to neuromorphic vision models, identifying next generation compute architectures that exploit the inherent robustness of these models is critical to enabling compelling perceptual computing in future embedded devices. Unfortunately, executing perceptual computing applications on traditional CPU and GPU architectures will neither meet performance requirements nor the power constraints of future smartphones, smart watches, and wearable computing glasses. As such there has been increased interest in architecting and employing domain-specific accelerators that support a broad set of neuromorphic vision models. Accordingly, our research has focused on developing high performance neuromorphic accelerator architectures and System-on-Chip designs for resource and power constrained embedded platforms. While there is ongoing research on realizing brain-like hardware fabrics based on analog spiking networks, our work has mainly focused on realizing systems using digital accelerators. Attributed to the dataflow nature of neuromorphic algorithms, the need to implement complex and power consuming control-flow structures is reduced when mapping to custom hardware. Moreover, when appropriately mapped to streaming accelerators, costly off-chip memory accesses can be reduced significantly. The result of our work are several accelerators for image data fusion, bottom-up image saliency, scene GIST extraction, and cortical based object classification. These end-to-end pipelines have been architected with particular focus on maximizing performance per watt which is critical for integration into power constrained embedded platforms. Performance evaluations have shown that our accelerated neuromorphic vision systems exhibit several orders of energy efficiency over state-of-art machine vision implementations on multicore CPU and GPUs.",
        "acm_key": "2555699",
        "bib_stats": {
            "cites": 8,
            "dl": 284,
            "dl_52": 30,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chen:2013:DDH:2555692.2555699,\n author = {Chen, Renhai and Wang, Yi and Shao, Zili},\n title = {DHeating: Dispersed Heating Repair for Self-healing NAND Flash Memory},\n booktitle = {Proceedings of the Ninth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES+ISSS '13},\n year = {2013},\n isbn = {978-1-4799-1417-3},\n location = {Montreal, Quebec, Canada},\n pages = {7:1--7:10},\n articleno = {7},\n numpages = {10},\n url = {http://dl.acm.org/citation.cfm?id=2555692.2555699},\n acmid = {2555699},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {dispersed heating, flash memory, power consumption, self-healing, wear leveling},\n} \r\n",
        "key": "2555699",
        "pub_year": "2013",
        "text": "Renhai Chen , Yi Wang , Zili Shao, DHeating: dispersed heating repair for self-healing NAND flash memory, Proceedings of the Ninth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, September 29-October 04, 2013, Montreal, Quebec, Canada"
    },
    "2555753": {
        "abstract": "Homogeneous multiprocessor systems with reconfigurable area (also known as Reconfigurable Multiprocessor Systems) are emerging as a popular design choice in current and future technology nodes to meet the heterogeneous computing demand of a multitude of applications enabled on these platforms. Application specific mapping decisions on such a platform involve partitioning a given application into software tasks (executed on one or more of the general purpose processors, GPPs) and the hardware tasks (realized as dedicated hardware on the reconfigurable area) to optimize and/or satisfy design constraints such as reliability, performance and design cost. Improving the reliability considering transient faults by increasing the number of checkpoints negatively impacts the reliability considering permanent faults. This trade-off is ignored in all prior studies on task mapping and scheduling. This paper proposes an optimization technique to decide the optimal number of checkpoints for the software tasks which minimizes aging of the GPPs while maximizing the transient fault-tolerance of the overall platform (GPPs and the reconfigurable area) and satisfying design cost and performance. Experiments conducted with synthetic and real-life application task graphs (cyclic and acyclic) demonstrate that the proposed technique minimizes aging and improves the platform lifetime by an average 60% as compared to the existing transient fault-aware techniques. Further, a gradient-based heuristic is proposed to minimize the design space exploration time by upto 500\u00d7 with less than 5% deviation from optimal solution.",
        "acm_key": "2555753",
        "bib_stats": {
            "cites": 1,
            "dl": 134,
            "dl_52": 29,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Zhang:2013:ERE:2555729.2555753,\n author = {Zhang, Xian and Zhang, Chao and Sun, Guangyu and Di, Jia and Zhang, Tao},\n title = {An Efficient Run-time Encryption Scheme for Non-volatile Main Memory},\n booktitle = {Proceedings of the 2013 International Conference on Compilers, Architectures and Synthesis for Embedded Systems},\n series = {CASES '13},\n year = {2013},\n isbn = {978-1-4799-1400-5},\n location = {Montreal, Quebec, Canada},\n pages = {24:1--24:10},\n articleno = {24},\n numpages = {10},\n url = {http://dl.acm.org/citation.cfm?id=2555729.2555753},\n acmid = {2555753},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2555753",
        "pub_year": "2013",
        "text": "Xian Zhang , Chao Zhang , Guangyu Sun , Jia Di , Tao Zhang, An efficient run-time encryption scheme for non-volatile main memory, Proceedings of the 2013 International Conference on Compilers, Architectures and Synthesis for Embedded Systems, p.1-10, September 29-October 04, 2013, Montreal, Quebec, Canada"
    },
    "2558080": {
        "abstract": "In this paper, an approach is proposed which builds an efficient and effective model for heavy rain forecasting in 6 hours based on the past weather data. Since the weather data has a huge amount of information, in order to build efficient and effective heavy rain prediction models, we need to find proper weather attributes, isobaric surfaces and suitable range for experiments. First, we have the candidate weather attributes with expert knowledge and evaluate those attributes using machine learning approach, Support Vector Machine (SVM). After the evaluation, we find out the best resulted 3 pairs of an attribute and an isobaric surface, and combine those to have better performance in prediction. The combination of high performed weather attributes showed better performance than the combined attributes which was recommended by the experts. We next figure out how the range of area affect in prediction. After the experiments, dimensions of the best resulted data were 4,800, which will be used as the inputs to prediction models. Even though we have dramatically reduced the number of dimension compared to the original weather data, it still is not proper for heavy rain forecasting in 6 hours. The running time of the model to produce an output with 4,800 dimensions of input takes about 2 minutes. However, 2 minute is not short enough since every local place may needs to predict heavy rain with their own local heavy rain cases for more accurate weather forecasting. If there are 30 local places, it would take an hour to produce outputs for all local places. An hour is not feasible to predict heavy rain in 6 hours. Therefore, in order to build more efficient models, we apply Genetic Algorithm (GA) to find a much smaller set of inputs without degrading performance. After running GA, 4,800 inputs are reduced 757 inputs and the running time of the model with 757 inputs is 1/8 of the model with 4,800 inputs. Finally, we compare the performance between the proposed GA and the information gain (IG) based feature selection method and prove our proposed GA selected more efficient features to predict heavy rain cases.",
        "acm_key": "2558080",
        "bib_stats": {
            "cites": 0,
            "dl": 120,
            "dl_52": 17,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Chang:2014:ARA:2557977.2558080,\n author = {Chang, Yu-Ming and Chang, Yuan-Hao and Huang, Po-Chun and Hsu, Shou-Chieh and Kuo, Tei-Wei},\n title = {Adaptive Range-based Address Mapping for the Flash Storage Devices with Explosive Capacity},\n booktitle = {Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication},\n series = {ICUIMC '14},\n year = {2014},\n isbn = {978-1-4503-2644-5},\n location = {Siem Reap, Cambodia},\n pages = {40:1--40:8},\n articleno = {40},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2557977.2558080},\n doi = {10.1145/2557977.2558080},\n acmid = {2558080},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, flash management, flash translation layer, storage system},\n} \r\n",
        "key": "2558080",
        "pub_year": "2014",
        "text": "Yu-Ming Chang , Yuan-Hao Chang , Po-Chun Huang , Shou-Chieh Hsu , Tei-Wei Kuo, Adaptive range-based address mapping for the flash storage devices with explosive capacity, Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication, p.1-8, January 09-11, 2014, Siem Reap, Cambodia"
    },
    "2558427": {
        "abstract": "Phase Change RAM (PRAM) is a candidate to replace DRAM main memory due to its low idle power consumption and high scalability. However, its latency and endurance have generated problems in fulfilling its main memory role. The latency can be treated with a DRAM buffer, but the endurance problem remains, with three critical points that need to be improved despite the use of, existing wear-leveling algorithms. First, existing DRAM buffering schemes do not consider write count distribution. Second, swapping and shifting operations are performed statically. Finally, swapping and shifting operations are loosely coupled with a DRAM buffer. As a remedy to these drawbacks, we propose an adaptive wear-leveling algorithm that consists of three novel schemes for PRAM main memory with a DRAM buffer. The PRAM-aware DRAM buffering scheme reduces the write count and prevents skewed writing by considering the write count and clean data based on the least recently used (LRU) scheme. The adaptive multiple swapping and shifting scheme makes the write count even with the dynamic operation timing, the number of swapping pages being based on the workload pattern. Our DRAM buffer-aware swapping and shifting scheme reduces overhead by curbing additional swapping and shifting operations, thus reducing unnecessary write operations. To evaluate the wear-leveling effect, we have implemented a PIN-based wear-leveling simulator. The evaluation confirms that the PRAM lifetime increases from 0.68 years with the previous wear-leveling algorithm to 5.32 years with the adaptive wear-leveling algorithm.",
        "acm_key": "2558427",
        "bib_stats": {
            "cites": 0,
            "dl": 465,
            "dl_52": 33,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Park:2014:AWA:2592905.2558427,\n author = {Park, Sung Kyu and Maeng, Min Kyu and Park, Ki-Woong and Park, Kyu Ho},\n title = {Adaptive Wear-leveling Algorithm for PRAM Main Memory with a DRAM Buffer},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {November 2014},\n volume = {13},\n number = {4},\n month = mar,\n year = {2014},\n issn = {1539-9087},\n pages = {88:1--88:25},\n articleno = {88},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2558427},\n doi = {10.1145/2558427},\n acmid = {2558427},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Adaptive wear-leveling, DRAM buffering, PIN-based simulator, PRAM main memory, swapping and shifting},\n} \r\n",
        "key": "2558427",
        "pub_year": "2014",
        "text": "Sung Kyu Park , Min Kyu Maeng , Ki-Woong Park , Kyu Ho Park, Adaptive wear-leveling algorithm for PRAM main memory with a DRAM buffer, ACM Transactions on Embedded Computing Systems (TECS), v.13 n.4, p.1-25, Feburary 2014"
    },
    "2577556": {
        "abstract": "In recent years, several approaches have been proposed for sentiment based classification of online text. Out of the different contemporary approaches, supervised machine learning techniques like Naive Bayes (NB) and Support Vector Machines (SVM) are found to be very effective, as reported in literature. However, some studies have reported that the conditional independence assumption of NB makes feature selection a crucial problem. Moreover, SVM also suffers from other issues like selection of kernel functions, skewed vector spaces and heterogeneity in the training examples. In this paper, we propose a hybrid method by integrating \"weak\" support vector machine classifiers using boosting techniques. The proposed model exploits classification performance of Boosting while using SVM as the base classifier, applied for sentiment based classification of online reviews. The results on movies and hotel review corpora of 2000 reviews have shown that the proposed approach has succeeded in improving the performance of SVM. The resultant ensemble classifier has performed better than the single base SVM classifier, and the results confirm that ensemble SVM with boosting, significantly outperforms single SVM in terms of accuracy.",
        "acm_key": "2577556",
        "bib_stats": {
            "cites": 0,
            "dl": 96,
            "dl_52": 17,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Huang:2013:MHC:2577554.2577556,\n author = {Huang, Po-Chun and Chang, Yuan-Hao and Tsao, Che-Wei and Yang, Ming-Chang and Hsieh, Cheng-Kang},\n title = {Migration-based Hybrid Cache Design for File Systems over Flash Storage Devices},\n journal = {SIGAPP Appl. Comput. Rev.},\n issue_date = {December 2013},\n volume = {13},\n number = {4},\n month = dec,\n year = {2013},\n issn = {1559-6915},\n pages = {8--16},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/2577554.2577556},\n doi = {10.1145/2577554.2577556},\n acmid = {2577556},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {file system, flash memory, hybrid cache, non-volatile RAM (NVRAM)},\n} \r\n",
        "key": "2577556",
        "pub_year": "2013",
        "text": "Po-Chun Huang , Yuan-Hao Chang , Che-Wei Tsao , Ming-Chang Yang , Cheng-Kang Hsieh, Migration-based hybrid cache design for file systems over flash storage devices, ACM SIGAPP Applied Computing Review, v.13 n.4, December 2013"
    },
    "2579671": {
        "abstract": "Compiler-based auto-parallelization is a much-studied area but has yet to find widespread application. This is largely due to the poor identification and exploitation of application parallelism, resulting in disappointing performance far below that which a skilled expert programmer could achieve. We have identified two weaknesses in traditional parallelizing compilers and propose a novel, integrated approach resulting in significant performance improvements of the generated parallel code. Using profile-driven parallelism detection, we overcome the limitations of static analysis, enabling the identification of more application parallelism, and only rely on the user for final approval. We then replace the traditional target-specific and inflexible mapping heuristics with a machine-learning-based prediction mechanism, resulting in better mapping decisions while automating adaptation to different target architectures. We have evaluated our parallelization strategy on the NAS and SPEC CPU2000 benchmarks and two different multicore platforms (dual quad-core Intel Xeon SMP and dual-socket QS20 Cell blade). We demonstrate that our approach not only yields significant improvements when compared with state-of-the-art parallelizing compilers but also comes close to and sometimes exceeds the performance of manually parallelized codes. On average, our methodology achieves 96&percnt; of the performance of the hand-tuned OpenMP NAS and SPEC parallel benchmarks on the Intel Xeon platform and gains a significant speedup for the IBM Cell platform, demonstrating the potential of profile-guided and machine-learning- based parallelization for complex multicore platforms.",
        "acm_key": "2579671",
        "bib_stats": {
            "cites": 1,
            "dl": 517,
            "dl_52": 30,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Wang:2014:ECL:2591460.2579671,\n author = {Wang, Jue and Dong, Xiangyu and Xie, Yuan and Jouppi, Norman P.},\n title = {Endurance-aware Cache Line Management for Non-volatile Caches},\n journal = {ACM Trans. Archit. Code Optim.},\n issue_date = {February 2014},\n volume = {11},\n number = {1},\n month = feb,\n year = {2014},\n issn = {1544-3566},\n pages = {4:1--4:25},\n articleno = {4},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2579671},\n doi = {10.1145/2579671},\n acmid = {2579671},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache, interset write variation, intraset write variation, lifetime improvement, wear leveling, write endurance},\n} \r\n",
        "key": "2579671",
        "pub_year": "2014",
        "text": "Jue Wang , Xiangyu Dong , Yuan Xie , Norman P. Jouppi, Endurance-aware cache line management for non-volatile caches, ACM Transactions on Architecture and Code Optimization (TACO), v.11 n.1, p.1-25, February 2014"
    },
    "2591278": {
        "abstract": "Conventional error correction codes (ECCs), such as the commonly used BCH code, have become increasingly inadequate for solid state drives (SSDs) as the capacity of NAND flash memory continues to increase and its reliability continues to degrade. It is highly desirable to deploy a much more powerful ECC, such as low-density parity-check (LDPC) code, to significantly improve the reliability of SSDs. Although LDPC code has had its success in commercial hard disk drives, to fully exploit its error correction capability in SSDs demands unconventional fine-grained flash memory sensing, leading to an increased memory read latency. To address this important but largely unexplored issue, this paper presents three techniques to mitigate the LDPC-induced response time delay so that SSDs can benefit its strong error correction capability to the full extent. We quantitatively evaluate these techniques by carrying out trace-based SSD simulations with runtime characterization of NAND flash memory reliability and LDPC code decoding. Our study based on intensive experiments shows that these techniques used in an integrated way in SSDs can reduce the worst-case system read response time delay from over 100% down to below 20%. With our proposed techniques, a strong ECC alternative can be used in NAND flash memory to retain its reliability to respond the continuous cost reduction, and its relatively small increase of response time delay is acceptable to mainstream application users, considering a huge gain in SSD capacity, its reliability, and the price reduction.",
        "acm_key": "2591278",
        "bib_stats": {
            "cites": 25,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Koller:2013:WPH:2591272.2591278,\n author = {Koller, Ricardo and Marmol, Leonardo and Rangaswami, Raju and Sundararaman, Swaminathan and Talagala, Nisha and Zhao, Ming},\n title = {Write Policies for Host-side Flash Caches},\n booktitle = {Proceedings of the 11th USENIX Conference on File and Storage Technologies},\n series = {FAST'13},\n year = {2013},\n location = {San Jose, CA},\n pages = {45--58},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2591272.2591278},\n acmid = {2591278},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2591278",
        "pub_year": "2013",
        "text": "Ricardo Koller , Leonardo Marmol , Raju Rangaswami , Swaminathan Sundararaman , Nisha Talagala , Ming Zhao, Write policies for host-side flash caches, Proceedings of the 11th USENIX conference on File and Storage Technologies, February 12-15, 2013, San Jose, CA"
    },
    "2591300": {
        "abstract": "Conventional error correction codes (ECCs), such as the commonly used BCH code, have become increasingly inadequate for solid state drives (SSDs) as the capacity of NAND flash memory continues to increase and its reliability continues to degrade. It is highly desirable to deploy a much more powerful ECC, such as low-density parity-check (LDPC) code, to significantly improve the reliability of SSDs. Although LDPC code has had its success in commercial hard disk drives, to fully exploit its error correction capability in SSDs demands unconventional fine-grained flash memory sensing, leading to an increased memory read latency. To address this important but largely unexplored issue, this paper presents three techniques to mitigate the LDPC-induced response time delay so that SSDs can benefit its strong error correction capability to the full extent. We quantitatively evaluate these techniques by carrying out trace-based SSD simulations with runtime characterization of NAND flash memory reliability and LDPC code decoding. Our study based on intensive experiments shows that these techniques used in an integrated way in SSDs can reduce the worst-case system read response time delay from over 100% down to below 20%. With our proposed techniques, a strong ECC alternative can be used in NAND flash memory to retain its reliability to respond the continuous cost reduction, and its relatively small increase of response time delay is acceptable to mainstream application users, considering a huge gain in SSD capacity, its reliability, and the price reduction.",
        "acm_key": "2591300",
        "bib_stats": {
            "cites": 11,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zheng:2013:URS:2591272.2591300,\n author = {Zheng, Mai and Tucek, Joseph and Qin, Feng and Lillibridge, Mark},\n title = {Understanding the Robustness of SSDS Under Power Fault},\n booktitle = {Proceedings of the 11th USENIX Conference on File and Storage Technologies},\n series = {FAST'13},\n year = {2013},\n location = {San Jose, CA},\n pages = {271--284},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2591272.2591300},\n acmid = {2591300},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2591300",
        "pub_year": "2013",
        "text": "Mai Zheng , Joseph Tucek , Feng Qin , Mark Lillibridge, Understanding the robustness of SSDS under power fault, Proceedings of the 11th USENIX conference on File and Storage Technologies, February 12-15, 2013, San Jose, CA"
    },
    "2591307": {
        "abstract": "The cost-per-bit of NAND flash memory has been continuously improved by semiconductor process scaling and multi-leveling technologies (e.g., a 10 nm-node TLC device). However, the decreasing lifetime of NAND flash memory as a side effect of recent advanced technologies is regarded as a main barrier for a wide adoption of NAND flash-based storage systems. In this paper, we propose a new system-level approach, called dynamic program and erase scaling (DPES), for improving the lifetime (particularly, endurance) of NAND flash memory. The DPES approach is based on our key observation that changing the erase voltage as well as the erase time significantly affects the NAND endurance. By slowly erasing a NAND blockwith a lower erase voltage, we can improve the NAND endurance very effectively. By modifying NAND chips to support multiple write and erase modes with different operation voltages and times, DPES enables a flash software to exploit the new tradeoff relationships between the NAND endurance and erase voltage/ speed under dynamic program and erase scaling. We have implemented the first DPES-aware FTL, called autoFTL, which improves the NAND endurance with a negligible degradation in the overall write throughput. Our experimental results using various I/O traces show that autoFTL can improve the maximum number of P/E cycles by 61.2% over an existing DPES-unaware FTL with less than 2.2% decrease in the overall write throughput.",
        "acm_key": "2591307",
        "bib_stats": {
            "cites": 21,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Rumble:2014:LMD:2591305.2591307,\n author = {Rumble, Stephen M. and Kejriwal, Ankita and Ousterhout, John},\n title = {Log-structured Memory for DRAM-based Storage},\n booktitle = {Proceedings of the 12th USENIX Conference on File and Storage Technologies},\n series = {FAST'14},\n year = {2014},\n isbn = {978-1-931971-08-9},\n location = {Santa Clara, CA},\n pages = {1--16},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=2591305.2591307},\n acmid = {2591307},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2591307",
        "pub_year": "2014",
        "text": "Stephen M. Rumble , Ankita Kejriwal , John Ousterhout, Log-structured memory for DRAM-based storage, Proceedings of the 12th USENIX conference on File and Storage Technologies, February 17-20, 2014, Santa Clara, CA"
    },
    "2591308": {
        "abstract": "The cost-per-bit of NAND flash memory has been continuously improved by semiconductor process scaling and multi-leveling technologies (e.g., a 10 nm-node TLC device). However, the decreasing lifetime of NAND flash memory as a side effect of recent advanced technologies is regarded as a main barrier for a wide adoption of NAND flash-based storage systems. In this paper, we propose a new system-level approach, called dynamic program and erase scaling (DPES), for improving the lifetime (particularly, endurance) of NAND flash memory. The DPES approach is based on our key observation that changing the erase voltage as well as the erase time significantly affects the NAND endurance. By slowly erasing a NAND blockwith a lower erase voltage, we can improve the NAND endurance very effectively. By modifying NAND chips to support multiple write and erase modes with different operation voltages and times, DPES enables a flash software to exploit the new tradeoff relationships between the NAND endurance and erase voltage/ speed under dynamic program and erase scaling. We have implemented the first DPES-aware FTL, called autoFTL, which improves the NAND endurance with a negligible degradation in the overall write throughput. Our experimental results using various I/O traces show that autoFTL can improve the maximum number of P/E cycles by 61.2% over an existing DPES-unaware FTL with less than 2.2% decrease in the overall write throughput.",
        "acm_key": "2591308",
        "bib_stats": {
            "cites": 15,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Cully:2014:SSH:2591305.2591308,\n author = {Cully, Brendan and Wires, Jake and Meyer, Dutch and Jamieson, Kevin and Fraser, Keir and Deegan, Tim and Stodden, Daniel and Lefebvre, Geoffrey and Ferstay, Daniel and Warfield, Andrew},\n title = {Strata: Scalable High-performance Storage on Virtualized Non-volatile Memory},\n booktitle = {Proceedings of the 12th USENIX Conference on File and Storage Technologies},\n series = {FAST'14},\n year = {2014},\n isbn = {978-1-931971-08-9},\n location = {Santa Clara, CA},\n pages = {17--31},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=2591305.2591308},\n acmid = {2591308},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2591308",
        "pub_year": "2014",
        "text": "Brendan Cully , Jake Wires , Dutch Meyer , Kevin Jamieson , Keir Fraser , Tim Deegan , Daniel Stodden , Geoffrey Lefebvre , Daniel Ferstay , Andrew Warfield, Strata: scalable high-performance storage on virtualized non-volatile memory, Proceedings of the 12th USENIX conference on File and Storage Technologies, February 17-20, 2014, Santa Clara, CA"
    },
    "2591309": {
        "abstract": "The cost-per-bit of NAND flash memory has been continuously improved by semiconductor process scaling and multi-leveling technologies (e.g., a 10 nm-node TLC device). However, the decreasing lifetime of NAND flash memory as a side effect of recent advanced technologies is regarded as a main barrier for a wide adoption of NAND flash-based storage systems. In this paper, we propose a new system-level approach, called dynamic program and erase scaling (DPES), for improving the lifetime (particularly, endurance) of NAND flash memory. The DPES approach is based on our key observation that changing the erase voltage as well as the erase time significantly affects the NAND endurance. By slowly erasing a NAND blockwith a lower erase voltage, we can improve the NAND endurance very effectively. By modifying NAND chips to support multiple write and erase modes with different operation voltages and times, DPES enables a flash software to exploit the new tradeoff relationships between the NAND endurance and erase voltage/ speed under dynamic program and erase scaling. We have implemented the first DPES-aware FTL, called autoFTL, which improves the NAND endurance with a negligible degradation in the overall write throughput. Our experimental results using various I/O traces show that autoFTL can improve the maximum number of P/E cycles by 61.2% over an existing DPES-unaware FTL with less than 2.2% decrease in the overall write throughput.",
        "acm_key": "2591309",
        "bib_stats": {
            "cites": 33,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2014:EPC:2591305.2591309,\n author = {Kim, Hyojun and Seshadri, Sangeetha and Dickey, Clement L. and Chiu, Lawrence},\n title = {Evaluating Phase Change Memory for Enterprise Storage Systems: A Study of Caching and Tiering Approaches},\n booktitle = {Proceedings of the 12th USENIX Conference on File and Storage Technologies},\n series = {FAST'14},\n year = {2014},\n isbn = {978-1-931971-08-9},\n location = {Santa Clara, CA},\n pages = {33--45},\n numpages = {13},\n url = {http://dl.acm.org/citation.cfm?id=2591305.2591309},\n acmid = {2591309},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2591309",
        "pub_year": "2014",
        "text": "Hyojun Kim , Sangeetha Seshadri , Clement L. Dickey , Lawrence Chiu, Evaluating phase change memory for enterprise storage systems: a study of caching and tiering approaches, Proceedings of the 12th USENIX conference on File and Storage Technologies, February 17-20, 2014, Santa Clara, CA"
    },
    "2591594": {
        "abstract": "Ubiquitous access to computers, cell phones, internet, personal digital devices, cameras and TV can be attributed to advances in the very large scale integration (VLSI) technology and the advances in circuit design to operate circuits at Gigahertz rates. One of the mysteries that we have not been able to unravel is the understanding of how the brain works from different perspectives. Reverse engineering the brain has been identified as one of the grand challenge problems by the National Academies. Advances in sensor technologies and imaging modalities such as electroencephalogram (EEG), intra-cranial electroencephalogram (iEEG), magnetoencephalogram (MEG), and magnetic resonance imaging (MRI) allow us to collect data from hundreds of electrodes from the brain at sample rates ranging from 256 Hz to 15kHz. These data can be key to not only understanding brain functioning and brain connectivity at macro and micro levels in healthy subjects but also in identifying patients with neurological and mental disorder. Extracting the appropriate biomarkers using spectral-temporal-spatial signal processing approaches and classifying states using machine learning approaches can assist clinicians in predicting and detecting seizures in epileptic patients, and in identifying patients with mental disorder such as schizophrenia, depression and personality disorder. The biomarkers can be tracked to design personalized therapy and effectiveness of therapy by closed loop drug delivery or closed loop neuromodulation, i.e., brain stimulation either by invasive or non-invasive means using electrical or magnetic stimulation. High-performance VLSI system design is critical to not-only increasing battery life of VLSI chips for neuromodulation but also for reducing computation time by orders of magnitude in analyzing MRI signals. Another grand challenge problem identified by the National Academies is Advanced Health Informatics. Analysis of health data is key to monitoring biomarkers and delivering drugs as needed. VLSI system design of biomarkers and disease state classification is again critical in improving the health and quality of life of human beings.",
        "acm_key": "2591594",
        "bib_stats": {
            "cites": 4,
            "dl": 296,
            "dl_52": 61,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Papandreou:2014:UAR:2591513.2591594,\n author = {Papandreou, Nikolaos and Parnell, Thomas and Pozidis, Haralampos and Mittelholzer, Thomas and Eleftheriou, Evangelos and Camp, Charles and Griffin, Thomas and Tressler, Gary and Walls, Andrew},\n title = {Using Adaptive Read Voltage Thresholds to Enhance the Reliability of MLC NAND Flash Memory Systems},\n booktitle = {Proceedings of the 24th Edition of the Great Lakes Symposium on VLSI},\n series = {GLSVLSI '14},\n year = {2014},\n isbn = {978-1-4503-2816-6},\n location = {Houston, Texas, USA},\n pages = {151--156},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2591513.2591594},\n doi = {10.1145/2591513.2591594},\n acmid = {2591594},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {characterization, nand flash, signal processing},\n} \r\n",
        "key": "2591594",
        "pub_year": "2014",
        "text": "Nikolaos Papandreou , Thomas Parnell , Haralampos Pozidis , Thomas Mittelholzer , Evangelos Eleftheriou , Charles Camp , Thomas Griffin , Gary Tressler , Andrew Walls, Using adaptive read voltage thresholds to enhance the reliability of MLC NAND flash memory systems, Proceedings of the 24th edition of the great lakes symposium on VLSI, May 21-23, 2014, Houston, Texas, USA  \u00a0[doi>"
    },
    "2592804": {
        "abstract": "The recent availability of Intel Haswell processors marks the transition of hardware transactional memory from research toys to mainstream reality. DBX is an in-memory database that uses Intel's restricted transactional memory (RTM) to achieve high performance and good scalability across multi-core machines. The main limitation (and also key to practicality) of RTM is its constrained working set size: an RTM region that reads or writes too much data will always be aborted. The design of DBX addresses this challenge in several ways. First, DBX builds a database transaction layer on top of an underlying shared-memory store. The two layers use separate RTM regions to synchronize shared memory access. Second, DBX uses optimistic concurrency control to separate transaction execution from its commit. Only the commit stage uses RTM for synchronization. As a result, the working set of the RTMs used scales with the meta-data of reads and writes in a database transaction as opposed to the amount of data read/written. Our evaluation using TPC-C workload mix shows that DBX achieves 506,817 transactions per second on a 4-core machine.",
        "acm_key": "2592804",
        "bib_stats": {
            "cites": 16,
            "dl": 904,
            "dl_52": 256,
            "dl_6": 21
        },
        "bibtex": "\r\n@inproceedings{Wang:2014:EDI:2592798.2592804,\n author = {Wang, Peng and Sun, Guangyu and Jiang, Song and Ouyang, Jian and Lin, Shiding and Zhang, Chen and Cong, Jason},\n title = {An Efficient Design and Implementation of LSM-tree Based Key-value Store on Open-channel SSD},\n booktitle = {Proceedings of the Ninth European Conference on Computer Systems},\n series = {EuroSys '14},\n year = {2014},\n isbn = {978-1-4503-2704-6},\n location = {Amsterdam, The Netherlands},\n pages = {16:1--16:14},\n articleno = {16},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2592798.2592804},\n doi = {10.1145/2592798.2592804},\n acmid = {2592804},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash, key-value store, log-structured merge tree, solid state disk},\n} \r\n",
        "key": "2592804",
        "pub_year": "2014",
        "text": "Peng Wang , Guangyu Sun , Song Jiang , Jian Ouyang , Shiding Lin , Chen Zhang , Jason Cong, An efficient design and implementation of LSM-tree based key-value store on open-channel SSD, Proceedings of the Ninth European Conference on Computer Systems, April 14-16, 2014, Amsterdam, The Netherlands"
    },
    "2597661": {
        "abstract": "Fast Fourier Transform (FFT) is frequently invoked in stream processing, e.g., calculating the spectral representation of audio/video frames, and in many cases the inputs are sparse, i.e., most of the inputs' Fourier coefficients being zero. Many sparse FFT algorithms have been proposed to improve FFT's efficiency when inputs are known to be sparse. However, like their \"dense\" counterparts, existing sparse FFT implementations are input oblivious in the sense that how the algorithms work is not affected by the value of input. The sparse FFT computation on one frame is exactly the same as the computation on the next frame. This paper improves upon existing sparse FFT algorithms by simultaneously exploiting the input sparsity and the similarity between adjacent inputs in stream processing. Our algorithm detects and takes advantage of the similarity between input samples to automatically design and customize sparse filters that lead to better parallelism and performance. More specifically, we develop an efficient heuristic to detect the similarity between the current input to its predecessor in stream processing, and when it is found to be similar, we novelly use the spectral representation of the predecessor to accelerate the sparse FFT computation on the current input. Given a sparse signal that has only $k$ non-zero Fourier coefficients, our algorithm utilizes sparse approximation by tuning several adaptive filters to efficiently package the non-zero Fourier coefficients into a small number of bins which can then be estimated accurately. Therefore, our algorithm has runtime sub-linear to the input size and gets rid of recursive coefficient estimation, both of which improve parallelism and performance. Furthermore, the new heuristic can detect the discontinuities inside the streams and resumes the input adaptation very quickly. We evaluate our input-adaptive sparse FFT implementation on Intel i7 CPU and three NVIDIA GPUs, i.e., NVIDIA GeForce GTX480, Tesla C2070 and Tesla C2075. Our algorithm is faster than previous FFT implementations both in theory and implementation. For inputs with size N=2^{24}, our parallel implementation outperforms FFTW for k up to 2^{18}, which is an order of magnitude higher than prior sparse algorithms. Furthermore, our input adaptive sparse FFT on Tesla C2075 GPU achieves up to 77.2x and 29.3x speedups over 1-thread and 4-thread FFTW, 10.7x, 6.4x, 5.2x speedups against sFFT 1.0, sFFT 2.0, CUFFT, and 6.9x speedup over our sequential CPU performance, respectively.",
        "acm_key": "2597661",
        "bib_stats": {
            "cites": 3,
            "dl": 311,
            "dl_52": 41,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Xia:2014:DDW:2597652.2597661,\n author = {Xia, Fei and Jiang, Dejun and Xiong, Jin and Chen, Mingyu and Zhang, Lixin and Sun, Ninghui},\n title = {DWC: Dynamic Write Consolidation for Phase Change Memory Systems},\n booktitle = {Proceedings of the 28th ACM International Conference on Supercomputing},\n series = {ICS '14},\n year = {2014},\n isbn = {978-1-4503-2642-1},\n location = {Munich, Germany},\n pages = {211--220},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2597652.2597661},\n doi = {10.1145/2597652.2597661},\n acmid = {2597661},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {performance optimization, phase change memory, write consolidation},\n} \r\n",
        "key": "2597661",
        "pub_year": "2014",
        "text": "Fei Xia , Dejun Jiang , Jin Xiong , Mingyu Chen , Lixin Zhang , Ninghui Sun, DWC: dynamic write consolidation for phase change memory systems, Proceedings of the 28th ACM international conference on Supercomputing, June 10-13, 2014, Munich, Germany"
    },
    "2597681": {
        "abstract": "Fast Fourier Transform (FFT) is frequently invoked in stream processing, e.g., calculating the spectral representation of audio/video frames, and in many cases the inputs are sparse, i.e., most of the inputs' Fourier coefficients being zero. Many sparse FFT algorithms have been proposed to improve FFT's efficiency when inputs are known to be sparse. However, like their \"dense\" counterparts, existing sparse FFT implementations are input oblivious in the sense that how the algorithms work is not affected by the value of input. The sparse FFT computation on one frame is exactly the same as the computation on the next frame. This paper improves upon existing sparse FFT algorithms by simultaneously exploiting the input sparsity and the similarity between adjacent inputs in stream processing. Our algorithm detects and takes advantage of the similarity between input samples to automatically design and customize sparse filters that lead to better parallelism and performance. More specifically, we develop an efficient heuristic to detect the similarity between the current input to its predecessor in stream processing, and when it is found to be similar, we novelly use the spectral representation of the predecessor to accelerate the sparse FFT computation on the current input. Given a sparse signal that has only $k$ non-zero Fourier coefficients, our algorithm utilizes sparse approximation by tuning several adaptive filters to efficiently package the non-zero Fourier coefficients into a small number of bins which can then be estimated accurately. Therefore, our algorithm has runtime sub-linear to the input size and gets rid of recursive coefficient estimation, both of which improve parallelism and performance. Furthermore, the new heuristic can detect the discontinuities inside the streams and resumes the input adaptation very quickly. We evaluate our input-adaptive sparse FFT implementation on Intel i7 CPU and three NVIDIA GPUs, i.e., NVIDIA GeForce GTX480, Tesla C2070 and Tesla C2075. Our algorithm is faster than previous FFT implementations both in theory and implementation. For inputs with size N=2^{24}, our parallel implementation outperforms FFTW for k up to 2^{18}, which is an order of magnitude higher than prior sparse algorithms. Furthermore, our input adaptive sparse FFT on Tesla C2075 GPU achieves up to 77.2x and 29.3x speedups over 1-thread and 4-thread FFTW, 10.7x, 6.4x, 5.2x speedups against sFFT 1.0, sFFT 2.0, CUFFT, and 6.9x speedup over our sequential CPU performance, respectively.",
        "acm_key": "2597681",
        "bib_stats": {
            "cites": 4,
            "dl": 298,
            "dl_52": 71,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Wang:2014:UIT:2597652.2597681,\n author = {Wang, Wei and Xie, Tao and Zhou, Deng},\n title = {Understanding the Impact of Threshold Voltage on MLC Flash Memory Performance and Reliability},\n booktitle = {Proceedings of the 28th ACM International Conference on Supercomputing},\n series = {ICS '14},\n year = {2014},\n isbn = {978-1-4503-2642-1},\n location = {Munich, Germany},\n pages = {201--210},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2597652.2597681},\n doi = {10.1145/2597652.2597681},\n acmid = {2597681},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {mlc flash, p/e performance, reliability, solid state disk, threshold voltage},\n} \r\n",
        "key": "2597681",
        "pub_year": "2014",
        "text": "Wei Wang , Tao Xie , Deng Zhou, Understanding the impact of threshold voltage on MLC flash memory performance and reliability, Proceedings of the 28th ACM international conference on Supercomputing, June 10-13, 2014, Munich, Germany"
    },
    "2611372": {
        "abstract": "As the size of cloud systems and the number of hosted VMs rapidly grow, the scalability of shared VM storage systems becomes a serious issue. Client-side flash-based caching has the potential to improve the performance of cloud VM storage by employing flash storage available on the client-side of the storage system to exploit the locality inherent in VM IOs. However, because of the limited capacity and durability of flash storage, it is important to determine the proper size and configuration of the flash caches used in cloud systems. This paper provides answers to the key design questions of cloud flash caching based on dm-cache, a block-level caching solution customized for cloud environments, and a large amount of long-term traces collected from real-world public and private clouds. The study first validates that cloud workloads have good cacheability and dm-cache-based flash caching incurs low overhead with respect to commodity flash devices. It further reveals that write-back caching substantially outperforms write-through caching in typical cloud environments due to the reduction of server IO load. It also shows that there is a tradeoff on making a flash cache persistent across client restarts which saves hours of cache warm-up time but incurs considerable overhead from committing every metadata update persistently. Finally, to reduce the data loss risk from using write-back caching, the paper proposes a new cache-optimized RAID technique, which minimizes the RAID overhead by introducing redundancy of cache dirty data only, and shows to be significantly faster than traditional RAID and write-through caching.",
        "acm_key": "2611372",
        "bib_stats": {
            "cites": 9,
            "dl": 197,
            "dl_52": 42,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Arteaga:2014:CFC:2611354.2611372,\n author = {Arteaga, Dulcardo and Zhao, Ming},\n title = {Client-side Flash Caching for Cloud Systems},\n booktitle = {Proceedings of International Conference on Systems and Storage},\n series = {SYSTOR 2014},\n year = {2014},\n isbn = {978-1-4503-2920-0},\n location = {Haifa, Israel},\n pages = {7:1--7:11},\n articleno = {7},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2611354.2611372},\n doi = {10.1145/2611354.2611372},\n acmid = {2611372},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2611372",
        "pub_year": "2014",
        "text": "Dulcardo Arteaga , Ming Zhao, Client-side Flash Caching for Cloud Systems, Proceedings of International Conference on Systems and Storage, June 30-July 02, 2014, Haifa, Israel  \u00a0[doi>"
    },
    "2616486": {
        "abstract": "Exploiting the increasingly wide use of Light-emitting Diode (LED) lighting, in this paper, we study the problem of using visible LED lights for accurate localization. The basic idea is to leverage the existing lighting infrastructure and apply trilateration to localize any devices with light sensing capability (e.g., a smartphone), using LED lamps as anchors. Through the design of Epsilon, we identify and tackle several technique challenges. In particular, we establish and experimentally verify the optical channel model for localization. We adopt BFSK and channel hopping to enable reliable location beaconing from multiple, uncoordinated light sources over the shared optical medium. We handle realistic situations towards robust localization, for example, we exploit user involvement to resolve the ambiguity in case of insufficient LED anchors. We have implemented the Epsilon system and evaluated it with a small scale hardware testbed as well as moderate-size simulations. Experimental results confirmed the effectiveness of Epsilon: the 90th percentile accuracies are 0.4m, 0.7m and 0.8m for three typical office environments. Even in the extreme situation with a single light, the 90th percentile accuracy is 1.1m. We believe that visible light based localization is promising to significantly improve the positioning accuracy, despite few open problems in practice.",
        "acm_key": "2616486",
        "bib_stats": {
            "cites": 73,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Dragojevic:2014:FFR:2616448.2616486,\n author = {Dragojevi\\'{c}, Aleksandar and Narayanan, Dushyanth and Hodson, Orion and Castro, Miguel},\n title = {FaRM: Fast Remote Memory},\n booktitle = {Proceedings of the 11th USENIX Conference on Networked Systems Design and Implementation},\n series = {NSDI'14},\n year = {2014},\n isbn = {978-1-931971-09-6},\n location = {Seattle, WA},\n pages = {401--414},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2616448.2616486},\n acmid = {2616486},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2616486",
        "pub_year": "2014",
        "text": "Aleksandar Dragojevi\u0107 , Dushyanth Narayanan , Orion Hodson , Miguel Castro, FaRM: fast remote memory, Proceedings of the 11th USENIX Conference on Networked Systems Design and Implementation, April 02-04, 2014, Seattle, WA"
    },
    "2616488": {
        "abstract": "Exploiting the increasingly wide use of Light-emitting Diode (LED) lighting, in this paper, we study the problem of using visible LED lights for accurate localization. The basic idea is to leverage the existing lighting infrastructure and apply trilateration to localize any devices with light sensing capability (e.g., a smartphone), using LED lamps as anchors. Through the design of Epsilon, we identify and tackle several technique challenges. In particular, we establish and experimentally verify the optical channel model for localization. We adopt BFSK and channel hopping to enable reliable location beaconing from multiple, uncoordinated light sources over the shared optical medium. We handle realistic situations towards robust localization, for example, we exploit user involvement to resolve the ambiguity in case of insufficient LED anchors. We have implemented the Epsilon system and evaluated it with a small scale hardware testbed as well as moderate-size simulations. Experimental results confirmed the effectiveness of Epsilon: the 90th percentile accuracies are 0.4m, 0.7m and 0.8m for three typical office environments. Even in the extreme situation with a single light, the 90th percentile accuracy is 1.1m. We believe that visible light based localization is promising to significantly improve the positioning accuracy, despite few open problems in practice.",
        "acm_key": "2616488",
        "bib_stats": {
            "cites": 52,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lim:2014:MHA:2616448.2616488,\n author = {Lim, Hyeontaek and Han, Dongsu and Andersen, David G. and Kaminsky, Michael},\n title = {MICA: A Holistic Approach to Fast In-memory Key-value Storage},\n booktitle = {Proceedings of the 11th USENIX Conference on Networked Systems Design and Implementation},\n series = {NSDI'14},\n year = {2014},\n isbn = {978-1-931971-09-6},\n location = {Seattle, WA},\n pages = {429--444},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=2616448.2616488},\n acmid = {2616488},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2616488",
        "pub_year": "2014",
        "text": "Hyeontaek Lim , Dongsu Han , David G. Andersen , Michael Kaminsky, MICA: a holistic approach to fast in-memory key-value storage, Proceedings of the 11th USENIX Conference on Networked Systems Design and Implementation, April 02-04, 2014, Seattle, WA"
    },
    "2616670": {
        "abstract": "Data mining, bioinformatics, knowledge discovery, social network analysis, are emerging irregular applications that exploits data structures based on pointers or linked lists, such as graphs, unbalanced trees or unstructured grids. These applications are characterized by unpredictable memory accesses and generally are memory bandwidth bound, but also presents large amounts of inherent dynamic parallelism because they can potentially spawn concurrent activities for each one of the element they are exploring. Hybrid architectures, which integrate general purpose processors with reconfigurable devices, appears promising target platforms for accelerating irregular applications. These systems often connect to distributed and multi-ported memories, potentially enabling parallel memory operations. However, these memory architectures introduce several challenges, such as the necessity to manage concurrency and synchronization to avoid structural conflicts on shared memory locations and to guarantee consistency. In this paper we present an adaptive Memory Interface Controller (MIC) that addresses these issues. The MIC is a general and customizable solution that can target several different memory structures, and is suitable for High Level Synthesis frameworks. It implements a dynamic arbitration scheme, which avoids conflicts on memory resources at runtime, and supports atomic memory operations, commonly exploited for synchronization directives in parallel programming paradigms. The MIC simultaneously maps multiple accesses to different memory ports, allowing fine grained parallelism exploitation and ensuring correctness also in the presence of irregular and statically unpredictable memory access patterns. We evaluated the effectiveness of our approach on a typical irregular kernel, graph Breadth First Search (BFS), exploring different design alternatives.",
        "acm_key": "2616670",
        "bib_stats": {
            "cites": 1,
            "dl": 69,
            "dl_52": 9,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Duan:2014:ENV:2616606.2616670,\n author = {Duan, Guangshan and Wang, Shuai},\n title = {Exploiting Narrow-width Values for Improving Non-volatile Cache Lifetime},\n booktitle = {Proceedings of the Conference on Design, Automation \\& Test in Europe},\n series = {DATE '14},\n year = {2014},\n isbn = {978-3-9815370-2-4},\n location = {Dresden, Germany},\n pages = {52:1--52:4},\n articleno = {52},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2616606.2616670},\n acmid = {2616670},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "2616670",
        "pub_year": "2014",
        "text": "Guangshan Duan , Shuai Wang, Exploiting narrow-width values for improving non-volatile cache lifetime, Proceedings of the conference on Design, Automation & Test in Europe, March 24-28, 2014, Dresden, Germany"
    },
    "2616671": {
        "abstract": "Data mining, bioinformatics, knowledge discovery, social network analysis, are emerging irregular applications that exploits data structures based on pointers or linked lists, such as graphs, unbalanced trees or unstructured grids. These applications are characterized by unpredictable memory accesses and generally are memory bandwidth bound, but also presents large amounts of inherent dynamic parallelism because they can potentially spawn concurrent activities for each one of the element they are exploring. Hybrid architectures, which integrate general purpose processors with reconfigurable devices, appears promising target platforms for accelerating irregular applications. These systems often connect to distributed and multi-ported memories, potentially enabling parallel memory operations. However, these memory architectures introduce several challenges, such as the necessity to manage concurrency and synchronization to avoid structural conflicts on shared memory locations and to guarantee consistency. In this paper we present an adaptive Memory Interface Controller (MIC) that addresses these issues. The MIC is a general and customizable solution that can target several different memory structures, and is suitable for High Level Synthesis frameworks. It implements a dynamic arbitration scheme, which avoids conflicts on memory resources at runtime, and supports atomic memory operations, commonly exploited for synchronization directives in parallel programming paradigms. The MIC simultaneously maps multiple accesses to different memory ports, allowing fine grained parallelism exploitation and ensuring correctness also in the presence of irregular and statically unpredictable memory access patterns. We evaluated the effectiveness of our approach on a typical irregular kernel, graph Breadth First Search (BFS), exploring different design alternatives.",
        "acm_key": "2616671",
        "bib_stats": {
            "cites": 2,
            "dl": 54,
            "dl_52": 7,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Li:2014:PWS:2616606.2616671,\n author = {Li, Bing and Shan, ShuChang and Hu, Yu and Li, Xiaowei},\n title = {Partial-SET: Write Speedup of PCM Main Memory},\n booktitle = {Proceedings of the Conference on Design, Automation \\& Test in Europe},\n series = {DATE '14},\n year = {2014},\n isbn = {978-3-9815370-2-4},\n location = {Dresden, Germany},\n pages = {53:1--53:4},\n articleno = {53},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2616606.2616671},\n acmid = {2616671},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "2616671",
        "pub_year": "2014",
        "text": "Bing Li , ShuChang Shan , Yu Hu , Xiaowei Li, Partial-SET: write speedup of PCM main memory, Proceedings of the conference on Design, Automation & Test in Europe, March 24-28, 2014, Dresden, Germany"
    },
    "2616676": {
        "abstract": "Data mining, bioinformatics, knowledge discovery, social network analysis, are emerging irregular applications that exploits data structures based on pointers or linked lists, such as graphs, unbalanced trees or unstructured grids. These applications are characterized by unpredictable memory accesses and generally are memory bandwidth bound, but also presents large amounts of inherent dynamic parallelism because they can potentially spawn concurrent activities for each one of the element they are exploring. Hybrid architectures, which integrate general purpose processors with reconfigurable devices, appears promising target platforms for accelerating irregular applications. These systems often connect to distributed and multi-ported memories, potentially enabling parallel memory operations. However, these memory architectures introduce several challenges, such as the necessity to manage concurrency and synchronization to avoid structural conflicts on shared memory locations and to guarantee consistency. In this paper we present an adaptive Memory Interface Controller (MIC) that addresses these issues. The MIC is a general and customizable solution that can target several different memory structures, and is suitable for High Level Synthesis frameworks. It implements a dynamic arbitration scheme, which avoids conflicts on memory resources at runtime, and supports atomic memory operations, commonly exploited for synchronization directives in parallel programming paradigms. The MIC simultaneously maps multiple accesses to different memory ports, allowing fine grained parallelism exploitation and ensuring correctness also in the presence of irregular and statically unpredictable memory access patterns. We evaluated the effectiveness of our approach on a typical irregular kernel, graph Breadth First Search (BFS), exploring different design alternatives.",
        "acm_key": "2616676",
        "bib_stats": {
            "cites": 2,
            "dl": 48,
            "dl_52": 9,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Lam:2014:GCM:2616606.2616676,\n author = {Lam, Kam-Yiu and Wang, Jiantao and Chang, Yuan-Hao and Hsieh, Jen-Wei and Huang, Po-Chun and Poon, Chung Keung and Zhu, Chun Jiang},\n title = {Garbage Collection for Multi-version Index on Flash Memory},\n booktitle = {Proceedings of the Conference on Design, Automation \\& Test in Europe},\n series = {DATE '14},\n year = {2014},\n isbn = {978-3-9815370-2-4},\n location = {Dresden, Germany},\n pages = {57:1--57:4},\n articleno = {57},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2616606.2616676},\n acmid = {2616676},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n keywords = {flash-based embedded database systems, multi-version data, multi-version index, real-time data},\n} \r\n",
        "key": "2616676",
        "pub_year": "2014",
        "text": "Kam-Yiu Lam , Jiantao Wang , Yuan-Hao Chang , Jen-Wei Hsieh , Po-Chun Huang , Chung Keung Poon , Chun Jiang Zhu, Garbage collection for multi-version index on flash memory, Proceedings of the conference on Design, Automation & Test in Europe, March 24-28, 2014, Dresden, Germany"
    },
    "2616715": {
        "abstract": "Data mining, bioinformatics, knowledge discovery, social network analysis, are emerging irregular applications that exploits data structures based on pointers or linked lists, such as graphs, unbalanced trees or unstructured grids. These applications are characterized by unpredictable memory accesses and generally are memory bandwidth bound, but also presents large amounts of inherent dynamic parallelism because they can potentially spawn concurrent activities for each one of the element they are exploring. Hybrid architectures, which integrate general purpose processors with reconfigurable devices, appears promising target platforms for accelerating irregular applications. These systems often connect to distributed and multi-ported memories, potentially enabling parallel memory operations. However, these memory architectures introduce several challenges, such as the necessity to manage concurrency and synchronization to avoid structural conflicts on shared memory locations and to guarantee consistency. In this paper we present an adaptive Memory Interface Controller (MIC) that addresses these issues. The MIC is a general and customizable solution that can target several different memory structures, and is suitable for High Level Synthesis frameworks. It implements a dynamic arbitration scheme, which avoids conflicts on memory resources at runtime, and supports atomic memory operations, commonly exploited for synchronization directives in parallel programming paradigms. The MIC simultaneously maps multiple accesses to different memory ports, allowing fine grained parallelism exploitation and ensuring correctness also in the presence of irregular and statically unpredictable memory access patterns. We evaluated the effectiveness of our approach on a typical irregular kernel, graph Breadth First Search (BFS), exploring different design alternatives.",
        "acm_key": "2616715",
        "bib_stats": {
            "cites": 0,
            "dl": 87,
            "dl_52": 11,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2014:WDS:2616606.2616715,\n author = {Li, Qingan and He, Yanxiang and Chen, Yong and Xue, Chun Jason and Jiang, Nan and Xu, Chao},\n title = {A Wear-leveling-aware Dynamic Stack for Pcm Memory in Embedded Systems},\n booktitle = {Proceedings of the Conference on Design, Automation \\& Test in Europe},\n series = {DATE '14},\n year = {2014},\n isbn = {978-3-9815370-2-4},\n location = {Dresden, Germany},\n pages = {89:1--89:4},\n articleno = {89},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2616606.2616715},\n acmid = {2616715},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "2616715",
        "pub_year": "2014",
        "text": "Qingan Li , Yanxiang He , Yong Chen , Chun Jason Xue , Nan Jiang , Chao Xu, A wear-leveling-aware dynamic stack for pcm memory in embedded systems, Proceedings of the conference on Design, Automation & Test in Europe, March 24-28, 2014, Dresden, Germany"
    },
    "2617021": {
        "abstract": "Data mining, bioinformatics, knowledge discovery, social network analysis, are emerging irregular applications that exploits data structures based on pointers or linked lists, such as graphs, unbalanced trees or unstructured grids. These applications are characterized by unpredictable memory accesses and generally are memory bandwidth bound, but also presents large amounts of inherent dynamic parallelism because they can potentially spawn concurrent activities for each one of the element they are exploring. Hybrid architectures, which integrate general purpose processors with reconfigurable devices, appears promising target platforms for accelerating irregular applications. These systems often connect to distributed and multi-ported memories, potentially enabling parallel memory operations. However, these memory architectures introduce several challenges, such as the necessity to manage concurrency and synchronization to avoid structural conflicts on shared memory locations and to guarantee consistency. In this paper we present an adaptive Memory Interface Controller (MIC) that addresses these issues. The MIC is a general and customizable solution that can target several different memory structures, and is suitable for High Level Synthesis frameworks. It implements a dynamic arbitration scheme, which avoids conflicts on memory resources at runtime, and supports atomic memory operations, commonly exploited for synchronization directives in parallel programming paradigms. The MIC simultaneously maps multiple accesses to different memory ports, allowing fine grained parallelism exploitation and ensuring correctness also in the presence of irregular and statically unpredictable memory access patterns. We evaluated the effectiveness of our approach on a typical irregular kernel, graph Breadth First Search (BFS), exploring different design alternatives.",
        "acm_key": "2617021",
        "bib_stats": {
            "cites": 0,
            "dl": 138,
            "dl_52": 24,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Zuolo:2014:SVP:2616606.2617021,\n author = {Zuolo, Lorenzo and Zambelli, Cristian and Micheloni, Rino and Galfano, Salvatore and Indaco, Marco and Carlo, Stefano Di and Prinetto, Paolo and Olivo, Piero and Bertozzi, Davide},\n title = {SSDExplorer: A Virtual Platform for Fine-grained Design Space Exploration of Solid State Drives},\n booktitle = {Proceedings of the Conference on Design, Automation \\& Test in Europe},\n series = {DATE '14},\n year = {2014},\n isbn = {978-3-9815370-2-4},\n location = {Dresden, Germany},\n pages = {284:1--284:6},\n articleno = {284},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2616606.2617021},\n acmid = {2617021},\n publisher = {European Design and Automation Association},\n address = {3001 Leuven, Belgium, Belgium},\n} \r\n",
        "key": "2617021",
        "pub_year": "2014",
        "text": "Lorenzo Zuolo , Cristian Zambelli , Rino Micheloni , Salvatore Galfano , Marco Indaco , Stefano Di Carlo , Paolo Prinetto , Piero Olivo , Davide Bertozzi, SSDExplorer: a virtual platform for fine-grained design space exploration of solid state drives, Proceedings of the conference on Design, Automation & Test in Europe, March 24-28, 2014, Dresden, Germany"
    },
    "2619092": {
        "abstract": "In this article, we propose six optimizations that enable an OS to fully exploit the performance characteristics of fast storage devices. With the support of new hardware interfaces, our optimizations minimize per-request latency by streamlining the I/O path and amortize per-request latency by maximizing parallelism inside the device. We demonstrate the impact on application performance through well-known storage benchmarks run against a Linux kernel with a customized SSD. We find that eliminating context switches in the I/O path decreases the software overhead of an I/O request from 20 microseconds to 5 microseconds and a new request merge scheme called Temporal Merge enables the OS to achieve 87&percnt; to 100&percnt; of peak device performance, regardless of request access patterns or types. Although the performance improvement by these optimizations on a standard SATA-based SSD is marginal (because of its limited interface and relatively high response times), our sensitivity analysis suggests that future SSDs with lower response times will benefit from these changes. The effectiveness of our optimizations encourages discussion between the OS community and storage vendors about future device interfaces for fast storage devices.",
        "acm_key": "2619092",
        "bib_stats": {
            "cites": 6,
            "dl": 1,
            "dl_52": 148,
            "dl_6": 18
        },
        "bibtex": "\r\n@article{Yu:2014:OBI:2642648.2619092,\n author = {Yu, Young Jin and Shin, Dong In and Shin, Woong and Song, Nae Young and Choi, Jae Woo and Kim, Hyeong Seog and Eom, Hyeonsang and Yeom, Heon Young},\n title = {Optimizing the Block I/O Subsystem for Fast Storage Devices},\n journal = {ACM Trans. Comput. Syst.},\n issue_date = {June 2014},\n volume = {32},\n number = {2},\n month = jun,\n year = {2014},\n issn = {0734-2071},\n pages = {6:1--6:48},\n articleno = {6},\n numpages = {48},\n url = {http://doi.acm.org/10.1145/2619092},\n doi = {10.1145/2619092},\n acmid = {2619092},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O subsystem, device polling, extended interface, request batching},\n} \r\n",
        "key": "2619092",
        "pub_year": "2014",
        "text": "Young Jin Yu , Dong In Shin , Woong Shin , Nae Young Song , Jae Woo Choi , Hyeong Seog Kim , Hyeonsang Eom , Heon Young Yeom, Optimizing the Block I/O Subsystem for Fast Storage Devices, ACM Transactions on Computer Systems (TOCS), v.32 n.2, p.1-48, June 2014"
    },
    "2629491": {
        "abstract": "Due to the large access latency of hard disks during data retrieval in computer systems, buffer caching mechanisms have been studied extensively in database and operating systems. By storing requested data into the buffer cache, subsequent requests can be directly serviced without accessing slow disk storage. Meanwhile, high-speed storage media like PCM (phase-change memory) have emerged recently, and one may wonder if the traditional buffer cache will be still effective for these high-speed storage media. This article answers the question by showing that the buffer cache is still effective in such environments due to the software overhead and the bimodal data access characteristics. Based on this observation, we present a new buffer cache management scheme appropriately designed for the system where the speed gap between cache and storage is narrow. To this end, we analyze the condition that caching will be effective and find the characteristics of access patterns that can be exploited in managing buffer cache for high performance storage like PCM.",
        "acm_key": "2629491",
        "bib_stats": {
            "cites": 1,
            "dl": 424,
            "dl_52": 34,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Saxena:2014:DPS:2661087.2629491,\n author = {Saxena, Mohit and Swift, Michael M.},\n title = {Design and Prototype of a Solid-State Cache},\n journal = {Trans. Storage},\n issue_date = {July 2014},\n volume = {10},\n number = {3},\n month = aug,\n year = {2014},\n issn = {1553-3077},\n pages = {10:1--10:34},\n articleno = {10},\n numpages = {34},\n url = {http://doi.acm.org/10.1145/2629491},\n doi = {10.1145/2629491},\n acmid = {2629491},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Solid-state cache, consistency, device interface, durability, prototype},\n} \r\n",
        "key": "2629491",
        "pub_year": "2014",
        "text": "Mohit Saxena , Michael M. Swift, Design and Prototype of a Solid-State Cache, ACM Transactions on Storage (TOS), v.10 n.3, p.1-34, July 2014"
    },
    "2631922": {
        "abstract": "In this work, we studied the energy consumption characteristics of various SSD design parameters. We developed an accurate energy consumption model for SSDs that computes aggregate, as well as component-specific, energy consumption of SSDs in sub-msec time scale. In our study, we used five different FTLs (page mapping, DFTL, block mapping, and two different hybrid mappings) and four different channel configurations (two, four, eight, and 16 channels) under seven different workloads (from large-scale enterprise systems to small-scale desktop applications) in a combinatorial manner. For each combination of the aforementioned parameters, we examined the energy consumption for individual hardware components of an SSD (microcontroller, DRAM, NAND flash, and host interface). The following are some of our findings. First, DFTL is the most energy-efficient address-mapping scheme among the five FTLs we tested due to its good write amplification and small DRAM footprint. Second, a significant fraction of energy is being consumed by idle flash chips waiting for the completion of NAND operations in the other channels. FTL should be designed to fully exploit the internal parallelism so that energy consumption by idle chips is minimized. Third, as a means to increase the internal parallelism, increasing way parallelism (the number of flash chips in a channel) is more effective than increasing channel parallelism in terms of peak energy consumption, performance, and hardware complexity. Fourth, in designing high-performance and energy-efficient SSDs, channel switching delay, way switching delay, and page write latency need to be incorporated in an integrated manner to determine the optimal configuration of internal parallelism.",
        "acm_key": "2631922",
        "bib_stats": {
            "cites": 2,
            "dl": 328,
            "dl_52": 66,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Gim:2015:SSS:2747982.2631922,\n author = {Gim, Jongmin and Hwang, Taeho and Won, Youjip and Kant, Krishna},\n title = {SmartCon: SmartCon: Smart Context Switching for Fast Storage Devices},\n journal = {Trans. Storage},\n issue_date = {March 2015},\n volume = {11},\n number = {2},\n month = mar,\n year = {2015},\n issn = {1553-3077},\n pages = {5:1--5:25},\n articleno = {5},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2631922},\n doi = {10.1145/2631922},\n acmid = {2631922},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O subsystem, Nonvolatile memory, context switch, solid state disk},\n} \r\n",
        "key": "2631922",
        "pub_year": "2015",
        "text": "Jongmin Gim , Taeho Hwang , Youjip Won , Krishna Kant, SmartCon: SmartCon: Smart Context Switching for Fast Storage Devices, ACM Transactions on Storage (TOS), v.11 n.2, p.1-25, March 2015"
    },
    "2638841": {
        "abstract": "Consumer electronic devices like smartphones increasingly feature arrays of sensors that can 'see', 'hear', and 'feel' the environment around them. While these devices began with primitive capabilities, newer generations of electronics offer sophisticated sensing arrays that collect high-fidelity representations of the physical world. For example, wearable cameras are becoming more prevalent with new consumer lifelogging products including the Narrative Clip, Autographer, and Google Glass. These wearable cameras give computing devices a persistent sense of sight, raising important concerns about protecting people's privacy. At the same time, these devices also provide opportunities for enhancing security, by allowing trusted devices to observe and react to the physical environment surrounding the user and the device. We propose Attribute Based Access Control (ABAC) to mediate access to sensors and their data using attributes of the context and content of sensor information. Attributes extracted from sensor data could be used to trigger policy actions ranging from sharing or not sharing images, to invoking system changes in reaction to outside visual stimuli such as automatically shutting down network interfaces when in the presence of unknown people. While prior work has addressed some specific actions, like preventing potentially private images from being shared based on their location, in this paper we present and advocate for a more general working definition of ABAC that applies to sensors and sensor data. We also present use cases for how this reactive security approach may help protect the privacy and security of users.",
        "acm_key": "2638841",
        "bib_stats": {
            "cites": 2,
            "dl": 115,
            "dl_52": 16,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Nguyen:2014:ISR:2638728.2638841,\n author = {Nguyen, David T.},\n title = {Improving Smartphone Responsiveness Through I/O Optimizations},\n booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication},\n series = {UbiComp '14 Adjunct},\n year = {2014},\n isbn = {978-1-4503-3047-3},\n location = {Seattle, Washington},\n pages = {337--342},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2638728.2638841},\n doi = {10.1145/2638728.2638841},\n acmid = {2638841},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O optimizations, application delay, application launch, smartphone responsiveness},\n} \r\n",
        "key": "2638841",
        "pub_year": "2014",
        "text": "David T. Nguyen, Improving smartphone responsiveness through I/O optimizations, Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication, September 13-17, 2014, Seattle, Washington"
    },
    "2643117": {
        "abstract": "Manifold is a parallel simulation framework for multi-core systems. For full-system simulation, Manifold adopts the timing-directed simulation paradigm that separates the simulation into a functional front-end and a timing back-end. Components in the front-end perform functional simulation of the cores and send streams of instructions to the back-end to simulate the timing behavior. In its current design, Manifold uses the QSim multi-core emulator as the front-end, which communicates with the back-end through network sockets. Experiments have shown that the latency of the socket communications has a significant impact on the overall simulation performance. This paper presents a novel method that attempts to hide the TCP/IP latency for the back-end by creating proxy processes as an intermediary between the front-end and the back-end. The proxies serve as clients to the QSim server in the front-end, and as servers to the back-end. They interact with the QSim server through sockets, while working with the back-end in a producer-consumer manner using shared memory segments. Experiments show that this method can completely hide the TCP/IP latency for the back-end. The back-end can always get its instructions from the shared memory without waiting for the QSim server. The overhead of getting inputs for the back-end simulation is reduced to almost zero. As confirmed by our experiments, this improvement causes some side effects that together lead to significant improvements in overall simulation performance. In testing of system models with up to 64 cores, we have achieved from 29% to 51% improvement in simulation performance.",
        "acm_key": "2643117",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Traue:2014:UES:2643094.2643117,\n author = {Traue, Jana and Nolte, J\\\"{o}rg and Engel, Philipp and Karnapke, Reinhardt},\n title = {Using Emulation Software to Predict the Performance of Algorithms on NVRAM},\n booktitle = {Proceedings of the 7th International ICST Conference on Simulation Tools and Techniques},\n series = {SIMUTools '14},\n year = {2014},\n isbn = {978-1-63190-007-5},\n location = {Lisbon, Portugal},\n pages = {142--146},\n numpages = {5},\n url = {https://doi.org/10.4108/icst.simutools.2014.254796},\n doi = {10.4108/icst.simutools.2014.254796},\n acmid = {2643117},\n publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},\n address = {ICST, Brussels, Belgium, Belgium},\n keywords = {emulation, non-volatile memory},\n} \r\n",
        "key": "2643117",
        "pub_year": "2014",
        "text": "Jana Traue , J\u00f6rg Nolte , Philipp Engel , Reinhardt Karnapke, Using emulation software to predict the performance of algorithms on NVRAM, Proceedings of the 7th International ICST Conference on Simulation Tools and Techniques, March 17-19, 2014, Lisbon, Portugal"
    },
    "2644808": {
        "abstract": "Approximate computing, where computation accuracy is traded off for better performance or higher data throughput, is one solution that can help data processing keep pace with the current and growing abundance of information. For particular domains, such as multimedia and learning algorithms, approximation is commonly used today. We consider automation to be essential to provide transparent approximation, and we show that larger benefits can be achieved by constructing the approximation techniques to fit the underlying hardware. Our target platform is the GPU because of its high performance capabilities and difficult programming challenges that can be alleviated with proper automation. Our approach\u2014SAGE\u2014combines a static compiler that automatically generates a set of CUDA kernels with varying levels of approximation with a runtime system that iteratively selects among the available kernels to achieve speedup while adhering to a target output quality set by the user. The SAGE compiler employs three optimization techniques to generate approximate kernels that exploit the GPU microarchitecture: selective discarding of atomic operations, data packing, and thread fusion. Across a set of machine learning and image processing kernels, SAGE's approximation yields an average of 2.5\u00d7 speedup with less than 10&percnt; quality loss compared to the accurate execution on a NVIDIA GTX 560 GPU.",
        "acm_key": "2644808",
        "bib_stats": {
            "cites": 5,
            "dl": 761,
            "dl_52": 215,
            "dl_6": 32
        },
        "bibtex": "\r\n@article{Sampson:2014:ASS:2666140.2644808,\n author = {Sampson, Adrian and Nelson, Jacob and Strauss, Karin and Ceze, Luis},\n title = {Approximate Storage in Solid-State Memories},\n journal = {ACM Trans. Comput. Syst.},\n issue_date = {September 2014},\n volume = {32},\n number = {3},\n month = sep,\n year = {2014},\n issn = {0734-2071},\n pages = {9:1--9:23},\n articleno = {9},\n numpages = {23},\n url = {http://doi.acm.org/10.1145/2644808},\n doi = {10.1145/2644808},\n acmid = {2644808},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Approximate computing, error tolerance, phase-change memory, storage},\n} \r\n",
        "key": "2644808",
        "pub_year": "2014",
        "text": "Adrian Sampson , Jacob Nelson , Karin Strauss , Luis Ceze, Approximate Storage in Solid-State Memories, ACM Transactions on Computer Systems (TOCS), v.32 n.3, p.1-23, September 2014"
    },
    "2644818": {
        "abstract": "In this work, we studied the energy consumption characteristics of various SSD design parameters. We developed an accurate energy consumption model for SSDs that computes aggregate, as well as component-specific, energy consumption of SSDs in sub-msec time scale. In our study, we used five different FTLs (page mapping, DFTL, block mapping, and two different hybrid mappings) and four different channel configurations (two, four, eight, and 16 channels) under seven different workloads (from large-scale enterprise systems to small-scale desktop applications) in a combinatorial manner. For each combination of the aforementioned parameters, we examined the energy consumption for individual hardware components of an SSD (microcontroller, DRAM, NAND flash, and host interface). The following are some of our findings. First, DFTL is the most energy-efficient address-mapping scheme among the five FTLs we tested due to its good write amplification and small DRAM footprint. Second, a significant fraction of energy is being consumed by idle flash chips waiting for the completion of NAND operations in the other channels. FTL should be designed to fully exploit the internal parallelism so that energy consumption by idle chips is minimized. Third, as a means to increase the internal parallelism, increasing way parallelism (the number of flash chips in a channel) is more effective than increasing channel parallelism in terms of peak energy consumption, performance, and hardware complexity. Fourth, in designing high-performance and energy-efficient SSDs, channel switching delay, way switching delay, and page write latency need to be incorporated in an integrated manner to determine the optimal configuration of internal parallelism.",
        "acm_key": "2644818",
        "bib_stats": {
            "cites": 1,
            "dl": 414,
            "dl_52": 90,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Cho:2015:DTS:2747982.2644818,\n author = {Cho, Seokhei and Park, Changhyun and Won, Youjip and Kang, Sooyong and Cha, Jaehyuk and Yoon, Sungroh and Choi, Jongmoo},\n title = {Design Tradeoffs of SSDs: From Energy Consumption\\&Rsquo;s Perspective},\n journal = {Trans. Storage},\n issue_date = {March 2015},\n volume = {11},\n number = {2},\n month = mar,\n year = {2015},\n issn = {1553-3077},\n pages = {8:1--8:24},\n articleno = {8},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/2644818},\n doi = {10.1145/2644818},\n acmid = {2644818},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, NAND flash, SSD, energy consumption, parallelism, simulator},\n} \r\n",
        "key": "2644818",
        "pub_year": "2015",
        "text": "Seokhei Cho , Changhyun Park , Youjip Won , Sooyong Kang , Jaehyuk Cha , Sungroh Yoon , Jongmoo Choi, Design Tradeoffs of SSDs: From Energy Consumption\u2019s Perspective, ACM Transactions on Storage (TOS), v.11 n.2, p.1-24, March 2015"
    },
    "2656076": {
        "abstract": "Firmware is low-level software which can directly access hardware and is often shipped with the hardware platform. This component of the system is increasing in scale and importance, and thus firmware validation is a critical part of system validation. Firmware validation relies on the interacting hardware components which are usually not available until the late design stages. This is generally addressed through co-simulating C/C++ based firmware code and HDL hardware models (including SystemC). However, this tends to be slow, and is further exacerbated by the large number of possible interleavings between the concurrent firmware and hardware threads. Typically, in the co-simulation, the scheduler, such as the SystemC scheduler, will only explore a single, or at best a small number of possible firmware-hardware interleavings and thus may miss critical bugs. In this paper we present an alternative approach to firmware validation that is based on automatically generating a test-set for the firmware with the goal of complete path coverage while considering its interactions with hardware and other firmware threads. It uses a service-function based Transaction Level Model (TLM) which has been used in the past for firmware-hardware codesign. The test generation is based on concolic testing which has been used successfully in software test generation. However, existing concolic testing tools are used for test-generation of sequential code, and cannot directly consider the interaction of other hardware/firmware threads with the target firmware thread during test generation. We address this limitation by exploiting specific interaction patterns between the firmware and hardware threads that can be analyzed from the TLM. We show how these patterns, along with the firmware and hardware threads are used to automatically generate a sequential program that is test-equivalent to the target firmware transaction and that can be used with a standard sequential program concolic test generator. The tests generated can be (i) directly used for the firmware transaction and (ii) account for the multi-threaded interactions. These interaction patterns are practically relevant as they occur often in practice in real firmware benchmarks such as Linux device driver code, and its interacting QEMU emulated hardware code. Finally, we demonstrate the efficacy of our techniques for these benchmarks through a practical implementation that is automated and built on top of Frama-C, a static code analyzer, and KLEE, a concolic testing tool.",
        "acm_key": "2656076",
        "bib_stats": {
            "cites": 3,
            "dl": 129,
            "dl_52": 27,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Pan:2014:EMW:2656075.2656076,\n author = {Pan, Chen and Xie, Mimi and Hu, Jingtong and Chen, Yiran and Yang, Chengmo},\n title = {3M-PCM: Exploiting Multiple Write Modes MLC Phase Change Main Memory in Embedded Systems},\n booktitle = {Proceedings of the 2014 International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '14},\n year = {2014},\n isbn = {978-1-4503-3051-0},\n location = {New Delhi, India},\n pages = {33:1--33:10},\n articleno = {33},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2656075.2656076},\n doi = {10.1145/2656075.2656076},\n acmid = {2656076},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2656076",
        "pub_year": "2014",
        "text": "Chen Pan , Mimi Xie , Jingtong Hu , Yiran Chen , Chengmo Yang, 3M-PCM: exploiting multiple write modes MLC phase change main memory in embedded systems, Proceedings of the 2014 International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 12-17, 2014, New Delhi, India"
    },
    "2656078": {
        "abstract": "Firmware is low-level software which can directly access hardware and is often shipped with the hardware platform. This component of the system is increasing in scale and importance, and thus firmware validation is a critical part of system validation. Firmware validation relies on the interacting hardware components which are usually not available until the late design stages. This is generally addressed through co-simulating C/C++ based firmware code and HDL hardware models (including SystemC). However, this tends to be slow, and is further exacerbated by the large number of possible interleavings between the concurrent firmware and hardware threads. Typically, in the co-simulation, the scheduler, such as the SystemC scheduler, will only explore a single, or at best a small number of possible firmware-hardware interleavings and thus may miss critical bugs. In this paper we present an alternative approach to firmware validation that is based on automatically generating a test-set for the firmware with the goal of complete path coverage while considering its interactions with hardware and other firmware threads. It uses a service-function based Transaction Level Model (TLM) which has been used in the past for firmware-hardware codesign. The test generation is based on concolic testing which has been used successfully in software test generation. However, existing concolic testing tools are used for test-generation of sequential code, and cannot directly consider the interaction of other hardware/firmware threads with the target firmware thread during test generation. We address this limitation by exploiting specific interaction patterns between the firmware and hardware threads that can be analyzed from the TLM. We show how these patterns, along with the firmware and hardware threads are used to automatically generate a sequential program that is test-equivalent to the target firmware transaction and that can be used with a standard sequential program concolic test generator. The tests generated can be (i) directly used for the firmware transaction and (ii) account for the multi-threaded interactions. These interaction patterns are practically relevant as they occur often in practice in real firmware benchmarks such as Linux device driver code, and its interacting QEMU emulated hardware code. Finally, we demonstrate the efficacy of our techniques for these benchmarks through a practical implementation that is automated and built on top of Frama-C, a static code analyzer, and KLEE, a concolic testing tool.",
        "acm_key": "2656078",
        "bib_stats": {
            "cites": 3,
            "dl": 240,
            "dl_52": 34,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Chang:2014:PTL:2656075.2656078,\n author = {Chang, Bing-Jing and Chang, Yuan-Hao and Chang, Hung-Sheng and Kuo, Tei-Wei and Li, Hsiang-Pang},\n title = {A PCM Translation Layer for Integrated Memory and Storage Management},\n booktitle = {Proceedings of the 2014 International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '14},\n year = {2014},\n isbn = {978-1-4503-3051-0},\n location = {New Delhi, India},\n pages = {6:1--6:10},\n articleno = {6},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2656075.2656078},\n doi = {10.1145/2656075.2656078},\n acmid = {2656078},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2656078",
        "pub_year": "2014",
        "text": "Bing-Jing Chang , Yuan-Hao Chang , Hung-Sheng Chang , Tei-Wei Kuo , Hsiang-Pang Li, A PCM translation layer for integrated memory and storage management, Proceedings of the 2014 International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 12-17, 2014, New Delhi, India"
    },
    "2660224": {
        "abstract": "Automatic type inference is a popular feature of functional programming languages. If a program cannot be typed, the compiler typically reports a single program location in its error message. This location is the point where the type inference failed, but not necessarily the actual source of the error. Other potential error sources are not even considered. Hence, the compiler often misses the true error source, which increases debugging time for the programmer. In this paper, we present a general framework for automatic localization of type errors. Our algorithm finds all minimum error sources, where the exact definition of minimum is given in terms of a compiler-specific ranking criterion. Compilers can use minimum error sources to produce more meaningful error reports, and for automatic error correction. Our approach works by reducing the search for minimum error sources to an optimization problem that we formulate in terms of weighted maximum satisfiability modulo theories (MaxSMT). The reduction to weighted MaxSMT allows us to build on SMT solvers to support rich type systems and at the same time abstract from the concrete criterion that is used for ranking the error sources. We have implemented an instance of our framework targeted at Hindley-Milner type systems and evaluated it on existing OCaml benchmarks for type error localization. Our evaluation shows that our approach has the potential to significantly improve the quality of type error reports produced by state of the art compilers.",
        "acm_key": "2660224",
        "bib_stats": {
            "cites": 16,
            "dl": 894,
            "dl_52": 250,
            "dl_6": 17
        },
        "bibtex": "\r\n@article{Chakrabarti:2014:ALL:2714064.2660224,\n author = {Chakrabarti, Dhruva R. and Boehm, Hans-J. and Bhandari, Kumud},\n title = {Atlas: Leveraging Locks for Non-volatile Memory Consistency},\n journal = {SIGPLAN Not.},\n issue_date = {October 2014},\n volume = {49},\n number = {10},\n month = oct,\n year = {2014},\n issn = {0362-1340},\n pages = {433--452},\n numpages = {20},\n url = {http://doi.acm.org/10.1145/2714064.2660224},\n doi = {10.1145/2714064.2660224},\n acmid = {2660224},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consistency semantics, durability, locks, logging, non-volatile memory, persistence, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2660224&parent_id=2714064&expformat=bibtex&CFID=982033669&CFTOKEN=24824745\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2660224\">\r\n@inproceedings{Chakrabarti:2014:ALL:2660193.2660224,\n author = {Chakrabarti, Dhruva R. and Boehm, Hans-J. and Bhandari, Kumud},\n title = {Atlas: Leveraging Locks for Non-volatile Memory Consistency},\n booktitle = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages \\& Applications},\n series = {OOPSLA '14},\n year = {2014},\n isbn = {978-1-4503-2585-1},\n location = {Portland, Oregon, USA},\n pages = {433--452},\n numpages = {20},\n url = {http://doi.acm.org/10.1145/2660193.2660224},\n doi = {10.1145/2660193.2660224},\n acmid = {2660224},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consistency semantics, durability, locks, logging, non-volatile memory, persistence, transactions},\n} \r\n",
        "key": "2660224",
        "pub_year": "2014",
        "text": "Dhruva R. Chakrabarti , Hans-J. Boehm , Kumud Bhandari, Atlas: leveraging locks for non-volatile memory consistency, Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages & Applications, October 20-24, 2014, Portland, Oregon, USA  \u00a0[doi>"
    },
    "2665712": {
        "abstract": "Cache coherence protocol bugs can cause multicores to fail. Existing coherence verification approaches incur state explosion at small scales or require considerable human effort. As protocols' complexity and multicores' core counts increase, verification continues to be a challenge. Recently, researchers proposed fractal coherence which achieves scalable verification by enforcing observational equivalence between sub-systems in the coherence protocol. A larger subsystem is verified implicitly if a smaller sub-system has been verified. Unfortunately, fractal protocols suffer from two fundamental limitations: (1) indirect-communication: sub-systems cannot directly communicate and (2) partially-serialinvalidations: cores must be invalidated in a specific, serial order. These limitations disallow common performance optimizations used by conventional directory protocols: replyforwarding where caches communicate directly and parallel invalidations. Therefore, fractal protocols lack performance scalability while directory protocols lack verification scalability. To enable both performance and verification scalability, we propose Fractal++ which employs a new class of protocol optimizations for verification-constrained architectures: decoupled-replies, contention-hints, and fully-parallel-fractal-invalidations. The first two optimizations allow reply-forwarding-like performance while the third optimization enables parallel invalidations in fractal protocols. Unlike conventional protocols, Fractal++ preserves observational equivalence and hence is scalably verifiable. In 32- core simulations of single- and four-socket systems, Fractal++ performs nearly as well as a directory protocol while providing scalable verifiability whereas the best-performing previous fractal protocol performs 8% on average and up to 26% worse with a single-socket and 12% on average and up to 34% worse with a longer-latency multi-socket system",
        "acm_key": "2665712",
        "bib_stats": {
            "cites": 31,
            "dl": 927,
            "dl_52": 162,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Pelley:2014:MP:2665671.2665712,\n author = {Pelley, Steven and Chen, Peter M. and Wenisch, Thomas F.},\n title = {Memory Persistency},\n booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},\n series = {ISCA '14},\n year = {2014},\n isbn = {978-1-4799-4394-4},\n location = {Minneapolis, Minnesota, USA},\n pages = {265--276},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2665671.2665712},\n acmid = {2665712},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2665712&parent_id=2665671&expformat=bibtex&CFID=982030675&CFTOKEN=94767054\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2665712\">\r\n@article{Pelley:2014:MP:2678373.2665712,\n author = {Pelley, Steven and Chen, Peter M. and Wenisch, Thomas F.},\n title = {Memory Persistency},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2014},\n volume = {42},\n number = {3},\n month = jun,\n year = {2014},\n issn = {0163-5964},\n pages = {265--276},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2678373.2665712},\n doi = {10.1145/2678373.2665712},\n acmid = {2665712},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2665712",
        "pub_year": "2014",
        "text": "Steven Pelley , Peter M. Chen , Thomas F. Wenisch, Memory persistency, Proceeding of the 41st annual international symposium on Computer architecuture, June 14-18, 2014, Minneapolis, Minnesota, USA"
    },
    "2665715": {
        "abstract": "Cache coherence protocol bugs can cause multicores to fail. Existing coherence verification approaches incur state explosion at small scales or require considerable human effort. As protocols' complexity and multicores' core counts increase, verification continues to be a challenge. Recently, researchers proposed fractal coherence which achieves scalable verification by enforcing observational equivalence between sub-systems in the coherence protocol. A larger subsystem is verified implicitly if a smaller sub-system has been verified. Unfortunately, fractal protocols suffer from two fundamental limitations: (1) indirect-communication: sub-systems cannot directly communicate and (2) partially-serialinvalidations: cores must be invalidated in a specific, serial order. These limitations disallow common performance optimizations used by conventional directory protocols: replyforwarding where caches communicate directly and parallel invalidations. Therefore, fractal protocols lack performance scalability while directory protocols lack verification scalability. To enable both performance and verification scalability, we propose Fractal++ which employs a new class of protocol optimizations for verification-constrained architectures: decoupled-replies, contention-hints, and fully-parallel-fractal-invalidations. The first two optimizations allow reply-forwarding-like performance while the third optimization enables parallel invalidations in fractal protocols. Unlike conventional protocols, Fractal++ preserves observational equivalence and hence is scalably verifiable. In 32- core simulations of single- and four-socket systems, Fractal++ performs nearly as well as a directory protocol while providing scalable verifiability whereas the best-performing previous fractal protocol performs 8% on average and up to 26% worse with a single-socket and 12% on average and up to 34% worse with a longer-latency multi-socket system",
        "acm_key": "2665715",
        "bib_stats": {
            "cites": 7,
            "dl": 417,
            "dl_52": 106,
            "dl_6": 3
        },
        "key": "2665715",
        "text": "Myoungsoo Jung , Wonil Choi , Shekhar Srikantaiah , Joonhyuk Yoo , Mahmut T. Kandemir, HIOS: a host interface I/O scheduler for solid state disks, ACM SIGARCH Computer Architecture News, v.42 n.3, June 2014  \u00a0[doi>"
    },
    "2665731": {
        "abstract": "Cache coherence protocol bugs can cause multicores to fail. Existing coherence verification approaches incur state explosion at small scales or require considerable human effort. As protocols' complexity and multicores' core counts increase, verification continues to be a challenge. Recently, researchers proposed fractal coherence which achieves scalable verification by enforcing observational equivalence between sub-systems in the coherence protocol. A larger subsystem is verified implicitly if a smaller sub-system has been verified. Unfortunately, fractal protocols suffer from two fundamental limitations: (1) indirect-communication: sub-systems cannot directly communicate and (2) partially-serialinvalidations: cores must be invalidated in a specific, serial order. These limitations disallow common performance optimizations used by conventional directory protocols: replyforwarding where caches communicate directly and parallel invalidations. Therefore, fractal protocols lack performance scalability while directory protocols lack verification scalability. To enable both performance and verification scalability, we propose Fractal++ which employs a new class of protocol optimizations for verification-constrained architectures: decoupled-replies, contention-hints, and fully-parallel-fractal-invalidations. The first two optimizations allow reply-forwarding-like performance while the third optimization enables parallel invalidations in fractal protocols. Unlike conventional protocols, Fractal++ preserves observational equivalence and hence is scalably verifiable. In 32- core simulations of single- and four-socket systems, Fractal++ performs nearly as well as a directory protocol while providing scalable verifiability whereas the best-performing previous fractal protocol performs 8% on average and up to 26% worse with a single-socket and 12% on average and up to 34% worse with a longer-latency multi-socket system",
        "acm_key": "2665731",
        "bib_stats": {
            "cites": 5,
            "dl": 152,
            "dl_52": 26,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Jiang:2014:LPR:2665671.2665731,\n author = {Jiang, Lei and Zhao, Bo and Yang, Jun and Zhang, Youtao},\n title = {A Low Power and Reliable Charge Pump Design for Phase Change Memories},\n booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},\n series = {ISCA '14},\n year = {2014},\n isbn = {978-1-4799-4394-4},\n location = {Minneapolis, Minnesota, USA},\n pages = {397--408},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=2665671.2665731},\n acmid = {2665731},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2665731&parent_id=2665671&expformat=bibtex&CFID=982043534&CFTOKEN=78904322\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2665731\">\r\n@article{Jiang:2014:LPR:2678373.2665731,\n author = {Jiang, Lei and Zhao, Bo and Yang, Jun and Zhang, Youtao},\n title = {A Low Power and Reliable Charge Pump Design for Phase Change Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2014},\n volume = {42},\n number = {3},\n month = jun,\n year = {2014},\n issn = {0163-5964},\n pages = {397--408},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2678373.2665731},\n doi = {10.1145/2678373.2665731},\n acmid = {2665731},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2665731",
        "pub_year": "2014",
        "text": "Lei Jiang , Bo Zhao , Jun Yang , Youtao Zhang, A low power and reliable charge pump design for phase change memories, Proceeding of the 41st annual international symposium on Computer architecuture, June 14-18, 2014, Minneapolis, Minnesota, USA"
    },
    "266665": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "266665",
        "bib_stats": {
            "cites": 69,
            "dl": 708,
            "dl_52": 35,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Lowell:1997:FTR:268998.266665,\n author = {Lowell, David E. and Chen, Peter M.},\n title = {Free Transactions with Rio Vista},\n booktitle = {Proceedings of the Sixteenth ACM Symposium on Operating Systems Principles},\n series = {SOSP '97},\n year = {1997},\n isbn = {0-89791-916-5},\n location = {Saint Malo, France},\n pages = {92--101},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/268998.266665},\n doi = {10.1145/268998.266665},\n acmid = {266665},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=266665&parent_id=268998&expformat=bibtex&CFID=982054521&CFTOKEN=30785384\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"266665\">\r\n@article{Lowell:1997:FTR:269005.266665,\n author = {Lowell, David E. and Chen, Peter M.},\n title = {Free Transactions with Rio Vista},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 1997},\n volume = {31},\n number = {5},\n month = oct,\n year = {1997},\n issn = {0163-5980},\n pages = {92--101},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/269005.266665},\n doi = {10.1145/269005.266665},\n acmid = {266665},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "266665",
        "pub_year": "1997",
        "text": "David E. Lowell , Peter M. Chen, Free transactions with Rio Vista, Proceedings of the sixteenth ACM symposium on Operating systems principles, p.92-101, October 05-08, 1997, Saint Malo, France"
    },
    "2668128": {
        "abstract": "Data corruption is the most common consequence of file-system bugs. When such corruption occurs, offline check and recovery tools must be used, but they are error prone and cause significant downtime. Previously we showed that a runtime checker for the Ext3 file system can verify that metadata updates are consistent, helping detect corruption in metadata blocks at transaction commit time. However, corruption can still occur when a bug in the file system\u2019s transactional mechanism loses, misdirects, or corrupts writes. We show that a runtime checker must enforce the atomicity and durability properties of the file system on every write, in addition to checking transactions at commit time, to provide the strong guarantee that every block write will maintain file system consistency.",
        "acm_key": "2668128",
        "bib_stats": {
            "cites": 1,
            "dl": 396,
            "dl_52": 90,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Kim:2014:EPC:2685385.2668128,\n author = {Kim, Hyojun and Seshadri, Sangeetha and Dickey, Clement L. and Chiu, Lawrence},\n title = {Evaluating Phase Change Memory for Enterprise Storage Systems: A Study of Caching and Tiering Approaches},\n journal = {Trans. Storage},\n issue_date = {October 2014},\n volume = {10},\n number = {4},\n month = oct,\n year = {2014},\n issn = {1553-3077},\n pages = {15:1--15:21},\n articleno = {15},\n numpages = {21},\n url = {http://doi.acm.org/10.1145/2668128},\n doi = {10.1145/2668128},\n acmid = {2668128},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, enterprise workloads, flash memory},\n} \r\n",
        "key": "2668128",
        "pub_year": "2014",
        "text": "Hyojun Kim , Sangeetha Seshadri , Clement L. Dickey , Lawrence Chiu, Evaluating Phase Change Memory for Enterprise Storage Systems: A Study of Caching and Tiering Approaches, ACM Transactions on Storage (TOS), v.10 n.4, p.1-21, October 2014"
    },
    "2672416": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2672416",
        "bib_stats": {
            "cites": 5
        },
        "key": "2672416",
        "text": "Lei Jiang , Youtao Zhang , Jun Yang, Mitigating Write Disturbance in Super-Dense Phase Change Memories, Proceedings of the 2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, p.216-227, June 23-26, 2014  \u00a0[doi>"
    },
    "2691512": {
        "abstract": "The comparison of temperatures (temperature correlation) obtained by measuring instruments and by thermal simulation is commonly necessary. Currently the way in which thermal maps are obtained by infrared thermographer yields inaccurate results since the emissivity values of all elements in an IC are ignored and measurement method assumes a constant emissivity. Without the correct settings of emissivity in infrared thermographer, the temperature variation could reach up to as high as 300%. Coating black paint on the IC surface is a widely used method to assume the IC with constant emissivity and simplify the measurement procedures. Coating a uniform black thin film on an IC is a highly skillful technique and the coated black paint is un-removable. In certain cases, it is not convenient or possible to do so - for example, as monitoring a working chip. This article proposes the first practical and feasible method for emissivity map measurement. Two reference plates are utilized to obtain an emissivity map, from which real emissivity value of each pixel of the infrared thermographer is obtained. Firstly the radiances of IC and two reference plates are measured by the infrared thermographer. After that, the emissivity map of the IC can be calculated by the radiances. According to the experimental results herein, the uncertainty in the emissivity measured using this method is very low, of the order of 0.01, consistent with the minimum resolution of all currently available infrared thermographic instruments. With the emissivity map, the high accuracy temperature map is then obtained. The comparison of the temperature maps simulated by the extend version of Noxim (Access Noxim) as well as measured by the thermographer with constant emissivity and with the accurate emissivity map are presented in this article. This work contributes to the field of thermal analysis and simulation. Accurate circuit characteristics can be obtained through accurate thermal map; on the other hand, the closeness between the thermal simulation result and the real thermal map can also be realized.",
        "acm_key": "2691512",
        "bib_stats": {
            "cites": 2,
            "dl": 68,
            "dl_52": 12,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Cheng:2014:WPM:2691365.2691512,\n author = {Cheng, Sheng-Wei and Chang, Yu-Fen and Chang, Yuan-Hao and Wei, Hsin-Wen and Shih, Wei-Kuan},\n title = {Warranty-aware Page Management for PCM-based Embedded Systems},\n booktitle = {Proceedings of the 2014 IEEE/ACM International Conference on Computer-Aided Design},\n series = {ICCAD '14},\n year = {2014},\n isbn = {978-1-4799-6277-8},\n location = {San Jose, California},\n pages = {734--741},\n numpages = {8},\n url = {http://dl.acm.org/citation.cfm?id=2691365.2691512},\n acmid = {2691512},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2691512",
        "pub_year": "2014",
        "text": "Sheng-Wei Cheng , Yu-Fen Chang , Yuan-Hao Chang , Hsin-Wen Wei , Wei-Kuan Shih, Warranty-aware page management for PCM-based embedded systems, Proceedings of the 2014 IEEE/ACM International Conference on Computer-Aided Design, November 03-06, 2014, San Jose, California"
    },
    "2694370": {
        "abstract": "All software in use today relies on libraries, including standard libraries (e.g., C, C++) and application-specific libraries (e.g., libxml, libpng). Most libraries are loaded in memory and dynamically linked when programs are launched, resolving symbol addresses across the applications and libraries. Dynamic linking has many benefits: It allows code to be reused between applications, conserves memory (because only one copy of a library is kept in memory for all the applications that share it), and allows libraries to be patched and updated without modifying programs, among numerous other benefits. However, these benefits come at the cost of performance. For every call made to a function in a dynamically linked library, a trampoline is used to read the function address from a lookup table and branch to the function, incurring memory load and branch operations. Static linking avoids this performance penalty, but loses all the benefits of dynamic linking. Given its myriad benefits, dynamic linking is the predominant choice today, despite the performance cost. In this work, we propose a speculative hardware mechanism to optimize dynamic linking by avoiding executing the trampolines for library function calls, providing the benefits of dynamic linking with the performance of static linking. Speculatively skipping the memory load and branch operations of the library call trampolines improves performance by reducing the number of executed instructions and gains additional performance by reducing pressure on the instruction and data caches, TLBs, and branch predictors. Because the indirect targets of library call trampolines do not change during program execution, our speculative mechanism never misspeculates in practice. We evaluate our technique on real hardware with production software and observe up to 4% speedup using only 1.5KB of on-chip storage.",
        "acm_key": "2694370",
        "bib_stats": {
            "cites": 14,
            "dl": 905,
            "dl_52": 314,
            "dl_6": 32
        },
        "key": "2694370",
        "text": "Yiying Zhang , Jian Yang , Amirsaman Memaripour , Steven Swanson, Mojim: A Reliable and Highly-Available Non-Volatile Memory System, Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, March 14-18, 2015, Istanbul, Turkey  \u00a0[doi>"
    },
    "2695756": {
        "abstract": "Risk hedging strategies are at the heart of financial risk management. As with many financial institutions, insurance companies try to hedge their risk against potentially large losses, such as those associated with natural catastrophes. Much of this hedging is facilitated by engaging in risk transfer contracts with the global reinsurance market. Devising an effective hedging strategy depends on careful data analysis and optimization. In this paper, we study from the perspective of an insurance company the Dynamic Reinsurance Optimization problem in which given a set of expected loss distributions (the result of running a Catastrophic Loss Model), a model of reinsurance market costs, and some general financial terms, our task is to evolve a set of complex multi-layered reinsurance contracts that define a Pareto frontier quantifying the best available tradeoffs between expected risk and returns for the insurer. Our approach to this reinsurance contract optimization problem is three fold. Firstly, we apply the Strength Pareto Evolutionary Algorithm 2 (SPEA2) meta-heuristic to guide the multi-objective search process. Secondly, we exploit equation reordering to minimize computation, aggressively pre-computation/caching methods, and discretization to efficiently evaluate individual solutions. Lastly, we apply High Performance Computing (HPC) techniques including shared memory parallelization, vectorization and data prefetching to accelerate the search process. As a result, our prototype Dynamic Reinsurance Optimizer is able to solve industrial sized problems on a single multi-core server in about 2 minutes for 7 layers and 4 minutes for 15 layers per run.",
        "acm_key": "2695756",
        "bib_stats": {
            "cites": 0,
            "dl": 104,
            "dl_52": 44,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Yang:2015:RSM:2695664.2695756,\n author = {Yang, Ming-Chang and Chang, Yu-Ming and Huang, Po-Chun and Chang, Yuan-Hao and Lee, Lue-Jane and Kuo, Tei-Wei},\n title = {Reliability-aware Striping with Minimized Performance Overheads for Flash-based Storage Devices},\n booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},\n series = {SAC '15},\n year = {2015},\n isbn = {978-1-4503-3196-8},\n location = {Salamanca, Spain},\n pages = {1906--1912},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2695664.2695756},\n doi = {10.1145/2695664.2695756},\n acmid = {2695756},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash memory, reliability-aware, storage systems, striping},\n} \r\n",
        "key": "2695756",
        "pub_year": "2015",
        "text": "Ming-Chang Yang , Yu-Ming Chang , Po-Chun Huang , Yuan-Hao Chang , Lue-Jane Lee , Tei-Wei Kuo, Reliability-aware striping with minimized performance overheads for flash-based storage devices, Proceedings of the 30th Annual ACM Symposium on Applied Computing, April 13-17, 2015, Salamanca, Spain"
    },
    "2695992": {
        "abstract": "Risk hedging strategies are at the heart of financial risk management. As with many financial institutions, insurance companies try to hedge their risk against potentially large losses, such as those associated with natural catastrophes. Much of this hedging is facilitated by engaging in risk transfer contracts with the global reinsurance market. Devising an effective hedging strategy depends on careful data analysis and optimization. In this paper, we study from the perspective of an insurance company the Dynamic Reinsurance Optimization problem in which given a set of expected loss distributions (the result of running a Catastrophic Loss Model), a model of reinsurance market costs, and some general financial terms, our task is to evolve a set of complex multi-layered reinsurance contracts that define a Pareto frontier quantifying the best available tradeoffs between expected risk and returns for the insurer. Our approach to this reinsurance contract optimization problem is three fold. Firstly, we apply the Strength Pareto Evolutionary Algorithm 2 (SPEA2) meta-heuristic to guide the multi-objective search process. Secondly, we exploit equation reordering to minimize computation, aggressively pre-computation/caching methods, and discretization to efficiently evaluate individual solutions. Lastly, we apply High Performance Computing (HPC) techniques including shared memory parallelization, vectorization and data prefetching to accelerate the search process. As a result, our prototype Dynamic Reinsurance Optimizer is able to solve industrial sized problems on a single multi-core server in about 2 minutes for 7 layers and 4 minutes for 15 layers per run.",
        "acm_key": "2695992",
        "bib_stats": {
            "cites": 0,
            "dl": 114,
            "dl_52": 41,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Lee:2015:PIC:2695664.2695992,\n author = {Lee, Kyungjun and Ryu, Sungtae and Han, Hwansoo},\n title = {Performance Implications of Cache Flushes for Non-volatile Memory File Systems},\n booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},\n series = {SAC '15},\n year = {2015},\n isbn = {978-1-4503-3196-8},\n location = {Salamanca, Spain},\n pages = {2069--2071},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/2695664.2695992},\n doi = {10.1145/2695664.2695992},\n acmid = {2695992},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {CPU cache management, cache flushing mechanism, non-volatile memory, performance},\n} \r\n",
        "key": "2695992",
        "pub_year": "2015",
        "text": "Kyungjun Lee , Sungtae Ryu , Hwansoo Han, Performance implications of cache flushes for non-volatile memory file systems, Proceedings of the 30th Annual ACM Symposium on Applied Computing, April 13-17, 2015, Salamanca, Spain"
    },
    "2696582": {
        "abstract": "High performance storage layer is vital for allowing interactive ad hoc SQL analytics (OLAP style) over Big Data. The paper makes a case for leveraging flash in the Big Data stack to speed up queries. State-of-the-art Big Data layouts and algorithms are optimized for hard disks (i.e., sequential access is emphasized over random access) and result in suboptimal performance on flash given its drastically different performance characteristics. While existing columnar and row-columnar layouts are able to reduce disk IO compared to row-based layouts, they still end up reading significant columnar data irrelevant to the query as they only employ coarse-grained, intra-columnar data skipping which doesn't work across all queries. FlashQueryFile's specialized columnar data layouts, selection, and projection algorithms fully exploit fast random accesses and high internal I/O parallelism of flash to allow fast and I/O-efficient query processing and fine-grained, intra-columnar data skipping to minimize data read per query. FlashQueryFile results in 11X-100X TPC-H query speedup and 38%-99.08% reduction in data read compared to flash-based HDD-optimized row-columnar data layout and its associated algorithms.",
        "acm_key": "2696582",
        "bib_stats": {
            "cites": 5,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2696582",
        "text": "Hao Luo , Lei Tian , Hong Jiang, qNVRAM: quasi non-volatile RAM for low overhead persistency enforcement in smartphones, Proceedings of the 6th USENIX conference on Hot Topics in Storage and File Systems, p.4-4, June 17-18, 2014, Philadelphia, PA"
    },
    "2696591": {
        "abstract": "High performance storage layer is vital for allowing interactive ad hoc SQL analytics (OLAP style) over Big Data. The paper makes a case for leveraging flash in the Big Data stack to speed up queries. State-of-the-art Big Data layouts and algorithms are optimized for hard disks (i.e., sequential access is emphasized over random access) and result in suboptimal performance on flash given its drastically different performance characteristics. While existing columnar and row-columnar layouts are able to reduce disk IO compared to row-based layouts, they still end up reading significant columnar data irrelevant to the query as they only employ coarse-grained, intra-columnar data skipping which doesn't work across all queries. FlashQueryFile's specialized columnar data layouts, selection, and projection algorithms fully exploit fast random accesses and high internal I/O parallelism of flash to allow fast and I/O-efficient query processing and fine-grained, intra-columnar data skipping to minimize data read per query. FlashQueryFile results in 11X-100X TPC-H query speedup and 38%-99.08% reduction in data read compared to flash-based HDD-optimized row-columnar data layout and its associated algorithms.",
        "acm_key": "2696591",
        "bib_stats": {
            "cites": 8,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kang:2014:MSD:2696578.2696591,\n author = {Kang, Jeong-Uk and Hyun, Jeeseok and Maeng, Hyunjoo and Cho, Sangyeun},\n title = {The Multi-streamed Solid-state Drive},\n booktitle = {Proceedings of the 6th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'14},\n year = {2014},\n location = {Philadelphia, PA},\n pages = {13--13},\n numpages = {1},\n url = {http://dl.acm.org/citation.cfm?id=2696578.2696591},\n acmid = {2696591},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2696591",
        "pub_year": "2014",
        "text": "Jeong-Uk Kang , Jeeseok Hyun , Hyunjoo Maeng , Sangyeun Cho, The multi-streamed solid-state drive, Proceedings of the 6th USENIX conference on Hot Topics in Storage and File Systems, p.13-13, June 17-18, 2014, Philadelphia, PA"
    },
    "2699866": {
        "abstract": "Resilient design techniques are used to (i) ensure correct operation under dynamic variations and to (ii) improve design performance (e.g., timing speculation). However, significant overheads (e.g., 16&percnt; and 14&percnt; energy penalties due to throughput degradation and additional circuits) are incurred by existing resilient design techniques. For instance, resilient designs require additional circuits to detect and correct timing errors. Further, when there is an error, the additional cycles needed to restore a previous correct state degrade throughput, which diminishes the performance benefit of using resilient designs. In this work, we describe an improved methodology for resilient design implementation to minimize the costs of resilience in terms of power, area, and throughput degradation. Our methodology uses two levers: selective-endpoint optimization (i.e., sensitivity-based margin insertion) and clock skew optimization. We integrate the two optimization techniques in an iterative optimization flow which comprehends toggle rate information and the trade-off between cost of resilience and margin on combinational paths. Since the error-detection network can result in up to 9&percnt; additional wirelength cost, we also propose a matching-based algorithm for construction of the error-detection network to minimize this resilience overhead. Further, our implementations comprehend the impacts of signoff corners (in particular, hold constraints, and use of typical vs. slow libraries) and process variation, which are typically omitted in previous studies of resilience trade-offs. Our proposed flow achieves energy reductions of up to 21&percnt; and 10&percnt; compared to a conventional (with only margin used to attain robustness) design and a brute-force implementation (i.e., a typical resilient design, where resilient endpoints are (greedily) instantiated at timing-critical endpoints), respectively. We show that these benefits increase in the context of an adaptive voltage scaling strategy.",
        "acm_key": "2699866",
        "bib_stats": {
            "cites": 1,
            "dl": 216,
            "dl_52": 67,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Papandreou:2015:ERM:2830627.2699866,\n author = {Papandreou, Nikolaos and Parnell, Thomas and Pozidis, Haralampos and Mittelholzer, Thomas and Eleftheriou, Evangelos and Camp, Charles and Griffin, Thomas and Tressler, Gary and Walls, Andrew},\n title = {Enhancing the Reliability of MLC NAND Flash Memory Systems by Read Channel Optimization},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {September 2015},\n volume = {20},\n number = {4},\n month = sep,\n year = {2015},\n issn = {1084-4309},\n pages = {62:1--62:24},\n articleno = {62},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/2699866},\n doi = {10.1145/2699866},\n acmid = {2699866},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash, characterization, signal processing},\n} \r\n",
        "key": "2699866",
        "pub_year": "2015",
        "text": "Nikolaos Papandreou , Thomas Parnell , Haralampos Pozidis , Thomas Mittelholzer , Evangelos Eleftheriou , Charles Camp , Thomas Griffin , Gary Tressler , Andrew Walls, Enhancing the Reliability of MLC NAND Flash Memory Systems by Read Channel Optimization, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.20 n.4, September 2015  \u00a0[doi>"
    },
    "2699867": {
        "abstract": "We describe an automated pipelining approach for optimally balanced pipeline implementation that achieves low area cost as well as meeting timing requirements. Most previous automatic pipelining methods have focused on Instruction Set Architecture (ISA)-based designs and the main goal of such methods generally has been maximizing performance as measured in terms of instructions per clock (IPC). By contrast, we focus on datapath-oriented designs (e.g., DSP filters for image or communication processing applications) in ASIC design flows. The goal of the proposed pipelining approach is to find the optimally pipelined design that not only meets the user-specified target clock frequency, but also seeks to minimize area cost of a given design. Unlike most previous approaches, the proposed methods incorporate the use of accurate area and timing information (iteratively achieved by synthesizing every interim pipelined design) to achieve higher accuracy during design exploration. When compared with exhaustive design exploration that considers all possible pipeline patterns, the two heuristic pipelining methods presented here involve only a small area penalty (typically under 5&percnt;) while offering dramatically reduced computational complexity. Experimental validation is performed with commercial ASIC design tools and described for applications including polynomial function evaluation, FIR filters, matrix multiplication, and discrete wavelet transform filter designs with a 90nm standard cell library.",
        "acm_key": "2699867",
        "bib_stats": {
            "cites": 3,
            "dl": 160,
            "dl_52": 37,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Asadinia:2015:PLP:2742143.2699867,\n author = {Asadinia, Marjan and Arjomand, Mohammad and Azad, Hamid Sarbazi},\n title = {Prolonging Lifetime of PCM-Based Main Memories Through On-Demand Page Pairing},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {February 2015},\n volume = {20},\n number = {2},\n month = mar,\n year = {2015},\n issn = {1084-4309},\n pages = {23:1--23:24},\n articleno = {23},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/2699867},\n doi = {10.1145/2699867},\n acmid = {2699867},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase-change memory, multilevel cell, page pairing},\n} \r\n",
        "key": "2699867",
        "pub_year": "2015",
        "text": "Marjan Asadinia , Mohammad Arjomand , Hamid Sarbazi Azad, Prolonging Lifetime of PCM-Based Main Memories through On-Demand Page Pairing, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.20 n.2, p.1-24, February 2015"
    },
    "2700310": {
        "abstract": "As the popularity of NAND flash expands in arenas from embedded systems to high-performance computing, a high-fidelity understanding of its specific properties becomes increasingly important. Further, with the increasing trend toward multiple-die, multiple-plane architectures and high-speed interfaces, flash memory systems are expected to continue to scale and cheapen, resulting in their broader proliferation. However, when designing NAND-based devices, making decisions about the optimal system configuration is nontrivial, because flash is sensitive to a number of parameters and suffers from inherent latency variations, and no available tools suffice for studying these nuances. The parameters include the architectures, such as multidie and multiplane, diverse node technologies, bit densities, and cell reliabilities. Therefore, we introduce NANDFlashSim, a high-fidelity, latency-variation-aware, and highly configurable NAND-flash simulator, which implements a detailed timing model for 16 state-of-the-art NAND operations. Using NANDFlashSim, we notably discover the following. First, regardless of the operation, reads fail to leverage internal parallelism. Second, MLC provides lower I/O bus contention than SLC, but contention becomes a serious problem as the number of dies increases. Third, many-die architectures outperform many-plane architectures for disk-friendly workloads. Finally, employing a high-performance I/O bus or an increased page size does not enhance energy savings. Our simulator is available at http://nfs.camelab.org.",
        "acm_key": "2700310",
        "bib_stats": {
            "cites": 1,
            "dl": 430,
            "dl_52": 189,
            "dl_6": 17
        },
        "bibtex": "\r\n@article{Jung:2016:NHM:2888404.2700310,\n author = {Jung, Myoungsoo and Choi, Wonil and Gao, Shuwen and Wilson III, Ellis Herbert and Donofrio, David and Shalf, John and Kandemir, Mahmut Taylan},\n title = {NANDFlashSim: High-Fidelity, Microarchitecture-Aware NAND Flash Memory Simulation},\n journal = {Trans. Storage},\n issue_date = {February 2016},\n volume = {12},\n number = {2},\n month = jan,\n year = {2016},\n issn = {1553-3077},\n pages = {6:1--6:32},\n articleno = {6},\n numpages = {32},\n url = {http://doi.acm.org/10.1145/2700310},\n doi = {10.1145/2700310},\n acmid = {2700310},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, Non-volatile memory, cycle-level simulation, performance evaluation, solid state disk},\n} \r\n",
        "key": "2700310",
        "pub_year": "2016",
        "text": "Myoungsoo Jung , Wonil Choi , Shuwen Gao , Ellis Herbert Wilson III , David Donofrio , John Shalf , Mahmut Taylan Kandemir, NANDFlashSim: High-Fidelity, Microarchitecture-Aware NAND Flash Memory Simulation, ACM Transactions on Storage (TOS), v.12 n.2, p.1-32, February 2016"
    },
    "2701227": {
        "abstract": "Cloud computing has become a prevalent technology and with its increased maturity more and more data including sensitive and non sensitive, is being centralized into it. While outsourcing the sensitive data into public cloud, its prior encryption is strongly recommended. Provisioning of encryption and existing work that guarantee security and privacy concerns on sensitive data, have removed the holdouts against cloud adoption at a large. One of the main issue with this data in cloud environment is to manage user access and its auto revocation in a controlled and flexible way. The issue becomes more complex when privacy on user access has to be ensured as well to hide additional leakage of information. For automatic revocation over cloud data, access can be bounded within certain anticipated time limit so that the access expires beyond effective time period as proposed by one of the existing system as time based proxy re-encryption. This time-oriented approach is more rigid and not a one-size-fits-all solution. In certain circumstances exact time anticipation is not an easy choice. Instead, the alternate solution could be task-oriented to restrict user beyond certain number of permissible attempts to access the data. In this paper we have proposed a system that allows authorized users to access encrypted data for predefined attempts rather pre-defined time. Our approach allows user to avail permissible attempts without time restriction and at the same time also preserves the privacy aspect of user access by concealing access limit until availed. Performance analysis revealed that the cost of operations performed are within the range of .097 to .278 $ per 1000 requests.",
        "acm_key": "2701227",
        "bib_stats": {
            "cites": 0,
            "dl": 78,
            "dl_52": 21,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Lee:2015:MCO:2701126.2701227,\n author = {Lee, Hyun Ku and Kim, Junghoon and Kang, Dong Hyun and Eom, Young Ik},\n title = {Minimizing Consistency-control Overhead with Rollback-recovery for Storage Class Memory},\n booktitle = {Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication},\n series = {IMCOM '15},\n year = {2015},\n isbn = {978-1-4503-3377-1},\n location = {Bali, Indonesia},\n pages = {53:1--53:6},\n articleno = {53},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2701126.2701227},\n doi = {10.1145/2701126.2701227},\n acmid = {2701227},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data consistency, file system, rollback-recovery, storage class memory},\n} \r\n",
        "key": "2701227",
        "pub_year": "2015",
        "text": "Hyun Ku Lee , Junghoon Kim , Dong Hyun Kang , Young Ik Eom, Minimizing consistency-control overhead with rollback-recovery for storage class memory, Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication, p.1-6, January 08-10, 2015, Bali, Indonesia"
    },
    "2701429": {
        "abstract": "Recently, domain wall memory was proposed as a spintronic memory that has a potential for very high density by storing multiple bits in the domains of a ferromagnetic nanowire. While reliable operation of DWM memory with multiple domains faces many challenges, single-bit cells that utilize domain wall motion for writes have been experimentally demonstrated [Fukami et al. 2009]. This bit-cell, which we refer to as Domain Wall Memory with Shift-based Write (DWM-SW), achieves improved write efficiency and features decoupled read-write paths, enabling independent optimizations of read and write operations. However, these benefits are achieved at the cost of sacrificing the original goal of improved density. In this work, we explore multilevel storage as a new direction to enhance the density benefits of DWM-SW. At the device level, we propose a new device--multilevel DWM with shift-based write (ML-DWM-SW)--that is capable of storing 2 bits in a single device. At the circuit level, we propose a ML-DWM-SW based bit-cell design and layout. The ML-DWM-SW bit-cell incurs no additional area overhead compared to the DWM-SW bit-cell despite storing an additional bit, thereby achieving roughly twice the density. However, it requires a two-step write operation and has data-dependent read and write energies, which pose unique challenges. To address these issues, we propose suitable architectural optimizations: (i) intra-word interleaving and (ii) bit encoding. We design \u201call-spin\u201d cache architectures using the proposed ML-DWM-SW bit-cell for both general purpose processors as well as general purpose graphics processing units (GPGPUs). We perform an iso-capacity replacement of SRAM with spintronic memories and study the energy and area benefits at iso-performance conditions. For general purpose processors, the ML-DWM-SW cache achieves 10X reduction in energy and 4.4X reduction in cache area compared to an SRAM cache and 2X and 1.7X reduction in energy and area, respectively, compared to an STT-MRAM cache. For GPGPUs, the ML-DWM-SW cache achieves 5.3X reduction in energy and 3.6X area reduction compared to SRAM and 3.5X energy reduction and 1.9X area reduction compared to STT-MRAM.",
        "acm_key": "2701429",
        "bib_stats": {
            "cites": 1,
            "dl": 168,
            "dl_52": 57,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Park:2015:MER:2810396.2701429,\n author = {Park, Kyu Ho and Hwang, Woomin and Seok, Hyunchul and Kim, Chulmin and Shin, Dong-jae and Kim, Dong Jin and Maeng, Min Kyu and Kim, Seong Min},\n title = {MN-MATE: Elastic Resource Management of Manycores and a Hybrid Memory Hierarchy for a Cloud Node},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {July 2015},\n volume = {12},\n number = {1},\n month = aug,\n year = {2015},\n issn = {1550-4832},\n pages = {5:1--5:25},\n articleno = {5},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2701429},\n doi = {10.1145/2701429},\n acmid = {2701429},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVRAM, Virtual machine, hybrid main memory, resource management, scheduling},\n} \r\n",
        "key": "2701429",
        "pub_year": "2015",
        "text": "Kyu Ho Park , Woomin Hwang , Hyunchul Seok , Chulmin Kim , Dong-jae Shin , Dong Jin Kim , Min Kyu Maeng , Seong Min Kim, MN-MATE: Elastic Resource Management of Manycores and a Hybrid Memory Hierarchy for a Cloud Node, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.12 n.1, p.1-25, July 2015  \u00a0[doi>"
    },
    "2702808": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2702808",
        "bib_stats": {
            "cites": 65
        },
        "bibtex": "\r\n@article{Dong:2012:NCP:2702739.2702808,\n author = {Dong, Xiangyu and Xu, Cong and Xie, Yuan and Jouppi, Norman P.},\n title = {NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {July 2012},\n volume = {31},\n number = {7},\n month = jul,\n year = {2012},\n issn = {0278-0070},\n pages = {994--1007},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TCAD.2012.2185930},\n doi = {10.1109/TCAD.2012.2185930},\n acmid = {2702808},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2702808",
        "pub_year": "2012",
        "text": "Xiangyu Dong , Cong Xu , Yuan Xie , Norman P. Jouppi, NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.31 n.7, p.994-1007, July 2012  \u00a0[doi>"
    },
    "2703001": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2703001",
        "bib_stats": {
            "cites": 8
        },
        "bibtex": "\r\n@article{Mohan:2013:MPC:2702751.2703001,\n author = {Mohan, Vidyabhushan and Bunker, Trevor and Grupp, Laura and Gurumurthi, Sudhanva and Stan, Mircea R. and Swanson, Steven},\n title = {Modeling Power Consumption of NAND Flash Memories Using FlashPower},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {July 2013},\n volume = {32},\n number = {7},\n month = jul,\n year = {2013},\n issn = {0278-0070},\n pages = {1031--1044},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TCAD.2013.2249557},\n doi = {10.1109/TCAD.2013.2249557},\n acmid = {2703001},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2703001",
        "pub_year": "2013",
        "text": "Vidyabhushan Mohan , Trevor Bunker , Laura Grupp , Sudhanva Gurumurthi , Mircea R. Stan , Steven Swanson, Modeling Power Consumption of NAND Flash Memories Using FlashPower, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.32 n.7, p.1031-1044, July 2013  \u00a0[doi>"
    },
    "2712501": {
        "abstract": "During the functional verification, complex interactions between multiple blocks that compose an Intellectual Property (IP) core can reveal hard-to-find bugs. Functional verification specifications must be precise to assure these interactions occur during the simulation. In this work, we are proposing a technique for improving the functional verification specification of individual blocks, preserving the occurrence of these interaction scenarios in the composition phase. Our approach was implemented for the VeriSC methodology, a SystemC-based functional verification methodology. After each block that composes the IP core was stand-alone verified, we exploit the composition phase using set theory to increase the coverage numbers and to justify why some of these numbers cannot, or need not, reach 100%. By applying our approach in a MPEG 4 video decoder design, we show how our work can save functional verification time during the hierarchical composition. Using mutation based-tests, we demonstrate that our work can contribute to error detection. Furthermore, we demonstrate the effectiveness of our approach with regard to traditional structural coverage metrics, such as line coverage and branch coverage.",
        "acm_key": "2712501",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@article{Kwon:2011:FAN:2712444.2712501,\n author = {Kwon, Se Jin and Ranjitkar, Arun and Ko, Young-Bae and Chung, Tae-Sun},\n title = {FTL Algorithms for NAND-type Flash Memories},\n journal = {Des. Autom. Embedded Syst.},\n issue_date = {December  2011},\n volume = {15},\n number = {3-4},\n month = dec,\n year = {2011},\n issn = {0929-5585},\n pages = {191--224},\n numpages = {34},\n url = {http://dx.doi.org/10.1007/s10617-011-9071-9},\n doi = {10.1007/s10617-011-9071-9},\n acmid = {2712501},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Embedded system, FTL, NAND flash memory},\n} \r\n",
        "key": "2712501",
        "pub_year": "2011",
        "text": "Se Jin Kwon , Arun Ranjitkar , Young-Bae Ko , Tae-Sun Chung, FTL algorithms for NAND-type flash memories, Design Automation for Embedded Systems, v.15 n.3-4, p.191-224, December  2011"
    },
    "2712904": {
        "abstract": "Flash memory is being actively employed in a variety of embedded systems such as digital cameras, MP3 players, cell phones, solid state disks (SSDs), and digital media broadcasting (DMB) devices. This paper considers performance issues in file systems that employ Flash memory as a storage medium. Firstly, it explores the characteristics of Flash memory and identifies the cost of block cleaning as the key performance bottleneck for Flash memory analogous to the seek time in disk storage. Then, it defines three performance parameters, namely, utilization, invalidity, and uniformity and derives a formula for block cleaning cost based on these parameters. It is shown that, of these parameters, uniformity exerts the strongest influence on the cost of cleaning and that uniformity is a file system controllable parameter. Finally, we design a uniformity-aware page allocation scheme and analyze how enhanced uniformity affects the block cleaning cost with various workloads. Real implementation experiments conducted on an embedded system show that the scheme proposed here typically reduces the cleaning time by 20 to 30% compared to the traditional sequential allocation scheme that is used in YAFFS.",
        "acm_key": "2712904",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Baek:2009:DIU:2712467.2712904,\n author = {Baek, Seungjae and Choi, Jongmoo and Ahn, Seongjun and Lee, Donghee and Noh, Sam H.},\n title = {Design and Implementation of a Uniformity-improving Page Allocation Scheme for Flash-based Storage Systems},\n journal = {Des. Autom. Embedded Syst.},\n issue_date = {June      2009},\n volume = {13},\n number = {1-2},\n month = jun,\n year = {2009},\n issn = {0929-5585},\n pages = {5--25},\n numpages = {21},\n url = {http://dx.doi.org/10.1007/s10617-008-9023-1},\n doi = {10.1007/s10617-008-9023-1},\n acmid = {2712904},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {File system, Flash memory, Implementation, Modeling, Performance Evaluation, Uniformity},\n} \r\n",
        "key": "2712904",
        "pub_year": "2009",
        "text": "Seungjae Baek , Jongmoo Choi , Seongjun Ahn , Donghee Lee , Sam H. Noh, Design and implementation of a uniformity-improving page allocation scheme for flash-based storage systems, Design Automation for Embedded Systems, v.13 n.1-2, p.5-25, June      2009"
    },
    "2724949": {
        "abstract": "Automotive embedded systems have become very complex, are strongly integrated, and the safety-criticality and real-time constraints of these systems raise new challenges. Distributed system development, short time-to-market intervals, and automotive safety standards (such as ISO 26262 [8]) require efficient and consistent product development along the entire development lifecycle. The automotive OSEK/VDX standard provides an architecture for distributed real-time units in vehicles and a language aiming in specifying the configuration of real-time OSEK operating systems. The aim of this paper is to enhance a model-driven system-engineering framework with the capability of generating OS configurations from existing high level control system information. Furthermore, to enable the possibility to update stored information from OSEK Implementation Language (OIL) files and support round-trip engineering of real-time operating system (RTOS) configurations. This enables the seamless description of automotive RTOS, from system level requirements to software implementation and therefore ensures consistency and correctness of the configuration. To that aim, a bidirectional tool bridge is proposed based on OSEK OIL exchange format files.",
        "acm_key": "2724949",
        "bib_stats": {
            "cites": 1,
            "dl": 37,
            "dl_52": 8,
            "dl_6": 1
        },
        "bibtex": "\r\n@article{Olivier:2015:RRE:2724942.2724949,\n author = {Olivier, Pierre and Boukhobza, Jalil and Senn, Eric},\n title = {Revisiting Read-ahead Efficiency for Raw NAND Flash Storage in Embedded Linux},\n journal = {SIGBED Rev.},\n issue_date = {December 2014},\n volume = {11},\n number = {4},\n month = jan,\n year = {2015},\n issn = {1551-3688},\n pages = {43--48},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2724942.2724949},\n doi = {10.1145/2724942.2724949},\n acmid = {2724949},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {JFFS2, Linux page cache, YAFFS2, embedded Linux, flash file system, read-ahead},\n} \r\n",
        "key": "2724949",
        "pub_year": "2015",
        "text": "Pierre Olivier , Jalil Boukhobza , Eric Senn, Revisiting read-ahead efficiency for raw NAND flash storage in embedded Linux, ACM SIGBED Review, v.11 n.4, p.43-48, December 2014"
    },
    "2732960": {
        "abstract": "Recent proposals for deterministic database system designs argue that deterministic database systems facilitate replication since the same input can be independently sent to two different replicas without concern for replica divergence. In addition, they argue that determinism yields performance benefits due to (1) the introduction of deadlock avoidance techniques, (2) the reduction (or elimination) of distributed commit protocols, and (3) light-weight locking. However, these performance benefits are not universally applicable, and there exist several disadvantages of determinism, including (1) the additional overhead of processing transactions for which it is not known in advance what data will be accessed, (2) an inability to abort transactions arbitrarily (e.g., in the case of database or partition overload), and (3) the increased latency required by a preprocessing layer that ensures that the same input is sent to every replica. This paper presents a thorough experimental study that carefully investigates both the advantages and disadvantages of determinism, in order to give a database user a more complete understanding of which database to use for a given database workload and cluster configuration.",
        "acm_key": "2732960",
        "bib_stats": {
            "cites": 25,
            "dl": 274,
            "dl_52": 112,
            "dl_6": 23
        },
        "key": "2732960",
        "text": "Tianzheng Wang , Ryan Johnson, Scalable logging through emerging non-volatile memory, Proceedings of the VLDB Endowment, v.7 n.10, p.865-876, June 2014"
    },
    "2735180": {
        "abstract": "Graphics Processing Units (GPUs) have a large and complex design space that needs to be explored in order to optimize the performance of future GPUs. Statistical techniques are useful tools to help computer architects to predict performance of complex processors. In this study, these methods are utilized to build an effective performance prediction model for a Fermi GPU. The design space of this GPU is more than 8 million points. In order to build an accurate model, we propose a two-tier algorithm which builds a multiple linear regression model from a small set of simulated data. In this algorithm the Plackett and Burman design is used to find the key parameters of the GPU, and further simulations are guided by a fractional factorial design for the most important parameters. The generated performance model is able to predict the performance of any other point in the design space with an average prediction error between 1% to 5% for different benchmark applications. This accuracy is achieved by only sampling between 0.0003% to 0.0015% of the full design space.",
        "acm_key": "2735180",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@inproceedings{Oikawa:2014:IKC:2735154.2735180,\n author = {Oikawa, Shuichi},\n title = {Independent Kernel/Process Checkpointing on Non-Volatile Main Memory for Quick Kernel Rejuvenation},\n booktitle = {Proceedings of the 27th International Conference on Architecture of Computing Systems \\&\\#151; ARCS 2014 - Volume 8350},\n year = {2014},\n isbn = {978-3-319-04890-1},\n pages = {233--244},\n numpages = {12},\n url = {http://dx.doi.org/10.1007/978-3-319-04891-8_20},\n doi = {10.1007/978-3-319-04891-8_20},\n acmid = {2735180},\n publisher = {Springer-Verlag New York, Inc.},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2735180",
        "pub_year": "2014",
        "text": "Shuichi Oikawa, Independent Kernel/Process Checkpointing on Non-Volatile Main Memory for Quick Kernel Rejuvenation, Proceedings of the 27th International Conference on Architecture of Computing Systems \u0097 ARCS 2014, February 25-28, 2014  \u00a0[doi>"
    },
    "2737832": {
        "abstract": "As the popularity of NAND flash expands in arenas from embedded systems to high-performance computing, a high-fidelity understanding of its specific properties becomes increasingly important. Further, with the increasing trend toward multiple-die, multiple-plane architectures and high-speed interfaces, flash memory systems are expected to continue to scale and cheapen, resulting in their broader proliferation. However, when designing NAND-based devices, making decisions about the optimal system configuration is nontrivial, because flash is sensitive to a number of parameters and suffers from inherent latency variations, and no available tools suffice for studying these nuances. The parameters include the architectures, such as multidie and multiplane, diverse node technologies, bit densities, and cell reliabilities. Therefore, we introduce NANDFlashSim, a high-fidelity, latency-variation-aware, and highly configurable NAND-flash simulator, which implements a detailed timing model for 16 state-of-the-art NAND operations. Using NANDFlashSim, we notably discover the following. First, regardless of the operation, reads fail to leverage internal parallelism. Second, MLC provides lower I/O bus contention than SLC, but contention becomes a serious problem as the number of dies increases. Third, many-die architectures outperform many-plane architectures for disk-friendly workloads. Finally, employing a high-performance I/O bus or an increased page size does not enhance energy savings. Our simulator is available at http://nfs.camelab.org.",
        "acm_key": "2737832",
        "bib_stats": {
            "cites": 0,
            "dl": 380,
            "dl_52": 269,
            "dl_6": 18
        },
        "bibtex": "\r\n@article{Huang:2016:IFD:2888404.2737832,\n author = {Huang, Sai and Wei, Qingsong and Feng, Dan and Chen, Jianxi and Chen, Cheng},\n title = {Improving Flash-Based Disk Cache with Lazy Adaptive Replacement},\n journal = {Trans. Storage},\n issue_date = {February 2016},\n volume = {12},\n number = {2},\n month = feb,\n year = {2016},\n issn = {1553-3077},\n pages = {8:1--8:24},\n articleno = {8},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/2737832},\n doi = {10.1145/2737832},\n acmid = {2737832},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache algorithm, endurance, flash memory, solid-state drive},\n} \r\n",
        "key": "2737832",
        "pub_year": "2016",
        "text": "Sai Huang , Qingsong Wei , Dan Feng , Jianxi Chen , Cheng Chen, Improving Flash-Based Disk Cache with Lazy Adaptive Replacement, ACM Transactions on Storage (TOS), v.12 n.2, p.1-24, February 2016"
    },
    "2738615": {
        "abstract": "To fully exploit the power of emerging multicore architectures, managing shared resources (i.e., caches) across applications and over time is critical. However, to our knowledge, most prior efforts view this problem from the OS/hardware side, and do not consider whether applications themselves can also participate in this process of managing shared resources. In this paper, we show how an application can react to OS/hardware-based resource management decisions by adapting itself (called reactive application), with the goal of maximizing the utilization of the shared resources allocated to it. Specifically, we present a framework that can generate code for adaptive (reactive) tiling, and propose an execution model in which a reactive application can react to the modulations in its cache space allocations to prevent its performance from degrading. One can expect two potential benefits from this approach. First, matching tile size to available cache capacity dynamically (during execution) improves performance of the target application. Second and equally important, better utilization of shared cache space reduces pressure on other applications (co-runners) that execute concurrently with the target application. Our experimental results show that the proposed scheme improves the performance of applications (over the best static tiles) by 8.4%, on average, when using synthetic cache allocations. Further with dynamic cache allocations determined by the utility-based cache partitioning (a state-of-the-art cache partitioning scheme), it improves performance of a set of eleven HPC applications by 11.3%.",
        "acm_key": "2738615",
        "bib_stats": {
            "cites": 1,
            "dl": 68,
            "dl_52": 20,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Pallister:2015:OFE:2738600.2738615,\n author = {Pallister, James and Eder, Kerstin and Hollis, Simon J.},\n title = {Optimizing the flash-RAM Energy Trade-off in Deeply Embedded Systems},\n booktitle = {Proceedings of the 13th Annual IEEE/ACM International Symposium on Code Generation and Optimization},\n series = {CGO '15},\n year = {2015},\n isbn = {978-1-4799-8161-8},\n location = {San Francisco, California},\n pages = {115--124},\n numpages = {10},\n url = {http://dl.acm.org/citation.cfm?id=2738600.2738615},\n acmid = {2738615},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2738615",
        "pub_year": "2015",
        "text": "James Pallister , Kerstin Eder , Simon J. Hollis, Optimizing the flash-RAM energy trade-off in deeply embedded systems, Proceedings of the 13th Annual IEEE/ACM International Symposium on Code Generation and Optimization, February 07-11, 2015, San Francisco, California"
    },
    "2742171": {
        "abstract": "Smart phones and tablets have recently become widespread and dominant in the computer market. Users require that these mobile devices provide a high-quality experience and an even higher performance. Hence, major developers adopt out-of-order superscalar processors as application processors. However, these processors consume much more energy than in-order superscalar processors, because a large amount of energy is consumed by the hardware for dynamic instruction scheduling. We propose a Front-end Execution Architecture (FXA). FXA has two execution units: an out-of-order execution unit (OXU) and an in-order execution unit (IXU). The OXU is the execution core of a common out-of-order superscalar processor. In contrast, the IXU comprises functional units and a bypass network only. The IXU is placed at the processor front end and executes instructions without scheduling. Fetched instructions are first fed to the IXU, and the instructions that are already ready or become ready to execute by the resolution of their dependencies through operand bypassing in the IXU are executed in-order. Not ready instructions go through the IXU as a NOP, thereby, its pipeline is not stalled, and instructions keep flowing. The not-ready instructions are then dispatched to the OXU, and are executed out-of-order. The IXU does not include dynamic scheduling logic, and its energy consumption is consequently small. Evaluation results show that FXA can execute over 50% of instructions using IXU, thereby making it possible to shrink the energy-consuming OXU without incurring performance degradation. As a result, FXA achieves both a high performance and low energy consumption. We evaluated FXA compared with conventional out-of-order/in-order superscalar processors after ARM big. LITTLE architecture. The results show that FXA achieves performance improvements of 67% at the maximum and 7.4% on geometric mean in SPECCPU INT 2006 benchmark suite relative to a conventional superscalar processor (big), while reducing the energy consumption by 86% at the issue queue and 17% in the whole processor. The performance/energy ratio (the inverse of the energy-delay product) of FXA is 25% higher than that of a conventional superscalar processor (big) and 27% higher than that of a conventional in-order superscalar processor (LITTLE).",
        "acm_key": "2742171",
        "bib_stats": {
            "cites": 20,
            "dl": 147,
            "dl_52": 40,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Zhao:2014:FFH:2742155.2742171,\n author = {Zhao, Jishen and Mutlu, Onur and Xie, Yuan},\n title = {FIRM: Fair and High-Performance Memory Control for Persistent Memory Systems},\n booktitle = {Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture},\n series = {MICRO-47},\n year = {2014},\n isbn = {978-1-4799-6998-2},\n location = {Cambridge, United Kingdom},\n pages = {153--165},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/MICRO.2014.47},\n doi = {10.1109/MICRO.2014.47},\n acmid = {2742171},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2742171",
        "pub_year": "2014",
        "text": "Jishen Zhao , Onur Mutlu , Yuan Xie, FIRM: Fair and High-Performance Memory Control for Persistent Memory Systems, Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture, December 13-17, 2014, Cambridge, United Kingdom  \u00a0[doi>"
    },
    "2742864": {
        "abstract": "Optical interconnect is a fundamental requisite to realize Internet-scale data centers due to capabilities and benefits of optical devices. Optical interconnects are energy efficient and offer massive bandwidth support. State of the art interconnects can be divided into three types based on the optical technology used: 1) micro-electromechanical system (MEMS) optical cross connects (OXCs), 2) arrayed waveguide grating routers (AWGRs) and 3) semiconductor optical amplifiers (SOAs). MEMS switches are based on mature technology, have low insertion loss and cross-talk, and are data rate independent. They are also the most scalable and the cheapest class of optical switches. However, the reconfiguration time of these switches is in the order of tens of milliseconds. An AWGR switch is a passive device and works in conjunction with tunable wavelength converters (TWCs) or tunable lasers (TLs) while an SOA works as a gate element that manipulates light and also compensates for losses that occur during transmission of optical signals. AWGR and SOA switches have switching time in the range of nanoseconds but they are expensive as compared to MEMS. In this paper, we propose a novel all optical core interconnection scheme that utilizes potentials of both slow and fast optical switches. The core idea is to route traffic through slow or fast optical switch so that minimum end-to-end latency is achieved. Our architecture employs a single stage topology which allows our design to both incrementally scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network reconfiguration. We evaluate performance of the system using simulation and investigate a trade-off between cost and power consumption by comparing it with other well known interconnects. Our technique demonstrates a considerable improvement in power consumption and low latency with high throughput is achieved.",
        "acm_key": "2742864",
        "bib_stats": {
            "cites": 3,
            "dl": 211,
            "dl_52": 47,
            "dl_6": 5
        },
        "key": "2742864",
        "text": "Long Sun , Youyou Lu , Jiwu Shu, DP2<sup>2</sup>: reducing transaction overhead with differential and dual persistency in persistent memory, Proceedings of the 12th ACM International Conference on Computing Frontiers, p.1-8, May 18-21, 2015, Ischia, Italy&#13;\n\t\t\t\t\t\t: reducing transaction overhead with differential and dual persistency in persistent memory, Proceedings of the 12th ACM International Conference on Computing Frontiers, p.1-8, May 18-21, 2015, Ischia, Italy"
    },
    "2742873": {
        "abstract": "Optical interconnect is a fundamental requisite to realize Internet-scale data centers due to capabilities and benefits of optical devices. Optical interconnects are energy efficient and offer massive bandwidth support. State of the art interconnects can be divided into three types based on the optical technology used: 1) micro-electromechanical system (MEMS) optical cross connects (OXCs), 2) arrayed waveguide grating routers (AWGRs) and 3) semiconductor optical amplifiers (SOAs). MEMS switches are based on mature technology, have low insertion loss and cross-talk, and are data rate independent. They are also the most scalable and the cheapest class of optical switches. However, the reconfiguration time of these switches is in the order of tens of milliseconds. An AWGR switch is a passive device and works in conjunction with tunable wavelength converters (TWCs) or tunable lasers (TLs) while an SOA works as a gate element that manipulates light and also compensates for losses that occur during transmission of optical signals. AWGR and SOA switches have switching time in the range of nanoseconds but they are expensive as compared to MEMS. In this paper, we propose a novel all optical core interconnection scheme that utilizes potentials of both slow and fast optical switches. The core idea is to route traffic through slow or fast optical switch so that minimum end-to-end latency is achieved. Our architecture employs a single stage topology which allows our design to both incrementally scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network reconfiguration. We evaluate performance of the system using simulation and investigate a trade-off between cost and power consumption by comparing it with other well known interconnects. Our technique demonstrates a considerable improvement in power consumption and low latency with high throughput is achieved.",
        "acm_key": "2742873",
        "bib_stats": {
            "cites": 0,
            "dl": 92,
            "dl_52": 29,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Wu:2015:DHP:2742854.2742873,\n author = {Wu, Lizhou and Xiao, Nong and Liu, Fang and Du, Yimo and Li, Shuo and Ou, Yang},\n title = {Dysource: A High Performance and Scalable NAND Flash Controller Architecture Based on Source Synchronous Interface},\n booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},\n series = {CF '15},\n year = {2015},\n isbn = {978-1-4503-3358-0},\n location = {Ischia, Italy},\n pages = {25:1--25:8},\n articleno = {25},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2742854.2742873},\n doi = {10.1145/2742854.2742873},\n acmid = {2742873},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash, dynamic scheduling, source synchronous interface, storage system},\n} \r\n",
        "key": "2742873",
        "pub_year": "2015",
        "text": "Lizhou Wu , Nong Xiao , Fang Liu , Yimo Du , Shuo Li , Yang Ou, Dysource: a high performance and scalable NAND flash controller architecture based on source synchronous interface, Proceedings of the 12th ACM International Conference on Computing Frontiers, p.1-8, May 18-21, 2015, Ischia, Italy"
    },
    "2742902": {
        "abstract": "Optical interconnect is a fundamental requisite to realize Internet-scale data centers due to capabilities and benefits of optical devices. Optical interconnects are energy efficient and offer massive bandwidth support. State of the art interconnects can be divided into three types based on the optical technology used: 1) micro-electromechanical system (MEMS) optical cross connects (OXCs), 2) arrayed waveguide grating routers (AWGRs) and 3) semiconductor optical amplifiers (SOAs). MEMS switches are based on mature technology, have low insertion loss and cross-talk, and are data rate independent. They are also the most scalable and the cheapest class of optical switches. However, the reconfiguration time of these switches is in the order of tens of milliseconds. An AWGR switch is a passive device and works in conjunction with tunable wavelength converters (TWCs) or tunable lasers (TLs) while an SOA works as a gate element that manipulates light and also compensates for losses that occur during transmission of optical signals. AWGR and SOA switches have switching time in the range of nanoseconds but they are expensive as compared to MEMS. In this paper, we propose a novel all optical core interconnection scheme that utilizes potentials of both slow and fast optical switches. The core idea is to route traffic through slow or fast optical switch so that minimum end-to-end latency is achieved. Our architecture employs a single stage topology which allows our design to both incrementally scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network reconfiguration. We evaluate performance of the system using simulation and investigate a trade-off between cost and power consumption by comparing it with other well known interconnects. Our technique demonstrates a considerable improvement in power consumption and low latency with high throughput is achieved.",
        "acm_key": "2742902",
        "bib_stats": {
            "cites": 0,
            "dl": 104,
            "dl_52": 20,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Giles:2015:FAC:2742854.2742902,\n author = {Giles, Ellis and Doshi, Kshitij and Varman, Peter},\n title = {Free Atomic Consistency in Storage Class Memory with Software Based Write-aside Persistence},\n booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},\n series = {CF '15},\n year = {2015},\n isbn = {978-1-4503-3358-0},\n location = {Ischia, Italy},\n pages = {46:1--46:2},\n articleno = {46},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2742854.2742902},\n doi = {10.1145/2742854.2742902},\n acmid = {2742902},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2742902",
        "pub_year": "2015",
        "text": "Ellis Giles , Kshitij Doshi , Peter Varman, Free atomic consistency in storage class memory with software based write-aside persistence, Proceedings of the 12th ACM International Conference on Computing Frontiers, p.1-2, May 18-21, 2015, Ischia, Italy"
    },
    "2744405": {
        "abstract": "The number of cores per processor has been increased on and on in recent years. Carrying on with that, manycore processor systems will be the future system structure, and even within range for usage in desktop or mobile systems. But today's manycore processors are primarily designed for high performance applications. Access to the external memory from the individual cores is avoided. As yet the system memory commonly consists of only one or a few memory components and offers access over a small number of controllers. This leads to congestion, inefficient memory assignment and the scalability of the memory is limited. However, there will be additional new scenarios, with multiple concurrently running dynamic applications, changing I/O characteristics and a not predictable memory usage in the near future. Highly dynamic workloads with varying memory usage have to be utilized. Consequently, the memory management must become more flexible and distributed in nature. Moreover, dynamic memory allocation will be a necessity, and a transparent optimization of the physical memory resource utilization can be done with integrated self-organization mechanisms, e.g. for locality, load distribution or energy efficiency issues. The autonomous self-optimizing memory architecture Self-aware Memory satisfies all these challenges with a scalable pooling of fully-decentralized interacting memory components. With it, flexible, reliable and scalable memory management is available. Access to private and shared memory is enabled in a flexible way and efficient synchronization mechanism are offered while contemporaneously providing comfortable usage and supporting well-known programming mechanisms. The presented evaluation addresses the parameters of the included self-optimization mechanism and their impact on the optimization. The results show that the overhead of the decentralized optimization process is amortized by the optimized runtime using the appropriate parameter settings.",
        "acm_key": "2744405",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Li:2013:CWM:2744357.2744405,\n author = {Li, Jian and Zhuge, Qingfeng and Liu, Duo and Luo, Huizhang and Sha, Edwin H.-M.},\n title = {A Content-aware Writing Mechanism for Reducing Energy on Non-volatile Memory Based Embedded Storage Systems},\n journal = {Des. Autom. Embedded Syst.},\n issue_date = {September 2013},\n volume = {17},\n number = {3-4},\n month = sep,\n year = {2013},\n issn = {0929-5585},\n pages = {711--737},\n numpages = {27},\n url = {http://dx.doi.org/10.1007/s10617-014-9150-9},\n doi = {10.1007/s10617-014-9150-9},\n acmid = {2744405},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Energy consumption, Non-volatile memory, Phase change memory, Write activity},\n} \r\n",
        "key": "2744405",
        "pub_year": "2013",
        "text": "Jian Li , Qingfeng Zhuge , Duo Liu , Huizhang Luo , Edwin H.-M. Sha, A content-aware writing mechanism for reducing energy on non-volatile memory based embedded storage systems, Design Automation for Embedded Systems, v.17 n.3-4, p.711-737, September 2013"
    },
    "2744809": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744809",
        "bib_stats": {
            "cites": 2,
            "dl": 173,
            "dl_52": 43,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Li:2015:CDA:2744769.2744809,\n author = {Li, Qingan and Zhao, Mengying and Hu, Jingtong and Liu, Yongpan and He, Yanxiang and Xue, Chun Jason},\n title = {Compiler Directed Automatic Stack Trimming for Efficient Non-volatile Processors},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {183:1--183:6},\n articleno = {183},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744809},\n doi = {10.1145/2744769.2744809},\n acmid = {2744809},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {compiler, non-volatile processor, stack},\n} \r\n",
        "key": "2744809",
        "pub_year": "2015",
        "text": "Qingan Li , Mengying Zhao , Jingtong Hu , Yongpan Liu , Yanxiang He , Chun Jason Xue, Compiler directed automatic stack trimming for efficient non-volatile processors, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California  \u00a0[doi>"
    },
    "2744841": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744841",
        "bib_stats": {
            "cites": 0,
            "dl": 159,
            "dl_52": 60,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Wang:2015:EIC:2744769.2744841,\n author = {Wang, Rujia and Jiang, Lei and Zhang, Youtao and Wang, Linzhang and Yang, Jun},\n title = {Exploit Imbalanced Cell Writes to Mitigate Write Disturbance in Dense Phase Change Memory},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {88:1--88:6},\n articleno = {88},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744841},\n doi = {10.1145/2744769.2744841},\n acmid = {2744841},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {PCM, density, reliability, write disturbance},\n} \r\n",
        "key": "2744841",
        "pub_year": "2015",
        "text": "Rujia Wang , Lei Jiang , Youtao Zhang , Linzhang Wang , Jun Yang, Exploit imbalanced cell writes to mitigate write disturbance in dense phase change memory, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California"
    },
    "2744842": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744842",
        "bib_stats": {
            "cites": 9,
            "dl": 314,
            "dl_52": 113,
            "dl_6": 10
        },
        "bibtex": "\r\n@inproceedings{Xie:2015:FBT:2744769.2744842,\n author = {Xie, Mimi and Zhao, Mengying and Pan, Chen and Hu, Jingtong and Liu, Yongpan and Xue, Chun Jason},\n title = {Fixing the Broken Time Machine: Consistency-aware Checkpointing for Energy Harvesting Powered Non-volatile Processor},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {184:1--184:6},\n articleno = {184},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744842},\n doi = {10.1145/2744769.2744842},\n acmid = {2744842},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2744842",
        "pub_year": "2015",
        "text": "Mimi Xie , Mengying Zhao , Chen Pan , Jingtong Hu , Yongpan Liu , Chun Jason Xue, Fixing the broken time machine: consistency-aware checkpointing for energy harvesting powered non-volatile processor, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California  \u00a0[doi>"
    },
    "2744843": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744843",
        "bib_stats": {
            "cites": 1,
            "dl": 138,
            "dl_52": 38,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Guo:2015:FNN:2744769.2744843,\n author = {Guo, Jie and Wen, Wujie and Hu, Jingtong and Wang, Danghui and Li, Hai and Chen, Yiran},\n title = {FlexLevel: A Novel NAND Flash Storage System Design for LDPC Latency Reduction},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {194:1--194:6},\n articleno = {194},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744843},\n doi = {10.1145/2744769.2744843},\n acmid = {2744843},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {LDPC, NAND, bit error rate, flash memories},\n} \r\n",
        "key": "2744843",
        "pub_year": "2015",
        "text": "Jie Guo , Wujie Wen , Jingtong Hu , Danghui Wang , Hai Li , Yiran Chen, FlexLevel: a novel NAND flash storage system design for LDPC latency reduction, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California"
    },
    "2744908": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744908",
        "bib_stats": {
            "cites": 6,
            "dl": 288,
            "dl_52": 76,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Wang:2015:SRE:2744769.2744908,\n author = {Wang, Rujia and Jiang, Lei and Zhang, Youtao and Wang, Linzhang and Yang, Jun},\n title = {Selective Restore: An Energy Efficient Read Disturbance Mitigation Scheme for Future STT-MRAM},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {21:1--21:6},\n articleno = {21},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744908},\n doi = {10.1145/2744769.2744908},\n acmid = {2744908},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-MRAM, energy, read disturbance},\n} \r\n",
        "key": "2744908",
        "pub_year": "2015",
        "text": "Rujia Wang , Lei Jiang , Youtao Zhang , Linzhang Wang , Jun Yang, Selective restore: an energy efficient read disturbance mitigation scheme for future STT-MRAM, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California  \u00a0[doi>"
    },
    "2744909": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744909",
        "bib_stats": {
            "cites": 4,
            "dl": 134,
            "dl_52": 41,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Jang:2015:SSU:2744769.2744909,\n author = {Jang, Jae-Won and Park, Jongsun and Ghosh, Swaroop and Bhunia, Swarup},\n title = {Self-correcting STTRAM Under Magnetic Field Attacks},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {77:1--77:6},\n articleno = {77},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744909},\n doi = {10.1145/2744769.2744909},\n acmid = {2744909},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STTRAM, contactless tampering, magnetic field attack, on-chip tamper mitigation, replica, variable ECC},\n} \r\n",
        "key": "2744909",
        "pub_year": "2015",
        "text": "Jae-Won Jang , Jongsun Park , Swaroop Ghosh , Swarup Bhunia, Self-correcting STTRAM under magnetic field attacks, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California  \u00a0[doi>"
    },
    "2744929": {
        "abstract": "Several decades of technology scaling has brought the challenge of soft errors to modern computing systems, and caches are most susceptible to soft errors. While it is straightforward to protect L2 and other lower level caches using error correcting coding (ECC), protecting the L1 data caches poses a challenge. Parity-based protection of L1 data cache is a more power-efficient alternative, however, some questions still linger -- How effective is parity protection for caches? How can we design a parity-based L1 data cache so as to maximize the protection achieved? The goal of this paper is to perform a quantitative evaluation of the protection afforded by various parity-protected cache design alternatives, and formulate guidelines for the design of power-efficient and reliable L1 data caches. Towards this goal, this paper develops an algorithm to accurately model the vulnerability of data in caches, in the presence of various configurations of parity protection, and validate it against extensive fault injection campaigns. We find that, (i) checking parity at reads only (and not at writes) provides 11% more protection with 30% lesser power overheads as compared to that at both reads and writes; and (ii) when implementing parity at the word-level granularity for 53% improved protection as compared to block-level parity implementation, the dirty-bits in the cache should also be implemented at the same granularity, otherwise, there is no improvement in protection. We find several popular commercial processors -- even the ones specifically designed for reliability -- not following these design guidelines, and resulting in sub-optimial designs.",
        "acm_key": "2744929",
        "bib_stats": {
            "cites": 0,
            "dl": 75,
            "dl_52": 21,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Yang:2015:VFC:2744769.2744929,\n author = {Yang, Ming-Chang and Chang, Yuan-Hao and Kuo, Tei-Wei},\n title = {Virtual Flash Chips: Rethinking the Layer Design of Flash Devices to Improve Data Recoverability},\n booktitle = {Proceedings of the 52Nd Annual Design Automation Conference},\n series = {DAC '15},\n year = {2015},\n isbn = {978-1-4503-3520-1},\n location = {San Francisco, California},\n pages = {193:1--193:6},\n articleno = {193},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2744769.2744929},\n doi = {10.1145/2744769.2744929},\n acmid = {2744929},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2744929",
        "pub_year": "2015",
        "text": "Ming-Chang Yang , Yuan-Hao Chang , Tei-Wei Kuo, Virtual flash chips: rethinking the layer design of flash devices to improve data recoverability, Proceedings of the 52nd Annual Design Automation Conference, p.1-6, June 07-11, 2015, San Francisco, California"
    },
    "2746480": {
        "abstract": "The increasing popularity and widespread use of online review sites over the past decade has motivated businesses of all types to possess an expansive arsenal of user feedback (preferably positive) in order to mark their reputation and presence in the Web. Though a significant proportion of purchasing decisions today are driven by average numeric scores (e.g., movie rating in IMDB), detailed reviews are critical for activities such as buying an expensive digital SLR camera, reserving a vacation package, etc. Since writing a detailed review for a product (or, a service) is usually time-consuming and may not offer any incentive, the number of useful reviews available in the Web is far from many. The corpus of reviews available at our disposal for making informed decisions also suffers from spam and misleading content, typographical and grammatical errors, etc. In this paper, we address the problem of how to engage the lurkers (i.e., people who read reviews but never take time and effort to write one) to participate and write online reviews by systematically simplifying the reviewing task. Given a user and an item that she wants to review, the task is to identify the top-$k$ meaningful phrases (i.e., tags) from the set of all tags (i.e., available user feedback for items) that, when advised, would help her review an item easily. We refer to it as the TagAdvisor problem, and formulate it as a general-constrained optimization goal. Our framework is centered around three measures - relevance (i.e., how well the result set of tags describes an item to a user), coverage (i.e., how well the result set of tags covers the different aspects of an item), and polarity (i.e., how well sentiment is attached to the result set of tags) in order to help a user review an item satisfactorily. By adopting different definitions of coverage, we identify two concrete problem instances that enable a wide range of real-world scenarios. We show that these problems are NP-hard and develop practical algorithms with theoretical bounds to solve them efficiently. We conduct detailed experiments on synthetic and real data crawled from the web to validate the utility of our problem and effectiveness of our solutions.",
        "acm_key": "2746480",
        "bib_stats": {
            "cites": 19,
            "dl": 1,
            "dl_52": 340,
            "dl_6": 14
        },
        "bibtex": "\r\n@inproceedings{Kimura:2015:FOE:2723372.2746480,\n author = {Kimura, Hideaki},\n title = {FOEDUS: OLTP Engine for a Thousand Cores and NVRAM},\n booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},\n series = {SIGMOD '15},\n year = {2015},\n isbn = {978-1-4503-2758-9},\n location = {Melbourne, Victoria, Australia},\n pages = {691--706},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2723372.2746480},\n doi = {10.1145/2723372.2746480},\n acmid = {2746480},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {many-cores, nvram},\n} \r\n",
        "key": "2746480",
        "pub_year": "2015",
        "text": "Hideaki Kimura, FOEDUS: OLTP Engine for a Thousand Cores and NVRAM, Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data, May 31-June 04, 2015, Melbourne, Victoria, Australia  \u00a0[doi>"
    },
    "2750500": {
        "abstract": "Host-side flash storage opens up an exciting avenue for accelerating Virtual Machine (VM) writes in virtualized datacenters. The key challenge with implementing such an acceleration layer is to do so without breaking live VM migration which is essential for providing distributed resource management and high availability. High availability also powers-on VMs on new host when the previous host crashes. We introduce FVP, a fault tolerant host-side flash write acceleration layer that seamlessly integrates with the virtualized environment while preserving dynamic resource management and high availability, the holy tenets of a virtualized environment. FVP integrates with the VMware ESX hypervisor kernel to intercept VM I/O and redirects the I/O to host-side flash devices. VMs experience flash latencies instead of SAN latencies and write intensive applications such as databases and email servers benefit from predictable write throughput. No changes are required to the VM guest operating systems so VM applications can continue to function seamlessly without any modifications. FVP pools together all the host-side flash devices in the cluster so every host can access another host's flash device preserving VM mobility. By replicating VM writes onto peer host-side flash devices, FVP is able to tolerate multiple cascading host and flash failures. Failure recovery is distributed, requiring no central co-ordination. We describe the workings of the FVP key components and demonstrate how FVP reduces VM latencies to accelerate VM writes, improves performance predictability, and increases virtualized datacenter efficiency.",
        "acm_key": "2750500",
        "bib_stats": {
            "cites": 5,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2015:MDC:2750482.2750500,\n author = {Li, Jiangpeng and Zhao, Kai and Zhang, Xuebin and Ma, Jun and Zhao, Ming and Zhang, Tong},\n title = {How Much Can Data Compressibility Help to Improve NAND Flash Memory Lifetime?},\n booktitle = {Proceedings of the 13th USENIX Conference on File and Storage Technologies},\n series = {FAST'15},\n year = {2015},\n isbn = {978-1-931971-201},\n location = {Santa Clara, CA},\n pages = {227--240},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2750482.2750500},\n acmid = {2750500},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2750500",
        "pub_year": "2015",
        "text": "Jiangpeng Li , Kai Zhao , Xuebin Zhang , Jun Ma , Ming Zhao , Tong Zhang, How much can data compressibility help to improve NAND flash memory lifetime?, Proceedings of the 13th USENIX Conference on File and Storage Technologies, p.227-240, February 16-19, 2015, Santa Clara, CA"
    },
    "2750503": {
        "abstract": "Host-side flash storage opens up an exciting avenue for accelerating Virtual Machine (VM) writes in virtualized datacenters. The key challenge with implementing such an acceleration layer is to do so without breaking live VM migration which is essential for providing distributed resource management and high availability. High availability also powers-on VMs on new host when the previous host crashes. We introduce FVP, a fault tolerant host-side flash write acceleration layer that seamlessly integrates with the virtualized environment while preserving dynamic resource management and high availability, the holy tenets of a virtualized environment. FVP integrates with the VMware ESX hypervisor kernel to intercept VM I/O and redirects the I/O to host-side flash devices. VMs experience flash latencies instead of SAN latencies and write intensive applications such as databases and email servers benefit from predictable write throughput. No changes are required to the VM guest operating systems so VM applications can continue to function seamlessly without any modifications. FVP pools together all the host-side flash devices in the cluster so every host can access another host's flash device preserving VM mobility. By replicating VM writes onto peer host-side flash devices, FVP is able to tolerate multiple cascading host and flash failures. Failure recovery is distributed, requiring no central co-ordination. We describe the workings of the FVP key components and demonstrate how FVP reduces VM latencies to accelerate VM writes, improves performance predictability, and increases virtualized datacenter efficiency.",
        "acm_key": "2750503",
        "bib_stats": {
            "cites": 37,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lee:2015:FNF:2750482.2750503,\n author = {Lee, Changman and Sim, Dongho and Hwang, Joo-Young and Cho, Sangyeun},\n title = {F2FS: A New File System for Flash Storage},\n booktitle = {Proceedings of the 13th USENIX Conference on File and Storage Technologies},\n series = {FAST'15},\n year = {2015},\n isbn = {978-1-931971-201},\n location = {Santa Clara, CA},\n pages = {273--286},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2750482.2750503},\n acmid = {2750503},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2750503",
        "pub_year": "2015",
        "text": "Changman Lee , Dongho Sim , Joo-Young Hwang , Sangyeun Cho, F2FS: a new file system for flash storage, Proceedings of the 13th USENIX Conference on File and Storage Technologies, p.273-286, February 16-19, 2015, Santa Clara, CA"
    },
    "2751212": {
        "abstract": "While there have been prior studies on underprovisioning the power distribution infrastructure for a grid-based datacenter, how to save grid capital investment by means of leveraging renewable energy to underprovision the grid power infrastructure in green datacenters remains largely an unexplored, open issue. Aggressively underprovisioning grid infrastructure can trigger power emergency in which simultaneous peak power draws across the datacenter exceed the tightly budgeted grid power capacity, leading to possible serious consequences including power shutdown. The resulting power emergency mandates a graceful reaction mechanism to sustain the power requirement to avoid power overdraw. While leveraging renewable energy in a green datacenter provides a possibility to prevent power overdraw during such a power emergency, the intermittent nature of renewable energy makes it a very challenging task because of the potentially unpredictable performance impact to individual applications. This paper addresses this issue by designing a novel renewable energy delivery infrastructure and considering performance consequences to individual applications of underprovisioning the grid power infrastructure in the presence of varied renewable power and limited battery's energy capacity in a datacenter. We build an experimental prototype to demonstrate such grid power underprovisioning on a cluster of 10 servers, with a simulated solar power generator. Using representative datacenter benchmarks to evaluate the effectiveness of the renewable solution in handling power emergencies, we show that renewable energy by itself can sustain different duration lengths of power emergency when its supply is sufficient. Batteries play an important role for performance boost when the supply of the renewable energy is insufficient. Our theoretical solution, in conjunction with workload migration, provides a seamless bridge across the whole spectrum of duration lengths of power emergency.",
        "acm_key": "2751212",
        "bib_stats": {
            "cites": 5,
            "dl": 209,
            "dl_52": 91,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Gao:2015:RIC:2751205.2751212,\n author = {Gao, Shen and He, Bingsheng and Xu, Jianliang},\n title = {Real-Time In-Memory Checkpointing for Future Hybrid Memory Systems},\n booktitle = {Proceedings of the 29th ACM on International Conference on Supercomputing},\n series = {ICS '15},\n year = {2015},\n isbn = {978-1-4503-3559-1},\n location = {Newport Beach, California, USA},\n pages = {263--272},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2751205.2751212},\n doi = {10.1145/2751205.2751212},\n acmid = {2751212},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {checkpointing, nvram, parallel computing, phase change memory},\n} \r\n",
        "key": "2751212",
        "pub_year": "2015",
        "text": "Shen Gao , Bingsheng He , Jianliang Xu, Real-Time In-Memory Checkpointing for Future Hybrid Memory Systems, Proceedings of the 29th ACM on International Conference on Supercomputing, June 08-11, 2015, Newport Beach, California, USA"
    },
    "2755881": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2755881",
        "bib_stats": {
            "cites": 6,
            "dl": 206,
            "dl_52": 52,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Zhao:2015:SAN:2755753.2755881,\n author = {Zhao, Mengying and Li, Qingan and Xie, Mimi and Liu, Yongpan and Hu, Jingtong and Xue, Chun Jason},\n title = {Software Assisted Non-volatile Register Reduction for Energy Harvesting Based Cyber-physical System},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {567--572},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2755881},\n acmid = {2755881},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2755881",
        "pub_year": "2015",
        "text": "Mengying Zhao , Qingan Li , Mimi Xie , Yongpan Liu , Jingtong Hu , Chun Jason Xue, Software assisted non-volatile register reduction for energy harvesting based cyber-physical system, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2755948": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2755948",
        "bib_stats": {
            "cites": 3,
            "dl": 364,
            "dl_52": 97,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Tang:2015:SNN:2755753.2755948,\n author = {Tang, Tianqi and Xia, Lixue and Li, Boxun and Luo, Rong and Chen, Yiran and Wang, Yu and Yang, Huazhong},\n title = {Spiking Neural Network with RRAM: Can We Use It for Real-world Application?},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {860--865},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2755948},\n acmid = {2755948},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2755948",
        "pub_year": "2015",
        "text": "Tianqi Tang , Lixue Xia , Boxun Li , Rong Luo , Yiran Chen , Yu Wang , Huazhong Yang, Spiking neural network with RRAM: can we use it for real-world application?, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2756555": {
        "abstract": "NAND flash-based Solid-State Drives (SSDs) are becoming a viable alternative as a secondary storage solution for many computing systems. Since the physical characteristics of NAND flash memory are different from conventional Hard-Disk Drives (HDDs), flash-based SSDs usually employ an intermediate software layer, called a Flash Translation Layer (FTL). The FTL runs several firmware algorithms for logical-to-physical mapping, I/O interleaving, garbage collection, wear-leveling, and so on. These FTL algorithms not only have a great effect on storage performance and lifetime, but also determine hardware cost and data integrity. In general, a hybrid FTL scheme has been widely used in mobile devices because it exhibits high performance and high data integrity at a low hardware cost. Recently, a demand-based FTL based on page-level mapping has been rapidly adopted in high-performance SSDs. The demand-based FTL more effectively exploits the device-level parallelism than the hybrid FTL and requires a small amount of memory by keeping only popular mapping entries in DRAM. Because of this caching mechanism, however, the demand-based FTL is not robust enough for power failures and requires extra reads to fetch missing mapping entries from NAND flash. In this article, we propose a new flash translation layer called LAST++. The proposed LAST++ scheme is based on the hybrid FTL, thus it has the inherent benefits of the hybrid FTL, including low resource requirements, strong robustness for power failures, and high read performance. By effectively exploiting the locality of I/O references, LAST++ increases device-level parallelism and reduces garbage collection overheads. This leads to a great improvement of I/O performance and makes it possible to overcome the limitations of the hybrid FTL. Our experimental results show that LAST++ outperforms the demand-based FTL by 27&percnt; for writes and 7&percnt; for reads, on average, while offering higher robustness against sudden power failures. LAST++ also improves write performance by 39&percnt;, on average, over the existing hybrid FTL.",
        "acm_key": "2756555",
        "bib_stats": {
            "cites": 0,
            "dl": 212,
            "dl_52": 116,
            "dl_6": 9
        },
        "bibtex": "\r\n@article{Wang:2016:SIW:2932205.2756555,\n author = {Wang, Wei and Xie, Tao and Sharma, Abhinav},\n title = {SWANS: An Interdisk Wear-Leveling Strategy for RAID-0 Structured SSD Arrays},\n journal = {Trans. Storage},\n issue_date = {June 2016},\n volume = {12},\n number = {3},\n month = apr,\n year = {2016},\n issn = {1553-3077},\n pages = {10:1--10:21},\n articleno = {10},\n numpages = {21},\n url = {http://doi.acm.org/10.1145/2756555},\n doi = {10.1145/2756555},\n acmid = {2756555},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, SSD array, solid state disk, wear-leveling},\n} \r\n",
        "key": "2756555",
        "pub_year": "2016",
        "text": "Wei Wang , Tao Xie , Abhinav Sharma, SWANS: An Interdisk Wear-Leveling Strategy for RAID-0 Structured SSD Arrays, ACM Transactions on Storage (TOS), v.12 n.3, p.1-21, June 2016"
    },
    "2757117": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2757117",
        "bib_stats": {
            "cites": 1,
            "dl": 144,
            "dl_52": 17,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Zhong:2015:NCL:2755753.2757117,\n author = {Zhong, Kan and Liu, Duo and Long, Linbo and Zhu, Xiao and Liu, Weichen and Zhuge, Qingfeng and Sha, Edwin H.-M.},\n title = {nCode: Limiting Harmful Writes to Emerging Mobile NVRAM Through Code Swapping},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {1305--1310},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2757117},\n acmid = {2757117},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2757117&parent_id=2755753&expformat=bibtex&CFID=982028541&CFTOKEN=94443909\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2757117\">\r\n@inproceedings{Zhong:2015:NCL:2757012.2757117,\n author = {Zhong, Kan and Liu, Duo and Long, Linbo and Zhu, Xiao and Liu, Weichen and Zhuge, Qingfeng and Sha, Edwin H.-M.},\n title = {nCode: Limiting Harmful Writes to Emerging Mobile NVRAM Through Code Swapping},\n booktitle = {Proceedings of the 2015 Design, Automation \\& Test in Europe Conference \\& Exhibition},\n series = {DATE '15},\n year = {2015},\n location = {Grenoble, France},\n pages = {1305--1310},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2757012.2757117},\n acmid = {2757117},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2757117",
        "pub_year": "2015",
        "text": "Kan Zhong , Duo Liu , Linbo Long , Xiao Zhu , Weichen Liu , Qingfeng Zhuge , Edwin H.-M. Sha, n<i>n</i>Code: limiting harmful writes to emerging mobile NVRAM through code swapping, Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition, March 09-13, 2015, Grenoble, France&#13;\n\t\t\t\t\t\tCode: limiting harmful writes to emerging mobile NVRAM through code swapping, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2757143": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2757143",
        "bib_stats": {
            "cites": 2,
            "dl": 338,
            "dl_52": 62,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Li:2015:VRD:2757012.2757143,\n author = {Li, H. and Jiang, Z. and Huang, P. and Wu, Y. and Chen, H.-Y. and Gao, B. and Liu, X. Y. and Kang, J. F. and Wong, H.-S. P.},\n title = {Variation-aware, Reliability-emphasized Design and Optimization of RRAM Using SPICE Model},\n booktitle = {Proceedings of the 2015 Design, Automation \\& Test in Europe Conference \\& Exhibition},\n series = {DATE '15},\n year = {2015},\n location = {Grenoble, France},\n pages = {1425--1430},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2757012.2757143},\n acmid = {2757143},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {SPICE model, design tool, emerging memory, reliability, resistive switching memory, variability},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2757143&parent_id=2757012&expformat=bibtex&CFID=982031778&CFTOKEN=87523778\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2757143\">\r\n@inproceedings{Li:2015:VRD:2755753.2757143,\n author = {Li, H. and Jiang, Z. and Huang, P. and Wu, Y. and Chen, H.-Y. and Gao, B. and Liu, X. Y. and Kang, J. F. and Wong, H.-S. P.},\n title = {Variation-aware, Reliability-emphasized Design and Optimization of RRAM Using SPICE Model},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {1425--1430},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2757143},\n acmid = {2757143},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {SPICE model, design tool, emerging memory, reliability, resistive switching memory, variability},\n} \r\n",
        "key": "2757143",
        "pub_year": "2015",
        "text": "H. Li , Z. Jiang , P. Huang , Y. Wu , H.-Y. Chen , B. Gao , X. Y. Liu , J. F. Kang , H.-S. P. Wong, Variation-aware, reliability-emphasized design and optimization of RRAM using SPICE model, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2757144": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2757144",
        "bib_stats": {
            "cites": 2,
            "dl": 155,
            "dl_52": 42,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Motaman:2015:IPS:2757012.2757144,\n author = {Motaman, Seyedhamidreza and Ghosh, Swaroop and Rathi, Nitin},\n title = {Impact of Process-variations in STTRAM and Adaptive Boosting for Robustness},\n booktitle = {Proceedings of the 2015 Design, Automation \\& Test in Europe Conference \\& Exhibition},\n series = {DATE '15},\n year = {2015},\n location = {Grenoble, France},\n pages = {1431--1436},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2757012.2757144},\n acmid = {2757144},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {STTRAM, process variation, variation tolerant design, write current boosting, write power},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2757144&parent_id=2757012&expformat=bibtex&CFID=982031760&CFTOKEN=19047941\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2757144\">\r\n@inproceedings{Motaman:2015:IPS:2755753.2757144,\n author = {Motaman, Seyedhamidreza and Ghosh, Swaroop and Rathi, Nitin},\n title = {Impact of Process-variations in STTRAM and Adaptive Boosting for Robustness},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {1431--1436},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2757144},\n acmid = {2757144},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {STTRAM, process variation, variation tolerant design, write current boosting, write power},\n} \r\n",
        "key": "2757144",
        "pub_year": "2015",
        "text": "Seyedhamidreza Motaman , Swaroop Ghosh , Nitin Rathi, Impact of process-variations in STTRAM and adaptive boosting for robustness, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2757168": {
        "abstract": "As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutilisation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and FIR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.",
        "acm_key": "2757168",
        "bib_stats": {
            "cites": 9,
            "dl": 167,
            "dl_52": 56,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Poremba:2015:DTM:2757012.2757168,\n author = {Poremba, Matt and Mittal, Sparsh and Li, Dong and Vetter, Jeffrey S. and Xie, Yuan},\n title = {DESTINY: A Tool for Modeling Emerging 3D NVM and eDRAM Caches},\n booktitle = {Proceedings of the 2015 Design, Automation \\& Test in Europe Conference \\& Exhibition},\n series = {DATE '15},\n year = {2015},\n location = {Grenoble, France},\n pages = {1543--1546},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2757012.2757168},\n acmid = {2757168},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {PCM, ReRAM, SRAM, STT-RAM, cache, eDRAM, modeling tool, non-volatile memory (NVM or NVRAM), validation},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2757168&parent_id=2757012&expformat=bibtex&CFID=982045588&CFTOKEN=48424027\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2757168\">\r\n@inproceedings{Poremba:2015:DTM:2755753.2757168,\n author = {Poremba, Matt and Mittal, Sparsh and Li, Dong and Vetter, Jeffrey S. and Xie, Yuan},\n title = {DESTINY: A Tool for Modeling Emerging 3D NVM and eDRAM Caches},\n booktitle = {Proceedings of the 2015 Design, Automation \\&\\#38; Test in Europe Conference \\&\\#38; Exhibition},\n series = {DATE '15},\n year = {2015},\n isbn = {978-3-9815370-4-8},\n location = {Grenoble, France},\n pages = {1543--1546},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2755753.2757168},\n acmid = {2757168},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {PCM, ReRAM, SRAM, STT-RAM, cache, eDRAM, modeling tool, non-volatile memory (NVM or NVRAM), validation},\n} \r\n",
        "key": "2757168",
        "pub_year": "2015",
        "text": "Matt Poremba , Sparsh Mittal , Dong Li , Jeffrey S. Vetter , Yuan Xie, DESTINY: a tool for modeling emerging 3D NVM and eDRAM caches, Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition, March 09-13, 2015, Grenoble, France"
    },
    "2757682": {
        "abstract": "Our work proposes a novel high-level abstraction for real-time control, called Proper Timed I/O (PTIO). The abstraction allows user-space programs running on an embedded system with a stock operating system (without real-time extensions) to perform high-resolution real-time digital I/O (setting pins high or low, responding to input transitions, etc). PTIO programs express their real-time I/O behavior in terms of a finite-state machine (FSM) that can communicate with the user-space program. Simple behaviors are encoded in the FSM; complex behaviors are implemented by arbitrary algorithms in the user-space program. The paper also presents two different implementations of the PTIO abstraction, both under Linux. One utilizes a deterministic co-processor that is available on some ARM-based system-on-a-chip processors. This implementation can achieve timing accuracy of 100ns or better and it can perform millions of finite-state transitions per second. The other implementation uses hardware timers that are available on every system-on-a-chip; it achieves a timing accuracy of 10\u03bc",
        "acm_key": "2757682",
        "bib_stats": {
            "cites": 0,
            "dl": 148,
            "dl_52": 28,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Brandes:2015:SWO:2757667.2757682,\n author = {Brandes, Philipp and Wattenhofer, Roger},\n title = {Space and Write Overhead Are Inversely Proportional in Flash Memory},\n booktitle = {Proceedings of the 8th ACM International Systems and Storage Conference},\n series = {SYSTOR '15},\n year = {2015},\n isbn = {978-1-4503-3607-9},\n location = {Haifa, Israel},\n pages = {9:1--9:6},\n articleno = {9},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2757667.2757682},\n doi = {10.1145/2757667.2757682},\n acmid = {2757682},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, flash memory, solid state disks, wear leveling, write amplification},\n} \r\n",
        "key": "2757682",
        "pub_year": "2015",
        "text": "Philipp Brandes , Roger Wattenhofer, Space and write overhead are inversely proportional in flash memory, Proceedings of the 8th ACM International Systems and Storage Conference, May 26-28, 2015, Haifa, Israel"
    },
    "2757684": {
        "abstract": "Our work proposes a novel high-level abstraction for real-time control, called Proper Timed I/O (PTIO). The abstraction allows user-space programs running on an embedded system with a stock operating system (without real-time extensions) to perform high-resolution real-time digital I/O (setting pins high or low, responding to input transitions, etc). PTIO programs express their real-time I/O behavior in terms of a finite-state machine (FSM) that can communicate with the user-space program. Simple behaviors are encoded in the FSM; complex behaviors are implemented by arbitrary algorithms in the user-space program. The paper also presents two different implementations of the PTIO abstraction, both under Linux. One utilizes a deterministic co-processor that is available on some ARM-based system-on-a-chip processors. This implementation can achieve timing accuracy of 100ns or better and it can perform millions of finite-state transitions per second. The other implementation uses hardware timers that are available on every system-on-a-chip; it achieves a timing accuracy of 10\u03bc",
        "acm_key": "2757684",
        "bib_stats": {
            "cites": 5,
            "dl": 753,
            "dl_52": 210,
            "dl_6": 30
        },
        "bibtex": "\r\n@inproceedings{Xu:2015:PAN:2757667.2757684,\n author = {Xu, Qiumin and Siyamwala, Huzefa and Ghosh, Mrinmoy and Suri, Tameesh and Awasthi, Manu and Guz, Zvika and Shayesteh, Anahita and Balakrishnan, Vijay},\n title = {Performance Analysis of NVMe SSDs and Their Implication on Real World Databases},\n booktitle = {Proceedings of the 8th ACM International Systems and Storage Conference},\n series = {SYSTOR '15},\n year = {2015},\n isbn = {978-1-4503-3607-9},\n location = {Haifa, Israel},\n pages = {6:1--6:11},\n articleno = {6},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2757667.2757684},\n doi = {10.1145/2757667.2757684},\n acmid = {2757684},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVMe, NoSQL databases, SSD, hyperscale applications, performance characterization},\n} \r\n",
        "key": "2757684",
        "pub_year": "2015",
        "text": "Qiumin Xu , Huzefa Siyamwala , Mrinmoy Ghosh , Tameesh Suri , Manu Awasthi , Zvika Guz , Anahita Shayesteh , Vijay Balakrishnan, Performance analysis of NVMe SSDs and their implication on real world databases, Proceedings of the 8th ACM International Systems and Storage Conference, May 26-28, 2015, Haifa, Israel  \u00a0[doi>"
    },
    "2757685": {
        "abstract": "Our work proposes a novel high-level abstraction for real-time control, called Proper Timed I/O (PTIO). The abstraction allows user-space programs running on an embedded system with a stock operating system (without real-time extensions) to perform high-resolution real-time digital I/O (setting pins high or low, responding to input transitions, etc). PTIO programs express their real-time I/O behavior in terms of a finite-state machine (FSM) that can communicate with the user-space program. Simple behaviors are encoded in the FSM; complex behaviors are implemented by arbitrary algorithms in the user-space program. The paper also presents two different implementations of the PTIO abstraction, both under Linux. One utilizes a deterministic co-processor that is available on some ARM-based system-on-a-chip processors. This implementation can achieve timing accuracy of 100ns or better and it can perform millions of finite-state transitions per second. The other implementation uses hardware timers that are available on every system-on-a-chip; it achieves a timing accuracy of 10\u03bc",
        "acm_key": "2757685",
        "bib_stats": {
            "cites": 0,
            "dl": 124,
            "dl_52": 23,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Wang:2015:ESF:2757667.2757685,\n author = {Wang, Wei and Zhou, Deng and Xie, Tao},\n title = {An Embedded Storage Framework Abstracting Each Raw Flash Device As an MTD},\n booktitle = {Proceedings of the 8th ACM International Systems and Storage Conference},\n series = {SYSTOR '15},\n year = {2015},\n isbn = {978-1-4503-3607-9},\n location = {Haifa, Israel},\n pages = {7:1--7:11},\n articleno = {7},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2757667.2757685},\n doi = {10.1145/2757667.2757685},\n acmid = {2757685},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MTD, NAND, embedded system, file system},\n} \r\n",
        "key": "2757685",
        "pub_year": "2015",
        "text": "Wei Wang , Deng Zhou , Tao Xie, An embedded storage framework abstracting each raw flash device as an MTD, Proceedings of the 8th ACM International Systems and Storage Conference, May 26-28, 2015, Haifa, Israel"
    },
    "2764915": {
        "abstract": "NAND flash-based Solid-State Drives (SSDs) are becoming a viable alternative as a secondary storage solution for many computing systems. Since the physical characteristics of NAND flash memory are different from conventional Hard-Disk Drives (HDDs), flash-based SSDs usually employ an intermediate software layer, called a Flash Translation Layer (FTL). The FTL runs several firmware algorithms for logical-to-physical mapping, I/O interleaving, garbage collection, wear-leveling, and so on. These FTL algorithms not only have a great effect on storage performance and lifetime, but also determine hardware cost and data integrity. In general, a hybrid FTL scheme has been widely used in mobile devices because it exhibits high performance and high data integrity at a low hardware cost. Recently, a demand-based FTL based on page-level mapping has been rapidly adopted in high-performance SSDs. The demand-based FTL more effectively exploits the device-level parallelism than the hybrid FTL and requires a small amount of memory by keeping only popular mapping entries in DRAM. Because of this caching mechanism, however, the demand-based FTL is not robust enough for power failures and requires extra reads to fetch missing mapping entries from NAND flash. In this article, we propose a new flash translation layer called LAST++. The proposed LAST++ scheme is based on the hybrid FTL, thus it has the inherent benefits of the hybrid FTL, including low resource requirements, strong robustness for power failures, and high read performance. By effectively exploiting the locality of I/O references, LAST++ increases device-level parallelism and reduces garbage collection overheads. This leads to a great improvement of I/O performance and makes it possible to overcome the limitations of the hybrid FTL. Our experimental results show that LAST++ outperforms the demand-based FTL by 27&percnt; for writes and 7&percnt; for reads, on average, while offering higher robustness against sudden power failures. LAST++ also improves write performance by 39&percnt;, on average, over the existing hybrid FTL.",
        "acm_key": "2764915",
        "bib_stats": {
            "cites": 0,
            "dl": 262,
            "dl_52": 171,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Moon:2016:RIL:2932205.2764915,\n author = {Moon, Sangwhan and Reddy, A. L. Narasimha},\n title = {Does RAID Improve Lifetime of SSD Arrays?},\n journal = {Trans. Storage},\n issue_date = {June 2016},\n volume = {12},\n number = {3},\n month = apr,\n year = {2016},\n issn = {1553-3077},\n pages = {11:1--11:29},\n articleno = {11},\n numpages = {29},\n url = {http://doi.acm.org/10.1145/2764915},\n doi = {10.1145/2764915},\n acmid = {2764915},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, MTTDL, RAID, SSD, lifetime, write amplification},\n} \r\n",
        "key": "2764915",
        "pub_year": "2016",
        "text": "Sangwhan Moon , A. L. Narasimha Reddy, Does RAID Improve Lifetime of SSD Arrays?, ACM Transactions on Storage (TOS), v.12 n.3, p.1-29, June 2016"
    },
    "2770295": {
        "abstract": "In this paper we propose to utilise 3D-stacked hybrid memories as alternative to traditional CMOS SRAMs in L1 and L2 cache implementations and analyse the potential implications of this approach on the processor performance, measured in terms of Instructions-per-Cycle (IPC) and energy consumption. The 3D hybrid memory cell relies on: (i) a Short Circuit Current Free Nano-Electro-Mechanical Field Effect Transistor (SCCF NEMFET) based inverter for data storage; and (ii) adjacent CMOS-based logic for read/write operations and data preservation. We compare 3D Stacked Hybrid NEMFET-CMOS Caches (3DS-HNCC) of various capacities against state of the art 45 nm low power CMOS SRAM counterparts (2D-CC). All the proposed implementations provide two orders of magnitude static energy reduction (due to NEMFET's extremely low OFF current), a slightly increased dynamic energy consumption, while requiring an approximately 55% larger footprint. The read access time is equivalent, while for write operations it is with about 3 ns higher, as it is dominated by the mechanical movement of the NEMFET's suspended gate. In order to determine if the write latency overhead inflicts any performance penalty, we consider as evaluation vehicle a state of the art mobile out-of-order processor core equipped with 32-kB instruction and data L1 caches, and a unified 2-MB L2 cache. We evaluate different scenarios, utilizing both 3DS-HNCC and 2D-CC at different hierarchy levels, on a set of SPEC 2000 benchmarks. Our simulations indicate that for the considered applications, despite of their increased write access time, 3DS-HNCC L2 caches inflict insignificant IPC penalty while providing, on average, 38% energy savings, when compared with 2D-CC. For L1 instruction caches the IPC penalty is also almost insignificant, while for L1 data caches IPC decreases between 1% to 12% were measured.",
        "acm_key": "2770295",
        "bib_stats": {
            "cites": 2,
            "dl": 33,
            "dl_52": 9,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Huang:2014:SBL:2770287.2770295,\n author = {Huang, Kejie and Zhao, Rong and Lian, Yong},\n title = {STT-MRAM Based Low Power Synchronous Non-volatile Logic with Timing Demultiplexing},\n booktitle = {Proceedings of the 2014 IEEE/ACM International Symposium on Nanoscale Architectures},\n series = {NANOARCH '14},\n year = {2014},\n isbn = {978-1-4503-2834-0},\n location = {Paris, France},\n pages = {31--36},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2770287.2770295},\n doi = {10.1145/2770287.2770295},\n acmid = {2770295},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2770295",
        "pub_year": "2014",
        "text": "Kejie Huang , Rong Zhao , Yong Lian, STT-MRAM based low power synchronous non-volatile logic with timing demultiplexing, Proceedings of the 2014 IEEE/ACM International Symposium on Nanoscale Architectures, July 08-10, 2014, Paris, France"
    },
    "2784283": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2784283",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{2015:MAN:2784050.2784283,\n title = {A Mathematical Approach to NAND Flash-memory Descrambling and Decoding},\n journal = {Digit. Investig.},\n issue_date = {March 2015},\n volume = {12},\n number = {C},\n month = mar,\n year = {2015},\n issn = {1742-2876},\n pages = {41--52},\n numpages = {12},\n url = {http://dx.doi.org/10.1016/j.diin.2015.01.003},\n doi = {10.1016/j.diin.2015.01.003},\n acmid = {2784283},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\nkey = {{$\\!\\!$}} ,\n} \r\n",
        "key": "2784283",
        "pub_year": "2015",
        "text": "A mathematical approach to NAND flash-memory descrambling and decoding, Digital Investigation: The International Journal of Digital Forensics & Incident Response, v.12 n.C, p.41-52, March 2015  \u00a0[doi>"
    },
    "2790302": {
        "abstract": "True random number generators (TRNGs) are crucial components for the security of cryptographic systems. In contrast to pseudo--random number generators (PRNGs), TRNGs provide higher security by extracting randomness from physical phenomena. To evaluate a TRNG, statistical properties of the circuit model and raw bitstream should be studied. In this article, a model for the beat frequency detector--based high-speed TRNG (BFD-TRNG) is proposed. The parameters of the model are extracted from the experimental data of a test chip. A statistical analysis of the proposed model is carried out to derive mean and variance of the counter values of the TRNG. Our statistical analysis results show that mean of the counter values is inversely proportional to the frequency difference of the two ring oscillators (ROSCs), whereas the dynamic range of the counter values increases linearly with standard deviation of environmental noise and decreases with increase of the frequency difference. Without the measurements from the test data, a model cannot be created; similarly, without a model, performance of a TRNG cannot be predicted. The key contribution of the proposed approach lies in fitting the model to measured data and the ability to use the model to predict performance of BFD-TRNGs that have not been fabricated. Several novel alternate BFD-TRNG architectures are also proposed; these include parallel BFD, cascade BFD, and parallel-cascade BFD. These TRNGs are analyzed using the proposed model, and it is shown that the parallel BFD structure requires less area per bit, whereas the cascade BFD structure has a larger dynamic range while maintaining the same mean of the counter values as the original BFD-TRNG. It is shown that 3.25",
        "acm_key": "2790302",
        "bib_stats": {
            "cites": 0,
            "dl": 182,
            "dl_52": 149,
            "dl_6": 20
        },
        "bibtex": "\r\n@article{Vatajelu:2016:SPA:2917757.2790302,\n author = {Vatajelu, Elena Ioana and Natale, Giorgio Di and Barbareschi, Mario and Torres, Lionel and Indaco, Marco and Prinetto, Paolo},\n title = {STT-MRAM-Based PUF Architecture Exploiting Magnetic Tunnel Junction Fabrication-Induced Variability},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {December 2016},\n volume = {13},\n number = {1},\n month = may,\n year = {2016},\n issn = {1550-4832},\n pages = {5:1--5:21},\n articleno = {5},\n numpages = {21},\n url = {http://doi.acm.org/10.1145/2790302},\n doi = {10.1145/2790302},\n acmid = {2790302},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Physically unclonable functions PUFs, STT-MRAM, emerging memory technology, security},\n} \r\n",
        "key": "2790302",
        "pub_year": "2016",
        "text": "Elena Ioana Vatajelu , Giorgio Di Natale , Mario Barbareschi , Lionel Torres , Marco Indaco , Paolo Prinetto, STT-MRAM-Based PUF Architecture Exploiting Magnetic Tunnel Junction Fabrication-Induced Variability, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.1, June 2016"
    },
    "2790795": {
        "abstract": "Currently, most of the processing techniques for the conventional location-based queries focus only on a single type of objects. However, in real-life applications the user may be interested in obtaining information about different types of objects, in terms of their neighboring relationship. We term the different types of objects closer to each other the heterogeneous neighboring objects (HNOs for short). Efficient processing of the location-based queries on the HNOs is more complicated than that on a single data source, because the neighboring relationship between the HNOs inevitably affects the query result. In this paper, we present a novel and important query on the HNOs, namely the shortest average-distance query (SAvgDQ for short), which can provide useful object information by considering both the spatial closeness of objects to the query object and the neighboring relationship between objects. Given a query object q and a distance d, the SAvgDQ retrieves a set of HNOs, such that the distances between any two objects in this set are less than or equal to d and its average distance to q is the smallest among all HNOs sets. To efficiently process the SAvgDQ, we develop an algorithm, the SAvgDQ processing algorithm, which operates based on three devised heuristics, the HNOs-qualifying heuristic, the HNOs-pruning heuristic, and the SAvgD-pruning heuristic, to reduce the number of distance computations required for query processing. Comprehensive experiments are conducted to demonstrate the effectiveness of the heuristics and the efficiency of the proposed algorithm.",
        "acm_key": "2790795",
        "bib_stats": {
            "cites": 0,
            "dl": 187,
            "dl_52": 61,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Yamato:2015:UCS:2790755.2790795,\n author = {Yamato, Yoji},\n title = {Use Case Study of HDD-SSD Hybrid Storage, Distributed Storage and HDD Storage on OpenStack},\n booktitle = {Proceedings of the 19th International Database Engineering \\&\\#38; Applications Symposium},\n series = {IDEAS '15},\n year = {2014},\n isbn = {978-1-4503-3414-3},\n location = {Yokohama, Japan},\n pages = {228--229},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2790755.2790795},\n doi = {10.1145/2790755.2790795},\n acmid = {2790795},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cloud Computing, Distributed Storage, HDD-SSD Hybrid Storage, OpenStack, Storage Performance},\n} \r\n",
        "key": "2790795",
        "pub_year": "2015",
        "text": "Yoji Yamato, Use case study of HDD-SSD hybrid storage, distributed storage and HDD storage on OpenStack, Proceedings of the 19th International Database Engineering & Applications Symposium, July 13-15, 2015, Yokohama, Japan"
    },
    "2801550": {
        "abstract": "Due to the increased complexity of modern embedded systems and time-to-market constraints, a debugger with efficient debugging functions is becoming increasingly necessary, and it plays an important role in the development of application systems. Accordingly, the implementation of efficient debug functionalities must a critical process in the design of a new processor. Since deeply embedded processor cores in a core-based system chip allow only restricted access for debugging its internal status, most recent processors employ the on-chip-based debug method that embeds special logic-supporting debug capabilities. In this paper, we propose an on-chip debug support logic that can be embedded into the processor core to support debug functions. Moreover, we describe an overall implementation method of the on-chip-based processor debugger based on the on-chip debug support logic, which includes a source-level debugger and an interface block. We designed an on-chip debug support logic, and embedded it into a target processor core. We used the GNU Project debugger (GDB) as the source-level debugger of the target processor core. An interface block that uses the remote debugging features of GDB was also developed and that includes a software module and a hardware board. We discuss all major design steps for implementing this on-chip-based processor debugger. We have successfully applied the proposed implementation method to develop the processor debugger for two new 32-bit RISC processors. In addition, we introduce another use of the on-chip-based processor debugger in the design of a processor-based system chip, which can facilitate simulation-based functional verification.",
        "acm_key": "2801550",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Paik:2015:ADP:2801538.2801550,\n author = {Paik, Joon-Young and Chung, Tae-Sun and Cho, Eun-Sun},\n title = {Application-aware Deduplication for Performance Improvement of Flash Memory},\n journal = {Des. Autom. Embedded Syst.},\n issue_date = {March     2015},\n volume = {19},\n number = {1-2},\n month = mar,\n year = {2015},\n issn = {0929-5585},\n pages = {161--188},\n numpages = {28},\n url = {http://dx.doi.org/10.1007/s10617-014-9142-9},\n doi = {10.1007/s10617-014-9142-9},\n acmid = {2801550},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Deduplication, Loop transformations, NAND flash memory, Performance improvement},\n} \r\n",
        "key": "2801550",
        "pub_year": "2015",
        "text": "Joon-Young Paik , Tae-Sun Chung , Eun-Sun Cho, Application-aware deduplication for performance improvement of flash memory, Design Automation for Embedded Systems, v.19 n.1-2, p.161-188, March     2015"
    },
    "2813430": {
        "abstract": "Entity resolution (ER) is the problem of identifying and grouping different manifestations of the same real world object. Algorithmic approaches have been developed where most tasks offer superior performance under supervised learning. However, the prohibitive cost of labeling training data is still a huge obstacle for detecting duplicate query records from online sources. Furthermore, the unique combinations of noisy data with missing elements make ER tasks more challenging. To address this, transfer learning has been adopted to adaptively share learned common structures of similarity scoring problems between multiple sources. Although such techniques reduce the labeling cost so that it is linear with respect to the number of sources, its random sampling strategy is not successful enough to handle the ordinary sample imbalance problem. In this paper, we present a novel multi-source active transfer learning framework to jointly select fewer data instances from all sources to train classifiers with constant precision/recall. The intuition behind our approach is to actively label the most informative samples while adaptively transferring collective knowledge between sources. In this way, the classifiers that are learned can be both label-economical and flexible even for imbalanced or quality diverse sources. We compare our method with the state-of-the-art approaches on real-word datasets. Our experimental results demonstrate that our active transfer learning algorithm can achieve impressive performance with far fewer labeled samples for record matching with numerous and varied sources.",
        "acm_key": "2813430",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Wang:2015:EWP:2812894.2813430,\n author = {Wang, Qi and Wang, Donghui and Hou, Chaohuan},\n title = {Exploiting Write Power Asymmetry to Improve Phase Change Memory System Performance},\n journal = {Front. Comput. Sci.},\n issue_date = {August    2015},\n volume = {9},\n number = {4},\n month = aug,\n year = {2015},\n issn = {2095-2228},\n pages = {566--575},\n numpages = {10},\n url = {http://dx.doi.org/10.1007/s11704-014-4185-4},\n doi = {10.1007/s11704-014-4185-4},\n acmid = {2813430},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {command scheduling, phase change memory, write power asymmetry},\n} \r\n",
        "key": "2813430",
        "pub_year": "2015",
        "text": "Qi Wang , Donghui Wang , Chaohuan Hou, Exploiting write power asymmetry to improve phase change memory system performance, Frontiers of Computer Science: Selected Publications from Chinese Universities, v.9 n.4, p.566-575, August    2015"
    },
    "2813782": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813782",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2015:RDW:2813767.2813782,\n author = {Kim, Sangwook and Kim, Hwanju and Kim, Sang-Hoon and Lee, Joonwon and Jeong, Jinkyu},\n title = {Request-oriented Durable Write Caching for Application Performance},\n booktitle = {Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '15},\n year = {2015},\n isbn = {978-1-931971-225},\n location = {Santa Clara, CA},\n pages = {193--206},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2813767.2813782},\n acmid = {2813782},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2813782",
        "pub_year": "2015",
        "text": "Sangwook Kim , Hwanju Kim , Sang-Hoon Kim , Joonwon Lee , Jinkyu Jeong, Request-oriented durable write caching for application performance, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.193-206, July 08-10, 2015, Santa Clara, CA"
    },
    "2813783": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813783",
        "bib_stats": {
            "cites": 8,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2813783",
        "text": "Leonardo Marmol , Swaminathan Sundararaman , Nisha Talagala , Raju Rangaswami, NVMKV: a scalable, lightweight, FTL-aware key-value store, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.207-219, July 08-10, 2015, Santa Clara, CA"
    },
    "2813784": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813784",
        "bib_stats": {
            "cites": 4,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Min:2015:LAC:2813767.2813784,\n author = {Min, Changwoo and Kang, Woon-Hak and Kim, Taesoo and Lee, Sang-Won and Eom, Young Ik},\n title = {Lightweight Application-level Crash Consistency on Transactional Flash Storage},\n booktitle = {Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '15},\n year = {2015},\n isbn = {978-1-931971-225},\n location = {Santa Clara, CA},\n pages = {221--234},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2813767.2813784},\n acmid = {2813784},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2813784",
        "pub_year": "2015",
        "text": "Changwoo Min , Woon-Hak Kang , Taesoo Kim , Sang-Won Lee , Young Ik Eom, Lightweight application-level crash consistency on transactional flash storage, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.221-234, July 08-10, 2015, Santa Clara, CA"
    },
    "2813785": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813785",
        "bib_stats": {
            "cites": 7,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2813785",
        "text": "Wongun Lee , Keonwoo Lee , Hankeun Sun , Wook-Hee Kim , Beomseok Nam , Youjip Won, WALDIO: eliminating the filesystem journaling in resolving the journaling of journal anomaly, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.235-247, July 08-10, 2015, Santa Clara, CA"
    },
    "2813786": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813786",
        "bib_stats": {
            "cites": 4,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "key": "2813786",
        "text": "Junbin Kang , Benlong Zhang , Tianyu Wo , Weiren Yu , Lian Du , Shuai Ma , Jinpeng Huai, SpanFS: a scalable file system on fast storage devices, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.249-261, July 08-10, 2015, Santa Clara, CA"
    },
    "2813813": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813813",
        "bib_stats": {
            "cites": 1,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ren:2015:MDS:2813767.2813813,\n author = {Ren, Jinglei and Liang, Chieh-Jan Mike and Wu, Yongwei and Moscibroda, Thomas},\n title = {Memory-centric Data Storage for Mobile Systems},\n booktitle = {Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '15},\n year = {2015},\n isbn = {978-1-931971-225},\n location = {Santa Clara, CA},\n pages = {599--611},\n numpages = {13},\n url = {http://dl.acm.org/citation.cfm?id=2813767.2813813},\n acmid = {2813813},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2813813",
        "pub_year": "2015",
        "text": "Jinglei Ren , Chieh-Jan Mike Liang , Yongwei Wu , Thomas Moscibroda, Memory-centric data storage for mobile systems, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.599-611, July 08-10, 2015, Santa Clara, CA"
    },
    "2813814": {
        "abstract": "This work is dedicated to resolve the Journaling of Journal Anomaly in Android IO stack. We orchestrate SQLite and EXT4 filesystem so that SQLite's file-backed journaling activity can dispense with the expensive filesystem intervention, the journaling, without compromising the file integrity under unexpected filesystem failure. In storing the logs, we exploit the direct IO to suppress the filesystem interference. This work consists of three key ingredients: (i) Preallocation with Explicit Journaling, (ii) Header Embedding, and (iii) Group Synchronization. Preallocation with Explicit Journaling eliminates the filesystem journaling properly protecting the file meta-data against the unexpected system crash. We redesign the SQLite B-tree structure with Header Embedding to make it direct IO compatible and block IO friendly. With Group Synch, we minimize the synchronization overhead of direct IO and make the SQLite operation NAND Flash friendly. Combining the three technical ingredients, we develop a new journal mode in SQLite, the WALDIO. We implement it on the commercially available smartphone. WALDIO mode achieves 5.1\u00d7 performance (insert/sec) against WAL mode which is the fastest journaling mode in SQLite. It yields 2.7\u00d7 performance (inserts/ sec) against the LS-MVBT, the fastest SQLite journaling mode known to public. WALDIO mode achieves 7.4\u00d7 performance (insert/sec) against WAL mode when it is relieved from the overhead of explicitly synchronizing individual log-commit operations. WALDIO mode reduces the IO volume to 1/6 compared against the WAL mode.",
        "acm_key": "2813814",
        "bib_stats": {
            "cites": 5,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Huang:2015:WFE:2813767.2813814,\n author = {Huang, Jian and Badam, Anirudh and Chandra, Ranveer and Nightingale, Edmund B.},\n title = {WearDrive: Fast and Energy-efficient Storage for Wearables},\n booktitle = {Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '15},\n year = {2015},\n isbn = {978-1-931971-225},\n location = {Santa Clara, CA},\n pages = {613--625},\n numpages = {13},\n url = {http://dl.acm.org/citation.cfm?id=2813767.2813814},\n acmid = {2813814},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2813814",
        "pub_year": "2015",
        "text": "Jian Huang , Anirudh Badam , Ranveer Chandra , Edmund B. Nightingale, WearDrive: fast and energy-efficient storage for wearables, Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference, p.613-625, July 08-10, 2015, Santa Clara, CA"
    },
    "2815622": {
        "abstract": "With the advent of ubiquitous computing and the Internet of Things (IoT), the security and privacy issues for various smart devices such as radio-frequency identification (RFID) tags and wireless sensor nodes are receiving increased attention from academia and industry. A number of lightweight cryptographic primitives have been proposed to provide security services for resource-constrained smart devices. As one of the core primitives, a cryptographically secure pseudorandom number generator (PRNG) plays an important role for lightweight embedded applications. The most existing PRNGs proposed for smart devices employ true random number generators as a component, which generally incur significant power consumption and gate count in hardware. In this article, we present Warbler family, a new pseudorandom number generator family based on nonlinear feedback shift registers (NLFSRs) with desirable randomness properties. The design of the Warbler family is based on the combination of modified de Bruijn blocks together with a nonlinear feedback Welch-Gong (WG) sequence generator, which enables us to precisely characterize the randomness properties and to flexibly adjust the security level of the resulting PRNG. Some criteria for selecting parameters of the Warbler family are proposed to offer the maximum level of security. Two instances of the Warbler family are also described, which feature two different security levels and are dedicated to EPC C1 Gen2 RFID tags and wireless sensor nodes, respectively. The security analysis shows that the proposed instances not only can pass the cryptographic statistical tests recommended by the EPC C1 Gen2 standard and NIST but also are resistant to the cryptanalytic attacks such as algebraic attacks, cube attacks, time-memory-data tradeoff attacks, Mihaljevi&cacute; et al.\u2019s attacks, and weak internal state and fault injection attacks. Our ASIC implementations using a 65nm CMOS process demonstrate that the proposed two lightweight instances of the Warbler family can achieve good performance in terms of speed and area and provide ideal solutions for securing low-cost smart devices.",
        "acm_key": "2815622",
        "bib_stats": {
            "cites": 1,
            "dl": 181,
            "dl_52": 90,
            "dl_6": 13
        },
        "bibtex": "\r\n@article{Huang:2016:EPC:2872313.2815622,\n author = {Huang, Sheng-Min and Chang, Li-Pin},\n title = {Exploiting Page Correlations for Write Buffering in Page-Mapping Multichannel SSDs},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {February 2016},\n volume = {15},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1539-9087},\n pages = {12:1--12:25},\n articleno = {12},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2815622},\n doi = {10.1145/2815622},\n acmid = {2815622},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Solid-state disks, flash memory, multichannel, write buffering},\n} \r\n",
        "key": "2815622",
        "pub_year": "2016",
        "text": "Sheng-Min Huang , Li-Pin Chang, Exploiting Page Correlations for Write Buffering in Page-Mapping Multichannel SSDs, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.1, p.1-25, February 2016"
    },
    "2818376": {
        "abstract": "NAND flash-based Solid-State Drives (SSDs) are becoming a viable alternative as a secondary storage solution for many computing systems. Since the physical characteristics of NAND flash memory are different from conventional Hard-Disk Drives (HDDs), flash-based SSDs usually employ an intermediate software layer, called a Flash Translation Layer (FTL). The FTL runs several firmware algorithms for logical-to-physical mapping, I/O interleaving, garbage collection, wear-leveling, and so on. These FTL algorithms not only have a great effect on storage performance and lifetime, but also determine hardware cost and data integrity. In general, a hybrid FTL scheme has been widely used in mobile devices because it exhibits high performance and high data integrity at a low hardware cost. Recently, a demand-based FTL based on page-level mapping has been rapidly adopted in high-performance SSDs. The demand-based FTL more effectively exploits the device-level parallelism than the hybrid FTL and requires a small amount of memory by keeping only popular mapping entries in DRAM. Because of this caching mechanism, however, the demand-based FTL is not robust enough for power failures and requires extra reads to fetch missing mapping entries from NAND flash. In this article, we propose a new flash translation layer called LAST++. The proposed LAST++ scheme is based on the hybrid FTL, thus it has the inherent benefits of the hybrid FTL, including low resource requirements, strong robustness for power failures, and high read performance. By effectively exploiting the locality of I/O references, LAST++ increases device-level parallelism and reduces garbage collection overheads. This leads to a great improvement of I/O performance and makes it possible to overcome the limitations of the hybrid FTL. Our experimental results show that LAST++ outperforms the demand-based FTL by 27&percnt; for writes and 7&percnt; for reads, on average, while offering higher robustness against sudden power failures. LAST++ also improves write performance by 39&percnt;, on average, over the existing hybrid FTL.",
        "acm_key": "2818376",
        "bib_stats": {
            "cites": 0,
            "dl": 370,
            "dl_52": 277,
            "dl_6": 14
        },
        "bibtex": "\r\n@article{Chen:2016:IPF:2932205.2818376,\n author = {Chen, Feng and Hou, Binbing and Lee, Rubao},\n title = {Internal Parallelism of Flash Memory-Based Solid-State Drives},\n journal = {Trans. Storage},\n issue_date = {June 2016},\n volume = {12},\n number = {3},\n month = may,\n year = {2016},\n issn = {1553-3077},\n pages = {13:1--13:39},\n articleno = {13},\n numpages = {39},\n url = {http://doi.acm.org/10.1145/2818376},\n doi = {10.1145/2818376},\n acmid = {2818376},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, internal parallelism, solid state drive, storage systems},\n} \r\n",
        "key": "2818376",
        "pub_year": "2016",
        "text": "Feng Chen , Binbing Hou , Rubao Lee, Internal Parallelism of Flash Memory-Based Solid-State Drives, ACM Transactions on Storage (TOS), v.12 n.3, p.1-39, June 2016"
    },
    "2820610": {
        "abstract": "Due to the inappropriate assignment of bump pads or the improper assignment of I/O buffers, the constructed buffered I/O signals in an area-I/O flip-chip design may yield longer maximum delay. In this article, the problem of assigning performance-driven buffered I/O signals in an area-I/O flip-chip design is first formulated. Furthermore, the assignment of the buffered I/O signals can be divided into two sequential phases: Construction of performance-driven I/O signals and Assignment of timing-constrained I/O buffers. Finally, an efficient matching-based approach is proposed to construct the performance-driven I/O signals for the given I/O pins and assign the timing-constrained I/O buffers into the constructed I/O signals in the assignment of the buffered I/O signals in an area-I/O flip-chip design. Compared with the experimental results of seven tested circuits in the Elmore delay model, the experimental results show that the matching-based assignment in our proposed approach can reduce 3.56&percnt; of the total path delay, 9.72&percnt; of the maximum input delay, 5.90&percnt; of the input skew, 5.64&percnt; of the maximum output delay, and 6.25&percnt; of the output skew on average by reassigning the I/O buffers. Our proposed approach can further reduce 38.89&percnt; of the total path delay, 44.00&percnt; of the maximum input delay, 49.13&percnt; of the input skew, 44.93&percnt; of the maximum output delay, and 50.82&percnt; of output skew on average by reconstructing the I/O signals and reassigning the I/O buffers into the I/O signals. Compared with the experimental results of seven tested circuits in Peng's [Peng et al. 2006] publication, the experimental results show that our proposed matching-based approach can further reduce 71.06&percnt; of the total path delay, 67.83&percnt; of the maximum input delay, 59.84&percnt; of the input skew, 68.87&percnt; of the maximum output delay, and 61.46&percnt; of the output skew on average. On the other hand, compared with the experimental results of five tested circuits in Lai's [Lai and Chen 2008] publication, the experimental results show that our proposed approach can further reduce 75.36&percnt; of the total path delay, 48.94&percnt; of the input skew, and 52.80&percnt; of the output skew on the average.",
        "acm_key": "2820610",
        "bib_stats": {
            "cites": 0,
            "dl": 171,
            "dl_52": 92,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Kim:2016:IWP:2888405.2820610,\n author = {Kim, Youngsik and Yoo, Sungjoo and Lee, Sunggu},\n title = {Improving Write Performance by Controlling Target Resistance Distributions in MLC PRAM},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {January 2016},\n volume = {21},\n number = {2},\n month = jan,\n year = {2016},\n issn = {1084-4309},\n pages = {23:1--23:27},\n articleno = {23},\n numpages = {27},\n url = {http://doi.acm.org/10.1145/2820610},\n doi = {10.1145/2820610},\n acmid = {2820610},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change RAM, multi-level cell, resistance distribution, write performance},\n} \r\n",
        "key": "2820610",
        "pub_year": "2016",
        "text": "Youngsik Kim , Sungjoo Yoo , Sunggu Lee, Improving Write Performance by Controlling Target Resistance Distributions in MLC PRAM, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.21 n.2, p.1-27, January 2016"
    },
    "2820613": {
        "abstract": "With the advent of ubiquitous computing and the Internet of Things (IoT), the security and privacy issues for various smart devices such as radio-frequency identification (RFID) tags and wireless sensor nodes are receiving increased attention from academia and industry. A number of lightweight cryptographic primitives have been proposed to provide security services for resource-constrained smart devices. As one of the core primitives, a cryptographically secure pseudorandom number generator (PRNG) plays an important role for lightweight embedded applications. The most existing PRNGs proposed for smart devices employ true random number generators as a component, which generally incur significant power consumption and gate count in hardware. In this article, we present Warbler family, a new pseudorandom number generator family based on nonlinear feedback shift registers (NLFSRs) with desirable randomness properties. The design of the Warbler family is based on the combination of modified de Bruijn blocks together with a nonlinear feedback Welch-Gong (WG) sequence generator, which enables us to precisely characterize the randomness properties and to flexibly adjust the security level of the resulting PRNG. Some criteria for selecting parameters of the Warbler family are proposed to offer the maximum level of security. Two instances of the Warbler family are also described, which feature two different security levels and are dedicated to EPC C1 Gen2 RFID tags and wireless sensor nodes, respectively. The security analysis shows that the proposed instances not only can pass the cryptographic statistical tests recommended by the EPC C1 Gen2 standard and NIST but also are resistant to the cryptanalytic attacks such as algebraic attacks, cube attacks, time-memory-data tradeoff attacks, Mihaljevi&cacute; et al.\u2019s attacks, and weak internal state and fault injection attacks. Our ASIC implementations using a 65nm CMOS process demonstrate that the proposed two lightweight instances of the Warbler family can achieve good performance in terms of speed and area and provide ideal solutions for securing low-cost smart devices.",
        "acm_key": "2820613",
        "bib_stats": {
            "cites": 1,
            "dl": 172,
            "dl_52": 102,
            "dl_6": 9
        },
        "bibtex": "\r\n@article{Chang:2016:SGA:2872313.2820613,\n author = {Chang, Li-Pin and Liu, Yu-Syun and Lin, Wen-Huei},\n title = {Stable Greedy: Adaptive Garbage Collection for Durable Page-Mapping Multichannel SSDs},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {February 2016},\n volume = {15},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1539-9087},\n pages = {13:1--13:25},\n articleno = {13},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2820613},\n doi = {10.1145/2820613},\n acmid = {2820613},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Garbage collection, flash translation layers, solid state disks},\n} \r\n",
        "key": "2820613",
        "pub_year": "2016",
        "text": "Li-Pin Chang , Yu-Syun Liu , Wen-Huei Lin, Stable Greedy: Adaptive Garbage Collection for Durable Page-Mapping Multichannel SSDs, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.1, p.1-25, February 2016"
    },
    "2820614": {
        "abstract": "With the advent of ubiquitous computing and the Internet of Things (IoT), the security and privacy issues for various smart devices such as radio-frequency identification (RFID) tags and wireless sensor nodes are receiving increased attention from academia and industry. A number of lightweight cryptographic primitives have been proposed to provide security services for resource-constrained smart devices. As one of the core primitives, a cryptographically secure pseudorandom number generator (PRNG) plays an important role for lightweight embedded applications. The most existing PRNGs proposed for smart devices employ true random number generators as a component, which generally incur significant power consumption and gate count in hardware. In this article, we present Warbler family, a new pseudorandom number generator family based on nonlinear feedback shift registers (NLFSRs) with desirable randomness properties. The design of the Warbler family is based on the combination of modified de Bruijn blocks together with a nonlinear feedback Welch-Gong (WG) sequence generator, which enables us to precisely characterize the randomness properties and to flexibly adjust the security level of the resulting PRNG. Some criteria for selecting parameters of the Warbler family are proposed to offer the maximum level of security. Two instances of the Warbler family are also described, which feature two different security levels and are dedicated to EPC C1 Gen2 RFID tags and wireless sensor nodes, respectively. The security analysis shows that the proposed instances not only can pass the cryptographic statistical tests recommended by the EPC C1 Gen2 standard and NIST but also are resistant to the cryptanalytic attacks such as algebraic attacks, cube attacks, time-memory-data tradeoff attacks, Mihaljevi&cacute; et al.\u2019s attacks, and weak internal state and fault injection attacks. Our ASIC implementations using a 65nm CMOS process demonstrate that the proposed two lightweight instances of the Warbler family can achieve good performance in terms of speed and area and provide ideal solutions for securing low-cost smart devices.",
        "acm_key": "2820614",
        "bib_stats": {
            "cites": 0,
            "dl": 188,
            "dl_52": 109,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Kwon:2016:CFT:2872313.2820614,\n author = {Kwon, Se Jin},\n title = {A Cache-Based Flash Translation Layer for TLC-Based Multimedia Storage Devices},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {February 2016},\n volume = {15},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1539-9087},\n pages = {11:1--11:28},\n articleno = {11},\n numpages = {28},\n url = {http://doi.acm.org/10.1145/2820614},\n doi = {10.1145/2820614},\n acmid = {2820614},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Solid-state drive, firmware, flash memory},\n} \r\n",
        "key": "2820614",
        "pub_year": "2016",
        "text": "Se Jin Kwon, A Cache-Based Flash Translation Layer for TLC-Based Multimedia Storage Devices, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.1, p.1-28, February 2016"
    },
    "2824044": {
        "abstract": "Graph data management systems have become very popular as graphs are the natural data model for many applications. One of the main problems addressed by these systems is subgraph query processing; i.e., given a query graph, return all graphs that contain the query. The naive method for processing such queries is to perform a subgraph isomorphism test against each graph in the dataset. This obviously does not scale, as subgraph isomorphism is NP-Complete. Thus, many indexing methods have been proposed to reduce the number of candidate graphs that have to underpass the subgraph isomorphism test. In this paper, we identify a set of key factors-parameters, that influence the performance of related methods: namely, the number of nodes per graph, the graph density, the number of distinct labels, the number of graphs in the dataset, and the query graph size. We then conduct comprehensive and systematic experiments that analyze the sensitivity of the various methods on the values of the key parameters. Our aims are twofold: first to derive conclusions about the algorithms' relative performance, and, second, to stress-test all algorithms, deriving insights as to their scalability, and highlight how both performance and scalability depend on the above factors. We choose six well-established indexing methods, namely Grapes, CT-Index, GraphGrepSX, gIndex, Tree+\u0394, and gCode, as representative approaches of the overall design space, including the most recent and best performing methods. We report on their index construction time and index size, and on query processing performance in terms of time and false positive ratio. We employ both real and synthetic datasets. Specifically, four real datasets of different characteristics are used: AIDS, PDBS, PCM, and PPI. In addition, we generate a large number of synthetic graph datasets, empowering us to systematically study the algorithms' performance and scalability versus the aforementioned key parameters.",
        "acm_key": "2824044",
        "bib_stats": {
            "cites": 5,
            "dl": 238,
            "dl_52": 95,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Oh:2015:SOP:2824032.2824044,\n author = {Oh, Gihwan and Kim, Sangchul and Lee, Sang-Won and Moon, Bongki},\n title = {SQLite Optimization with Phase Change Memory for Mobile Applications},\n journal = {Proc. VLDB Endow.},\n issue_date = {August 2015},\n volume = {8},\n number = {12},\n month = aug,\n year = {2015},\n issn = {2150-8097},\n pages = {1454--1465},\n numpages = {12},\n url = {http://dx.doi.org/10.14778/2824032.2824044},\n doi = {10.14778/2824032.2824044},\n acmid = {2824044},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "2824044",
        "pub_year": "2015",
        "text": "Gihwan Oh , Sangchul Kim , Sang-Won Lee , Bongki Moon, SQLite optimization with phase change memory for mobile applications, Proceedings of the VLDB Endowment, v.8 n.12, August 2015  \u00a0[doi>"
    },
    "2827697": {
        "abstract": "Due to the inappropriate assignment of bump pads or the improper assignment of I/O buffers, the constructed buffered I/O signals in an area-I/O flip-chip design may yield longer maximum delay. In this article, the problem of assigning performance-driven buffered I/O signals in an area-I/O flip-chip design is first formulated. Furthermore, the assignment of the buffered I/O signals can be divided into two sequential phases: Construction of performance-driven I/O signals and Assignment of timing-constrained I/O buffers. Finally, an efficient matching-based approach is proposed to construct the performance-driven I/O signals for the given I/O pins and assign the timing-constrained I/O buffers into the constructed I/O signals in the assignment of the buffered I/O signals in an area-I/O flip-chip design. Compared with the experimental results of seven tested circuits in the Elmore delay model, the experimental results show that the matching-based assignment in our proposed approach can reduce 3.56&percnt; of the total path delay, 9.72&percnt; of the maximum input delay, 5.90&percnt; of the input skew, 5.64&percnt; of the maximum output delay, and 6.25&percnt; of the output skew on average by reassigning the I/O buffers. Our proposed approach can further reduce 38.89&percnt; of the total path delay, 44.00&percnt; of the maximum input delay, 49.13&percnt; of the input skew, 44.93&percnt; of the maximum output delay, and 50.82&percnt; of output skew on average by reconstructing the I/O signals and reassigning the I/O buffers into the I/O signals. Compared with the experimental results of seven tested circuits in Peng's [Peng et al. 2006] publication, the experimental results show that our proposed matching-based approach can further reduce 71.06&percnt; of the total path delay, 67.83&percnt; of the maximum input delay, 59.84&percnt; of the input skew, 68.87&percnt; of the maximum output delay, and 61.46&percnt; of the output skew on average. On the other hand, compared with the experimental results of five tested circuits in Lai's [Lai and Chen 2008] publication, the experimental results show that our proposed approach can further reduce 75.36&percnt; of the total path delay, 48.94&percnt; of the input skew, and 52.80&percnt; of the output skew on the average.",
        "acm_key": "2827697",
        "bib_stats": {
            "cites": 0,
            "dl": 138,
            "dl_52": 58,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Tan:2016:ESR:2888405.2827697,\n author = {Tan, Jingweijia and Li, Zhi and Chen, Mingsong and Fu, Xin},\n title = {Exploring Soft-Error Robust and Energy-Efficient Register File in GPGPUs Using Resistive Memory},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {January 2016},\n volume = {21},\n number = {2},\n month = jan,\n year = {2016},\n issn = {1084-4309},\n pages = {34:1--34:25},\n articleno = {34},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2827697},\n doi = {10.1145/2827697},\n acmid = {2827697},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {GPGPU, energy efficiency, register file, reliability, resistive memory, soft error},\n} \r\n",
        "key": "2827697",
        "pub_year": "2016",
        "text": "Jingweijia Tan , Zhi Li , Mingsong Chen , Xin Fu, Exploring Soft-Error Robust and Energy-Efficient Register File in GPGPUs using Resistive Memory, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.21 n.2, p.1-25, January 2016"
    },
    "2829951": {
        "abstract": "Due to its rich memory model, the partitioned global address space (PGAS) parallel programming model strikes a balance between locality-awareness and the ease of use of the global address space model. Although locality-awareness can lead to high performance, supporting the PGAS memory model is associated with penalties that can hinder PGAS\u2019s potential for scalability and speed of execution. This is because mapping the PGAS memory model to the underlying system requires a mapping process that is done in software, thereby introducing substantial overhead for shared accesses even when they are local. Compiler optimizations have not been sufficient to offset this overhead. On the other hand, manual code optimizations can help, but this eliminates the productivity edge of PGAS. This article proposes a processor microarchitecture extension that can perform such address mapping in hardware with nearly no performance overhead. These extensions are then availed to compilers through extensions to the processor instructions. Thus, the need for manual optimizations is eliminated and the productivity of PGAS languages is unleashed. Using Unified Parallel C (UPC), a PGAS language, we present a case study of a prototype compiler and architecture support. Two different implementations of the system were realized. The first uses a full-system simulator, gem5, which evaluates the overall performance gain of the new hardware support. The second uses an FPGA Leon3 soft-core processor to verify implementation feasibility and to parameterize the cost of the new hardware. The new instructions show promising results on all tested codes, including the NAS Parallel Benchmark kernels in UPC. Performance improvements of up to 5.5\u00d7 for unmodified codes, sometimes surpassing hand-optimized performance, were demonstrated. We also show that our four-core FPGA prototype requires less than 2.4&percnt; of the overall chip\u2019s area.",
        "acm_key": "2829951",
        "bib_stats": {
            "cites": 1,
            "dl": 156,
            "dl_52": 61,
            "dl_6": 6
        },
        "bibtex": "\r\n@article{Hoseinzadeh:2015:SSP:2836331.2829951,\n author = {Hoseinzadeh, Morteza and Arjomand, Mohammad and Sarbazi-Azad, Hamid},\n title = {SPCM: The Striped Phase Change Memory},\n journal = {ACM Trans. Archit. Code Optim.},\n issue_date = {January 2016},\n volume = {12},\n number = {4},\n month = nov,\n year = {2015},\n issn = {1544-3566},\n pages = {38:1--38:25},\n articleno = {38},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2829951},\n doi = {10.1145/2829951},\n acmid = {2829951},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, line striping, multilevel cell memory},\n} \r\n",
        "key": "2829951",
        "pub_year": "2016",
        "text": "Morteza Hoseinzadeh , Mohammad Arjomand , Hamid Sarbazi-Azad, SPCM: The Striped Phase Change Memory, ACM Transactions on Architecture and Code Optimization (TACO), v.12 n.4, p.1-25, January 2016  \u00a0[doi>"
    },
    "2830887": {
        "abstract": "Memory management is a crucial aspect of mobile sensing applications that must process high-rate data streams in an energy-efficient manner. Our work is done in the context of synchronous data-flow models in which applications are implemented as a graph of components that exchange data at fixed and known rates over FIFO channels. In this paper, we show that it is feasible to leverage the restricted semantics of synchronous data-flow models to optimize memory management. Our memory optimization approach includes two components: (1) We use abstract interpretation to analyze the complete memory behavior of a mobile sensing application and identify data sharing opportunities across components according to the live ranges of exchanged samples. Experiments indicate that the static analysis is precise for a majority of considered stream applications whose control logic does not depend on input data. (2) We propose novel heuristics for memory allocation that leverage the graph structure of applications to optimize data exchanges between application components to achieve not only significantly lower memory footprints but also increased stream processing throughput. We incorporate code generation techniques that transform a stream program into efficient C code. The memory optimizations are implemented as a new compiler for the StreamIt programming language. Experiments show that our memory optimizations reduce memory footprint by as much as 96% while matching or improving the performance of the StreamIt compiler with cache optimizations enabled. These results suggest that highly efficient stream processing engines may be built using synchronous data-flow languages.",
        "acm_key": "2830887",
        "bib_stats": {
            "cites": 1,
            "dl": 57,
            "dl_52": 18,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Pan:2015:NMM:2830865.2830887,\n author = {Pan, Chen and Xie, Mimi and Yang, Chengmo and Shao, Zili and Hu, Jingtong},\n title = {Nonvolatile Main Memory Aware Garbage Collection in High-level Language Virtual Machine},\n booktitle = {Proceedings of the 12th International Conference on Embedded Software},\n series = {EMSOFT '15},\n year = {2015},\n isbn = {978-1-4673-8079-9},\n location = {Amsterdam, The Netherlands},\n pages = {197--206},\n numpages = {10},\n url = {http://dl.acm.org/citation.cfm?id=2830865.2830887},\n acmid = {2830887},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2830887",
        "pub_year": "2015",
        "text": "Chen Pan , Mimi Xie , Chengmo Yang , Zili Shao , Jingtong Hu, Nonvolatile main memory aware garbage collection in high-level language virtual machine, Proceedings of the 12th International Conference on Embedded Software, p.197-206, October 04-09, 2015, Amsterdam, The Netherlands"
    },
    "2830898": {
        "abstract": "Distributed systems found in application domains, such as smart transportation and smart grids, inherently require dissemination of large amount of data over wide area networks (WAN). A large portion of this data is analyzed and used to manage the overall health and safety of these distributed systems. The data-centric, publish/subscribe (pub/sub) paradigm is an attractive choice to address these needs because it provides scalable and loosely coupled data communications. However, existing data-centric pub/sub mechanisms supporting quality of service (QoS) tend to operate effectively only within local area networks. Likewise broker-based solutions that operate at WAN-scale seldom provide mechanisms to coordinate among themselves for discovery and dissemination of information, and cannot handle both the heterogeneity of pub/sub endpoints as well as the significant churn in endpoints that is common in WAN-scale systems. To address these limitations, this paper presents PubSubCoord, which is a cloud-based coordination and discovery service for WAN-scale pub/sub systems. PubSubCoord, which builds upon the ZooKeeper coordination primitives, realizes a WAN-scale, adaptive, and low-latency endpoint discovery and data dissemination architecture by (a) balancing the load using elastic cloud resources, (b) clustering brokers by topics for affinity, and (c) minimizing the number of data delivery hops in the pub/sub overlay.",
        "acm_key": "2830898",
        "bib_stats": {
            "cites": 0,
            "dl": 46,
            "dl_52": 20,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Kim:2015:CFF:2830894.2830898,\n author = {Kim, Baekyeop and Jeon, Byungjun and Lee, Eunji and Chun, Hansung and Bahn, Hyokyung},\n title = {What Constrains Flash File System Performances?},\n booktitle = {Proceedings of the Posters and Demos Session of the 16th International Middleware Conference},\n series = {Middleware Posters and Demos '15},\n year = {2015},\n isbn = {978-1-4503-3729-8},\n location = {Vancouver, BC, Canada},\n pages = {4:1--4:2},\n articleno = {4},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2830894.2830898},\n doi = {10.1145/2830894.2830898},\n acmid = {2830898},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2830898",
        "pub_year": "2015",
        "text": "Baekyeop Kim , Byungjun Jeon , Eunji Lee , Hansung Chun , Hyokyung Bahn, What Constrains Flash File System Performances?, Proceedings of the Posters and Demos Session of the 16th International Middleware Conference, p.1-2, December 07-11, 2015, Vancouver, BC, Canada"
    },
    "2831250": {
        "abstract": "In the current scientific computing scenario storage systems are one of the main bottlenecks in computing platforms. This issue affects both traditional high performance computing systems and modern systems based on cloud platforms. Accelerating the I/O subsystems can improve the overall performance of the applications. In this paper, we present Hercules as an I/O accelerator specially designed for improving I/O access in workflow engines deployed over cloud-based infraestructures. Hercules provides a dynamic and flexible in-memory storage platform based on NoSQL-based distributed memory systems. In addition, Hercules offers a user-level interface based on POSIX for facilitating its usage on existing solutions and legacy applications. We have evaluated the proposed solution in a public cloud environment, in this case Amazon EC2. The results show that Hercules provides a scalable I/O solution with remarkable performance, especially for write operations, compared with classic I/O approaches for high performance computing in cloud environments.",
        "acm_key": "2831250",
        "bib_stats": {
            "cites": 0,
            "dl": 96,
            "dl_52": 38,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Xie:2015:LAD:2831244.2831250,\n author = {Xie, Wei and Chen, Yong and Roth, Philip C.},\n title = {A Low-cost Adaptive Data Separation Method for the Flash Translation Layer of Solid State Drives},\n booktitle = {Proceedings of the 2015 International Workshop on Data-Intensive Scalable Computing Systems},\n series = {DISCS '15},\n year = {2015},\n isbn = {978-1-4503-3993-3},\n location = {Austin, Texas},\n pages = {3:1--3:8},\n articleno = {3},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2831244.2831250},\n doi = {10.1145/2831244.2831250},\n acmid = {2831250},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data separation, flash translation layer, storage system},\n} \r\n",
        "key": "2831250",
        "pub_year": "2015",
        "text": "Wei Xie , Yong Chen , Philip C. Roth, A low-cost adaptive data separation method for the flash translation layer of solid state drives, Proceedings of the 2015 International Workshop on Data-Intensive Scalable Computing Systems, November 15-15, 2015, Austin, Texas"
    },
    "2840886": {
        "abstract": "Modern SoC designs incorporate several security policies to protect sensitive assets from unauthorized access. The policies affect multiple design blocks, and may involve subtle interactions between hardware, firmware, and software. This makes it difficult for SoC designers to implement these policies, and system validators to ensure adherence. Associated problems include complexity in upgrading these policies, IP reuse for systems targeted for markets with differing security requirement, and consequent increase in design time and time-to-market. In this paper, we address this important problem by developing a generic, flexible architectural framework for implementing arbitrary security policies in SoC designs. Our architecture has several distinctive features: (1) it relies on a dedicated, centralized, firmware-upgradable plug-and-play IP block that can implement diverse security policies; (2) it interfaces with individual IP blocks through their \"security wrapper\", which exploits and extends test/debug wrappers; (3) it implements a security policy as firmware code following existing security policy languages; (4) it can implement any security policy as long as relevant observable and controllable signals from the constituent IPs are accessible through the security wrappers; and (5) it realizes a low-overhead communication link between security wrappers of IP blocks and the centralized, dedicated controller. The approach builds on and extends the recent work on developing a centralized infrastructure IP for SoC security, referred to as IIPS, that interface with IP blocks using their boundary scan based wrappers. While this architecture is generic and independent of security policy types, we provide case studies with several common policies to show the flexibility and extendibility of the architecture. We also evaluate its viability in terms of overhead in area and power.",
        "acm_key": "2840886",
        "bib_stats": {
            "cites": 0,
            "dl": 97,
            "dl_52": 38,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Chang:2015:RPP:2840819.2840886,\n author = {Chang, Yu-Ming and Li, Yung-Chun and Chang, Yuan-Hao and Kuo, Tei-Wei and Hsieh, Chih-Chang and Li, Hsiang-Pang},\n title = {On Relaxing Page Program Disturbance over 3D MLC Flash Memory},\n booktitle = {Proceedings of the IEEE/ACM International Conference on Computer-Aided Design},\n series = {ICCAD '15},\n year = {2015},\n isbn = {978-1-4673-8389-9},\n location = {Austin, TX, USA},\n pages = {479--486},\n numpages = {8},\n url = {http://dl.acm.org/citation.cfm?id=2840819.2840886},\n acmid = {2840886},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2840886",
        "pub_year": "2015",
        "text": "Yu-Ming Chang , Yung-Chun Li , Yuan-Hao Chang , Tei-Wei Kuo , Chih-Chang Hsieh , Hsiang-Pang Li, On Relaxing Page Program Disturbance over 3D MLC Flash Memory, Proceedings of the IEEE/ACM International Conference on Computer-Aided Design, p.479-486, November 02-06, 2015, Austin, TX, USA"
    },
    "2842613": {
        "abstract": "The increasing impact of interconnections on overall circuit performance makes timing-driven placement (TDP) a crucial step toward timing closure. Current TDP techniques improve critical paths but overlook the impact of register placement on clock tree quality. On the other hand, register placement techniques found in the literature mainly focus on power consumption, disregarding timing and routabilty. Indeed, postponing register placement may undermine the optimization achieved by TDP, since the wiring between sequential and combinational elements would be touched. This work proposes a new approach for an effective coupling between register placement and TDP that relies on two key aspects to handle sequential and combinational elements separately: only the registers in the critical paths are touched by TDP (in practice they represent a small percentage of the total number of registers), and the shortening of clock tree wirelength can be obtained with limited variation in signal wirelength and placement density. The approach consists of two steps: (1) incremental register placement guided by a virtual clock tree to reduce clock wiring capacitance while preserving signal wirelength and density, and (2) incremental TDP to minimize the total negative slack. For the first step, we propose a novel technique that combines clock-net contraction and register clustering forces to reduce the clock wirelength. For the second step, we propose a novel Lagrangian Relaxation formulation that minimizes total negative slack for both setup and hold timing violations. To solve the formulation, we propose a TDP technique using a novel discrete search that employs a Euclidean distance to define a proper neighborhood. For the experimental evaluation of the proposed approach, we relied on the ICCAD 2014 TDP contest infrastructure and compared our results with the best results obtained from that contest in terms of timing closure, clock tree compactness, signal wirelength, and density. Assuming a long displacement constraint, our technique achieves worst and total negative slack reductions of around 24&percnt; and 26&percnt;, respectively. In addition, our approach leads to 44&percnt; shorter clock tree wirelength with negligible impact on signal wirelength and placement density. In the face of such results, the proposed coupling seems a useful approach to handle the challenges faced by contemporary physical synthesis.",
        "acm_key": "2842613",
        "bib_stats": {
            "cites": 0,
            "dl": 168,
            "dl_52": 121,
            "dl_6": 9
        },
        "bibtex": "\r\n@article{Lee:2016:DWS:2926747.2842613,\n author = {Lee, Sungkwang and Lee, Taemin and Park, Hyunsun and Ahn, Junwhan and Yoo, Sungjoo and Won, Youjip and Lee, Sunggu},\n title = {Differential Write-Conscious Software Design on Phase-Change Memory: An SQLite Case Study},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {July 2016},\n volume = {21},\n number = {3},\n month = apr,\n year = {2016},\n issn = {1084-4309},\n pages = {47:1--47:25},\n articleno = {47},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2842613},\n doi = {10.1145/2842613},\n acmid = {2842613},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, SQLite, differential write, wear leveling},\n} \r\n",
        "key": "2842613",
        "pub_year": "2016",
        "text": "Sungkwang Lee , Taemin Lee , Hyunsun Park , Junwhan Ahn , Sungjoo Yoo , Youjip Won , Sunggu Lee, Differential Write-Conscious Software Design on Phase-Change Memory: An SQLite Case Study, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.21 n.3, May 2016"
    },
    "2851504": {
        "abstract": "File-system snapshots have been a key component of enterprise storage management since their inception. Creating and managing them efficiently, while maintaining flexibility and low overhead, has been a constant struggle. Although the current state-of-the-art mechanism\u2014hierarchical reference counting\u2014performs reasonably well for traditional small-file workloads, these workloads are increasingly vanishing from the enterprise data center, replaced instead with virtual machine and database workloads. These workloads center around a few very large files, violating the assumptions that allow hierarchical reference counting to operate efficiently. To better cope with these workloads, we introduce Generational Chain Trees (GCTrees), a novel method of space management that uses concepts of block lineage across snapshots rather than explicit reference counting. As a proof of concept, we create a prototype file system\u2014gcext4, a modified version of ext4 that uses GCTrees as a basis for snapshots and copy-on-write. In evaluating this prototype empirically, we find that although they have a somewhat higher overhead for traditional workloads, GCTrees have dramatically lower overhead than hierarchical reference counting for large-file workloads, improving by a factor of 34 or more in some cases. Furthermore, gcext4 performs comparably to ext4 across all workloads, showing that GCTrees impose minor cost for their benefits.",
        "acm_key": "2851504",
        "bib_stats": {
            "cites": 0,
            "dl": 293,
            "dl_52": 124,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Lu:2016:BPE:2875132.2851504,\n author = {Lu, Youyou and Shu, Jiwu and Sun, Long},\n title = {Blurred Persistence: Efficient Transactions in Persistent Memory},\n journal = {Trans. Storage},\n issue_date = {February 2016},\n volume = {12},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1553-3077},\n pages = {3:1--3:29},\n articleno = {3},\n numpages = {29},\n url = {http://doi.acm.org/10.1145/2851504},\n doi = {10.1145/2851504},\n acmid = {2851504},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Persistent memory, persistence, transaction consistency},\n} \r\n",
        "key": "2851504",
        "pub_year": "2016",
        "text": "Youyou Lu , Jiwu Shu , Long Sun, Blurred Persistence: Efficient Transactions in Persistent Memory, ACM Transactions on Storage (TOS), v.12 n.1, January 2016"
    },
    "2851663": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851663",
        "bib_stats": {
            "cites": 0,
            "dl": 31,
            "dl_52": 24,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Shin:2016:OHP:2851613.2851663,\n author = {Shin, Mincheol and Roh, Hongchan and Jung, Wonmook and Park, Sanghyun},\n title = {Optimizing Hash Partitioning for Solid State Drives},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1000--1007},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2851613.2851663},\n doi = {10.1145/2851613.2851663},\n acmid = {2851663},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash storage devices, hash join, hash partitioning, internal parallelism of flashSSDs, query execution},\n} \r\n",
        "key": "2851663",
        "pub_year": "2016",
        "text": "Mincheol Shin , Hongchan Roh , Wonmook Jung , Sanghyun Park, Optimizing hash partitioning for solid state drives, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851670": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851670",
        "bib_stats": {
            "cites": 0,
            "dl": 53,
            "dl_52": 38,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Qiu:2016:BLR:2851613.2851670,\n author = {Qiu, Keni and Zhang, Weigong and Wu, Xiaoqiang and Zhu, Xiaoyan and Wang, Jing and Xu, Yuanchao and Xue, Chun Jason},\n title = {Balanced Loop Retiming to Effectively Architect STT-RAM-based Hybrid Cache for VLIW Processors},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1710--1716},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2851613.2851670},\n doi = {10.1145/2851613.2851670},\n acmid = {2851670},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {ILP, STT-RAM, VLIW, loop retiming, migration overhead},\n} \r\n",
        "key": "2851670",
        "pub_year": "2016",
        "text": "Keni Qiu , Weigong Zhang , Xiaoqiang Wu , Xiaoyan Zhu , Jing Wang , Yuanchao Xu , Chun Jason Xue, Balanced loop retiming to effectively architect STT-RAM-based hybrid cache for VLIW processors, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851673": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851673",
        "bib_stats": {
            "cites": 0,
            "dl": 32,
            "dl_52": 18,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Atoofian:2016:LPS:2851613.2851673,\n author = {Atoofian, Ehsan},\n title = {A Low Power STT-RAM Based Register File for GPGPUs},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1732--1738},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2851613.2851673},\n doi = {10.1145/2851613.2851673},\n acmid = {2851673},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {GPGPU, STT-RAM, performance, power, register file},\n} \r\n",
        "key": "2851673",
        "pub_year": "2016",
        "text": "Ehsan Atoofian, A low power STT-RAM based register file for GPGPUs, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851735": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851735",
        "bib_stats": {
            "cites": 0,
            "dl": 106,
            "dl_52": 88,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Wang:2016:INR:2851613.2851735,\n author = {Wang, Mingyang and Hu, Yiming},\n title = {i-RAID: A Novel Redundant Storage Architecture for Improving Reliability, Performance, and Life-span of Solid-state Disk Systems},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1824--1831},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2851613.2851735},\n doi = {10.1145/2851613.2851735},\n acmid = {2851735},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {internal RAID, non-volatile memory, program disturb, read disturb, redundancy, solid state disk, write endurance},\n} \r\n",
        "key": "2851735",
        "pub_year": "2016",
        "text": "Mingyang Wang , Yiming Hu, i-RAID: a novel redundant storage architecture for improving reliability, performance, and life-span of solid-state disk systems, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851744": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851744",
        "bib_stats": {
            "cites": 0,
            "dl": 93,
            "dl_52": 57,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Yamauchi:2016:PPM:2851613.2851744,\n author = {Yamauchi, Toshihiro and Yamamoto, Yuta and Nagai, Kengo and Matono, Tsukasa and Inamoto, Shinji and Ichikawa, Masaya and Goto, Masataka and Taniguchi, Hideo},\n title = {Plate: Persistent Memory Management for Nonvolatile Main Memory},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1885--1892},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2851613.2851744},\n doi = {10.1145/2851613.2851744},\n acmid = {2851744},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory, memory management, nonvolatile main, operating system, persistent mechanism},\n} \r\n",
        "key": "2851744",
        "pub_year": "2016",
        "text": "Toshihiro Yamauchi , Yuta Yamamoto , Kengo Nagai , Tsukasa Matono , Shinji Inamoto , Masaya Ichikawa , Masataka Goto , Hideo Taniguchi, Plate: persistent memory management for nonvolatile main memory, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851905": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851905",
        "bib_stats": {
            "cites": 0,
            "dl": 53,
            "dl_52": 40,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Hsieh:2016:PMS:2851613.2851905,\n author = {Hsieh, Jen-Wei and Su, Che-Jen},\n title = {Parity Management Scheme for a Hybrid-storage RAID},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1774--1776},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/2851613.2851905},\n doi = {10.1145/2851613.2851905},\n acmid = {2851905},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {RAID, SSD, partial parity buffer, partial parity cache},\n} \r\n",
        "key": "2851905",
        "pub_year": "2016",
        "text": "Jen-Wei Hsieh , Che-Jen Su, Parity management scheme for a hybrid-storage RAID, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2851944": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2851944",
        "bib_stats": {
            "cites": 0,
            "dl": 100,
            "dl_52": 72,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Kim:2016:ZZF:2851613.2851944,\n author = {Kim, Dongwook and Kang, Sooyong},\n title = {zf-FTL: A Zero-free Flash Translation Layer},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1893--1896},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/2851613.2851944},\n doi = {10.1145/2851613.2851944},\n acmid = {2851944},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data reduction, flash translation layer, solid state drive, zero page elimination},\n} \r\n",
        "key": "2851944",
        "pub_year": "2016",
        "text": "Dongwook Kim , Sooyong Kang, zf-FTL: a zero-free flash translation layer, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2852024": {
        "abstract": "Previous studies have shown that using traditional RAID-5 algorithms directly on SSDs may lead to many pitfalls. They introduce some huge performance penalty and other reliability issues. We propose a novel solution called i-RAID (internal RAID) that introduces RAID-like parity-based redundancy while avoiding many of its problems. Unlike traditional disk drives, SSDs cannot perform in-place updates. We view this unique characteristic as an opportunity instead of a hurdle. The out-of-place update feature means that old data will not be over-written by the new data, which allows us to design some fundamentally new algorithms that defer the computing and updating of parity blocks until the garbage collection time, thereby significantly reducing the overhead and possibly increasing the life-time of SSDs. Our algorithms also dynamically and selectively construct parity stripes only on aged, error-prone blocks, and utilize the internal parallelism of SSDs to further improve performance. Our study shows that by constructing i-RAID on aged blocks only (90% of rated life cycles), i-RAID introduces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. only small time performance overhead (2% - 6%) and erase count overhead (3% - 15%) comparing to non-redundant devices. By trading more performance overhead, reliability can be even more enhanced which may be necessary for a highly-demanding environment.",
        "acm_key": "2852024",
        "bib_stats": {
            "cites": 0,
            "dl": 21,
            "dl_52": 16,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Kang:2016:MEE:2851613.2852024,\n author = {Kang, Yoonsuk},\n title = {A Methodology for Estimating Execution Times of IO Traces in SSDs: Student Research Abstract},\n booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},\n series = {SAC '16},\n year = {2016},\n isbn = {978-1-4503-3739-7},\n location = {Pisa, Italy},\n pages = {1011--1012},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2851613.2852024},\n doi = {10.1145/2851613.2852024},\n acmid = {2852024},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2852024",
        "pub_year": "2016",
        "text": "Yoonsuk Kang, A methodology for estimating execution times of IO traces in SSDs: student research abstract, Proceedings of the 31st Annual ACM Symposium on Applied Computing, April 04-08, 2016, Pisa, Italy"
    },
    "2856423": {
        "abstract": "With dramatic growth of data and rapid enhancement of computing powers, data accesses become the bottleneck restricting overall performance of a computer system. Emerging phase-change memory (PCM) is byte-addressable like DRAM, persistent like hard disks and Flash SSD, and about four orders of magnitude faster than hard disks or Flash SSDs for typical file system I/Os. The maturity of PCM from research to production provides a new opportunity for improving the I/O performance of a system. However, PCM also has some weaknesses, for example, long write latency, limited write endurance, and high active energy. Existing processor cache systems, main memory systems, and online storage systems are unable to leverage the advantages of PCM, and/or to mitigate PCM\u2019s drawbacks. The reason behind this incompetence is that they are designed and optimized for SRAM, DRAM memory, and hard drives, respectively, instead of PCM memory. There have been some efforts concentrating on rethinking computer architectures and software systems for PCM. This article presents a detailed survey and review of the areas of computer architecture and software systems that are oriented to PCM devices. First, we identify key technical challenges that need to be addressed before this memory technology can be leveraged, in the form of processor cache, main memory, and online storage, to build high-performance computer systems. Second, we examine various designs of computer architectures and software systems that are PCM aware. Finally, we obtain several helpful observations and propose a few suggestions on how to leverage PCM to optimize the performance of a computer system.",
        "acm_key": "2856423",
        "bib_stats": {
            "cites": 0,
            "dl": 163,
            "dl_52": 114,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Khouzani:2016:FEP:2856147.2856423,\n author = {Khouzani, Hoda Aghaei and Xue, Yuan and Yang, Chengmo},\n title = {Fully Exploiting PCM Write Capacity Within Near Zero Cost Through Segment-Based Page Allocation},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {July 2016},\n volume = {12},\n number = {4},\n month = may,\n year = {2016},\n issn = {1550-4832},\n pages = {31:1--31:26},\n articleno = {31},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/2856423},\n doi = {10.1145/2856423},\n acmid = {2856423},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, age-aware page allocation, interprocess wear leveling, segment information exploitation},\n} \r\n",
        "key": "2856423",
        "pub_year": "2016",
        "text": "Hoda Aghaei Khouzani , Yuan Xue , Chengmo Yang, Fully Exploiting PCM Write Capacity Within Near Zero Cost Through Segment-Based Page Allocation, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.12 n.4, June 2016"
    },
    "2861999": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2861999",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@inproceedings{Son:2015:EEN:2861850.2861999,\n author = {Son, Yongseok and Kang, Hara and Han, Hyuck and Yeom, Heon Young},\n title = {An Empirical Evaluation of NVM Express SSD},\n booktitle = {Proceedings of the 2015 International Conference on Cloud and Autonomic Computing},\n series = {ICCAC '15},\n year = {2015},\n isbn = {978-1-4673-9566-3},\n pages = {275--282},\n numpages = {8},\n url = {http://dx.doi.org/10.1109/ICCAC.2015.41},\n doi = {10.1109/ICCAC.2015.41},\n acmid = {2861999},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {Performance Evaluation, NVM express, Solid State Drives, File System, Database},\n} \r\n",
        "key": "2861999",
        "pub_year": "2015",
        "text": "Yongseok Son , Hara Kang , Hyuck Han , Heon Young Yeom, An Empirical Evaluation of NVM Express SSD, Proceedings of the 2015 International Conference on Cloud and Autonomic Computing, p.275-282, September 21-25, 2015  \u00a0[doi>"
    },
    "2862154": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2862154",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@inproceedings{Koller:2015:CHS:2861853.2862154,\n author = {Koller, Ricardo and Mashtizadeh, Ali Jos\u00e9 and Rangaswami, Raju},\n title = {Centaur: Host-Side SSD Caching for Storage Performance Control},\n booktitle = {Proceedings of the 2015 IEEE International Conference on Autonomic Computing},\n series = {ICAC '15},\n year = {2015},\n isbn = {978-1-4673-6971-8},\n pages = {51--60},\n numpages = {10},\n url = {http://dx.doi.org/10.1109/ICAC.2015.44},\n doi = {10.1109/ICAC.2015.44},\n acmid = {2862154},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2862154",
        "pub_year": "2015",
        "text": "Ricardo Koller , Ali Jos\u00e9 Mashtizadeh , Raju Rangaswami, Centaur: Host-Side SSD Caching for Storage Performance Control, Proceedings of the 2015 IEEE International Conference on Autonomic Computing, p.51-60, July 07-10, 2015  \u00a0[doi>"
    },
    "2872377": {
        "abstract": "Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90% of users, the level of acceptable quality loss is 2% for one application (image processing) and 26% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.",
        "acm_key": "2872377",
        "bib_stats": {
            "cites": 3,
            "dl": 423,
            "dl_52": 237,
            "dl_6": 12
        },
        "bibtex": "\r\n@article{Awad:2016:SSZ:2954680.2872377,\n author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},\n title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2016},\n volume = {50},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5980},\n pages = {263--276},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2954680.2872377},\n doi = {10.1145/2954680.2872377},\n acmid = {2872377},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data protection, hardware security, keywords encryption, phase-change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872377&parent_id=2954680&expformat=bibtex&CFID=982054835&CFTOKEN=47812983\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872377\">\r\n@article{Awad:2016:SSZ:2954679.2872377,\n author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},\n title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},\n journal = {SIGPLAN Not.},\n issue_date = {April 2016},\n volume = {51},\n number = {4},\n month = mar,\n year = {2016},\n issn = {0362-1340},\n pages = {263--276},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2954679.2872377},\n doi = {10.1145/2954679.2872377},\n acmid = {2872377},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data protection, hardware security, keywords encryption, phase-change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872377&parent_id=2954679&expformat=bibtex&CFID=982054835&CFTOKEN=47812983\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872377\">\r\n@inproceedings{Awad:2016:SSZ:2872362.2872377,\n author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},\n title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},\n booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '16},\n year = {2016},\n isbn = {978-1-4503-4091-5},\n location = {Atlanta, Georgia, USA},\n pages = {263--276},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2872362.2872377},\n doi = {10.1145/2872362.2872377},\n acmid = {2872377},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data protection, hardware security, keywords encryption, phase-change memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872377&parent_id=2872362&expformat=bibtex&CFID=982054835&CFTOKEN=47812983\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872377\">\r\n@article{Awad:2016:SSZ:2980024.2872377,\n author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},\n title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {May 2016},\n volume = {44},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5964},\n pages = {263--276},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2980024.2872377},\n doi = {10.1145/2980024.2872377},\n acmid = {2872377},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data protection, hardware security, keywords encryption, phase-change memory},\n} \r\n",
        "key": "2872377",
        "pub_year": "2016",
        "text": "Amro Awad , Pratyusa Manadhata , Stuart Haber , Yan Solihin , William Horne, Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA  \u00a0[doi>"
    },
    "2872381": {
        "abstract": "Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90% of users, the level of acceptable quality loss is 2% for one application (image processing) and 26% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.",
        "acm_key": "2872381",
        "bib_stats": {
            "cites": 7,
            "dl": 489,
            "dl_52": 343,
            "dl_6": 29
        },
        "bibtex": "\r\n@article{Kolli:2016:HTP:2954679.2872381,\n author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},\n title = {High-Performance Transactions for Persistent Memories},\n journal = {SIGPLAN Not.},\n issue_date = {April 2016},\n volume = {51},\n number = {4},\n month = mar,\n year = {2016},\n issn = {0362-1340},\n pages = {399--411},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2954679.2872381},\n doi = {10.1145/2954679.2872381},\n acmid = {2872381},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory persistency, non-volatile memory, recoverability, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872381&parent_id=2954679&expformat=bibtex&CFID=982028435&CFTOKEN=26556719\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872381\">\r\n@article{Kolli:2016:HTP:2954680.2872381,\n author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},\n title = {High-Performance Transactions for Persistent Memories},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2016},\n volume = {50},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5980},\n pages = {399--411},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2954680.2872381},\n doi = {10.1145/2954680.2872381},\n acmid = {2872381},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory persistency, non-volatile memory, recoverability, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872381&parent_id=2954680&expformat=bibtex&CFID=982028435&CFTOKEN=26556719\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872381\">\r\n@inproceedings{Kolli:2016:HTP:2872362.2872381,\n author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},\n title = {High-Performance Transactions for Persistent Memories},\n booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '16},\n year = {2016},\n isbn = {978-1-4503-4091-5},\n location = {Atlanta, Georgia, USA},\n pages = {399--411},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2872362.2872381},\n doi = {10.1145/2872362.2872381},\n acmid = {2872381},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory persistency, non-volatile memory, recoverability, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872381&parent_id=2872362&expformat=bibtex&CFID=982028435&CFTOKEN=26556719\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872381\">\r\n@article{Kolli:2016:HTP:2980024.2872381,\n author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},\n title = {High-Performance Transactions for Persistent Memories},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {May 2016},\n volume = {44},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5964},\n pages = {399--411},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2980024.2872381},\n doi = {10.1145/2980024.2872381},\n acmid = {2872381},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {memory persistency, non-volatile memory, recoverability, transactions},\n} \r\n",
        "key": "2872381",
        "pub_year": "2016",
        "text": "Aasheesh Kolli , Steven Pelley , Ali Saidi , Peter M. Chen , Thomas F. Wenisch, High-Performance Transactions for Persistent Memories, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA  \u00a0[doi>"
    },
    "2872392": {
        "abstract": "Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90% of users, the level of acceptable quality loss is 2% for one application (image processing) and 26% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.",
        "acm_key": "2872392",
        "bib_stats": {
            "cites": 5,
            "dl": 658,
            "dl_52": 363,
            "dl_6": 23
        },
        "bibtex": "\r\n@article{Kim:2016:NEN:2954679.2872392,\n author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},\n title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},\n journal = {SIGPLAN Not.},\n issue_date = {April 2016},\n volume = {51},\n number = {4},\n month = mar,\n year = {2016},\n issn = {0362-1340},\n pages = {385--398},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2954679.2872392},\n doi = {10.1145/2954679.2872392},\n acmid = {2872392},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory, write-ahead-logging},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872392&parent_id=2954679&expformat=bibtex&CFID=982051226&CFTOKEN=92635298\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872392\">\r\n@article{Kim:2016:NEN:2954680.2872392,\n author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},\n title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2016},\n volume = {50},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5980},\n pages = {385--398},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2954680.2872392},\n doi = {10.1145/2954680.2872392},\n acmid = {2872392},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory, write-ahead-logging},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872392&parent_id=2954680&expformat=bibtex&CFID=982051226&CFTOKEN=92635298\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872392\">\r\n@inproceedings{Kim:2016:NEN:2872362.2872392,\n author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},\n title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},\n booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '16},\n year = {2016},\n isbn = {978-1-4503-4091-5},\n location = {Atlanta, Georgia, USA},\n pages = {385--398},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2872362.2872392},\n doi = {10.1145/2872362.2872392},\n acmid = {2872392},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory, write-ahead-logging},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872392&parent_id=2872362&expformat=bibtex&CFID=982051226&CFTOKEN=92635298\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872392\">\r\n@article{Kim:2016:NEN:2980024.2872392,\n author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},\n title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {May 2016},\n volume = {44},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5964},\n pages = {385--398},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2980024.2872392},\n doi = {10.1145/2980024.2872392},\n acmid = {2872392},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {non-volatile memory, write-ahead-logging},\n} \r\n",
        "key": "2872392",
        "pub_year": "2016",
        "text": "Wook-Hee Kim , Jinwoong Kim , Woongki Baek , Beomseok Nam , Youjip Won, NVWAL: Exploiting NVRAM in Write-Ahead Logging, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA"
    },
    "2872401": {
        "abstract": "Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90% of users, the level of acceptable quality loss is 2% for one application (image processing) and 26% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.",
        "acm_key": "2872401",
        "bib_stats": {
            "cites": 3,
            "dl": 312,
            "dl_52": 179,
            "dl_6": 23
        },
        "bibtex": "\r\n@article{Lin:2016:MTP:2980024.2872401,\n author = {Lin, Felix Xiaozhu and Liu, Xu},\n title = {Memif: Towards Programming Heterogeneous Memory Asynchronously},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {May 2016},\n volume = {44},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5964},\n pages = {369--383},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2980024.2872401},\n doi = {10.1145/2980024.2872401},\n acmid = {2872401},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data-intensive computing, heterogeneous memory, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872401&parent_id=2980024&expformat=bibtex&CFID=982043515&CFTOKEN=10589382\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872401\">\r\n@article{Lin:2016:MTP:2954679.2872401,\n author = {Lin, Felix Xiaozhu and Liu, Xu},\n title = {Memif: Towards Programming Heterogeneous Memory Asynchronously},\n journal = {SIGPLAN Not.},\n issue_date = {April 2016},\n volume = {51},\n number = {4},\n month = mar,\n year = {2016},\n issn = {0362-1340},\n pages = {369--383},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2954679.2872401},\n doi = {10.1145/2954679.2872401},\n acmid = {2872401},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data-intensive computing, heterogeneous memory, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872401&parent_id=2954679&expformat=bibtex&CFID=982043515&CFTOKEN=10589382\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872401\">\r\n@article{Lin:2016:MTP:2954680.2872401,\n author = {Lin, Felix Xiaozhu and Liu, Xu},\n title = {Memif: Towards Programming Heterogeneous Memory Asynchronously},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2016},\n volume = {50},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5980},\n pages = {369--383},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2954680.2872401},\n doi = {10.1145/2954680.2872401},\n acmid = {2872401},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data-intensive computing, heterogeneous memory, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872401&parent_id=2954680&expformat=bibtex&CFID=982043515&CFTOKEN=10589382\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872401\">\r\n@inproceedings{Lin:2016:MTP:2872362.2872401,\n author = {Lin, Felix Xiaozhu and Liu, Xu},\n title = {Memif: Towards Programming Heterogeneous Memory Asynchronously},\n booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '16},\n year = {2016},\n isbn = {978-1-4503-4091-5},\n location = {Atlanta, Georgia, USA},\n pages = {369--383},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2872362.2872401},\n doi = {10.1145/2872362.2872401},\n acmid = {2872401},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {data-intensive computing, heterogeneous memory, operating systems},\n} \r\n",
        "key": "2872401",
        "pub_year": "2016",
        "text": "Felix Xiaozhu Lin , Xu Liu, memif<i>memif</i>: Towards Programming Heterogeneous Memory Asynchronously, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA : Towards Programming Heterogeneous Memory Asynchronously, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA  \u00a0[doi>"
    },
    "2872410": {
        "abstract": "Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90% of users, the level of acceptable quality loss is 2% for one application (image processing) and 26% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.",
        "acm_key": "2872410",
        "bib_stats": {
            "cites": 6,
            "dl": 476,
            "dl_52": 291,
            "dl_6": 25
        },
        "bibtex": "\r\n@article{Izraelevitz:2016:FPM:2954679.2872410,\n author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},\n title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},\n journal = {SIGPLAN Not.},\n issue_date = {April 2016},\n volume = {51},\n number = {4},\n month = mar,\n year = {2016},\n issn = {0362-1340},\n pages = {427--442},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2954679.2872410},\n doi = {10.1145/2954679.2872410},\n acmid = {2872410},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872410&parent_id=2954679&expformat=bibtex&CFID=982052308&CFTOKEN=25349573\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872410\">\r\n@inproceedings{Izraelevitz:2016:FPM:2872362.2872410,\n author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},\n title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},\n booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '16},\n year = {2016},\n isbn = {978-1-4503-4091-5},\n location = {Atlanta, Georgia, USA},\n pages = {427--442},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2872362.2872410},\n doi = {10.1145/2872362.2872410},\n acmid = {2872410},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872410&parent_id=2872362&expformat=bibtex&CFID=982052308&CFTOKEN=25349573\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872410\">\r\n@article{Izraelevitz:2016:FPM:2954680.2872410,\n author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},\n title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2016},\n volume = {50},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5980},\n pages = {427--442},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2954680.2872410},\n doi = {10.1145/2954680.2872410},\n acmid = {2872410},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2872410&parent_id=2954680&expformat=bibtex&CFID=982052308&CFTOKEN=25349573\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2872410\">\r\n@article{Izraelevitz:2016:FPM:2980024.2872410,\n author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},\n title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {May 2016},\n volume = {44},\n number = {2},\n month = mar,\n year = {2016},\n issn = {0163-5964},\n pages = {427--442},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2980024.2872410},\n doi = {10.1145/2980024.2872410},\n acmid = {2872410},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions},\n} \r\n",
        "key": "2872410",
        "pub_year": "2016",
        "text": "Joseph Izraelevitz , Terence Kelly , Aasheesh Kolli, Failure-Atomic Persistent Memory Updates via JUSTDO Logging, Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, April 02-06, 2016, Atlanta, Georgia, USA  \u00a0[doi>"
    },
    "2872579": {
        "abstract": "Time series classification is related to many different domains, such as health informatics, finance, and bioinformatics. Due to its broad applications, researchers have developed many algorithms for this kind of tasks, e.g., multivariate time series classification. Among the classification algorithms, k-nearest neighbor (k-NN) classification (particularly 1-NN) combined with dynamic time warping (DTW) achieves the state of the art performance. The deficiency is that when the data set grows large, the time consumption of 1-NN with DTWwill be very expensive. In contrast to 1-NN with DTW, it is more efficient but less effective for feature-based classification methods since their performance usually depends on the quality of hand-crafted features. In this paper, we aim to improve the performance of traditional feature-based approaches through the feature learning techniques. Specifically, we propose a novel deep learning framework, multi-channels deep convolutional neural networks (MC-DCNN), for multivariate time series classification. This model first learns features from individual univariate time series in each channel, and combines information from all channels as feature representation at the final layer. Then, the learnt features are applied into a multilayer perceptron (MLP) for classification. Finally, the extensive experiments on real-world data sets show that our model is not only more efficient than the state of the art but also competitive in accuracy. This study implies that feature learning is worth to be investigated for the problem of time series classification.",
        "acm_key": "2872579",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Li:2016:WTV:2872563.2872579,\n author = {Li, Dingding and Liao, Xiaofei and Jin, Hai and Tang, Yong and Zhao, Gansen},\n title = {Writeback Throttling in a Virtualized System with SCM},\n journal = {Front. Comput. Sci.},\n issue_date = {February  2016},\n volume = {10},\n number = {1},\n month = feb,\n year = {2016},\n issn = {2095-2228},\n pages = {82--95},\n numpages = {14},\n url = {http://dx.doi.org/10.1007/s11704-015-4217-8},\n doi = {10.1007/s11704-015-4217-8},\n acmid = {2872579},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {storage class memory, virtualization, writeback},\n} \r\n",
        "key": "2872579",
        "pub_year": "2016",
        "text": "Dingding Li , Xiaofei Liao , Hai Jin , Yong Tang , Gansen Zhao, Writeback throttling in a virtualized system with SCM, Frontiers of Computer Science: Selected Publications from Chinese Universities, v.10 n.1, p.82-95, February  2016"
    },
    "2876507": {
        "abstract": "With dramatic growth of data and rapid enhancement of computing powers, data accesses become the bottleneck restricting overall performance of a computer system. Emerging phase-change memory (PCM) is byte-addressable like DRAM, persistent like hard disks and Flash SSD, and about four orders of magnitude faster than hard disks or Flash SSDs for typical file system I/Os. The maturity of PCM from research to production provides a new opportunity for improving the I/O performance of a system. However, PCM also has some weaknesses, for example, long write latency, limited write endurance, and high active energy. Existing processor cache systems, main memory systems, and online storage systems are unable to leverage the advantages of PCM, and/or to mitigate PCM\u2019s drawbacks. The reason behind this incompetence is that they are designed and optimized for SRAM, DRAM memory, and hard drives, respectively, instead of PCM memory. There have been some efforts concentrating on rethinking computer architectures and software systems for PCM. This article presents a detailed survey and review of the areas of computer architecture and software systems that are oriented to PCM devices. First, we identify key technical challenges that need to be addressed before this memory technology can be leveraged, in the form of processor cache, main memory, and online storage, to build high-performance computer systems. Second, we examine various designs of computer architectures and software systems that are PCM aware. Finally, we obtain several helpful observations and propose a few suggestions on how to leverage PCM to optimize the performance of a computer system.",
        "acm_key": "2876507",
        "bib_stats": {
            "cites": 0,
            "dl": 148,
            "dl_52": 100,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Layer:2016:RSP:2856147.2876507,\n author = {Layer, Christophe and Becker, Laurent and Jabeur, Kotb and Claireux, Sylvain and Dieny, Bernard and Prenat, Guillaume and Pendina, Gregory Di and Gros, Stephane and Paoli, Pierre and Javerliac, Virgile and Bernard-Granger, Fabrice and Decloedt, Loic},\n title = {Reducing System Power Consumption Using Check-Pointing on Nonvolatile Embedded Magnetic Random Access Memories},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {July 2016},\n volume = {12},\n number = {4},\n month = may,\n year = {2016},\n issn = {1550-4832},\n pages = {32:1--32:24},\n articleno = {32},\n numpages = {24},\n url = {http://doi.acm.org/10.1145/2876507},\n doi = {10.1145/2876507},\n acmid = {2876507},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Hybrid CMOS/magnetic, STT-MRAM, check-pointing interrupt},\n} \r\n",
        "key": "2876507",
        "pub_year": "2016",
        "text": "Christophe Layer , Laurent Becker , Kotb Jabeur , Sylvain Claireux , Bernard Dieny , Guillaume Prenat , Gregory Di Pendina , Stephane Gros , Pierre Paoli , Virgile Javerliac , Fabrice Bernard-Granger , Loic Decloedt, Reducing System Power Consumption Using Check-Pointing on Nonvolatile Embedded Magnetic Random Access Memories, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.12 n.4, June 2016"
    },
    "2877743": {
        "abstract": "Recently, with the widely use of flash memory based solid state drives (SSDs), a lot of studies have been conducted on SSD-based data management, such as index structures, query processing, and buffer management schemes. This paper focuses on buffer schemes for SSD-based database systems. However, differing from previous studies, we concentrate on buffer schemes for tree indexes on SSDs. This work is motivated by the observation that access patterns on index pages are much different from those on data pages. Generally, in a typical tree index, e.g., B+-tree, the root and internal nodes have higher read frequencies than leaf nodes have. However, traditional SSD-oriented buffering methods do not consider this special feature of indexes, and thus is not efficient when used as index buffer management schemes. In this paper, we present a new buffering scheme for tree indexes on SSDs that is named Clean-First and Dirty-Redundant-Write (CFDRW) scheme. The contributions of CFDRW are manifold. First, it assigns priorities to index pages to reflect the differences of access patterns of the nodes in a tree index. Second, it uses priority and recency to detect the hotness of index pages and proposes a new replacement algorithm based on priority and recency of the buffered index pages. Third, it exploits the internal parallelism of SSDs and proposes to write out buffer pages in a coarse granularity, i.e., to write out several pages using one physical I/O operation. We compare our proposal on two commodity SSDs with many previous methods including LRU, LIRS, and six flash-memory-based buffering schemes, by using synthetic and real workloads. The results show that our proposal outperforms the competitors under all workloads and SSDs in terms of various metrics including hit ratio, read count, write count, and elapsed time.",
        "acm_key": "2877743",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Yang:2016:EBM:2877704.2877743,\n author = {Yang, Chengcheng and Jin, Peiquan and Yue, Lihua and Yang, Puyuan},\n title = {Efficient Buffer Management for Tree Indexes on Solid State Drives},\n journal = {Int. J. Parallel Program.},\n issue_date = {February  2016},\n volume = {44},\n number = {1},\n month = feb,\n year = {2016},\n issn = {0885-7458},\n pages = {5--25},\n numpages = {21},\n url = {http://dx.doi.org/10.1007/s10766-014-0340-7},\n doi = {10.1007/s10766-014-0340-7},\n acmid = {2877743},\n publisher = {Kluwer Academic Publishers},\n address = {Norwell, MA, USA},\n keywords = {Buffer management, Solid state drive, Tree indexes},\n} \r\n",
        "key": "2877743",
        "pub_year": "2016",
        "text": "Chengcheng Yang , Peiquan Jin , Lihua Yue , Puyuan Yang, Efficient Buffer Management for Tree Indexes on Solid State Drives, International Journal of Parallel Programming, v.44 n.1, p.5-25, February  2016"
    },
    "2877758": {
        "abstract": "Video segmentation acts as the fundamental step for various applications like, archiving, content based retrieval, copy detection and summarization of video data. Shot detection is first level of segmentation. In this work, a shot detection methodology is presented that evolves around a simple shot transition model based on the similarity of the frames with respect to a reference frame. Frames in an individual shot are very similar in terms of their visual content. Whenever a shot transition occurs a change in similarity values appears. For an abrupt transition, the rate of change is very high, while for gradual it is not so apparent. To overcome the effect of noise in similarity values, line is fit over a small window using a linear regression. Thus slope of this line exhibits the underlying pattern of transition. A novel algorithm for shot detection, hence, is developed based on the variation pattern of the similarity values of the frames with respect to a reference frame. First an algorithm is proposed, which is direct descendant of the underlying transition model and applies a threshold on the similarity values to detect the transitions. Then this algorithm is improved by utilizing the slope of linear approximation of variation in similarity values rather than the absolute values, following least square regression. Threshold on the slope is determined with a bias towards minimizing false rejection rate at the cost of false acceptance rate. Finally, a simple post-processing technique is adopted to reduce the false detection. Experiment is done with the video sequences taken from TRECVID 2001 database, action type movie video, recorded sports and news video. Comparison with few other systems indicates that the performance of the proposed scheme is quite satisfactory.",
        "acm_key": "2877758",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Ling:2016:FAD:2877705.2877758,\n author = {Ling, Qiang and Xu, Lixiang and Yan, Jinfeng and Zhang, Yicheng and Li, Feng},\n title = {A Feedback-based Adaptive Data Migration Method for Hybrid Storage VOD Caching Systems},\n journal = {Multimedia Tools Appl.},\n issue_date = {January   2016},\n volume = {75},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1380-7501},\n pages = {165--180},\n numpages = {16},\n url = {http://dx.doi.org/10.1007/s11042-014-2281-y},\n doi = {10.1007/s11042-014-2281-y},\n acmid = {2877758},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Caching, Data migration, Feedback, SSD},\n} \r\n",
        "key": "2877758",
        "pub_year": "2016",
        "text": "Qiang Ling , Lixiang Xu , Jinfeng Yan , Yicheng Zhang , Feng Li, A feedback-based adaptive data migration method for hybrid storage VOD caching systems, Multimedia Tools and Applications, v.75 n.1, p.165-180, January   2016"
    },
    "2878174": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2878174",
        "bib_stats": {
            "cites": 3
        },
        "bibtex": "\r\n@inproceedings{Choi:2015:EEO:2877966.2878174,\n author = {Choi, I. Stephen and Yang, Weiqing and Kee, Yang-Suk},\n title = {Early Experience with Optimizing I/O Performance Using High-performance SSDs for In-memory Cluster Computing},\n booktitle = {Proceedings of the 2015 IEEE International Conference on Big Data (Big Data)},\n series = {BIG DATA '15},\n year = {2015},\n isbn = {978-1-4799-9926-2},\n pages = {1073--1083},\n numpages = {11},\n url = {https://doi.org/10.1109/BigData.2015.7363861},\n doi = {10.1109/BigData.2015.7363861},\n acmid = {2878174},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2878174",
        "pub_year": "2015",
        "text": "I. Stephen Choi , Weiqing Yang , Yang-Suk Kee, Early experience with optimizing I/O performance using high-performance SSDs for in-memory cluster computing, Proceedings of the 2015 IEEE International Conference on Big Data (Big Data), p.1073-1083, October 29-November 01, 2015"
    },
    "2878679": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2878679",
        "bib_stats": {
            "cites": 4
        },
        "key": "2878679",
        "text": "Matthew Poremba , Tao Zhang , Yuan Xie, NVMain 2.0: A User-Friendly Memory Simulator to Model (Non-)Volatile Memory Systems, IEEE Computer Architecture Letters, v.14 n.2, p.140-143, July 2015  \u00a0[doi>"
    },
    "2882910": {
        "abstract": "The volume of metadata needed by a flash translation layer (FTL) is proportional to the storage capacity of a flash device. Ideally, this metadata should reside in the device's integrated RAM to enable fast access. However, as flash devices scale to terabytes, the necessary volume of metadata is exceeding the available integrated RAM. Moreover, recovery time after power failure, which is proportional to the size of the metadata, is becoming impractical. The simplest solution is to persist more metadata in flash. The problem is that updating metadata in flash increases the amount of internal IOs thereby harming performance and device lifetime. In this paper, we identify a key component of the metadata called the Page Validity Bitmap (PVB) as the bottleneck. PVB is used by the garbage-collectors of state-of-the-art FTLs to keep track of which physical pages in the device are invalid. PVB constitutes 95% of the FTL's RAM-resident metadata, and recovering PVB after power fails takes a significant proportion of the overall recovery time. To solve this problem, we propose a page-associative FTL called GeckoFTL, whose central innovation is replacing PVB with a new data structure called Logarithmic Gecko. Logarithmic Gecko is similar to an LSM-tree in that it first logs updates and later reorganizes them to ensure fast and scalable access time. Relative to the baseline of storing PVB in flash, Logarithmic Gecko enables cheaper updates at the cost of slightly more expensive garbage-collection queries. We show that this is a good trade-off because (1) updates are intrinsically more frequent than garbage-collection queries to page validity metadata, and (2) flash writes are more expensive than flash reads. We demonstrate analytically and empirically through simulation that GeckoFTL achieves a 95% reduction in space requirements and at least a 51% reduction in recovery time by storing page validity metadata in flash while keeping the contribution to internal IO overheads 98% lower than the baseline.",
        "acm_key": "2882910",
        "bib_stats": {
            "cites": 3,
            "dl": 542,
            "dl_52": 406,
            "dl_6": 17
        },
        "bibtex": "\r\n@inproceedings{Oh:2016:SIF:2882903.2882910,\n author = {Oh, Gihwan and Seo, Chiyoung and Mayuram, Ravi and Kee, Yang-Suk and Lee, Sang-Won},\n title = {SHARE Interface in Flash Storage for Relational and NoSQL Databases},\n booktitle = {Proceedings of the 2016 International Conference on Management of Data},\n series = {SIGMOD '16},\n year = {2016},\n isbn = {978-1-4503-3531-7},\n location = {San Francisco, California, USA},\n pages = {343--354},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2882903.2882910},\n doi = {10.1145/2882903.2882910},\n acmid = {2882910},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {address remapping, flash storage devices, flash translation layer, share interface, write atomicity},\n} \r\n",
        "key": "2882910",
        "pub_year": "2016",
        "text": "Gihwan Oh , Chiyoung Seo , Ravi Mayuram , Yang-Suk Kee , Sang-Won Lee, SHARE Interface in Flash Storage for Relational and NoSQL Databases, Proceedings of the 2016 International Conference on Management of Data, June 26-July 01, 2016, San Francisco, California, USA"
    },
    "2883597": {
        "abstract": "The uncontrolled use of the cache hierarchy in a multicore processor by real-time tasks may impact their worst-case execution times. Several operating system techniques have been recently proposed to deal with caches in a multiprocessor in order to improve predictability, such as cache partitioning, cache locking, and real-time scheduling. However, the contention caused by the cache coherence protocol and its implication for real-time tasks is still an open problem. In this paper, we present the design and evaluation of a real-time operating system for cache-coherent multicore architectures. The real-time operating system infrastructure includes real-time schedulers, cache partitioning, and cache coherence contention detection through hardware performance counters. We evaluate the real-time operating system in terms of run-time overhead, schedulability of realtime tasks, cache partitioning performance, and hardware performance counters usability. Our results indicate that: (i) a real-time operating system designed from scratch reduces the run-time overhead, and thus improves the realtime schedulability, when compared to a patched operating system; (ii) cache partitioning reduces the contention in the shared cache and provides safe real-time bounds; and (iii) hardware performance counters can detect when real-time tasks interfere with each other at the shared cache level. Scheduling, cache partitioning, and hardware performance counters together are a step-forward to provide real-time bounds in cache-coherent architectures.",
        "acm_key": "2883597",
        "bib_stats": {
            "cites": 1,
            "dl": 52,
            "dl_52": 20,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Debnath:2016:RHT:2883591.2883597,\n author = {Debnath, Biplob and Haghdoost, Alireza and Kadav, Asim and Khatib, Mohammed G. and Ungureanu, Cristian},\n title = {Revisiting Hash Table Design for Phase Change Memory},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {December 2015},\n volume = {49},\n number = {2},\n month = jan,\n year = {2016},\n issn = {0163-5980},\n pages = {18--26},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/2883591.2883597},\n doi = {10.1145/2883591.2883597},\n acmid = {2883597},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2883597",
        "pub_year": "2016",
        "text": "Biplob Debnath , Alireza Haghdoost , Asim Kadav , Mohammed G. Khatib , Cristian Ungureanu, Revisiting Hash Table Design for Phase Change Memory, ACM SIGOPS Operating Systems Review, v.49 n.2, December 2015"
    },
    "2883598": {
        "abstract": "The uncontrolled use of the cache hierarchy in a multicore processor by real-time tasks may impact their worst-case execution times. Several operating system techniques have been recently proposed to deal with caches in a multiprocessor in order to improve predictability, such as cache partitioning, cache locking, and real-time scheduling. However, the contention caused by the cache coherence protocol and its implication for real-time tasks is still an open problem. In this paper, we present the design and evaluation of a real-time operating system for cache-coherent multicore architectures. The real-time operating system infrastructure includes real-time schedulers, cache partitioning, and cache coherence contention detection through hardware performance counters. We evaluate the real-time operating system in terms of run-time overhead, schedulability of realtime tasks, cache partitioning performance, and hardware performance counters usability. Our results indicate that: (i) a real-time operating system designed from scratch reduces the run-time overhead, and thus improves the realtime schedulability, when compared to a patched operating system; (ii) cache partitioning reduces the contention in the shared cache and provides safe real-time bounds; and (iii) hardware performance counters can detect when real-time tasks interfere with each other at the shared cache level. Scheduling, cache partitioning, and hardware performance counters together are a step-forward to provide real-time bounds in cache-coherent architectures.",
        "acm_key": "2883598",
        "bib_stats": {
            "cites": 1,
            "dl": 152,
            "dl_52": 51,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Santana:2016:FSS:2883591.2883598,\n author = {Santana, Ricardo and Rangaswami, Raju and Tarasov, Vasily and Hildebrand, Dean},\n title = {A Fast and Slippery Slope for File Systems},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {December 2015},\n volume = {49},\n number = {2},\n month = jan,\n year = {2016},\n issn = {0163-5980},\n pages = {27--34},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2883591.2883598},\n doi = {10.1145/2883591.2883598},\n acmid = {2883598},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {File systems, high-speed devices},\n} \r\n",
        "key": "2883598",
        "pub_year": "2016",
        "text": "Ricardo Santana , Raju Rangaswami , Vasily Tarasov , Dean Hildebrand, A Fast and Slippery Slope for File Systems, ACM SIGOPS Operating Systems Review, v.49 n.2, December 2015  \u00a0[doi>"
    },
    "2890870": {
        "abstract": "Nowadays we are witnessing a trend with significantly increasing number of networked and computing-capable devices being integrated into everyday environment. This trend is expected to continue. With computing devices available as logic structures, they might use each other's processing capabilities to achieve a given goal. In this paper, the authors propose an architectural solution to perform the processing of tasks using a distributed structure of Internet of Things devices. They also include ZigBee devices that are not connected to the Internet, but participate with the processing swarm using local network. This significantly extends the flexibility and potential of the IoT structure, while being still not a well-researched area. Unlike many high-level realizations for IoT processing, the authors present a realization operating on the communications, computing and near protocol level that achieves energy consumption efficiency. They also include the reconfigurability of IoT devices. The authors' work is suitable to be the base for higher-level realizations, especially for systems with devices operating on battery power. At the same time, the architecture presented in this paper uses minimal centralization, moving maximum responsibilities to regular devices. The proposed realizations are described using linear programming models and their high efficiency is evaluated.",
        "acm_key": "2890870",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Kawata:2016:UDC:2890865.2890870,\n author = {Kawata, Hirotaka and Nakagawa, Gaku and Oikawa, Shuichi},\n title = {Using DRAM As Cache for Non-Volatile Main Memory Swapping},\n journal = {Int. J. Softw. Innov.},\n issue_date = {January 2016},\n volume = {4},\n number = {1},\n month = jan,\n year = {2016},\n issn = {2166-7160},\n pages = {61--71},\n numpages = {11},\n url = {http://dx.doi.org/10.4018/IJSI.2016010105},\n doi = {10.4018/IJSI.2016010105},\n acmid = {2890870},\n publisher = {IGI Global},\n address = {Hershey, PA, USA},\n keywords = {Memory Swapping, Non Volatile Memory, Persistent Memory, Virtual Memory, Virtual Memory System},\n} \r\n",
        "key": "2890870",
        "pub_year": "2016",
        "text": "Hirotaka Kawata , Gaku Nakagawa , Shuichi Oikawa, Using DRAM as Cache for Non-Volatile Main Memory Swapping, International Journal of Software Innovation, v.4 n.1, p.61-71, January 2016"
    },
    "2892639": {
        "abstract": "With the explosive growth in data volume, the I/O bottleneck has become an increasingly daunting challenge for big data analytics. Economic forces, driven by the desire to introduce flash-based Solid-State Drives (SSDs) into the high-end storage market, have resulted in hybrid storage systems in the cloud. However, a single flash-based SSD cannot satisfy the performance, reliability, and capacity requirements of enterprise or HPC storage systems in the cloud. While an array of SSDs organized in a RAID structure, such as RAID5, provides the potential for high storage capacity and bandwidth, reliability and performance problems will likely result from the parity update operations. In this article, we propose a Log Disk Mirroring scheme (LDM) to improve the performance and reliability of SSD-based disk arrays. LDM is a hybrid disk array architecture that consists of several SSDs and two hard disk drives (HDDs). In an LDM array, the two HDDs are mirrored as a write buffer that temporally absorbs the small write requests. The small and random write data are written on the mirroring buffer by using the logging technique that sequentially appends new data. The small write data are merged and destaged to the SSD-based disk array during the system idle periods. Our prototype implementation of the LDM array and the performance evaluations show that the LDM array significantly outperforms the pure SSD-based disk arrays by a factor of 20.4 on average, and outperforms HPDA by a factor of 5.0 on average. The reliability analysis shows that the MTTDL of the LDM array is 2.7 times and 1.7 times better than that of pure SSD-based disk arrays and HPDA disk arrays.",
        "acm_key": "2892639",
        "bib_stats": {
            "cites": 0,
            "dl": 214,
            "dl_52": 173,
            "dl_6": 6
        },
        "bibtex": "\r\n@article{Wu:2016:LLD:2940403.2892639,\n author = {Wu, Suzhen and Mao, Bo and Chen, Xiaolan and Jiang, Hong},\n title = {LDM: Log Disk Mirroring with Improved Performance and Reliability for SSD-Based Disk Arrays},\n journal = {Trans. Storage},\n issue_date = {August 2016},\n volume = {12},\n number = {4},\n month = may,\n year = {2016},\n issn = {1553-3077},\n pages = {22:1--22:21},\n articleno = {22},\n numpages = {21},\n url = {http://doi.acm.org/10.1145/2892639},\n doi = {10.1145/2892639},\n acmid = {2892639},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {SSD-based disk arrays, disk buffer, log technique, performance evaluation, reliability analysis},\n} \r\n",
        "key": "2892639",
        "pub_year": "2016",
        "text": "Suzhen Wu , Bo Mao , Xiaolan Chen , Hong Jiang, LDM: Log Disk Mirroring with Improved Performance and Reliability for SSD-Based Disk Arrays, ACM Transactions on Storage (TOS), v.12 n.4, p.1-21, June 2016"
    },
    "2893186": {
        "abstract": "With dramatic growth of data and rapid enhancement of computing powers, data accesses become the bottleneck restricting overall performance of a computer system. Emerging phase-change memory (PCM) is byte-addressable like DRAM, persistent like hard disks and Flash SSD, and about four orders of magnitude faster than hard disks or Flash SSDs for typical file system I/Os. The maturity of PCM from research to production provides a new opportunity for improving the I/O performance of a system. However, PCM also has some weaknesses, for example, long write latency, limited write endurance, and high active energy. Existing processor cache systems, main memory systems, and online storage systems are unable to leverage the advantages of PCM, and/or to mitigate PCM\u2019s drawbacks. The reason behind this incompetence is that they are designed and optimized for SRAM, DRAM memory, and hard drives, respectively, instead of PCM memory. There have been some efforts concentrating on rethinking computer architectures and software systems for PCM. This article presents a detailed survey and review of the areas of computer architecture and software systems that are oriented to PCM devices. First, we identify key technical challenges that need to be addressed before this memory technology can be leveraged, in the form of processor cache, main memory, and online storage, to build high-performance computer systems. Second, we examine various designs of computer architectures and software systems that are PCM aware. Finally, we obtain several helpful observations and propose a few suggestions on how to leverage PCM to optimize the performance of a computer system.",
        "acm_key": "2893186",
        "bib_stats": {
            "cites": 0,
            "dl": 283,
            "dl_52": 192,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Wu:2016:RCA:2856147.2893186,\n author = {Wu, Chengwen and Zhang, Guangyan and Li, Keqin},\n title = {Rethinking Computer Architectures and Software Systems for Phase-Change Memory},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {July 2016},\n volume = {12},\n number = {4},\n month = may,\n year = {2016},\n issn = {1550-4832},\n pages = {33:1--33:40},\n articleno = {33},\n numpages = {40},\n url = {http://doi.acm.org/10.1145/2893186},\n doi = {10.1145/2893186},\n acmid = {2893186},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Computer architecture, I/O performance, energy consumption, phase-change memory, system software, write lifetime},\n} \r\n",
        "key": "2893186",
        "pub_year": "2016",
        "text": "Chengwen Wu , Guangyan Zhang , Keqin Li, Rethinking Computer Architectures and Software Systems for Phase-Change Memory, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.12 n.4, June 2016"
    },
    "2897882": {
        "abstract": "Malicious domains are key components to a variety of cyber attacks. Several recent techniques are proposed to identify malicious domains through analysis of DNS data. The general approach is to build classifiers based on DNS-related local domain features. One potential problem is that many local features, e.g., domain name patterns and temporal patterns, tend to be not robust. Attackers could easily alter these features to evade detection without affecting much their attack capabilities. In this paper, we take a complementary approach. Instead of focusing on local features, we propose to discover and analyze global associations among domains. The key challenges are (1) to build meaningful associations among domains; and (2) to use these associations to reason about the potential maliciousness of domains. For the first challenge, we take advantage of the modus operandi of attackers. To avoid detection, malicious domains exhibit dynamic behavior by, for example, frequently changing the malicious domain-IP resolutions and creating new domains. This makes it very likely for attackers to reuse resources. It is indeed commonly observed that over a period of time multiple malicious domains are hosted on the same IPs and multiple IPs host the same malicious domains, which creates intrinsic association among them. For the second challenge, we develop a graph-based inference technique over associated domains. Our approach is based on the intuition that a domain having strong associations with known malicious domains is likely to be malicious. Carefully established associations enable the discovery of a large set of new malicious domains using a very small set of previously known malicious ones. Our experiments over a public passive DNS database show that the proposed technique can achieve high true positive rates (over 95%) while maintaining low false positive rates (less than 0.5%). Further, even with a small set of known malicious domains (a couple of hundreds), our technique can discover a large set of potential malicious domains (in the scale of up to tens of thousands).",
        "acm_key": "2897882",
        "bib_stats": {
            "cites": 2,
            "dl": 137,
            "dl_52": 92,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Jia:2016:NAU:2897845.2897882,\n author = {Jia, Shijie and Xia, Luning and Chen, Bo and Liu, Peng},\n title = {NFPS: Adding Undetectable Secure Deletion to Flash Translation Layer},\n booktitle = {Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security},\n series = {ASIA CCS '16},\n year = {2016},\n isbn = {978-1-4503-4233-9},\n location = {Xi'an, China},\n pages = {305--315},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2897845.2897882},\n doi = {10.1145/2897845.2897882},\n acmid = {2897882},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash, flash translation layer, secure deletion},\n} \r\n",
        "key": "2897882",
        "pub_year": "2016",
        "text": "Shijie Jia , Luning Xia , Bo Chen , Peng Liu, NFPS: Adding Undetectable Secure Deletion to Flash Translation Layer, Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security, May 30-June 03, 2016, Xi'an, China"
    },
    "2897979": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2897979",
        "bib_stats": {
            "cites": 0,
            "dl": 104,
            "dl_52": 73,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Wang:2016:MVM:2897937.2897979,\n author = {Wang, Shaodi and Lee, Hochul and Grezes, Cecile and Khalili, Pedram and Wang, Kang L. and Gupta, Puneet},\n title = {MTJ Variation Monitor-assisted Adaptive MRAM Write},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {169:1--169:6},\n articleno = {169},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2897979},\n doi = {10.1145/2897937.2897979},\n acmid = {2897979},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MTJ, MeRAM, STT-RAM, adaptive write, process variation, temperature variation, thermal monitor},\n} \r\n",
        "key": "2897979",
        "pub_year": "2016",
        "text": "Shaodi Wang , Hochul Lee , Cecile Grezes , Pedram Khalili , Kang L. Wang , Puneet Gupta, MTJ variation monitor-assisted adaptive MRAM write, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2897987": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2897987",
        "bib_stats": {
            "cites": 2,
            "dl": 117,
            "dl_52": 91,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:AAO:2897937.2897987,\n author = {Chen, Xunchao and Khoshavi, Navid and Zhou, Jian and Huang, Dan and DeMara, Ronald F. and Wang, Jun and Wen, Wujie and Chen, Yiran},\n title = {AOS: Adaptive Overwrite Scheme for Energy-efficient MLC STT-RAM Cache},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {170:1--170:6},\n articleno = {170},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2897987},\n doi = {10.1145/2897937.2897987},\n acmid = {2897987},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MLC, STT-RAM, prediction, write disturbance},\n} \r\n",
        "key": "2897987",
        "pub_year": "2016",
        "text": "Xunchao Chen , Navid Khoshavi , Jian Zhou , Dan Huang , Ronald F. DeMara , Jun Wang , Wujie Wen , Yiran Chen, AOS: adaptive overwrite scheme for energy-efficient MLC STT-RAM cache, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2897989": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2897989",
        "bib_stats": {
            "cites": 2,
            "dl": 157,
            "dl_52": 92,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:AES:2897937.2897989,\n author = {Zhang, Hang and Chen, Xuhao and Xiao, Nong and Liu, Fang},\n title = {Architecting Energy-efficient STT-RAM Based Register File on GPGPUs via Delta Compression},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {119:1--119:6},\n articleno = {119},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2897989},\n doi = {10.1145/2897937.2897989},\n acmid = {2897989},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2897989",
        "pub_year": "2016",
        "text": "Hang Zhang , Xuhao Chen , Nong Xiao , Fang Liu, Architecting energy-efficient STT-RAM based register file on GPGPUs via delta compression, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2897993": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2897993",
        "bib_stats": {
            "cites": 0,
            "dl": 95,
            "dl_52": 65,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Asadinia:2016:BSE:2897937.2897993,\n author = {Asadinia, Marjan and Jalili, Majid and Sarbazi-Azad, Hamid},\n title = {BLESS: A Simple and Efficient Scheme for Prolonging PCM Lifetime},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {93:1--93:6},\n articleno = {93},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2897993},\n doi = {10.1145/2897937.2897993},\n acmid = {2897993},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {fault tolerant, hard error, lifetime, phase change memory},\n} \r\n",
        "key": "2897993",
        "pub_year": "2016",
        "text": "Marjan Asadinia , Majid Jalili , Hamid Sarbazi-Azad, BLESS: a simple and efficient scheme for prolonging PCM lifetime, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898018": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898018",
        "bib_stats": {
            "cites": 1,
            "dl": 178,
            "dl_52": 127,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:ESE:2897937.2898018,\n author = {Chen, Tseng-Yi and Chang, Yuan-Hao and Ho, Chien-Chung and Chen, Shuo-Han},\n title = {Enabling Sub-blocks Erase Management to Boost the Performance of 3D NAND Flash Memory},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {92:1--92:6},\n articleno = {92},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898018},\n doi = {10.1145/2897937.2898018},\n acmid = {2898018},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, NAND flash, garbage collection, sub-block erased},\n} \r\n",
        "key": "2898018",
        "pub_year": "2016",
        "text": "Tseng-Yi Chen , Yuan-Hao Chang , Chien-Chung Ho , Shuo-Han Chen, Enabling sub-blocks erase management to boost the performance of 3D NAND flash memory, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2898024": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898024",
        "bib_stats": {
            "cites": 0,
            "dl": 85,
            "dl_52": 54,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Poremba:2016:FTP:2897937.2898024,\n author = {Poremba, Matthew and Zhang, Tao and Xie, Yuan},\n title = {Fine-granularity Tile-level Parallelism in Non-volatile Memory Architecture with Two-dimensional Bank Subdivision},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {168:1--168:6},\n articleno = {168},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898024},\n doi = {10.1145/2897937.2898024},\n acmid = {2898024},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898024",
        "pub_year": "2016",
        "text": "Matthew Poremba , Tao Zhang , Yuan Xie, Fine-granularity tile-level parallelism in non-volatile memory architecture with two-dimensional bank subdivision, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898032": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898032",
        "bib_stats": {
            "cites": 1,
            "dl": 151,
            "dl_52": 113,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Park:2016:IPL:2897937.2898032,\n author = {Park, Jisung and Jeong, Jaeyong and Lee, Sungjin and Song, Youngsun and Kim, Jihong},\n title = {Improving Performance and Lifetime of NAND Storage Systems Using Relaxed Program Sequence},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {63:1--63:6},\n articleno = {63},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898032},\n doi = {10.1145/2897937.2898032},\n acmid = {2898032},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898032",
        "pub_year": "2016",
        "text": "Jisung Park , Jaeyong Jeong , Sungjin Lee , Youngsun Song , Jihong Kim, Improving performance and lifetime of NAND storage systems using relaxed program sequence, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2898050": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898050",
        "bib_stats": {
            "cites": 1,
            "dl": 254,
            "dl_52": 189,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{George:2016:NMD:2897937.2898050,\n author = {George, Sumitha and Ma, Kaisheng and Aziz, Ahmedullah and Li, Xueqing and Khan, Asif and Salahuddin, Sayeef and Chang, Meng-Fan and Datta, Suman and Sampson, John and Gupta, Sumeet and Narayanan, Vijaykrishnan},\n title = {Nonvolatile Memory Design Based on Ferroelectric FETs},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {118:1--118:6},\n articleno = {118},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898050},\n doi = {10.1145/2897937.2898050},\n acmid = {2898050},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NCFET, ferroelectric FET (FEFET), hysteresis, non-volatility, nonvolatile memory (NVM), nonvolatile processor (NVP)},\n} \r\n",
        "key": "2898050",
        "pub_year": "2016",
        "text": "Sumitha George , Kaisheng Ma , Ahmedullah Aziz , Xueqing Li , Asif Khan , Sayeef Salahuddin , Meng-Fan Chang , Suman Datta , John Sampson , Sumeet Gupta , Vijaykrishnan Narayanan, Nonvolatile memory design based on ferroelectric FETs, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898053": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898053",
        "bib_stats": {
            "cites": 0,
            "dl": 155,
            "dl_52": 106,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Eken:2016:NSI:2897937.2898053,\n author = {Eken, Enes and Song, Linghao and Bayram, Ismail and Xu, Cong and Wen, Wujie and Xie, Yuan and Chen, Yiran},\n title = {NVSim-VXs: An Improved NVSim for Variation Aware STT-RAM Simulation},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {70:1--70:6},\n articleno = {70},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898053},\n doi = {10.1145/2897937.2898053},\n acmid = {2898053},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898053",
        "pub_year": "2016",
        "text": "Enes Eken , Linghao Song , Ismail Bayram , Cong Xu , Wujie Wen , Yuan Xie , Yiran Chen, NVSim-VXs<sup>s</sup>: an improved NVSim for variation aware STT-RAM simulation, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas&#13;\n\t\t\t\t\t\t: an improved NVSim for variation aware STT-RAM simulation, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898058": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898058",
        "bib_stats": {
            "cites": 0,
            "dl": 106,
            "dl_52": 68,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Kang:2016:PPS:2897937.2898058,\n author = {Kang, Wang and Pang, Tingting and Wu, Bi and Lv, Weifeng and Zhang, Youguang and Sun, Guanyu and Zhao, Weisheng},\n title = {PDS: Pseudo-differential Sensing Scheme for STT-MRAM},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {120:1--120:6},\n articleno = {120},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898058},\n doi = {10.1145/2897937.2898058},\n acmid = {2898058},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-MRAM, asymmetric sensing, error detection and correction, reliability, write power},\n} \r\n",
        "key": "2898058",
        "pub_year": "2016",
        "text": "Wang Kang , Tingting Pang , Bi Wu , Weifeng Lv , Youguang Zhang , Guanyu Sun , Weisheng Zhao, PDS: pseudo-differential sensing scheme for STT-MRAM, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898059": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898059",
        "bib_stats": {
            "cites": 1,
            "dl": 130,
            "dl_52": 86,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Li:2016:PTS:2897937.2898059,\n author = {Li, Hehe and Liu, Yongpan and Fu, Chenchen and Xue, Chun Jason and Xiang, Donglai and Yue, Jinshan and Li, Jinyang and Zhang, Daming and Hu, Jingtong and Yang, Huazhong},\n title = {Performance-aware Task Scheduling for Energy Harvesting Nonvolatile Processors Considering Power Switching Overhead},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {156:1--156:6},\n articleno = {156},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898059},\n doi = {10.1145/2897937.2898059},\n acmid = {2898059},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy harvesting, nonvolatile processors, power switching overhead, scheduling},\n} \r\n",
        "key": "2898059",
        "pub_year": "2016",
        "text": "Hehe Li , Yongpan Liu , Chenchen Fu , Chun Jason Xue , Donglai Xiang , Jinshan Yue , Jinyang Li , Daming Zhang , Jingtong Hu , Huazhong Yang, Performance-aware task scheduling for energy harvesting nonvolatile processors considering power switching overhead, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898064": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898064",
        "bib_stats": {
            "cites": 4,
            "dl": 89,
            "dl_52": 70,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Li:2016:PPA:2897937.2898064,\n author = {Li, Shuangchen and Xu, Cong and Zou, Qiaosha and Zhao, Jishen and Lu, Yu and Xie, Yuan},\n title = {Pinatubo: A Processing-in-memory Architecture for Bulk Bitwise Operations in Emerging Non-volatile Memories},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {173:1--173:6},\n articleno = {173},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898064},\n doi = {10.1145/2897937.2898064},\n acmid = {2898064},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898064",
        "pub_year": "2016",
        "text": "Shuangchen Li , Cong Xu , Qiaosha Zou , Jishen Zhao , Yu Lu , Yuan Xie, Pinatubo: a processing-in-memory architecture for bulk bitwise operations in emerging non-volatile memories, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898087": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898087",
        "bib_stats": {
            "cites": 1,
            "dl": 189,
            "dl_52": 140,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Swami:2016:SSE:2897937.2898087,\n author = {Swami, Shivam and Rakshit, Joydeep and Mohanram, Kartik},\n title = {SECRET: Smartly EnCRypted Energy Efficient Non-volatile Memories},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {166:1--166:6},\n articleno = {166},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898087},\n doi = {10.1145/2897937.2898087},\n acmid = {2898087},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {encryption, non-volatile memories, security},\n} \r\n",
        "key": "2898087",
        "pub_year": "2016",
        "text": "Shivam Swami , Joydeep Rakshit , Kartik Mohanram, SECRET: smartly EnCRypted energy efficient non-volatile memories, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2898099": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898099",
        "bib_stats": {
            "cites": 2,
            "dl": 116,
            "dl_52": 85,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Winograd:2016:HSD:2897937.2898099,\n author = {Winograd, Theodore and Salmani, Hassan and Mahmoodi, Hamid and Gaj, Kris and Homayoun, Houman},\n title = {Hybrid STT-CMOS Designs for Reverse-engineering Prevention},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {88:1--88:6},\n articleno = {88},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898099},\n doi = {10.1145/2897937.2898099},\n acmid = {2898099},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898099",
        "pub_year": "2016",
        "text": "Theodore Winograd , Hassan Salmani , Hamid Mahmoodi , Kris Gaj , Houman Homayoun, Hybrid STT-CMOS designs for reverse-engineering prevention, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898106": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898106",
        "bib_stats": {
            "cites": 1,
            "dl": 138,
            "dl_52": 94,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Luo:2016:TST:2897937.2898106,\n author = {Luo, Huizhang and Hu, Jingtong and Shi, Liang and Xue, Chun Jason and Zhuge, Qingfeng},\n title = {Two-step State Transition Minimization for Lifetime and Performance Improvement on MLC STT-RAM},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {171:1--171:6},\n articleno = {171},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898106},\n doi = {10.1145/2897937.2898106},\n acmid = {2898106},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898106",
        "pub_year": "2016",
        "text": "Huizhang Luo , Jingtong Hu , Liang Shi , Chun Jason Xue , Qingfeng Zhuge, Two-step state transition minimization for lifetime and performance improvement on MLC STT-RAM, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2898110": {
        "abstract": "Neuromorphic algorithms are being increasingly deployed across the entire computing spectrum from data centers to mobile and wearable devices to solve problems involving recognition, analytics, search and inference. For example, large-scale artificial neural networks (popularly called deep learning) now represent the state-of-the art in a wide and ever-increasing range of video/image/audio/text recognition problems. However, the growth in data sets and network complexities have led to deep learning becoming one of the most challenging workloads across the computing spectrum. We posit that approximate computing can play a key role in the quest for energy-efficient neuromorphic systems. We show how the principles of approximate computing can be applied to the design of neuromorphic systems at various layers of the computing stack. At the algorithm level, we present techniques to significantly scale down the computational requirements of a neural network with minimal impact on its accuracy. At the circuit level, we show how approximate logic and memory can be used to implement neurons and synapses in an energy-efficient manner, while still meeting accuracy requirements. A fundamental limitation to the efficiency of neuromorphic computing in traditional implementations (software and custom hardware alike) is the mismatch between neuromorphic algorithms and the underlying computing models such as von Neumann architecture and Boolean logic. To overcome this limitation, we describe how emerging spintronic devices can offer highly efficient, approximate realization of the building blocks of neuromorphic computing systems.",
        "acm_key": "2898110",
        "bib_stats": {
            "cites": 0,
            "dl": 194,
            "dl_52": 119,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:WAS:2897937.2898110,\n author = {Zhang, Deshan and Ju, Lei and Zhao, Mengying and Gao, Xiang and Jia, Zhiping},\n title = {Write-back Aware Shared Last-level Cache Management for Hybrid Main Memory},\n booktitle = {Proceedings of the 53rd Annual Design Automation Conference},\n series = {DAC '16},\n year = {2016},\n isbn = {978-1-4503-4236-0},\n location = {Austin, Texas},\n pages = {172:1--172:6},\n articleno = {172},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2897937.2898110},\n doi = {10.1145/2897937.2898110},\n acmid = {2898110},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2898110",
        "pub_year": "2016",
        "text": "Deshan Zhang , Lei Ju , Mengying Zhao , Xiang Gao , Zhiping Jia, Write-back aware shared last-level cache management for hybrid main memory, Proceedings of the 53rd Annual Design Automation Conference, p.1-6, June 05-09, 2016, Austin, Texas"
    },
    "2898502": {
        "abstract": "Erasure coding has become an integral part of the storage infrastructure in data-centers and cloud backends--since it provides significantly higher fault tolerance for substantially lower storage overhead compared to a naive approach like n-way replication. Fault tolerance refers to the ability to achieve very high availability despite (temporary) failures, but for long term data durability, the redundancy provided by erasure coding needs to be replenished as storage nodes fail or are retired. Traditional erasure codes are not easily amenable to repairs, and their repair process is usually both expensive and slow. Consequently, in recent years, numerous novel codes tailor-made for distributed storage have been proposed to optimize the repair process. Broadly, most of these codes belong to either of the two following families: network coding inspired regenerating codes that aim at minimizing the per repair traffic, and locally repairable codes (LRC) which minimize the number of nodes contacted per repair (which in turn leads to the reduction of repair traffic and latency). Existing studies of these codes however restrict themselves to the repair of individual data objects in isolation. They ignore many practical issues that a real system storing multiple objects needs to take into account. Our goal is to explore a subset of such issues, particularly pertaining to the scenario where multiple objects are stored in the system. We use a simulation based approach, which models the network bottlenecks at the edges of a distributed storage system, and the nodes' load and (un)availability. Specifically, we abstract the key features of both regenerating and LRC, and examine the effect of data placement and the corresponding de/correlation of failures, and the competition for limited network resources when multiple objects need to be repaired simultaneously by exploring the interplay of code parameters and trade-offs of bandwidth usage and speed of repairs.",
        "acm_key": "2898502",
        "bib_stats": {
            "cites": 4
        },
        "bibtex": "\r\n@article{Wang:2016:EAS:2898489.2898502,\n author = {Wang, Guohui and Guan, Yong and Wang, Yi and Shao, Zili},\n title = {Energy-aware Assignment and Scheduling for Hybrid Main Memory in Embedded Systems},\n journal = {Computing},\n issue_date = {March     2016},\n volume = {98},\n number = {3},\n month = mar,\n year = {2016},\n issn = {0010-485X},\n pages = {279--301},\n numpages = {23},\n url = {http://dx.doi.org/10.1007/s00607-015-0464-7},\n doi = {10.1007/s00607-015-0464-7},\n acmid = {2898502},\n publisher = {Springer-Verlag New York, Inc.},\n address = {New York, NY, USA},\n keywords = {68m07 Mathematical problems of computer architecture, Embedded systems, Energy consumption, Hybrid memory architecture, PCM (phase change memory)},\n} \r\n",
        "key": "2898502",
        "pub_year": "2016",
        "text": "Guohui Wang , Yong Guan , Yi Wang , Zili Shao, Energy-aware assignment and scheduling for hybrid main memory in embedded systems, Computing, v.98 n.3, p.279-301, March     2016"
    },
    "2898996": {
        "abstract": "Complex data queries, because of their need for random accesses, have proven to be slow unless all the data can be accommodated in DRAM. There are many domains, such as genomics, geological data, and daily Twitter feeds, where the datasets of interest are 5TB to 20TB. For such a dataset, one would need a cluster with 100 servers, each with 128GB to 256GB of DRAM, to accommodate all the data in DRAM. On the other hand, such datasets could be stored easily in the flash memory of a rack-sized cluster. Flash storage has much better random access performance than hard disks, which makes it desirable for analytics workloads. However, currently available off-the-shelf flash storage packaged as SSDs does not make effective use of flash storage because it incurs a great amount of additional overhead during flash device management and network access. In this article, we present BlueDBM, a new system architecture that has flash-based storage with in-store processing capability and a low-latency high-throughput intercontroller network between storage devices. We show that BlueDBM outperforms a flash-based system without these features by a factor of 10 for some important applications. While the performance of a DRAM-centric system falls sharply even if only 5&percnt; to 10&percnt; of the references are to secondary storage, this sharp performance degradation is not an issue in BlueDBM. BlueDBM presents an attractive point in the cost/performance tradeoff for Big Data analytics.",
        "acm_key": "2898996",
        "bib_stats": {
            "cites": 0,
            "dl": 530,
            "dl_52": 412,
            "dl_6": 27
        },
        "bibtex": "\r\n@article{Jun:2016:BDF:2966277.2898996,\n author = {Jun, Sang-Woo and Liu, Ming and Lee, Sungjin and Hicks, Jamey and Ankcorn, John and King, Myron and Xu, Shuotao and Arvind},\n title = {BlueDBM: Distributed Flash Storage for Big Data Analytics},\n journal = {ACM Trans. Comput. Syst.},\n issue_date = {September 2016},\n volume = {34},\n number = {3},\n month = jun,\n year = {2016},\n issn = {0734-2071},\n pages = {7:1--7:31},\n articleno = {7},\n numpages = {31},\n url = {http://doi.acm.org/10.1145/2898996},\n doi = {10.1145/2898996},\n acmid = {2898996},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Wireless sensor networks, media access control, multichannel, radio interference, time synchronization},\n} \r\n",
        "key": "2898996",
        "pub_year": "2016",
        "text": "Sang-Woo Jun , Ming Liu , Sungjin Lee , Jamey Hicks , John Ankcorn , Myron King , Shuotao Xu , Arvind, BlueDBM: Distributed Flash Storage for Big Data Analytics, ACM Transactions on Computer Systems (TOCS), v.34 n.3, p.1-31, June 2016"
    },
    "2899048": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2899048",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{2016:PAM:2899036.2899048,\n title = {On the Power of Asymmetry and Memory in Flash-based SSD Garbage Collection},\n journal = {Perform. Eval.},\n issue_date = {March 2016},\n volume = {97},\n number = {C},\n month = mar,\n year = {2016},\n issn = {0166-5316},\n pages = {1--15},\n numpages = {15},\n url = {http://dx.doi.org/10.1016/j.peva.2015.11.002},\n doi = {10.1016/j.peva.2015.11.002},\n acmid = {2899048},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\nkey = {{$\\!\\!$}} ,\n} \r\n",
        "key": "2899048",
        "pub_year": "2016",
        "text": "On the power of asymmetry and memory in flash-based SSD garbage collection, Performance Evaluation, v.97 n.C, p.1-15, March 2016"
    },
    "2899708": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2899708",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Wei:2016:PWS:2899533.2899708,\n author = {Wei, Debao and Deng, Libao and Zhang, Peng and Qiao, Liyan and Peng, Xiyuan},\n title = {A Page-granularity Wear-leveling (PGWL) Strategy for NAND Flash Memory-based Sink Nodes in Wireless Sensor Networks},\n journal = {J. Netw. Comput. Appl.},\n issue_date = {March 2016},\n volume = {63},\n number = {C},\n month = mar,\n year = {2016},\n issn = {1084-8045},\n pages = {125--139},\n numpages = {15},\n url = {http://dx.doi.org/10.1016/j.jnca.2015.12.010},\n doi = {10.1016/j.jnca.2015.12.010},\n acmid = {2899708},\n publisher = {Academic Press Ltd.},\n address = {London, UK, UK},\n keywords = {Bit error rate prediction, Flash memory, Massive storage management, Page-granularity wear leveling, Sink nodes, Wireless sensor networks},\n} \r\n",
        "key": "2899708",
        "pub_year": "2016",
        "text": "Debao Wei , Libao Deng , Peng Zhang , Liyan Qiao , Xiyuan Peng, A page-granularity wear-leveling (PGWL) strategy for NAND flash memory-based sink nodes in wireless sensor networks, Journal of Network and Computer Applications, v.63 n.C, p.125-139, March 2016"
    },
    "2901324": {
        "abstract": "Machine learning (ML) algorithms are commonly applied to big data, using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters --- a strategy known as data parallelism. An alternative and complimentary strategy, model parallelism, partitions the model parameters for non-shared parallel access and updates, and may periodically repartition the parameters to facilitate communication. Model parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallelism (SchMP), a programming approach that improves ML algorithm convergence speed by efficiently scheduling parameter updates, taking into account parameter dependencies and uneven convergence. To support SchMP at scale, we develop a distributed framework STRADS which optimizes the throughput of SchMP programs, and benchmark four common ML applications written as SchMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations: for example, SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.",
        "acm_key": "2901324",
        "bib_stats": {
            "cites": 4,
            "dl": 873,
            "dl_52": 461,
            "dl_6": 32
        },
        "bibtex": "\r\n@inproceedings{Ou:2016:HPF:2901318.2901324,\n author = {Ou, Jiaxin and Shu, Jiwu and Lu, Youyou},\n title = {A High Performance File System for Non-volatile Main Memory},\n booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},\n series = {EuroSys '16},\n year = {2016},\n isbn = {978-1-4503-4240-7},\n location = {London, United Kingdom},\n pages = {12:1--12:16},\n articleno = {12},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2901318.2901324},\n doi = {10.1145/2901318.2901324},\n acmid = {2901324},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2901324",
        "pub_year": "2016",
        "text": "Jiaxin Ou , Jiwu Shu , Youyou Lu, A high performance file system for non-volatile main memory, Proceedings of the Eleventh European Conference on Computer Systems, April 18-21, 2016, London, United Kingdom  \u00a0[doi>"
    },
    "2901325": {
        "abstract": "Machine learning (ML) algorithms are commonly applied to big data, using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters --- a strategy known as data parallelism. An alternative and complimentary strategy, model parallelism, partitions the model parameters for non-shared parallel access and updates, and may periodically repartition the parameters to facilitate communication. Model parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallelism (SchMP), a programming approach that improves ML algorithm convergence speed by efficiently scheduling parameter updates, taking into account parameter dependencies and uneven convergence. To support SchMP at scale, we develop a distributed framework STRADS which optimizes the throughput of SchMP programs, and benchmark four common ML applications written as SchMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations: for example, SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.",
        "acm_key": "2901325",
        "bib_stats": {
            "cites": 7,
            "dl": 878,
            "dl_52": 495,
            "dl_6": 46
        },
        "bibtex": "\r\n@inproceedings{Kannan:2016:PPV:2901318.2901325,\n author = {Kannan, Sudarsun and Gavrilovska, Ada and Schwan, Karsten},\n title = {pVM: Persistent Virtual Memory for Efficient Capacity Scaling and Object Storage},\n booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},\n series = {EuroSys '16},\n year = {2016},\n isbn = {978-1-4503-4240-7},\n location = {London, United Kingdom},\n pages = {13:1--13:16},\n articleno = {13},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2901318.2901325},\n doi = {10.1145/2901318.2901325},\n acmid = {2901325},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2901325",
        "pub_year": "2016",
        "text": "Sudarsun Kannan , Ada Gavrilovska , Karsten Schwan, pVM: persistent virtual memory for efficient capacity scaling and object storage, Proceedings of the Eleventh European Conference on Computer Systems, April 18-21, 2016, London, United Kingdom"
    },
    "2901337": {
        "abstract": "Machine learning (ML) algorithms are commonly applied to big data, using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters --- a strategy known as data parallelism. An alternative and complimentary strategy, model parallelism, partitions the model parameters for non-shared parallel access and updates, and may periodically repartition the parameters to facilitate communication. Model parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallelism (SchMP), a programming approach that improves ML algorithm convergence speed by efficiently scheduling parameter updates, taking into account parameter dependencies and uneven convergence. To support SchMP at scale, we develop a distributed framework STRADS which optimizes the throughput of SchMP programs, and benchmark four common ML applications written as SchMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations: for example, SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.",
        "acm_key": "2901337",
        "bib_stats": {
            "cites": 4,
            "dl": 614,
            "dl_52": 231,
            "dl_6": 26
        },
        "bibtex": "\r\n@inproceedings{Klimovic:2016:FSD:2901318.2901337,\n author = {Klimovic, Ana and Kozyrakis, Christos and Thereska, Eno and John, Binu and Kumar, Sanjeev},\n title = {Flash Storage Disaggregation},\n booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},\n series = {EuroSys '16},\n year = {2016},\n isbn = {978-1-4503-4240-7},\n location = {London, United Kingdom},\n pages = {29:1--29:15},\n articleno = {29},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2901318.2901337},\n doi = {10.1145/2901318.2901337},\n acmid = {2901337},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenter, flash, network storage},\n} \r\n",
        "key": "2901337",
        "pub_year": "2016",
        "text": "Ana Klimovic , Christos Kozyrakis , Eno Thereska , Binu John , Sanjeev Kumar, Flash storage disaggregation, Proceedings of the Eleventh European Conference on Computer Systems, April 18-21, 2016, London, United Kingdom"
    },
    "2901344": {
        "abstract": "Machine learning (ML) algorithms are commonly applied to big data, using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters --- a strategy known as data parallelism. An alternative and complimentary strategy, model parallelism, partitions the model parameters for non-shared parallel access and updates, and may periodically repartition the parameters to facilitate communication. Model parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallelism (SchMP), a programming approach that improves ML algorithm convergence speed by efficiently scheduling parameter updates, taking into account parameter dependencies and uneven convergence. To support SchMP at scale, we develop a distributed framework STRADS which optimizes the throughput of SchMP programs, and benchmark four common ML applications written as SchMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations: for example, SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.",
        "acm_key": "2901344",
        "bib_stats": {
            "cites": 7,
            "dl": 937,
            "dl_52": 539,
            "dl_6": 38
        },
        "bibtex": "\r\n@inproceedings{Dulloor:2016:DTH:2901318.2901344,\n author = {Dulloor, Subramanya R. and Roy, Amitabha and Zhao, Zheguang and Sundaram, Narayanan and Satish, Nadathur and Sankaran, Rajesh and Jackson, Jeff and Schwan, Karsten},\n title = {Data Tiering in Heterogeneous Memory Systems},\n booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},\n series = {EuroSys '16},\n year = {2016},\n isbn = {978-1-4503-4240-7},\n location = {London, United Kingdom},\n pages = {15:1--15:16},\n articleno = {15},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2901318.2901344},\n doi = {10.1145/2901318.2901344},\n acmid = {2901344},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2901344",
        "pub_year": "2016",
        "text": "Subramanya R. Dulloor , Amitabha Roy , Zheguang Zhao , Narayanan Sundaram , Nadathur Satish , Rajesh Sankaran , Jeff Jackson , Karsten Schwan, Data tiering in heterogeneous memory systems, Proceedings of the Eleventh European Conference on Computer Systems, April 18-21, 2016, London, United Kingdom  \u00a0[doi>"
    },
    "2901489": {
        "abstract": "We study the value of data privacy in a game-theoretic model of trading private data, where a data collector purchases private data from strategic data subjects (individuals) through an incentive mechanism. The private data of each individual represents her knowledge about an underlying state, which is the information that the data collector desires to learn. Different from most of the existing work on privacy-aware surveys, our model does not assume the data collector to be trustworthy. Then, an individual takes full control of its own data privacy and reports only a privacy-preserving version of her data. In this paper, the value of \u03b5 units of privacy is measured by the minimum payment of all nonnegative payment mechanisms, under which an individual's best response at a Nash equilibrium is to report the data with a privacy level of \u03b5. The higher \u03b5 is, the less private the reported data is. We derive lower and upper bounds on the value of privacy which are asymptotically tight as the number of data subjects becomes large. Specifically, the lower bound assures that it is impossible to use less amount of payment to buy \u03b5 units of privacy, and the upper bound is given by an achievable payment mechanism that we designed. Based on these fundamental limits, we further derive lower and upper bounds on the minimum total payment for the data collector to achieve a given learning accuracy target, and show that the total payment of the designed mechanism is at most one individual's payment away from the minimum.",
        "acm_key": "2901489",
        "bib_stats": {
            "cites": 2,
            "dl": 207,
            "dl_52": 98,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Narayanan:2016:SFD:2964791.2901489,\n author = {Narayanan, Iyswarya and Wang, Di and Jeon, Myeongjae and Sharma, Bikash and Caulfield, Laura and Sivasubramaniam, Anand and Cutler, Ben and Liu, Jie and Khessib, Badriddine and Vaid, Kushagra},\n title = {SSD Failures in Datacenters: What, When and Why?},\n journal = {SIGMETRICS Perform. Eval. Rev.},\n issue_date = {June 2016},\n volume = {44},\n number = {1},\n month = jun,\n year = {2016},\n issn = {0163-5999},\n pages = {407--408},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2964791.2901489},\n doi = {10.1145/2964791.2901489},\n acmid = {2901489},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenters, reliability, solid state drives},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2901489&parent_id=2964791&expformat=bibtex&CFID=982044571&CFTOKEN=56075620\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2901489\">\r\n@inproceedings{Narayanan:2016:SFD:2896377.2901489,\n author = {Narayanan, Iyswarya and Wang, Di and Jeon, Myeongjae and Sharma, Bikash and Caulfield, Laura and Sivasubramaniam, Anand and Cutler, Ben and Liu, Jie and Khessib, Badriddine and Vaid, Kushagra},\n title = {SSD Failures in Datacenters: What, When and Why?},\n booktitle = {Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science},\n series = {SIGMETRICS '16},\n year = {2016},\n isbn = {978-1-4503-4266-7},\n location = {Antibes Juan-les-Pins, France},\n pages = {407--408},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2896377.2901489},\n doi = {10.1145/2896377.2901489},\n acmid = {2901489},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenters, reliability, solid state drives},\n} \r\n",
        "key": "2901489",
        "pub_year": "2016",
        "text": "Iyswarya Narayanan , Di Wang , Myeongjae Jeon , Bikash Sharma , Laura Caulfield , Anand Sivasubramaniam , Ben Cutler , Jie Liu , Badriddine Khessib , Kushagra Vaid, SSD Failures in Datacenters: What, When and Why?, ACM SIGMETRICS Performance Evaluation Review, v.44 n.1, June 2016"
    },
    "2902967": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2902967",
        "bib_stats": {
            "cites": 0,
            "dl": 121,
            "dl_52": 51,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Hu:2016:EMM:2902961.2902967,\n author = {Hu, Qingda and Sun, Guangyu and Shu, Jiwu and Zhang, Chao},\n title = {Exploring Main Memory Design Based on Racetrack Memory Technology},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {397--402},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2902967},\n doi = {10.1145/2902961.2902967},\n acmid = {2902967},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {energy, main memory, performance, racetrack, shifts},\n} \r\n",
        "key": "2902967",
        "pub_year": "2016",
        "text": "Qingda Hu , Guangyu Sun , Jiwu Shu , Chao Zhang, Exploring Main Memory Design Based on Racetrack Memory Technology, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2902979": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2902979",
        "bib_stats": {
            "cites": 0,
            "dl": 61,
            "dl_52": 32,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Alsuwaiyan:2016:OFV:2902961.2902979,\n author = {Alsuwaiyan, Ali and Mohanram, Kartik},\n title = {An Offline Frequent Value Encoding for Energy-Efficient MLC/TLC Non-volatile Memories},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {403--408},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2902979},\n doi = {10.1145/2902961.2902979},\n acmid = {2902979},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {encoding, energy, non-volatile memories},\n} \r\n",
        "key": "2902979",
        "pub_year": "2016",
        "text": "Ali Alsuwaiyan , Kartik Mohanram, An Offline Frequent Value Encoding for Energy-Efficient MLC/TLC Non-volatile Memories, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2902980": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2902980",
        "bib_stats": {
            "cites": 0,
            "dl": 62,
            "dl_52": 28,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Soltani:2016:PLN:2902961.2902980,\n author = {Soltani, Morteza and Ebrahimi, Mohammad and Navabi, Zainalabedin},\n title = {Prolonging Lifetime of Non-volatile Last Level Caches with Cluster Mapping},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {329--334},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2902980},\n doi = {10.1145/2902961.2902980},\n acmid = {2902980},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cold cluster, data movement, wear leveling technique, write traffic},\n} \r\n",
        "key": "2902980",
        "pub_year": "2016",
        "text": "Morteza Soltani , Mohammad Ebrahimi , Zainalabedin Navabi, Prolonging Lifetime of Non-volatile Last Level Caches with Cluster Mapping, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903002": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2903002",
        "bib_stats": {
            "cites": 0,
            "dl": 55,
            "dl_52": 27,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Wei:2016:DCE:2902961.2903002,\n author = {Wei, Wei and Namba, Kazuteru and Lombardi, Fabrizio},\n title = {Design and Comparative Evaluation of a Hybrid Cache Memory at Architectural Level},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {125--128},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/2902961.2903002},\n doi = {10.1145/2902961.2903002},\n acmid = {2903002},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {hybrid cache memory, low power, memory design, non-volatile memory, static and dynamic random-access-memory},\n} \r\n",
        "key": "2903002",
        "pub_year": "2016",
        "text": "Wei Wei , Kazuteru Namba , Fabrizio Lombardi, Design and Comparative Evaluation of a Hybrid Cache Memory at Architectural Level, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903009": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2903009",
        "bib_stats": {
            "cites": 0,
            "dl": 59,
            "dl_52": 35,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Adegbija:2016:ECN:2902961.2903009,\n author = {Adegbija, Tosiron},\n title = {Exploring Configurable Non-Volatile Memory-based Caches for Energy-Efficient Embedded Systems},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {157--162},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2903009},\n doi = {10.1145/2902961.2903009},\n acmid = {2903009},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {adaptable hardware., cache memories, configurable memory, low-power design, low-power embedded systems, non-volatile memory},\n} \r\n",
        "key": "2903009",
        "pub_year": "2016",
        "text": "Tosiron Adegbija, Exploring Configurable Non-Volatile Memory-based Caches for Energy-Efficient Embedded Systems, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903015": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2903015",
        "bib_stats": {
            "cites": 0,
            "dl": 79,
            "dl_52": 40,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Park:2016:MAW:2902961.2903015,\n author = {Park, Jaeyoung and Orshansky, Michael},\n title = {Multiple Attempt Write Strategy for Low Energy STT-RAM},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {163--168},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2903015},\n doi = {10.1145/2902961.2903015},\n acmid = {2903015},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-RAM, memory design, multiple attempt},\n} \r\n",
        "key": "2903015",
        "pub_year": "2016",
        "text": "Jaeyoung Park , Michael Orshansky, Multiple Attempt Write Strategy for Low Energy STT-RAM, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903017": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2903017",
        "bib_stats": {
            "cites": 0,
            "dl": 77,
            "dl_52": 36,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Tosson:2016:RRC:2902961.2903017,\n author = {Tosson, Amr M.S. and Anis, Mohab and Wei, Lan},\n title = {RRAM Refresh Circuit: A Proposed Solution To Resolve The Soft-Error Failures For HfO2/Hf 1T1R RRAM Memory Cell},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {227--232},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2903017},\n doi = {10.1145/2902961.2903017},\n acmid = {2903017},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {RRAM array, refresh, reliability},\n} \r\n",
        "key": "2903017",
        "pub_year": "2016",
        "text": "Amr M.S. Tosson , Mohab Anis , Lan Wei, RRAM Refresh Circuit: A Proposed Solution To Resolve The Soft-Error Failures For HfO2<sub>2</sub>/Hf 1T1R RRAM Memory Cell, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA&#13;\n\t\t\t\t\t\t/Hf 1T1R RRAM Memory Cell, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903022": {
        "abstract": "In recent years, the semiconductor industry has been witnessing an increasing reuse of hardware IPs for System-on-Chip (SoC) designs and embedded computing systems on FPGA platforms with hard-core processors. The IP-reuse comes with an increasing complexity at the hardware-software (HW-SW) interface. The efforts required to access the HW through the increasingly complex HW-SW interface diminishes the potential IP-reuse productivity gain. In our work, we are proposing hierarchical drivers for accessing IP-subsystems and its generation for enabling easier SW application adaptation to HW-changes and faster design space exploration (DSE) on a targeted HW-accelerated SW libraries. At the lowest level, closest to the HW, is the hardware abstraction layer (HAL), these are the platform-specific register-access drivers. At the next layer are the drivers to access the registers and bit-fields of each IP component of the IP-library. Next are the IP-subsystems drivers. At the top-layer, closest to the SW, is the simple scheduler with SW interface library that provides access functions to the SW application. The drivers generator uses the HW knowledge of IPs and IP-subsystems encoded in IP-XACT for generating the drivers for both operating system (OS) and non-OS based applications. For the OS-based applications, user-space drivers are generated, as well as device tree source (DTS) and drivers mapping in the kernel-space. In a case study, we have validated our methodology while performing DSE for a video processing application targeted to an IP-library, both as non-OS and with OS on Xilinx Zynq-based FPGA.",
        "acm_key": "2903022",
        "bib_stats": {
            "cites": 0,
            "dl": 99,
            "dl_52": 44,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Bishnoi:2016:LMM:2902961.2903022,\n author = {Bishnoi, Rajendra and Oboril, Fabian and Tahoori, Mehdi B.},\n title = {Low-Power Multi-Port Memory Architecture Based on Spin Orbit Torque Magnetic Devices},\n booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},\n series = {GLSVLSI '16},\n year = {2016},\n isbn = {978-1-4503-4274-2},\n location = {Boston, Massachusetts, USA},\n pages = {409--414},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2902961.2903022},\n doi = {10.1145/2902961.2903022},\n acmid = {2903022},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {low power, non-volatile multi-port memory, register file, spin orbit torque},\n} \r\n",
        "key": "2903022",
        "pub_year": "2016",
        "text": "Rajendra Bishnoi , Fabian Oboril , Mehdi B. Tahoori, Low-Power Multi-Port Memory Architecture based on Spin Orbit Torque Magnetic Devices, Proceedings of the 26th edition on Great Lakes Symposium on VLSI, May 18-20, 2016, Boston, Massachusetts, USA"
    },
    "2903139": {
        "abstract": "Recently, it has been shown that the hard real-time scheduling theory can be applied to streaming applications modeled as acyclic Cyclo-Static Dataflow (CSDF) graphs. However, this recent approach is not always efficient in terms of throughput and processor utilization. Therefore, in this article, we propose an improved hard real-time scheduling approach to schedule streaming applications modeled as acyclic CSDF graphs on a Multiprocessor System-on-Chip (MPSoC) platform. The proposed approach converts each actor in a CSDF graph to a set of real-time periodic tasks. The conversion enables application of many hard real-time scheduling algorithms that offer fast calculation of the required number of processors for scheduling the tasks. In addition, we propose a method to reduce the graph latency when the converted tasks are scheduled as real-time periodic tasks. We evaluate the performance and time complexity of our approach in comparison to several existing scheduling approaches. Experiments on a set of real-life streaming applications demonstrate that our approach (1) results in systems with higher throughput and better processor utilization in comparison to the existing hard real-time scheduling approach for CSDF graphs, while requiring comparable time for the system derivation; (2) delivers shorter application latency by applying the proposed method for graph latency reduction while providing better throughput and processor utilization when compared to the existing hard real-time scheduling approach; (3) gives the same throughput as the existing periodic scheduling approach for CSDF graphs, but requires much shorter time to derive the task schedule and tasks\u2019 parameters (periods, start times, and so on); and (4) gives the throughput that is equal to or very close to the maximum achievable throughput of an application obtained via self-timed scheduling, but requires much shorter time to derive the schedule. The total time needed for the proposed conversion approach and the calculation of the minimum number of processors needed to schedule the tasks and the calculation of the size of communication buffers between tasks is in the range of seconds.",
        "acm_key": "2903139",
        "bib_stats": {
            "cites": 0,
            "dl": 93,
            "dl_52": 93,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Olivier:2016:MEP:2982215.2903139,\n author = {Olivier, Pierre and Boukhobza, Jalil and Senn, Eric and Ouarnoughi, Hamza},\n title = {A Methodology for Estimating Performance and Power Consumption of Embedded Flash File Systems},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {August 2016},\n volume = {15},\n number = {4},\n month = aug,\n year = {2016},\n issn = {1539-9087},\n pages = {79:1--79:25},\n articleno = {79},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2903139},\n doi = {10.1145/2903139},\n acmid = {2903139},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, embedded Linux, estimation, flash file systems, modeling, performance, power consumption, simulation},\n} \r\n",
        "key": "2903139",
        "pub_year": "2016",
        "text": "Pierre Olivier , Jalil Boukhobza , Eric Senn , Hamza Ouarnoughi, A Methodology for Estimating Performance and Power Consumption of Embedded Flash File Systems, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.4, August 2016"
    },
    "2903160": {
        "abstract": "Emerging big data analytics applications require a significant amount of server computational power. The costs of building and running a computing server to process big data and the capacity to which we can scale it are driven in large part by those computational resources. However, big data applications share many characteristics that are fundamentally different from traditional desktop, parallel, and scale-out applications. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and are running a complex and deep software stack with various components (e.g. Hadoop, Spark, MPI, Hbase, Impala, MySQL, Hive, Shark, Apache, and MangoDB) that are bound together with a runtime software system and interact significantly with I/O and OS, exhibiting high computational intensity, memory intensity, I/O intensity and control intensity. Current server designs, based on commodity homogeneous processors, will not be the most efficient in terms of performance/watt for this emerging class of applications. In other domains, heterogeneous architectures have emerged as a promising solution to enhance energy-efficiency by allowing each application to run on a core that matches resource needs more closely than a one-size-fits-all core. A heterogeneous architecture integrates cores with various micro-architectures and accelerators to provide more opportunity for efficient workload mapping. In this work, through methodical investigation of power and performance measurements, and comprehensive system level characterization, we demonstrate that a heterogeneous architecture combining high performance big and low power little cores is required for efficient big data analytics applications processing, and in particular in the presence of accelerators and near real-time performance constraints.",
        "acm_key": "2903160",
        "bib_stats": {
            "cites": 0,
            "dl": 134,
            "dl_52": 85,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Zha:2016:CMN:2903150.2903160,\n author = {Zha, Jin and Huang, Linpeng and Wu, Linzhu and Zheng, Sheng-an and Liu, Hao},\n title = {A Consistency Mechanism for NVM-Based In-memory File Systems},\n booktitle = {Proceedings of the ACM International Conference on Computing Frontiers},\n series = {CF '16},\n year = {2016},\n isbn = {978-1-4503-4128-8},\n location = {Como, Italy},\n pages = {197--204},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2903150.2903160},\n doi = {10.1145/2903150.2903160},\n acmid = {2903160},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consistency, file system, non-volatile memory, performance, snapshot},\n} \r\n",
        "key": "2903160",
        "pub_year": "2016",
        "text": "Jin Zha , Linpeng Huang , Linzhu Wu , Sheng-an Zheng , Hao Liu, A consistency mechanism for NVM-Based in-memory file systems, Proceedings of the ACM International Conference on Computing Frontiers, May 16-19, 2016, Como, Italy"
    },
    "2903799": {
        "abstract": "Adaptive tracking method of group targets using random matrix based on the current statistical model CS is presented in order to improve tracking performance of group targets in strong manoeuvring and high measurement error. In the estimation of group centroid, a bell-shape function is utilised as fuzzy membership function to adjust the maximum acceleration which can modify the process noise variance adaptively. The introduction of strong tracking filter with multiple suboptimal fading factors adjusts error covariance of predicted group centroid state adaptively when group targets manoeuvre strongly. In the estimation of group extension, the measurement accuracy is considered in the extended state estimation where the likelihood function is formatted with extended state and measurement error covariance which is calculated by the innovation and adaptive fading memory updated in iterative process. The simulation results show that the method presented in the paper achieves better tracking performance of group targets in strong manoeuvring and high measurement error compared with the existing methods.",
        "acm_key": "2903799",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Shen:2016:LLC:2903797.2903799,\n author = {Shen, Yan and Luo, Liming and Zhang, Guangyan},\n title = {LOCA: A Low-overhead Caching Algorithm for Flash-based SSDs},\n journal = {Int. J. Wire. Mob. Comput.},\n issue_date = {March 2016},\n volume = {10},\n number = {1},\n month = mar,\n year = {2016},\n issn = {1741-1084},\n pages = {13--19},\n numpages = {7},\n url = {http://dx.doi.org/10.1504/IJWMC.2016.075217},\n doi = {10.1504/IJWMC.2016.075217},\n acmid = {2903799},\n publisher = {Inderscience Publishers},\n address = {Inderscience Publishers, Geneva, SWITZERLAND},\n} \r\n",
        "key": "2903799",
        "pub_year": "2016",
        "text": "Yan Shen , Liming Luo , Guangyan Zhang, LOCA: a low-overhead caching algorithm for flash-based SSDs, International Journal of Wireless and Mobile Computing, v.10 n.1, p.13-19, March 2016"
    },
    "2904046": {
        "abstract": "Nowadays we are witnessing a trend with significantly increasing number of networked and computing-capable devices being integrated into everyday environment. This trend is expected to continue. With computing devices available as logic structures, they might use each other's processing capabilities to achieve a given goal. In this paper, the authors propose an architectural solution to perform the processing of tasks using a distributed structure of Internet of Things devices. They also include ZigBee devices that are not connected to the Internet, but participate with the processing swarm using local network. This significantly extends the flexibility and potential of the IoT structure, while being still not a well-researched area. Unlike many high-level realizations for IoT processing, the authors present a realization operating on the communications, computing and near protocol level that achieves energy consumption efficiency. They also include the reconfigurability of IoT devices. The authors' work is suitable to be the base for higher-level realizations, especially for systems with devices operating on battery power. At the same time, the architecture presented in this paper uses minimal centralization, moving maximum responsibilities to regular devices. The proposed realizations are described using linear programming models and their high efficiency is evaluated.",
        "acm_key": "2904046",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Kawata:2016:UDC:2904041.2904046,\n author = {Kawata, Hirotaka and Nakagawa, Gaku and Oikawa, Shuichi},\n title = {Using DRAM As Cache for Non-Volatile Main Memory Swapping},\n journal = {Int. J. Softw. Innov.},\n issue_date = {January 2016},\n volume = {4},\n number = {1},\n month = jan,\n year = {2016},\n issn = {2166-7160},\n pages = {61--71},\n numpages = {11},\n url = {http://dx.doi.org/10.4018/IJSI.2016010105},\n doi = {10.4018/IJSI.2016010105},\n acmid = {2904046},\n publisher = {IGI Global},\n address = {Hershey, PA, USA},\n keywords = {Memory Swapping, Non Volatile Memory, Persistent Memory, Virtual Memory, Virtual Memory System},\n} \r\n",
        "key": "2904046",
        "pub_year": "2016",
        "text": "Hirotaka Kawata , Gaku Nakagawa , Shuichi Oikawa, Using DRAM as Cache for Non-Volatile Main Memory Swapping, International Journal of Software Innovation, v.4 n.1, p.61-71, January 2016"
    },
    "2904667": {
        "abstract": "A hybrid file system with high flexibility and performance, called Trident file system TridentFS, is proposed to manage three types of storage with different performance characteristics, that is, Non-Volatile RAM NVRAM, flash memory and magnetic disk. Unlike previous NVRAM-based hybrid file systems, novel techniques are used in TridentFS to improve the flexibility and performance. TridentFS is flexible by the support of various forms of flash memory and a wide range of NVRAM size. The former is achieved on the basis of the concept of stackable file systems, and the latter is achieved by allowing data eviction from the NVRAM. TridentFS achieves high performance by keeping hot data in the NVRAM and allowing data evicted from the NVRAM to be parallel distributed to the flash memory and disk. A data eviction policy is proposed to determine the data to be evicted from the NVRAM. Moreover, a data distribution algorithm is proposed to effectively leverage the parallelism between flash memory and disk during data distribution. TridentFS is implemented as a loadable module on Linux 2.6.29. The performance results show that it works well for both small-sized and large-sized NVRAM, and the proposed eviction policy outperforms LRU by 27%. Moreover, by effectively leveraging the parallelism between flash memory and disk, the proposed data distribution algorithm outperforms the RAID-0 and a size-based distribution method by up to 471.6% and 82.6%, respectively. By considering the data size and performance characteristics of the storage, the proposed data distribution algorithm outperforms the greedy algorithm by up to 15.5%. Copyright \u00a9 2014 John Wiley & Sons, Ltd.",
        "acm_key": "2904667",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Huang:2016:THF:2904664.2904667,\n author = {Huang, Ting-Chang and Chang, Da-Wei},\n title = {TridentFS: A Hybrid File System for Non-volatile RAM, Flash Memory and Magnetic Disk},\n journal = {Softw. Pract. Exper.},\n issue_date = {March 2016},\n volume = {46},\n number = {3},\n month = mar,\n year = {2016},\n issn = {0038-0644},\n pages = {291--318},\n numpages = {28},\n url = {http://dx.doi.org/10.1002/spe.2299},\n doi = {10.1002/spe.2299},\n acmid = {2904667},\n publisher = {John Wiley \\&amp; Sons, Inc.},\n address = {New York, NY, USA},\n keywords = {file distribution, flash memory, hybrid file systems, magnetic disk, non-volatile memory},\n} \r\n",
        "key": "2904667",
        "pub_year": "2016",
        "text": "Ting-Chang Huang , Da-Wei Chang, TridentFS: a hybrid file system for non-volatile RAM, flash memory and magnetic disk, Software\u2014Practice & Experience, v.46 n.3, p.291-318, March 2016  \u00a0[doi>"
    },
    "2905054": {
        "abstract": "NAND flash-based Solid-State Drives (SSDs) are becoming a viable alternative as a secondary storage solution for many computing systems. Since the physical characteristics of NAND flash memory are different from conventional Hard-Disk Drives (HDDs), flash-based SSDs usually employ an intermediate software layer, called a Flash Translation Layer (FTL). The FTL runs several firmware algorithms for logical-to-physical mapping, I/O interleaving, garbage collection, wear-leveling, and so on. These FTL algorithms not only have a great effect on storage performance and lifetime, but also determine hardware cost and data integrity. In general, a hybrid FTL scheme has been widely used in mobile devices because it exhibits high performance and high data integrity at a low hardware cost. Recently, a demand-based FTL based on page-level mapping has been rapidly adopted in high-performance SSDs. The demand-based FTL more effectively exploits the device-level parallelism than the hybrid FTL and requires a small amount of memory by keeping only popular mapping entries in DRAM. Because of this caching mechanism, however, the demand-based FTL is not robust enough for power failures and requires extra reads to fetch missing mapping entries from NAND flash. In this article, we propose a new flash translation layer called LAST++. The proposed LAST++ scheme is based on the hybrid FTL, thus it has the inherent benefits of the hybrid FTL, including low resource requirements, strong robustness for power failures, and high read performance. By effectively exploiting the locality of I/O references, LAST++ increases device-level parallelism and reduces garbage collection overheads. This leads to a great improvement of I/O performance and makes it possible to overcome the limitations of the hybrid FTL. Our experimental results show that LAST++ outperforms the demand-based FTL by 27&percnt; for writes and 7&percnt; for reads, on average, while offering higher robustness against sudden power failures. LAST++ also improves write performance by 39&percnt;, on average, over the existing hybrid FTL.",
        "acm_key": "2905054",
        "bib_stats": {
            "cites": 0,
            "dl": 249,
            "dl_52": 178,
            "dl_6": 14
        },
        "bibtex": "\r\n@article{Lee:2016:EST:2932205.2905054,\n author = {Lee, Sungjin and Shin, Dongkun and Kim, Youngjin and Kim, Jihong},\n title = {Exploiting Sequential and Temporal Localities to Improve Performance of NAND Flash-Based SSDs},\n journal = {Trans. Storage},\n issue_date = {June 2016},\n volume = {12},\n number = {3},\n month = may,\n year = {2016},\n issn = {1553-3077},\n pages = {15:1--15:39},\n articleno = {15},\n numpages = {39},\n url = {http://doi.acm.org/10.1145/2905054},\n doi = {10.1145/2905054},\n acmid = {2905054},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash translation layer, address mapping, garbage collection},\n} \r\n",
        "key": "2905054",
        "pub_year": "2016",
        "text": "Sungjin Lee , Dongkun Shin , Youngjin Kim , Jihong Kim, Exploiting Sequential and Temporal Localities to Improve Performance of NAND Flash-Based SSDs, ACM Transactions on Storage (TOS), v.12 n.3, p.1-39, June 2016"
    },
    "2905364": {
        "abstract": "For decades, various concepts in security monitoring have been proposed. In principle, they all in common in regard to the monitoring of the execution behavior of a program (e.g., control-flow or dataflow) running on the machine to find symptoms of attacks. Among the proposed monitoring schemes, software-based ones are known for their adaptability on the commercial products, but there have been concerns that they may suffer from nonnegligible runtime overhead. On the other hand, hardware-based solutions are recognized for their high performance. However, most of them have an inherent problem in that they usually mandate drastic changes to the internal processor architecture. More recent ones have strived to minimize such modifications by employing external hardware security monitors in the system. However, these approaches intrinsically suffer from the overhead caused by communication between the host and the external monitor. Our solution also relies on external hardware for security monitoring, but unlike the others, ours tackles the communication overhead by using the core debug interface (CDI), which is readily available in most commercial processors for debugging. We build our system simply by plugging our monitoring hardware into the processor via CDI, precluding the need for altering the processor internals. To validate the effectiveness of our approach, we implement two well-known monitoring techniques on our proposed framework: dynamic information flow tracking and branch regulation. The experimental results on our FPGA prototype show that our external hardware monitors efficiently perform monitoring tasks with negligible performance overhead, mainly with thanks to the support of CDI, which helps us reduce communication costs substantially.",
        "acm_key": "2905364",
        "bib_stats": {
            "cites": 1,
            "dl": 126,
            "dl_52": 103,
            "dl_6": 10
        },
        "bibtex": "\r\n@article{Chang:2016:IPE:2948199.2905364,\n author = {Chang, Yu-Ming and Hsiu, Pi-Cheng and Chang, Yuan-Hao and Chen, Chi-Hao and Kuo, Tei-Wei and Wang, Cheng-Yuan Michael},\n title = {Improving PCM Endurance with a Constant-Cost Wear Leveling Design},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {December 2016},\n volume = {22},\n number = {1},\n month = jun,\n year = {2016},\n issn = {1084-4309},\n pages = {9:1--9:27},\n articleno = {9},\n numpages = {27},\n url = {http://doi.acm.org/10.1145/2905364},\n doi = {10.1145/2905364},\n acmid = {2905364},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, endurance, wear leveling},\n} \r\n",
        "key": "2905364",
        "pub_year": "2016",
        "text": "Yu-Ming Chang , Pi-Cheng Hsiu , Yuan-Hao Chang , Chi-Hao Chen , Tei-Wei Kuo , Cheng-Yuan Michael Wang, Improving PCM Endurance with a Constant-Cost Wear Leveling Design, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.22 n.1, June 2016"
    },
    "2907303": {
        "abstract": "Next generation datacenter and exascale machines will include significantly larger amounts of memory, greater heterogeneity in the performance, persistence or sharing properties of the memory components they encompass, and increase in the relative cost and complexity of the data paths in the resulting memory topology. This poses several challenges to the systems software stacks managing these memory-centric platform designs. First, technology advances in novel memory technologies shift the data access bottlenecks into the software stack. Second, current systems software lacks capabilities to bridge the multi-dimensional non-uniformity in the memory subsystem to the dynamic nature of the workloads it must support. In addition, current memory management solutions have limited ability to explicitly reason about the costs and tradeoffs associated with data movement operations, leading to limited efficiency of their interconnect use. To address these problems, next generation systems software stacks require new data structures, abstractions and mechanisms in order to enable new levels of efficiency in the data placement, movement, and transformation decisions that govern the underlying memory use. In this talk, I will present our approach to rearchitecting systems software and services in response to both node-level and system-wide memory heterogeneity and scale, particularly concerning the presence of non-volatile memories, and will demonstrate the resulting performance and efficiency gains using several scientific and data-intensive workloads.",
        "acm_key": "2907303",
        "bib_stats": {
            "cites": 0,
            "dl": 344,
            "dl_52": 276,
            "dl_6": 19
        },
        "bibtex": "\r\n@inproceedings{Denny:2016:NSA:2907294.2907303,\n author = {Denny, Joel E. and Lee, Seyong and Vetter, Jeffrey S.},\n title = {NVL-C: Static Analysis Techniques for Efficient, Correct Programming of Non-Volatile Main Memory Systems},\n booktitle = {Proceedings of the 25th ACM International Symposium on High-Performance Parallel and Distributed Computing},\n series = {HPDC '16},\n year = {2016},\n isbn = {978-1-4503-4314-5},\n location = {Kyoto, Japan},\n pages = {125--136},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2907294.2907303},\n doi = {10.1145/2907294.2907303},\n acmid = {2907303},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid transactions, c, flash, llvm, nvm, openarc, persistent memory, pmem, scm, ssd},\n} \r\n",
        "key": "2907303",
        "pub_year": "2016",
        "text": "Joel E. Denny , Seyong Lee , Jeffrey S. Vetter, NVL-C: Static Analysis Techniques for Efficient, Correct Programming of Non-Volatile Main Memory Systems, Proceedings of the 25th ACM International Symposium on High-Performance Parallel and Distributed Computing, May 31-June 04, 2016, Kyoto, Japan"
    },
    "2907321": {
        "abstract": "Next generation datacenter and exascale machines will include significantly larger amounts of memory, greater heterogeneity in the performance, persistence or sharing properties of the memory components they encompass, and increase in the relative cost and complexity of the data paths in the resulting memory topology. This poses several challenges to the systems software stacks managing these memory-centric platform designs. First, technology advances in novel memory technologies shift the data access bottlenecks into the software stack. Second, current systems software lacks capabilities to bridge the multi-dimensional non-uniformity in the memory subsystem to the dynamic nature of the workloads it must support. In addition, current memory management solutions have limited ability to explicitly reason about the costs and tradeoffs associated with data movement operations, leading to limited efficiency of their interconnect use. To address these problems, next generation systems software stacks require new data structures, abstractions and mechanisms in order to enable new levels of efficiency in the data placement, movement, and transformation decisions that govern the underlying memory use. In this talk, I will present our approach to rearchitecting systems software and services in response to both node-level and system-wide memory heterogeneity and scale, particularly concerning the presence of non-volatile memories, and will demonstrate the resulting performance and efficiency gains using several scientific and data-intensive workloads.",
        "acm_key": "2907321",
        "bib_stats": {
            "cites": 1,
            "dl": 244,
            "dl_52": 206,
            "dl_6": 24
        },
        "bibtex": "\r\n@inproceedings{Wu:2016:ADP:2907294.2907321,\n author = {Wu, Panruo and Li, Dong and Chen, Zizhong and Vetter, Jeffrey S. and Mittal, Sparsh},\n title = {Algorithm-Directed Data Placement in Explicitly Managed Non-Volatile Memory},\n booktitle = {Proceedings of the 25th ACM International Symposium on High-Performance Parallel and Distributed Computing},\n series = {HPDC '16},\n year = {2016},\n isbn = {978-1-4503-4314-5},\n location = {Kyoto, Japan},\n pages = {141--152},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2907294.2907321},\n doi = {10.1145/2907294.2907321},\n acmid = {2907321},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {codesign, hpc, in-memory dma, memory organization, non volatile memory, pcm, phase change memory, relaxed persistence},\n} \r\n",
        "key": "2907321",
        "pub_year": "2016",
        "text": "Panruo Wu , Dong Li , Zizhong Chen , Jeffrey S. Vetter , Sparsh Mittal, Algorithm-Directed Data Placement in Explicitly Managed Non-Volatile Memory, Proceedings of the 25th ACM International Symposium on High-Performance Parallel and Distributed Computing, May 31-June 04, 2016, Kyoto, Japan"
    },
    "2910590": {
        "abstract": "With limited battery supply, power is a scarce commodity in wireless sensor networks. Thus, to prolong the lifetime of the network, it is imperative that the sensor resources are managed effectively. This task is particularly challenging in heterogeneous sensor networks for which decisions and compromises regarding sensing strategies are to be made under time and resource constraints. In such networks, a sensor has to reason about its current state to take actions that are deemed appropriate with respect to its mission, its energy reserve, and the survivability of the overall network. Sensor Management controls and coordinates the use of the sensory suites in a manner that maximizes the success rate of the system in achieving its missions. This article focuses on formulating and developing an autonomous energy-aware sensor management system that strives to achieve network objectives while maximizing its lifetime. A team-theoretic formulation based on the Belief-Desire-Intention (BDI) model and the Joint Intention theory is proposed as a mechanism for effective and energy-aware collaborative decision-making. The proposed system models the collective behavior of the sensor nodes using the Joint Intention theory to enhance sensors\u2019 collaboration and success rate. Moreover, the BDI modeling of the sensor operation and reasoning allows a sensor node to adapt to the environment dynamics, situation-criticality level, and availability of its own resources. The simulation scenario selected in this work is the surveillance of the Waterloo International Airport. Various experiments are conducted to investigate the effect of varying the network size, number of threats, threat agility, environment dynamism, as well as tracking quality and energy consumption, on the performance of the proposed system. The experimental results demonstrate the merits of the proposed approach compared to the state-of-the-art centralized approach adapted from Atia et al. [2011] and the localized approach in Hilal and Basir [2015] in terms of energy consumption, adaptability, and network lifetime. The results show that the proposed approach has 12 \u00d7 less energy consumption than that of the popular centralized approach.",
        "acm_key": "2910590",
        "bib_stats": {
            "cites": 0,
            "dl": 75,
            "dl_52": 60,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Yang:2016:BUS:2899033.2910590,\n author = {Yang, Ming-Chang and Chang, Yuan-Hao and Tsao, Che-Wei},\n title = {Byte-Addressable Update Scheme to Minimize the Energy Consumption of PCM-Based Storage Systems},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {July 2016},\n volume = {15},\n number = {3},\n month = jun,\n year = {2016},\n issn = {1539-9087},\n pages = {55:1--55:20},\n articleno = {55},\n numpages = {20},\n url = {http://doi.acm.org/10.1145/2910590},\n doi = {10.1145/2910590},\n acmid = {2910590},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, asymmetry, byte addressability, energy consumption, file system, journaling, nonvolatility, performance, reliability, storage system},\n} \r\n",
        "key": "2910590",
        "pub_year": "2016",
        "text": "Ming-Chang Yang , Yuan-Hao Chang , Che-Wei Tsao, Byte-Addressable Update Scheme to Minimize the Energy Consumption of PCM-Based Storage Systems, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.3, p.1-20, June 2016"
    },
    "2914009": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2914009",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Yang:2016:CAM:2913985.2914009,\n author = {Yang, Ming-Chang and Chang, Yuan-Hao and Kuo, Tei-Wei and Huang, Po-Chun},\n title = {Capacity-Independent Address Mapping for Flash Storage Devices with Explosively Growing Capacity},\n journal = {IEEE Trans. Comput.},\n issue_date = {February 2016},\n volume = {65},\n number = {2},\n month = feb,\n year = {2016},\n issn = {0018-9340},\n pages = {448--465},\n numpages = {18},\n url = {http://dx.doi.org/10.1109/TC.2015.2428702},\n doi = {10.1109/TC.2015.2428702},\n acmid = {2914009},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2914009",
        "pub_year": "2016",
        "text": "Ming-Chang Yang , Yuan-Hao Chang , Tei-Wei Kuo , Po-Chun Huang, Capacity-Independent Address Mapping for Flash Storage Devices with Explosively Growing Capacity, IEEE Transactions on Computers, v.65 n.2, p.448-465, February 2016  \u00a0[doi>"
    },
    "2914019": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2914019",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Guo:2016:MMA:2913986.2914019,\n author = {Guo, Weichao and Chen, Kang and Feng, Huan and Wu, Yongwei and Zhang, Rui and Zheng, Weimin},\n title = {\\$MARS\\$ : Mobile Application Relaunching Speed-Up Through Flash-Aware Page Swapping},\n journal = {IEEE Trans. Comput.},\n issue_date = {March 2016},\n volume = {65},\n number = {3},\n month = mar,\n year = {2016},\n issn = {0018-9340},\n pages = {916--928},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TC.2015.2428692},\n doi = {10.1109/TC.2015.2428692},\n acmid = {2914019},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2914019",
        "pub_year": "2016",
        "text": "Weichao Guo , Kang Chen , Huan Feng , Yongwei Wu , Rui Zhang , Weimin Zheng, <inline-formula><tex-math>$MARS$</tex-math><alternatives> <inline-graphic xlink:=\"\" type=\"simple\" xlink:href=\"wu-ieq1-2428692.gif\"/></alternatives></inline-formula>: Mobile Application Relaunching Speed-Up through Flash-Aware Page Swapping, IEEE Transactions on Computers, v.65 n.3, p.916-928, March 2016 : Mobile Application Relaunching Speed-Up through Flash-Aware Page Swapping, IEEE Transactions on Computers, v.65 n.3, p.916-928, March 2016  \u00a0[doi>"
    },
    "2914022": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2914022",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Ahn:2016:PHC:2913986.2914022,\n author = {Ahn, Junwhan and Yoo, Sungjoo and Choi, Kiyoung},\n title = {Prediction Hybrid Cache: An Energy-Efficient STT-RAM Cache Architecture},\n journal = {IEEE Trans. Comput.},\n issue_date = {March 2016},\n volume = {65},\n number = {3},\n month = mar,\n year = {2016},\n issn = {0018-9340},\n pages = {940--951},\n numpages = {12},\n url = {http://dx.doi.org/10.1109/TC.2015.2435772},\n doi = {10.1109/TC.2015.2435772},\n acmid = {2914022},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2914022",
        "pub_year": "2016",
        "text": "Junwhan Ahn , Sungjoo Yoo , Kiyoung Choi, Prediction Hybrid Cache: An Energy-Efficient STT-RAM Cache Architecture, IEEE Transactions on Computers, v.65 n.3, p.940-951, March 2016  \u00a0[doi>"
    },
    "2914058": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2914058",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Liu:2016:IRP:2913987.2914058,\n author = {Liu, Ren-Shuo and Chuang, Meng-Yen and Yang, Chia-Lin and Li, Cheng-Hsuan and Ho, Kin-Chu and Li, Hsiang-Pang},\n title = {Improving Read Performance of NAND Flash SSDs by Exploiting Error Locality},\n journal = {IEEE Trans. Comput.},\n issue_date = {April 2016},\n volume = {65},\n number = {4},\n month = apr,\n year = {2016},\n issn = {0018-9340},\n pages = {1090--1102},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TC.2014.2345387},\n doi = {10.1109/TC.2014.2345387},\n acmid = {2914058},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2914058",
        "pub_year": "2016",
        "text": "Ren-Shuo Liu , Meng-Yen Chuang , Chia-Lin Yang , Cheng-Hsuan Li , Kin-Chu Ho , Hsiang-Pang Li, Improving Read Performance of NAND Flash SSDs by Exploiting Error Locality, IEEE Transactions on Computers, v.65 n.4, p.1090-1102, April 2016  \u00a0[doi>"
    },
    "2915251": {
        "abstract": "The volume of metadata needed by a flash translation layer (FTL) is proportional to the storage capacity of a flash device. Ideally, this metadata should reside in the device's integrated RAM to enable fast access. However, as flash devices scale to terabytes, the necessary volume of metadata is exceeding the available integrated RAM. Moreover, recovery time after power failure, which is proportional to the size of the metadata, is becoming impractical. The simplest solution is to persist more metadata in flash. The problem is that updating metadata in flash increases the amount of internal IOs thereby harming performance and device lifetime. In this paper, we identify a key component of the metadata called the Page Validity Bitmap (PVB) as the bottleneck. PVB is used by the garbage-collectors of state-of-the-art FTLs to keep track of which physical pages in the device are invalid. PVB constitutes 95% of the FTL's RAM-resident metadata, and recovering PVB after power fails takes a significant proportion of the overall recovery time. To solve this problem, we propose a page-associative FTL called GeckoFTL, whose central innovation is replacing PVB with a new data structure called Logarithmic Gecko. Logarithmic Gecko is similar to an LSM-tree in that it first logs updates and later reorganizes them to ensure fast and scalable access time. Relative to the baseline of storing PVB in flash, Logarithmic Gecko enables cheaper updates at the cost of slightly more expensive garbage-collection queries. We show that this is a good trade-off because (1) updates are intrinsically more frequent than garbage-collection queries to page validity metadata, and (2) flash writes are more expensive than flash reads. We demonstrate analytically and empirically through simulation that GeckoFTL achieves a 95% reduction in space requirements and at least a 51% reduction in recovery time by storing page validity metadata in flash while keeping the contribution to internal IO overheads 98% lower than the baseline.",
        "acm_key": "2915251",
        "bib_stats": {
            "cites": 4,
            "dl": 754,
            "dl_52": 541,
            "dl_6": 32
        },
        "bibtex": "\r\n@inproceedings{Oukid:2016:FHS:2882903.2915251,\n author = {Oukid, Ismail and Lasperas, Johan and Nica, Anisoara and Willhalm, Thomas and Lehner, Wolfgang},\n title = {FPTree: A Hybrid SCM-DRAM Persistent and Concurrent B-Tree for Storage Class Memory},\n booktitle = {Proceedings of the 2016 International Conference on Management of Data},\n series = {SIGMOD '16},\n year = {2016},\n isbn = {978-1-4503-3531-7},\n location = {San Francisco, California, USA},\n pages = {371--386},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2882903.2915251},\n doi = {10.1145/2882903.2915251},\n acmid = {2915251},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {B-tree, data management, data structures, database recovery, hardware transactional memory, storage class memory},\n} \r\n",
        "key": "2915251",
        "pub_year": "2016",
        "text": "Ismail Oukid , Johan Lasperas , Anisoara Nica , Thomas Willhalm , Wolfgang Lehner, FPTree: A Hybrid SCM-DRAM Persistent and Concurrent B-Tree for Storage Class Memory, Proceedings of the 2016 International Conference on Management of Data, June 26-July 01, 2016, San Francisco, California, USA"
    },
    "2915916": {
        "abstract": "Recently, it has been shown that the hard real-time scheduling theory can be applied to streaming applications modeled as acyclic Cyclo-Static Dataflow (CSDF) graphs. However, this recent approach is not always efficient in terms of throughput and processor utilization. Therefore, in this article, we propose an improved hard real-time scheduling approach to schedule streaming applications modeled as acyclic CSDF graphs on a Multiprocessor System-on-Chip (MPSoC) platform. The proposed approach converts each actor in a CSDF graph to a set of real-time periodic tasks. The conversion enables application of many hard real-time scheduling algorithms that offer fast calculation of the required number of processors for scheduling the tasks. In addition, we propose a method to reduce the graph latency when the converted tasks are scheduled as real-time periodic tasks. We evaluate the performance and time complexity of our approach in comparison to several existing scheduling approaches. Experiments on a set of real-life streaming applications demonstrate that our approach (1) results in systems with higher throughput and better processor utilization in comparison to the existing hard real-time scheduling approach for CSDF graphs, while requiring comparable time for the system derivation; (2) delivers shorter application latency by applying the proposed method for graph latency reduction while providing better throughput and processor utilization when compared to the existing hard real-time scheduling approach; (3) gives the same throughput as the existing periodic scheduling approach for CSDF graphs, but requires much shorter time to derive the task schedule and tasks\u2019 parameters (periods, start times, and so on); and (4) gives the throughput that is equal to or very close to the maximum achievable throughput of an application obtained via self-timed scheduling, but requires much shorter time to derive the schedule. The total time needed for the proposed conversion approach and the calculation of the minimum number of processors needed to schedule the tasks and the calculation of the size of communication buffers between tasks is in the range of seconds.",
        "acm_key": "2915916",
        "bib_stats": {
            "cites": 1,
            "dl": 109,
            "dl_52": 109,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Wu:2016:JJO:2982215.2915916,\n author = {Wu, Chin-Hsien and Chen, Syuan-An},\n title = {JOM: A Joint Operation Mechanism for NAND Flash Memory},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {August 2016},\n volume = {15},\n number = {4},\n month = aug,\n year = {2016},\n issn = {1539-9087},\n pages = {74:1--74:26},\n articleno = {74},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/2915916},\n doi = {10.1145/2915916},\n acmid = {2915916},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, embedded systems, flash translation layers, storage systems},\n} \r\n",
        "key": "2915916",
        "pub_year": "2016",
        "text": "Chin-Hsien Wu , Syuan-An Chen, JOM: A Joint Operation Mechanism for NAND Flash Memory, ACM Transactions on Embedded Computing Systems (TECS), v.15 n.4, August 2016"
    },
    "2926263": {
        "abstract": "Recent commercial chip-multiprocessors (CMPs) have integrated CPU as well as GPU cores on the same die. In today's designs, these cores typically share parts of the memory system resources. However, since the CPU and the GPU cores have vastly different resource requirements, challenging resource partitioning problems arise in such heterogeneous CMPs. In one class of designs, the CPU and the GPU cores share the large on-die last-level SRAM cache. In this paper, we explore mechanisms to dynamically allocate the shared last-level cache space to the CPU and GPU applications in such designs. A CPU core executes an instruction progressively in a pipeline generating memory accesses (for instruction and data) only in a few pipeline stages. On the other hand, a GPU can access different data streams having different semantic meanings and disparate access patterns throughout the rendering pipeline. Such data streams include input vertex, pixel depth, pixel color, texture map, shader instructions, shader data (including shader register spills and fills), etc.. Without carefully designed last-level cache management policies, the CPU and the GPU data streams can interfere with each other leading to significant loss in CPU and GPU performance accompanied by degradation in GPU-rendered 3D animation quality. Our proposal dynamically estimates the reuse probabilities of the GPU streams as well as the CPU data by sampling portions of the CPU and GPU working sets and storing the sampled tags in a small working set sample cache. Since the GPU application working sets are typically very large, for this working set sample cache to be effective, it is custom-designed to have large coverage while requiring few tens of kilobytes of storage. We use the estimated reuse probabilities to design shared last-level cache policies for handling hits and misses to reads and writes from both types of cores. Studies on a detailed heterogeneous CMP simulator show that compared to a state-of-the-art baseline with a 16 MB shared last-level cache, our proposal can improve the performance (frame rate or execution cycles, as applicable) of eighteen GPU workloads spanning DirectX and OpenGL game titles as well as CUDA applications by 12% on average and up to 51% while improving the performance of the co-running quad-core CPU workload mixes by 7% on average and up to 19%.",
        "acm_key": "2926263",
        "bib_stats": {
            "cites": 0,
            "dl": 209,
            "dl_52": 171,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Wu:2016:GGC:2925426.2926263,\n author = {Wu, Suzhen and Lin, Yanping and Mao, Bo and Jiang, Hong},\n title = {GCaR: Garbage Collection Aware Cache Management with Improved Performance for Flash-based SSDs},\n booktitle = {Proceedings of the 2016 International Conference on Supercomputing},\n series = {ICS '16},\n year = {2016},\n isbn = {978-1-4503-4361-9},\n location = {Istanbul, Turkey},\n pages = {28:1--28:12},\n articleno = {28},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2925426.2926263},\n doi = {10.1145/2925426.2926263},\n acmid = {2926263},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2926263",
        "pub_year": "2016",
        "text": "Suzhen Wu , Yanping Lin , Bo Mao , Hong Jiang, GCaR: Garbage Collection aware Cache Management with Improved Performance for Flash-based SSDs, Proceedings of the 2016 International Conference on Supercomputing, June 01-03, 2016, Istanbul, Turkey"
    },
    "2926284": {
        "abstract": "Recent commercial chip-multiprocessors (CMPs) have integrated CPU as well as GPU cores on the same die. In today's designs, these cores typically share parts of the memory system resources. However, since the CPU and the GPU cores have vastly different resource requirements, challenging resource partitioning problems arise in such heterogeneous CMPs. In one class of designs, the CPU and the GPU cores share the large on-die last-level SRAM cache. In this paper, we explore mechanisms to dynamically allocate the shared last-level cache space to the CPU and GPU applications in such designs. A CPU core executes an instruction progressively in a pipeline generating memory accesses (for instruction and data) only in a few pipeline stages. On the other hand, a GPU can access different data streams having different semantic meanings and disparate access patterns throughout the rendering pipeline. Such data streams include input vertex, pixel depth, pixel color, texture map, shader instructions, shader data (including shader register spills and fills), etc.. Without carefully designed last-level cache management policies, the CPU and the GPU data streams can interfere with each other leading to significant loss in CPU and GPU performance accompanied by degradation in GPU-rendered 3D animation quality. Our proposal dynamically estimates the reuse probabilities of the GPU streams as well as the CPU data by sampling portions of the CPU and GPU working sets and storing the sampled tags in a small working set sample cache. Since the GPU application working sets are typically very large, for this working set sample cache to be effective, it is custom-designed to have large coverage while requiring few tens of kilobytes of storage. We use the estimated reuse probabilities to design shared last-level cache policies for handling hits and misses to reads and writes from both types of cores. Studies on a detailed heterogeneous CMP simulator show that compared to a state-of-the-art baseline with a 16 MB shared last-level cache, our proposal can improve the performance (frame rate or execution cycles, as applicable) of eighteen GPU workloads spanning DirectX and OpenGL game titles as well as CUDA applications by 12% on average and up to 51% while improving the performance of the co-running quad-core CPU workload mixes by 7% on average and up to 19%.",
        "acm_key": "2926284",
        "bib_stats": {
            "cites": 1,
            "dl": 294,
            "dl_52": 224,
            "dl_6": 17
        },
        "bibtex": "\r\n@inproceedings{Awad:2016:WMN:2925426.2926284,\n author = {Awad, Amro and Blagodurov, Sergey and Solihin, Yan},\n title = {Write-Aware Management of NVM-based Memory Extensions},\n booktitle = {Proceedings of the 2016 International Conference on Supercomputing},\n series = {ICS '16},\n year = {2016},\n isbn = {978-1-4503-4361-9},\n location = {Istanbul, Turkey},\n pages = {9:1--9:12},\n articleno = {9},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2925426.2926284},\n doi = {10.1145/2925426.2926284},\n acmid = {2926284},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVM Memory Extensions, PCM, System Software},\n} \r\n",
        "key": "2926284",
        "pub_year": "2016",
        "text": "Amro Awad , Sergey Blagodurov , Yan Solihin, Write-Aware Management of NVM-based Memory Extensions, Proceedings of the 2016 International Conference on Supercomputing, June 01-03, 2016, Istanbul, Turkey"
    },
    "2926290": {
        "abstract": "Recent commercial chip-multiprocessors (CMPs) have integrated CPU as well as GPU cores on the same die. In today's designs, these cores typically share parts of the memory system resources. However, since the CPU and the GPU cores have vastly different resource requirements, challenging resource partitioning problems arise in such heterogeneous CMPs. In one class of designs, the CPU and the GPU cores share the large on-die last-level SRAM cache. In this paper, we explore mechanisms to dynamically allocate the shared last-level cache space to the CPU and GPU applications in such designs. A CPU core executes an instruction progressively in a pipeline generating memory accesses (for instruction and data) only in a few pipeline stages. On the other hand, a GPU can access different data streams having different semantic meanings and disparate access patterns throughout the rendering pipeline. Such data streams include input vertex, pixel depth, pixel color, texture map, shader instructions, shader data (including shader register spills and fills), etc.. Without carefully designed last-level cache management policies, the CPU and the GPU data streams can interfere with each other leading to significant loss in CPU and GPU performance accompanied by degradation in GPU-rendered 3D animation quality. Our proposal dynamically estimates the reuse probabilities of the GPU streams as well as the CPU data by sampling portions of the CPU and GPU working sets and storing the sampled tags in a small working set sample cache. Since the GPU application working sets are typically very large, for this working set sample cache to be effective, it is custom-designed to have large coverage while requiring few tens of kilobytes of storage. We use the estimated reuse probabilities to design shared last-level cache policies for handling hits and misses to reads and writes from both types of cores. Studies on a detailed heterogeneous CMP simulator show that compared to a state-of-the-art baseline with a 16 MB shared last-level cache, our proposal can improve the performance (frame rate or execution cycles, as applicable) of eighteen GPU workloads spanning DirectX and OpenGL game titles as well as CUDA applications by 12% on average and up to 51% while improving the performance of the co-running quad-core CPU workload mixes by 7% on average and up to 19%.",
        "acm_key": "2926290",
        "bib_stats": {
            "cites": 2,
            "dl": 449,
            "dl_52": 381,
            "dl_6": 62
        },
        "bibtex": "\r\n@inproceedings{Islam:2016:HPD:2925426.2926290,\n author = {Islam, Nusrat Sharmin and Wasi-ur-Rahman, Md. and Lu, Xiaoyi and Panda, Dhabaleswar K.},\n title = {High Performance Design for HDFS with Byte-Addressability of NVM and RDMA},\n booktitle = {Proceedings of the 2016 International Conference on Supercomputing},\n series = {ICS '16},\n year = {2016},\n isbn = {978-1-4503-4361-9},\n location = {Istanbul, Turkey},\n pages = {8:1--8:14},\n articleno = {8},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2925426.2926290},\n doi = {10.1145/2925426.2926290},\n acmid = {2926290},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2926290",
        "pub_year": "2016",
        "text": "Nusrat Sharmin Islam , Md. Wasi-ur-Rahman , Xiaoyi Lu , Dhabaleswar K. Panda, High Performance Design for HDFS with Byte-Addressability of NVM and RDMA, Proceedings of the 2016 International Conference on Supercomputing, June 01-03, 2016, Istanbul, Turkey"
    },
    "2926702": {
        "abstract": " High performance garbage collectors build upon performance-critical low-level code, typically exhibit multiple levels of concurrency, and are prone to subtle bugs. Implementing, debugging and maintaining such collectors can therefore be extremely challenging. The choice of implementation language is a crucial consideration when building a collector. Typically, the drive for performance and the need for efficient support of low-level memory operations leads to the use of low-level languages like C or C++, which offer little by way of safety and software engineering benefits. This risks undermining the robustness and flexibility of the collector design. Rust's ownership model, lifetime specification, and reference borrowing deliver safety guarantees through a powerful static checker with little runtime overhead. These features make Rust a compelling candidate for a collector implementation language, but they come with restrictions that threaten expressiveness and efficiency. We describe our experience implementing an Immix garbage collector in Rust and C. We discuss the benefits of Rust, the obstacles encountered, and how we overcame them. We show that our Immix implementation has almost identical performance on micro benchmarks, compared to its implementation in C, and outperforms the popular BDW collector on the gcbench micro benchmark. We find that Rust's safety features do not create significant barriers to implementing a high performance collector. Though memory managers are usually considered low-level, our high performance implementation relies on very little unsafe code, with the vast majority of the implementation benefiting from Rust's safety. We see our experience as a compelling proof-of-concept of Rust as an implementation language for high performance garbage collection. ",
        "acm_key": "2926702",
        "bib_stats": {
            "cites": 1,
            "dl": 207,
            "dl_52": 155,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Shen:2016:CEH:2926697.2926702,\n author = {Shen, Du and Liu, Xu and Lin, Felix Xiaozhu},\n title = {Characterizing Emerging Heterogeneous Memory},\n booktitle = {Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management},\n series = {ISMM 2016},\n year = {2016},\n isbn = {978-1-4503-4317-6},\n location = {Santa Barbara, CA, USA},\n pages = {13--23},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2926697.2926702},\n doi = {10.1145/2926697.2926702},\n acmid = {2926702},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Heterogeneous memory, data placement, heterogeneous benchmarks, performance characterization},\n} \r\n",
        "key": "2926702",
        "pub_year": "2016",
        "text": "Du Shen , Xu Liu , Felix Xiaozhu Lin, Characterizing emerging heterogeneous memory, Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management, June 14-14, 2016, Santa Barbara, CA, USA"
    },
    "2926704": {
        "abstract": " High performance garbage collectors build upon performance-critical low-level code, typically exhibit multiple levels of concurrency, and are prone to subtle bugs. Implementing, debugging and maintaining such collectors can therefore be extremely challenging. The choice of implementation language is a crucial consideration when building a collector. Typically, the drive for performance and the need for efficient support of low-level memory operations leads to the use of low-level languages like C or C++, which offer little by way of safety and software engineering benefits. This risks undermining the robustness and flexibility of the collector design. Rust's ownership model, lifetime specification, and reference borrowing deliver safety guarantees through a powerful static checker with little runtime overhead. These features make Rust a compelling candidate for a collector implementation language, but they come with restrictions that threaten expressiveness and efficiency. We describe our experience implementing an Immix garbage collector in Rust and C. We discuss the benefits of Rust, the obstacles encountered, and how we overcame them. We show that our Immix implementation has almost identical performance on micro benchmarks, compared to its implementation in C, and outperforms the popular BDW collector on the gcbench micro benchmark. We find that Rust's safety features do not create significant barriers to implementing a high performance collector. Though memory managers are usually considered low-level, our high performance implementation relies on very little unsafe code, with the vast majority of the implementation benefiting from Rust's safety. We see our experience as a compelling proof-of-concept of Rust as an implementation language for high performance garbage collection. ",
        "acm_key": "2926704",
        "bib_stats": {
            "cites": 1,
            "dl": 179,
            "dl_52": 145,
            "dl_6": 14
        },
        "bibtex": "\r\n@inproceedings{Boehm:2016:PPM:2926697.2926704,\n author = {Boehm, Hans-J. and Chakrabarti, Dhruva R.},\n title = {Persistence Programming Models for Non-volatile Memory},\n booktitle = {Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management},\n series = {ISMM 2016},\n year = {2016},\n isbn = {978-1-4503-4317-6},\n location = {Santa Barbara, CA, USA},\n pages = {55--67},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2926697.2926704},\n doi = {10.1145/2926697.2926704},\n acmid = {2926704},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consistency, locks, non-volatile memory, transactions},\n} \r\n",
        "key": "2926704",
        "pub_year": "2016",
        "text": "Hans-J. Boehm , Dhruva R. Chakrabarti, Persistence programming models for non-volatile memory, Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management, June 14-14, 2016, Santa Barbara, CA, USA"
    },
    "2927584": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2927584",
        "bib_stats": {
            "cites": 6
        },
        "bibtex": "\r\n@article{Mittal:2016:SST:2927512.2927584,\n author = {Mittal, Sparsh and Vetter, Jeffrey S.},\n title = {A Survey of Software Techniques for Using Non-Volatile Memories for Storage and Main Memory Systems},\n journal = {IEEE Trans. Parallel Distrib. Syst.},\n issue_date = {May 2016},\n volume = {27},\n number = {5},\n month = may,\n year = {2016},\n issn = {1045-9219},\n pages = {1537--1550},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TPDS.2015.2442980},\n doi = {10.1109/TPDS.2015.2442980},\n acmid = {2927584},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2927584",
        "pub_year": "2016",
        "text": "Sparsh Mittal , Jeffrey S. Vetter, A Survey of Software Techniques for Using Non-Volatile Memories for Storage and Main Memory Systems, IEEE Transactions on Parallel and Distributed Systems, v.27 n.5, p.1537-1550, May 2016  \u00a0[doi>"
    },
    "2928278": {
        "abstract": "In the coded switching paradigm we propose, our objective is to maximize the number of full packets read from the switch memory simultaneously in a read cycle. The packets to read at each read cycle are specified in a request issued by the control plane of the switch. We show that coding the packets upon their write can significantly increase the number of read packets, in return to a small increase in the write load to store the redundancy. Thus coding can significantly increase the overall switching throughput. We identify and study two key components for high-throughput coded switches: 1) Read algorithms that can recover the maximal number of packets given an arbitrary request for previously written packets, and 2) Placement policies determining how coded chunks are placed in the switch MUs. Our results contribute art and insight for each of these two components, and more importantly, they reveal the tight relations between them. At a high level, the choice of placement policy can improve both the performance and the computational efficiency of the read algorithm. To show the former, we derive a collection of analysis tools to calculate and/or bound the performance of a read algorithm given the placement policy in use. For the latter, we show a huge gap between an NP-hard optimal read problem for one policy (uniform placement), and extremely efficient optimal read algorithms for two others (cyclic and design placements).",
        "acm_key": "2928278",
        "bib_stats": {
            "cites": 2,
            "dl": 5,
            "dl_52": 206,
            "dl_6": 30
        },
        "bibtex": "\r\n@inproceedings{Narayanan:2016:SFD:2928275.2928278,\n author = {Narayanan, Iyswarya and Wang, Di and Jeon, Myeongjae and Sharma, Bikash and Caulfield, Laura and Sivasubramaniam, Anand and Cutler, Ben and Liu, Jie and Khessib, Badriddine and Vaid, Kushagra},\n title = {SSD Failures in Datacenters: What? When? And Why?},\n booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},\n series = {SYSTOR '16},\n year = {2016},\n isbn = {978-1-4503-4381-7},\n location = {Haifa, Israel},\n pages = {7:1--7:11},\n articleno = {7},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2928275.2928278},\n doi = {10.1145/2928275.2928278},\n acmid = {2928278},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {characterization, reliability, solid state drives},\n} \r\n",
        "key": "2928278",
        "pub_year": "2016",
        "text": "Iyswarya Narayanan , Di Wang , Myeongjae Jeon , Bikash Sharma , Laura Caulfield , Anand Sivasubramaniam , Ben Cutler , Jie Liu , Badriddine Khessib , Kushagra Vaid, SSD Failures in Datacenters: What? When? and Why?, Proceedings of the 9th ACM International on Systems and Storage Conference, June 06-08, 2016, Haifa, Israel"
    },
    "2928279": {
        "abstract": "In the coded switching paradigm we propose, our objective is to maximize the number of full packets read from the switch memory simultaneously in a read cycle. The packets to read at each read cycle are specified in a request issued by the control plane of the switch. We show that coding the packets upon their write can significantly increase the number of read packets, in return to a small increase in the write load to store the redundancy. Thus coding can significantly increase the overall switching throughput. We identify and study two key components for high-throughput coded switches: 1) Read algorithms that can recover the maximal number of packets given an arbitrary request for previously written packets, and 2) Placement policies determining how coded chunks are placed in the switch MUs. Our results contribute art and insight for each of these two components, and more importantly, they reveal the tight relations between them. At a high level, the choice of placement policy can improve both the performance and the computational efficiency of the read algorithm. To show the former, we derive a collection of analysis tools to calculate and/or bound the performance of a read algorithm given the placement policy in use. For the latter, we show a huge gap between an NP-hard optimal read problem for one policy (uniform placement), and extremely efficient optimal read algorithms for two others (cyclic and design placements).",
        "acm_key": "2928279",
        "bib_stats": {
            "cites": 0,
            "dl": 171,
            "dl_52": 102,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Pletka:2016:HMP:2928275.2928279,\n author = {Pletka, Roman A. and Tomi\\'{c}, Sa\\v{s}a},\n title = {Health-Binning: Maximizing the Performance and the Endurance of Consumer-Level NAND Flash},\n booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},\n series = {SYSTOR '16},\n year = {2016},\n isbn = {978-1-4503-4381-7},\n location = {Haifa, Israel},\n pages = {4:1--4:10},\n articleno = {4},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2928275.2928279},\n doi = {10.1145/2928275.2928279},\n acmid = {2928279},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash memory, data placement, endurance, solid-state drives, solid-state storage systems, wear leveling},\n} \r\n",
        "key": "2928279",
        "pub_year": "2016",
        "text": "Roman A. Pletka , Sa\u0161a Tomi\u0107, Health-Binning: Maximizing the Performance and the Endurance of Consumer-Level NAND Flash, Proceedings of the 9th ACM International on Systems and Storage Conference, June 06-08, 2016, Haifa, Israel"
    },
    "2928284": {
        "abstract": "In the coded switching paradigm we propose, our objective is to maximize the number of full packets read from the switch memory simultaneously in a read cycle. The packets to read at each read cycle are specified in a request issued by the control plane of the switch. We show that coding the packets upon their write can significantly increase the number of read packets, in return to a small increase in the write load to store the redundancy. Thus coding can significantly increase the overall switching throughput. We identify and study two key components for high-throughput coded switches: 1) Read algorithms that can recover the maximal number of packets given an arbitrary request for previously written packets, and 2) Placement policies determining how coded chunks are placed in the switch MUs. Our results contribute art and insight for each of these two components, and more importantly, they reveal the tight relations between them. At a high level, the choice of placement policy can improve both the performance and the computational efficiency of the read algorithm. To show the former, we derive a collection of analysis tools to calculate and/or bound the performance of a read algorithm given the placement policy in use. For the latter, we show a huge gap between an NP-hard optimal read problem for one policy (uniform placement), and extremely efficient optimal read algorithms for two others (cyclic and design placements).",
        "acm_key": "2928284",
        "bib_stats": {
            "cites": 0,
            "dl": 223,
            "dl_52": 156,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Ni:2016:SSF:2928275.2928284,\n author = {Ni, Yuanjiang and Jiang, Ji and Jiang, Dejun and Ma, Xiaosong and Xiong, Jin and Wang, Yuangang},\n title = {S-RAC: SSD Friendly Caching for Data Center Workloads},\n booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},\n series = {SYSTOR '16},\n year = {2016},\n isbn = {978-1-4503-4381-7},\n location = {Haifa, Israel},\n pages = {8:1--8:12},\n articleno = {8},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2928275.2928284},\n doi = {10.1145/2928275.2928284},\n acmid = {2928284},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache hit ratio, SSD Caching, Write endurance},\n} \r\n",
        "key": "2928284",
        "pub_year": "2016",
        "text": "Yuanjiang Ni , Ji Jiang , Dejun Jiang , Xiaosong Ma , Jin Xiong , Yuangang Wang, S-RAC: SSD Friendly Caching for Data Center Workloads, Proceedings of the 9th ACM International on Systems and Storage Conference, June 06-08, 2016, Haifa, Israel"
    },
    "2928286": {
        "abstract": "In the coded switching paradigm we propose, our objective is to maximize the number of full packets read from the switch memory simultaneously in a read cycle. The packets to read at each read cycle are specified in a request issued by the control plane of the switch. We show that coding the packets upon their write can significantly increase the number of read packets, in return to a small increase in the write load to store the redundancy. Thus coding can significantly increase the overall switching throughput. We identify and study two key components for high-throughput coded switches: 1) Read algorithms that can recover the maximal number of packets given an arbitrary request for previously written packets, and 2) Placement policies determining how coded chunks are placed in the switch MUs. Our results contribute art and insight for each of these two components, and more importantly, they reveal the tight relations between them. At a high level, the choice of placement policy can improve both the performance and the computational efficiency of the read algorithm. To show the former, we derive a collection of analysis tools to calculate and/or bound the performance of a read algorithm given the placement policy in use. For the latter, we show a huge gap between an NP-hard optimal read problem for one policy (uniform placement), and extremely efficient optimal read algorithms for two others (cyclic and design placements).",
        "acm_key": "2928286",
        "bib_stats": {
            "cites": 0,
            "dl": 187,
            "dl_52": 129,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Liang:2016:EQU:2928275.2928286,\n author = {Liang, Yushi and Chai, Yunpeng and Bao, Ning and Chen, Hengyu and Liu, Yaohong},\n title = {Elastic Queue: A Universal SSD Lifetime Extension Plug-in for Cache Replacement Algorithms},\n booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},\n series = {SYSTOR '16},\n year = {2016},\n isbn = {978-1-4503-4381-7},\n location = {Haifa, Israel},\n pages = {5:1--5:11},\n articleno = {5},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2928275.2928286},\n doi = {10.1145/2928275.2928286},\n acmid = {2928286},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache, Endurance, Flash, Lifetime, SSD},\n} \r\n",
        "key": "2928286",
        "pub_year": "2016",
        "text": "Yushi Liang , Yunpeng Chai , Ning Bao , Hengyu Chen , Yaohong Liu, Elastic Queue: A Universal SSD Lifetime Extension Plug-in for Cache Replacement Algorithms, Proceedings of the 9th ACM International on Systems and Storage Conference, June 06-08, 2016, Haifa, Israel"
    },
    "2929962": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2929962",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Wang:2016:PCW:2929923.2929962,\n author = {Wang, Ying and Han, Yinhe and Li, Huawei and Zhang, Lei and Cheng, Yuanqing and Li, Xiaowei},\n title = {PSI Conscious Write Scheduling: Architectural Support for Reliable Power Delivery in 3-D Die-Stacked PCM},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {May 2016},\n volume = {24},\n number = {5},\n month = may,\n year = {2016},\n issn = {1063-8210},\n pages = {1613--1625},\n numpages = {13},\n url = {http://dx.doi.org/10.1109/TVLSI.2015.2467157},\n doi = {10.1109/TVLSI.2015.2467157},\n acmid = {2929962},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2929962",
        "pub_year": "2016",
        "text": "Ying Wang , Yinhe Han , Huawei Li , Lei Zhang , Yuanqing Cheng , Xiaowei Li, PSI Conscious Write Scheduling: Architectural Support for Reliable Power Delivery in 3-D Die-Stacked PCM, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.24 n.5, p.1613-1625, May 2016  \u00a0[doi>"
    },
    "2930589": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930589",
        "bib_stats": {
            "cites": 11,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Schroeder:2016:FRP:2930583.2930589,\n author = {Schroeder, Bianca and Lagisetty, Raghav and Merchant, Arif},\n title = {Flash Reliability in Production: The Expected and the Unexpected},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {67--80},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930589},\n acmid = {2930589},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930589",
        "pub_year": "2016",
        "text": "Bianca Schroeder , Raghav Lagisetty , Arif Merchant, Flash reliability in production: the expected and the unexpected, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.67-80, February 22-25, 2016, Santa Clara, CA"
    },
    "2930591": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930591",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Margaglia:2016:DDI:2930583.2930591,\n author = {Margaglia, Fabio and Yadgar, Gala and Yaakobi, Eitan and Li, Yue and Schuster, Assaf and Brinkmann, Andr{\\'e}},\n title = {The Devil is in the Details: Implementing Flash Page Reuse with WOM Codes},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {95--109},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930591},\n acmid = {2930591},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930591",
        "pub_year": "2016",
        "text": "Fabio Margaglia , Gala Yadgar , Eitan Yaakobi , Yue Li , Assaf Schuster , Andr\u00e9 Brinkmann, The devil is in the details: implementing flash page reuse with WOM codes, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.95-109, February 22-25, 2016, Santa Clara, CA"
    },
    "2930592": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930592",
        "bib_stats": {
            "cites": 3,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:RSS:2930583.2930592,\n author = {Zhang, Xuebin and Li, Jiangpeng and Wang, Hao and Zhao, Kai and Zhang, Tong},\n title = {Reducing Solid-state Storage Device Write Stress Through Opportunistic In-place Delta Compression},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {111--124},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930592},\n acmid = {2930592},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930592",
        "pub_year": "2016",
        "text": "Xuebin Zhang , Jiangpeng Li , Hao Wang , Kai Zhao , Tong Zhang, Reducing solid-state storage device write stress through opportunistic in-place delta compression, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.111-124, February 22-25, 2016, Santa Clara, CA"
    },
    "2930593": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930593",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2016:ACG:2930583.2930593,\n author = {Li, Qiao and Shi, Liang and Xue, Chun Jason and Wu, Kaijie and Ji, Cheng and Zhuge, Qingfeng and Sha, Edwin H.-M.},\n title = {Access Characteristic Guided Read and Write Cost Regulation for Performance Improvement on Flash Memory},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {125--132},\n numpages = {8},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930593},\n acmid = {2930593},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930593",
        "pub_year": "2016",
        "text": "Qiao Li , Liang Shi , Chun Jason Xue , Kaijie Wu , Cheng Ji , Qingfeng Zhuge , Edwin H.-M. Sha, Access characteristic guided read and write cost regulation for performance improvement on flash memory, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.125-132, February 22-25, 2016, Santa Clara, CA"
    },
    "2930594": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930594",
        "bib_stats": {
            "cites": 10,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lu:2016:WSK:2930583.2930594,\n author = {Lu, Lanyue and Pillai, Thanumalayan Sankaranarayana and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},\n title = {WiscKey: Separating Keys from Values in SSD-conscious Storage},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {133--148},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930594},\n acmid = {2930594},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930594",
        "pub_year": "2016",
        "text": "Lanyue Lu , Thanumalayan Sankaranarayana Pillai , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-Dusseau, WiscKey: separating keys from values in SSD-conscious storage, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.133-148, February 22-25, 2016, Santa Clara, CA"
    },
    "2930603": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930603",
        "bib_stats": {
            "cites": 6,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Hao:2016:TSR:2930583.2930603,\n author = {Hao, Mingzhe and Soundararajan, Gokul and Kenchammana-Hosekote, Deepak and Chien, Andrew A. and Gunawi, Haryadi S.},\n title = {The Tail at Store: A Revelation from Millions of Hours of Disk and SSD Deployments},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {263--276},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930603},\n acmid = {2930603},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930603",
        "pub_year": "2016",
        "text": "Mingzhe Hao , Gokul Soundararajan , Deepak Kenchammana-Hosekote , Andrew A. Chien , Haryadi S. Gunawi, The tail at store: a revelation from millions of hours of disk and SSD deployments, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.263-276, February 22-25, 2016, Santa Clara, CA"
    },
    "2930605": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930605",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:OEF:2930583.2930605,\n author = {Chen, Zhuan and Shen, Kai},\n title = {OrderMergeDedup: Efficient, Failure-consistent Deduplication on Flash},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {291--299},\n numpages = {9},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930605},\n acmid = {2930605},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930605",
        "pub_year": "2016",
        "text": "Zhuan Chen , Kai Shen, OrderMergeDedup: efficient, failure-consistent deduplication on flash, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.291-299, February 22-25, 2016, Santa Clara, CA"
    },
    "2930606": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930606",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2016:CID:2930583.2930606,\n author = {Li, Wenji and Jean-Baptise, Gregory and Riveros, Juan and Narasimhan, Giri and Zhang, Tong and Zhao, Ming},\n title = {CacheDedup: In-line Deduplication for Flash Caching},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {301--314},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930606},\n acmid = {2930606},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930606",
        "pub_year": "2016",
        "text": "Wenji Li , Gregory Jean-Baptise , Juan Riveros , Giri Narasimhan , Tong Zhang , Ming Zhao, CacheDedup: in-line deduplication for flash caching, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.301-314, February 22-25, 2016, Santa Clara, CA"
    },
    "2930610": {
        "abstract": "Inside modern SSDs, a small portion of MLC/TLC NAND flash memory blocks operate in SLC-mode to serve as write buffer/cache and/or store hot data. These SLC-mode blocks absorb a large percentage of write operations. To balance memory wear-out, such MLC/TLC-to-SLC configuration rotates among all the memory blocks inside SSDs. This paper presents a simple yet effective design approach to reduce write stress on SLC-mode flash blocks and hence improve the overall SSD lifetime. The key is to implement well-known delta compression without being subject to the read latency and data management complexity penalties inherent to conventional practice. The underlying theme is to leverage the partial programmability of SLC-mode flash memory pages to ensure that the original data and all the subsequent deltas always reside in the same memory physical page. To avoid the storage capacity overhead, we further propose to combine intra-sector lossless data compression with intra-page delta compression, leading to opportunistic in-place delta compression. This paper presents specific techniques to address important issues for its practical implementation, including data error correction, and intra-page data placement and management. We carried out comprehensive experiments, simulations, and ASIC (application-specific integrated circuit) design. The results show that the proposed design solution can largely reduce the write stress on SLC-mode flash memory pages without significant latency overhead and meanwhile incurs relatively small silicon implementation cost.",
        "acm_key": "2930610",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Arteaga:2016:COF:2930583.2930610,\n author = {Arteaga, Dulcardo and Cabrera, Jorge and Xu, Jing and Sundararaman, Swaminathan and Zhao, Ming},\n title = {CloudCache: On-demand Flash Cache Management for Cloud Computing},\n booktitle = {Proceedings of the 14th Usenix Conference on File and Storage Technologies},\n series = {FAST'16},\n year = {2016},\n isbn = {978-1-931971-28-7},\n location = {Santa Clara, CA},\n pages = {355--369},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=2930583.2930610},\n acmid = {2930610},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "2930610",
        "pub_year": "2016",
        "text": "Dulcardo Arteaga , Jorge Cabrera , Jing Xu , Swaminathan Sundararaman , Ming Zhao, CloudCache: on-demand flash cache management for Cloud Computing, Proceedings of the 14th Usenix Conference on File and Storage Technologies, p.355-369, February 22-25, 2016, Santa Clara, CA"
    },
    "2930668": {
        "abstract": "Caches have been widely used in modern embedded processors to bridge the increasing speed gap between processors and off-chip memory. In real-time embedded systems, computing the Worst-Case Execution Time (WCET) of a task is essential for the task scheduler to construct a valid schedule for a task set. Unfortunately, caches make it much harder to compute the WCET of a task. Cache locking has been proposed to alleviate the timing unpredictability problem caused by caches. In this article, we investigate the following WCET-aware data-cache locking problem for a single task. Given a task, select a set of variables as locked cache contents such that the WCET of the task is minimized. We propose two dynamic full cache-locking approaches. The first formulates the problem as a global Integer Linear Programming (ILP) problem that simultaneously selects a minimum set of memory blocks of variables as locked cache contents and allocates them to the data cache. The second iteratively constructs a subgraph of the Control Flow Graph (CFG) of the task in which the lengths of all the paths are close to the longest path length, uses an ILP formulation to select a minimum set of memory blocks of variables in the subgraph as locked cache contents, and allocates the selected memory blocks to the data cache. We also propose two novel, efficient data-cache allocation algorithms for the global ILP approach and the iterative ILP approach, respectively. We have implemented both approaches and compared them with two state-of-the-art approaches, the longest path-based dynamic cache-locking approach and the static WCET analysis approach without cache locking by using a set of benchmarks from the M\u00e4lardalen WCET benchmark suite, SNU real-time benchmarks, and Powerstone benchmarks. Compared to the static WCET analysis approach, the average WCET improvements of the first approach range between 11.4% and 26.4%. Compared to the longest path--based, dynamic cache-locking approach, the average WCET improvements of the first approach range between 5.0% and 15.4%. The second approach performs slightly better than the first approach.",
        "acm_key": "2930668",
        "bib_stats": {
            "cites": 0,
            "dl": 85,
            "dl_52": 85,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Chang:2016:ESS:3025020.2930668,\n author = {Chang, Li-Pin and Sung, Po-Han and Chen, Po-Tsang and Chen, Po-Hung},\n title = {Eager Synching: A Selective Logging Strategy for Fast Fsync() on Flash-Based Android Devices},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {April 2017},\n volume = {16},\n number = {2},\n month = dec,\n year = {2016},\n issn = {1539-9087},\n pages = {34:1--34:25},\n articleno = {34},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/2930668},\n doi = {10.1145/2930668},\n acmid = {2930668},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Android, eMMC, file system, flash storage, fsync()},\n} \r\n",
        "key": "2930668",
        "pub_year": "2017",
        "text": "Li-Pin Chang , Po-Han Sung , Po-Tsang Chen , Po-Hung Chen, Eager Synching: A Selective Logging Strategy for Fast fsync() on Flash-Based Android Devices, ACM Transactions on Embedded Computing Systems (TECS), v.16 n.2, February 2017"
    },
    "2933124": {
        "abstract": "We present an optimal emulation of a server based regular read/write storage in a synchronous round-free message-passing system that is subject to mobile Byzantine failures and prove that the problem is impossible to solve in asynchronous settings. In a system with n servers implementing a regular register, our construction tolerates faults (or attacks) that can be abstracted by agents that are moved (in an arbitrary and unforeseen manner) by a computationally unbounded adversary from a server to another in order to deviate the server's computation. When a server is infected by an adversarial agent, it behaves arbitrarily until the adversary decides to \"move\" the agent to another server. We investigate the case where the movements of the mobile Byzantine agents are decided by the adversary and are completely decoupled from the message communication delay. Our emulation spans two awareness models: servers with and without self-diagnosis mechanism. In the first case servers are aware that the mobile Byzantine agent has left and hence they can stop running the protocol until they recover a correct state while in the second case, servers are not aware of their faulty state and continue to run the protocol using an incorrect local state. Our results, proven optimal with respect to the threshold of the tolerated mobile Byzantine faults in the first model, are significantly different from the round-based synchronous models. Another interesting side result of our study is that, contrary to the round-based synchronous consensus implementation for systems prone to mobile Byzantine faults, our storage emulation does not rely on the necessity of a core of correct processes all along the computation. That is, every server in the system can be compromised by the mobile Byzantine agents at some point in the computation. This leads to another interesting conclusion: storage is easier than consensus in synchronous settings, when the system is hit by mobile Byzantine failures.",
        "acm_key": "2933124",
        "bib_stats": {
            "cites": 0,
            "dl": 143,
            "dl_52": 140,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Gibbons:2016:EMT:2933057.2933124,\n author = {Gibbons, Phillip B.},\n title = {How Emerging Memory Technologies Will Have You Rethinking Algorithm Design},\n booktitle = {Proceedings of the 2016 ACM Symposium on Principles of Distributed Computing},\n series = {PODC '16},\n year = {2016},\n isbn = {978-1-4503-3964-3},\n location = {Chicago, Illinois, USA},\n pages = {303--303},\n numpages = {1},\n url = {http://doi.acm.org/10.1145/2933057.2933124},\n doi = {10.1145/2933057.2933124},\n acmid = {2933124},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {asymmetric read-write costs, memory hierarchies, models of computation, nvram, persistent memory, shared memory algorithms, write-efficient algorithms},\n} \r\n",
        "key": "2933124",
        "pub_year": "2016",
        "text": "Phillip B. Gibbons, How Emerging Memory Technologies Will Have You Rethinking Algorithm Design, Proceedings of the 2016 ACM Symposium on Principles of Distributed Computing, July 25-28, 2016, Chicago, Illinois, USA"
    },
    "2933354": {
        "abstract": "Leveraging Storage Class Memory (SCM) as a universal memory--i.e. as memory and storage at the same time--has deep implications on database architectures. It becomes possible to store a single copy of the data in SCM and directly operate on it at a fine granularity. However, exposing the whole database with direct access to the application dramatically increases the risk of data corruption. In this paper we propose a lightweight on-line testing framework that helps find and debug SCM-related errors that can occur upon software or power failures. Our testing framework simulates failures in critical code paths and achieves fast code coverage by leveraging call stack information to limit duplicate testing. It also partially covers the errors that might arise as a result of reordered memory operations. We show through an experimental evaluation that our testing framework is fast enough to be used with large software systems and discuss its use during the development of our in-house persistent SCM allocator.",
        "acm_key": "2933354",
        "bib_stats": {
            "cites": 1,
            "dl": 154,
            "dl_52": 120,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Oukid:2016:TPS:2933349.2933354,\n author = {Oukid, Ismail and Booss, Daniel and Lespinasse, Adrien and Lehner, Wolfgang},\n title = {On Testing Persistent-memory-based Software},\n booktitle = {Proceedings of the 12th International Workshop on Data Management on New Hardware},\n series = {DaMoN '16},\n year = {2016},\n isbn = {978-1-4503-4319-0},\n location = {San Francisco, California},\n pages = {5:1--5:7},\n articleno = {5},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2933349.2933354},\n doi = {10.1145/2933349.2933354},\n acmid = {2933354},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2933354",
        "pub_year": "2016",
        "text": "Ismail Oukid , Daniel Booss , Adrien Lespinasse , Wolfgang Lehner, On testing persistent-memory-based software, Proceedings of the 12th International Workshop on Data Management on New Hardware, p.1-7, June 26-July 01, 2016, San Francisco, California"
    },
    "2934610": {
        "abstract": "Designing reliable systems, while eschewing the high overheads of conventional fault tolerance techniques, is a critical challenge in the deeply scaled CMOS and post-CMOS era. To address this challenge, we leverage the intrinsic resilience of application domains such as multimedia, recognition, mining, search, and analytics where acceptable outputs are produced despite occasional approximate computations. We propose stochastic checkers, wherein a stochastic logic based realization of the circuit is used as an error checker, and the original circuit's output is declared to be correct if it lies within a certain range of the checker's output. The key benefit of stochastic checkers is that the intrinsic compactness of stochastic logic leads to greatly reduced overheads. However, due to the approximate nature of stochastic circuits, errors that cause the output to be within a certain range of the correct value may not be detected (missed coverage). In addition, some correct outputs may be incorrectly flagged as erroneous (false positives). To limit the number of missed errors and false positives, we propose a technique that uses input permuted partial replicas of the stochastic logic to improve accuracy without greatly increasing the overheads. We also address the challenge of error detection latency (due to the bit-serial nature of stochastic logic) through progressive checking policies that produce an early decision based on a prefix of the checker's output bitstream. We evaluate stochastic checkers on hardware implementations of a suite of error-resilient applications, and demonstrate that they can lead to greatly reduced overheads (29.5% area and 21.5% power, on average) compared to traditional fault tolerance techniques, while achieving very high coverage (average of 99.5%) and very low false positives (average of 0.1%).",
        "acm_key": "2934610",
        "bib_stats": {
            "cites": 1,
            "dl": 73,
            "dl_52": 73,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Zhou:2016:EPS:2934583.2934610,\n author = {Zhou, Wen and Feng, Dan and Hua, Yu and Liu, Jingning and Huang, Fangting and Chen, Yu},\n title = {An Efficient Parallel Scheduling Scheme on Multi-partition PCM Architecture},\n booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},\n series = {ISLPED '16},\n year = {2016},\n isbn = {978-1-4503-4185-1},\n location = {San Francisco Airport, CA, USA},\n pages = {344--349},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2934583.2934610},\n doi = {10.1145/2934583.2934610},\n acmid = {2934610},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {PCM, multiple partitions, parallel scheduling},\n} \r\n",
        "key": "2934610",
        "pub_year": "2016",
        "text": "Wen Zhou , Dan Feng , Yu Hua , Jingning Liu , Fangting Huang , Yu Chen, An Efficient Parallel Scheduling Scheme on Multi-partition PCM Architecture, Proceedings of the 2016 International Symposium on Low Power Electronics and Design, August 08-10, 2016, San Francisco Airport, CA, USA"
    },
    "2934611": {
        "abstract": "Designing reliable systems, while eschewing the high overheads of conventional fault tolerance techniques, is a critical challenge in the deeply scaled CMOS and post-CMOS era. To address this challenge, we leverage the intrinsic resilience of application domains such as multimedia, recognition, mining, search, and analytics where acceptable outputs are produced despite occasional approximate computations. We propose stochastic checkers, wherein a stochastic logic based realization of the circuit is used as an error checker, and the original circuit's output is declared to be correct if it lies within a certain range of the checker's output. The key benefit of stochastic checkers is that the intrinsic compactness of stochastic logic leads to greatly reduced overheads. However, due to the approximate nature of stochastic circuits, errors that cause the output to be within a certain range of the correct value may not be detected (missed coverage). In addition, some correct outputs may be incorrectly flagged as erroneous (false positives). To limit the number of missed errors and false positives, we propose a technique that uses input permuted partial replicas of the stochastic logic to improve accuracy without greatly increasing the overheads. We also address the challenge of error detection latency (due to the bit-serial nature of stochastic logic) through progressive checking policies that produce an early decision based on a prefix of the checker's output bitstream. We evaluate stochastic checkers on hardware implementations of a suite of error-resilient applications, and demonstrate that they can lead to greatly reduced overheads (29.5% area and 21.5% power, on average) compared to traditional fault tolerance techniques, while achieving very high coverage (average of 99.5%) and very low false positives (average of 0.1%).",
        "acm_key": "2934611",
        "bib_stats": {
            "cites": 0,
            "dl": 108,
            "dl_52": 108,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Li:2016:DIS:2934583.2934611,\n author = {Li, Zheng and Bi, Xiuyuan and Li, Hai Helen and Chen, Yiran and Qin, Jianying and Guo, Peng and Kong, Wenjie and Zhan, Wenshan and Han, Xiufeng and Zhang, Hong and Wang, Lingling and Wu, Guanping and Wu, Hanming},\n title = {Design and Implementation of a 4Kb STT-MRAM with Innovative 200Nm Nano-ring Shaped MTJ},\n booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},\n series = {ISLPED '16},\n year = {2016},\n isbn = {978-1-4503-4185-1},\n location = {San Francisco Airport, CA, USA},\n pages = {4--9},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2934583.2934611},\n doi = {10.1145/2934583.2934611},\n acmid = {2934611},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2934611",
        "pub_year": "2016",
        "text": "Zheng Li , Xiuyuan Bi , Hai Helen Li , Yiran Chen , Jianying Qin , Peng Guo , Wenjie Kong , Wenshan Zhan , Xiufeng Han , Hong Zhang , Lingling Wang , Guanping Wu , Hanming Wu, Design and Implementation of a 4Kb STT-MRAM with Innovative 200nm Nano-ring Shaped MTJ, Proceedings of the 2016 International Symposium on Low Power Electronics and Design, August 08-10, 2016, San Francisco Airport, CA, USA"
    },
    "2934629": {
        "abstract": "Designing reliable systems, while eschewing the high overheads of conventional fault tolerance techniques, is a critical challenge in the deeply scaled CMOS and post-CMOS era. To address this challenge, we leverage the intrinsic resilience of application domains such as multimedia, recognition, mining, search, and analytics where acceptable outputs are produced despite occasional approximate computations. We propose stochastic checkers, wherein a stochastic logic based realization of the circuit is used as an error checker, and the original circuit's output is declared to be correct if it lies within a certain range of the checker's output. The key benefit of stochastic checkers is that the intrinsic compactness of stochastic logic leads to greatly reduced overheads. However, due to the approximate nature of stochastic circuits, errors that cause the output to be within a certain range of the correct value may not be detected (missed coverage). In addition, some correct outputs may be incorrectly flagged as erroneous (false positives). To limit the number of missed errors and false positives, we propose a technique that uses input permuted partial replicas of the stochastic logic to improve accuracy without greatly increasing the overheads. We also address the challenge of error detection latency (due to the bit-serial nature of stochastic logic) through progressive checking policies that produce an early decision based on a prefix of the checker's output bitstream. We evaluate stochastic checkers on hardware implementations of a suite of error-resilient applications, and demonstrate that they can lead to greatly reduced overheads (29.5% area and 21.5% power, on average) compared to traditional fault tolerance techniques, while achieving very high coverage (average of 99.5%) and very low false positives (average of 0.1%).",
        "acm_key": "2934629",
        "bib_stats": {
            "cites": 0,
            "dl": 121,
            "dl_52": 121,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Oboril:2016:NSC:2934583.2934629,\n author = {Oboril, Fabian and Hameed, Fazal and Bishnoi, Rajendra and Ahari, Ali and Naeimi, Helia and Tahoori, Mehdi},\n title = {Normally-OFF STT-MRAM Cache with Zero-Byte Compression for Energy Efficient Last-Level Caches},\n booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},\n series = {ISLPED '16},\n year = {2016},\n isbn = {978-1-4503-4185-1},\n location = {San Francisco Airport, CA, USA},\n pages = {236--241},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2934583.2934629},\n doi = {10.1145/2934583.2934629},\n acmid = {2934629},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache, Compression, MRAM, Normally-Off, Zero-Byte},\n} \r\n",
        "key": "2934629",
        "pub_year": "2016",
        "text": "Fabian Oboril , Fazal Hameed , Rajendra Bishnoi , Ali Ahari , Helia Naeimi , Mehdi Tahoori, Normally-OFF STT-MRAM Cache with Zero-Byte Compression for Energy Efficient Last-Level Caches, Proceedings of the 2016 International Symposium on Low Power Electronics and Design, August 08-10, 2016, San Francisco Airport, CA, USA"
    },
    "2934685": {
        "abstract": "The number of chip pins is limited due to the cost and reliability issues of sophisticated packages, and it is predicted that the chip pin count will be overstretched to satisfy the requirements of both power delivery and memory access. The gap between the achievable pin count and the demand will increase as the technology scales, due to the increasing computation resources and supply current. Pin reduction techniques are thus required for continued computing performance growth. In this article, we propose a chip pin constraint alleviation strategy, through on/off-chip power delivery system co-design, to effectively reduce the demand for power pins. An analytical model of a power delivery system, consisting of on/off-chip regulators and a power delivery network, is proposed to evaluate the influence of regulator design and package conduction loss. By combining this model with a multi-core processor model of performance and memory bandwidth requirements, we characterize the entire multi-core processor system to investigate the relationship between the chip pin constraint and performance in multi-core processor scaling and the effectiveness of our strategy. Experiments show that with the conventional power delivery system design, the chip pin constraint severely limits the performance growth as the technology scales. Using the on/off-chip power delivery system co-design, our strategy achieves a significant pin count reduction, for example, 31.3% at the 8nm technology node, compared to the conventional design with the same chip performance, while, provided with the same chip pin count, it is able to improve, by 35.0%, the chip performance at 8nm compared to the conventional design. For real applications of different parallelism, our strategy outperforms its counterpart, with a 23.7% performance improvement on average at the 8nm technology node.",
        "acm_key": "2934685",
        "bib_stats": {
            "cites": 0,
            "dl": 67,
            "dl_52": 67,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Pajouhi:2016:YAE:3014160.2934685,\n author = {Pajouhi, Zoha and Fong, Xuanyao and Raghunathan, Anand and Roy, Kaushik},\n title = {Yield, Area, and Energy Optimization in STT-MRAMs Using Failure-Aware ECC},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {March 2017},\n volume = {13},\n number = {2},\n month = nov,\n year = {2016},\n issn = {1550-4832},\n pages = {20:1--20:20},\n articleno = {20},\n numpages = {20},\n url = {http://doi.acm.org/10.1145/2934685},\n doi = {10.1145/2934685},\n acmid = {2934685},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Embedded memories, emerging technologies},\n} \r\n",
        "key": "2934685",
        "pub_year": "2017",
        "text": "Zoha Pajouhi , Xuanyao Fong , Anand Raghunathan , Kaushik Roy, Yield, Area, and Energy Optimization in STT-MRAMs Using Failure-Aware ECC, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.2, February 2017"
    },
    "2935767": {
        "abstract": "The single-source shortest path problem (SSSP) with nonnegative edge weights is notoriously difficult to solve efficiently in parallel---it is one of the graph problems said to suffer from the transitive-closure bottleneck. Yet, in practice, the \u0394-stepping algorithm of Meyer and Sanders (J. Algorithms, 2003) often works efficiently but has no known theoretical bounds on general graphs. The algorithm takes a sequence of steps, each increasing the radius by a user-specified value \u0394. Each step settles the vertices in its annulus but can take \u0398(n) substeps, each requiring \u0398(m) work (n vertices and m edges). Building on the success of \u0394-stepping, this paper describes Radius Stepping, an algorithm with one of the best-known tradeoffs between work and depth bounds for SSSP with nearly-linear (~O(m)) work. The algorithm is a \u0394-stepping-like algorithm but uses a variable instead of a fixed-size increase in radii, allowing us to prove a bound on the number of steps. In particular, by using what we define as a vertex k-radius, each step takes at most k+2 substeps. Furthermore, we define a (k, \u03c1)-graph property and show that if an undirected graph has this property, then the number of steps can be bounded by O(n/\u03c1 log \u03c1 L), for a total of O(kn/\u03c1 log \u03c1 L) substeps, each parallel. We describe how to preprocess a graph to have this property. Altogether, for an arbitrary input graph with n vertices and m edges, Radius Stepping, after preprocessing, takes O((m+n\u03c1)log n) work and $O(n/\u03c1 log n log (\u03c1 L)) depth per source. The preprocessing step takes O(m log n + n\u03c1",
        "acm_key": "2935767",
        "bib_stats": {
            "cites": 3,
            "dl": 90,
            "dl_52": 81,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Ben-David:2016:PAA:2935764.2935767,\n author = {Ben-David, Naama and Blelloch, Guy E. and Fineman, Jeremy T. and Gibbons, Phillip B. and Gu, Yan and McGuffey, Charles and Shun, Julian},\n title = {Parallel Algorithms for Asymmetric Read-Write Costs},\n booktitle = {Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures},\n series = {SPAA '16},\n year = {2016},\n isbn = {978-1-4503-4210-0},\n location = {Pacific Grove, California, USA},\n pages = {145--156},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2935764.2935767},\n doi = {10.1145/2935764.2935767},\n acmid = {2935767},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {asymmetric nested-parallel, asymmetric read-write costs, breadth-first search, convex hull, list contraction, minimum spanning tree, non-volatile memory, parallel algorithms, tree contraction, work stealing, write-avoiding, write-efficient},\n} \r\n",
        "key": "2935767",
        "pub_year": "2016",
        "text": "Naama Ben-David , Guy E. Blelloch , Jeremy T. Fineman , Phillip B. Gibbons , Yan Gu , Charles McGuffey , Julian Shun, Parallel Algorithms for Asymmetric Read-Write Costs, Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures, July 11-13, 2016, Pacific Grove, California, USA"
    },
    "2935810": {
        "abstract": "The single-source shortest path problem (SSSP) with nonnegative edge weights is notoriously difficult to solve efficiently in parallel---it is one of the graph problems said to suffer from the transitive-closure bottleneck. Yet, in practice, the \u0394-stepping algorithm of Meyer and Sanders (J. Algorithms, 2003) often works efficiently but has no known theoretical bounds on general graphs. The algorithm takes a sequence of steps, each increasing the radius by a user-specified value \u0394. Each step settles the vertices in its annulus but can take \u0398(n) substeps, each requiring \u0398(m) work (n vertices and m edges). Building on the success of \u0394-stepping, this paper describes Radius Stepping, an algorithm with one of the best-known tradeoffs between work and depth bounds for SSSP with nearly-linear (~O(m)) work. The algorithm is a \u0394-stepping-like algorithm but uses a variable instead of a fixed-size increase in radii, allowing us to prove a bound on the number of steps. In particular, by using what we define as a vertex k-radius, each step takes at most k+2 substeps. Furthermore, we define a (k, \u03c1)-graph property and show that if an undirected graph has this property, then the number of steps can be bounded by O(n/\u03c1 log \u03c1 L), for a total of O(kn/\u03c1 log \u03c1 L) substeps, each parallel. We describe how to preprocess a graph to have this property. Altogether, for an arbitrary input graph with n vertices and m edges, Radius Stepping, after preprocessing, takes O((m+n\u03c1)log n) work and $O(n/\u03c1 log n log (\u03c1 L)) depth per source. The preprocessing step takes O(m log n + n\u03c1",
        "acm_key": "2935810",
        "bib_stats": {
            "cites": 0,
            "dl": 72,
            "dl_52": 54,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Izraelevitz:2016:BAP:2935764.2935810,\n author = {Izraelevitz, Joseph and Mendes, Hammurabi and Scott, Michael L.},\n title = {Brief Announcement: Preserving Happens-before in Persistent Memory},\n booktitle = {Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures},\n series = {SPAA '16},\n year = {2016},\n isbn = {978-1-4503-4210-0},\n location = {Pacific Grove, California, USA},\n pages = {157--159},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/2935764.2935810},\n doi = {10.1145/2935764.2935810},\n acmid = {2935810},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {consistency models, nonvolatile memory, persistency models},\n} \r\n",
        "key": "2935810",
        "pub_year": "2016",
        "text": "Joseph Izraelevitz , Hammurabi Mendes , Michael L. Scott, Brief Announcement: Preserving Happens-before in Persistent Memory, Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures, July 11-13, 2016, Pacific Grove, California, USA"
    },
    "2943676": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2943676",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Ramos:2014:RPH:2943462.2943676,\n author = {Ramos, Luiz and Bianchini, Ricardo},\n title = {Robust Performance in Hybrid-memory Cooperative Caches},\n journal = {Parallel Comput.},\n issue_date = {October 2014},\n volume = {40},\n number = {9},\n month = oct,\n year = {2014},\n issn = {0167-8191},\n pages = {514--525},\n numpages = {12},\n url = {http://dx.doi.org/10.1016/j.parco.2014.04.004},\n doi = {10.1016/j.parco.2014.04.004},\n acmid = {2943676},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Cooperative memory caches, Phase-Change Memory},\n} \r\n",
        "key": "2943676",
        "pub_year": "2014",
        "text": "Luiz Ramos , Ricardo Bianchini, Robust performance in hybrid-memory cooperative caches, Parallel Computing, v.40 n.9, p.514-525, October 2014"
    },
    "2944770": {
        "abstract": "Self-powered systems that interact with the physical world require computing platforms with predictable timing behavior and a low energy demand. Energy consumption can be reduced by choosing energy-efficient designs for both hardware and software components of the platform. We leverage the state-of-the-art in hardware design by adopting Heterogeneous Multi-core Processors with support for Dynamic Voltage and Frequency Scaling and Dynamic Power Management. Through experiments on one such platform, we expose the hardware characteristics that violate assumptions of conventional energy models and propose a revised model suitable for identifying the energy-efficient frequency range. We then address the problem of allocating real-time software components onto heterogeneous cores such that total energy is minimized. Our approach is to start from an analytically justified target load distribution and find a task assignment heuristic that approximates it. Our analysis shows that neither balancing the load nor assigning all load to the \"cheapest\" core is the best load distribution strategy, unless the cores are extremely alike or extremely different. The optimal load distribution is then formulated as a solution to a convex optimization problem. A heuristic that approximates this load distribution and an alternative method that leverages the solution explicitly are proposed as viable task assignment methods. The proposed methods are compared to state-of-the-art on simulated problem instances and in a case study of a soft-real-time application on an off-the-shelf ARM big.LITTLE heterogeneous processor.",
        "acm_key": "2944770",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Zhang:2016:EER:2944721.2944770,\n author = {Zhang, Zhiyong and Jia, Zhiping and Liu, Peng and Ju, Lei},\n title = {Energy Efficient Real-Time Task Scheduling for Embedded Systems with Hybrid Main Memory},\n journal = {J. Signal Process. Syst.},\n issue_date = {July      2016},\n volume = {84},\n number = {1},\n month = jul,\n year = {2016},\n issn = {1939-8018},\n pages = {69--89},\n numpages = {21},\n url = {http://dx.doi.org/10.1007/s11265-015-0995-3},\n doi = {10.1007/s11265-015-0995-3},\n acmid = {2944770},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Energy, Hybrid main memory, PCM, Real-time task scheduling},\n} \r\n",
        "key": "2944770",
        "pub_year": "2016",
        "text": "Zhiyong Zhang , Zhiping Jia , Peng Liu , Lei Ju, Energy Efficient Real-Time Task Scheduling for Embedded Systems with Hybrid Main Memory, Journal of Signal Processing Systems, v.84 n.1, p.69-89, July      2016"
    },
    "2947360": {
        "abstract": "A very important challenge in designing through-silicon via (TSV)-based 3D ICs is to accurately estimate, through all stages of the physical design, the interconnect delay which is strongly dependent on the layout of 3D IC. The earlier in the design process and more accurate it can be done; the better design decisions can be made. Incorporating an optimal buffer insertion approach in the early layout design stage can significantly minimize delay and power in 3D circuits. Unlike 2D ICs, buffer insertion in 3D ICs needs careful consideration of additional design constraints in interconnects spanning multiple device layers. In this paper, we propose a novel buffer insertion scheme for delay optimization during 3D floorplanning. For individual 3D nets, the algorithm efficiently computes the desired distance between consecutive buffers (buffer insertion length), which depends on the non-negligible TSV RC delay contribution of the net. This technique of variable buffer insertion length, used during floorplanning, allows optimizing buffers for individual 3D interconnects and reduces overall buffer count by up to 25% and total power consumption by up to 12%. The proposed approach also includes a method for buffer insertion around a TSV, based on the TSV location and its RC delay. Our experiments suggest that the proposed method of buffer planning around TSVs avoids delay violation and reduces delay across TSVs up to 11%, minimizing buffer usage. The paper also analyzes the impact of key parameters such as buffer size and TSV contact resistance on the delay and power dissipation in 3D interconnects.",
        "acm_key": "2947360",
        "bib_stats": {
            "cites": 0,
            "dl": 50,
            "dl_52": 43,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Eken:2016:SAS:2947357.2947360,\n author = {Eken, Enes and Bayram, Ismail and Zhang, Yaojun and Yan, Bonan and Wu, Wenqing and Li, Hai Helen and Chen, Yiran},\n title = {Spin-Hall Assisted STT-RAM Design and Discussion},\n booktitle = {Proceedings of the 18th System Level Interconnect Prediction Workshop},\n series = {SLIP '16},\n year = {2016},\n isbn = {978-1-4503-4430-2},\n location = {Austin, TX, USA},\n pages = {7:1--7:4},\n articleno = {7},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/2947357.2947360},\n doi = {10.1145/2947357.2947360},\n acmid = {2947360},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {SHE-RAM, Spin-Hall Assist, Spintronic},\n} \r\n",
        "key": "2947360",
        "pub_year": "2016",
        "text": "Enes Eken , Ismail Bayram , Yaojun Zhang , Bonan Yan , Wenqing Wu , Hai Helen Li , Yiran Chen, Spin-Hall Assisted STT-RAM Design and Discussion, Proceedings of the 18th System Level Interconnect Prediction Workshop, p.1-4, June 04-04, 2016, Austin, TX, USA"
    },
    "2947658": {
        "abstract": "For decades, various concepts in security monitoring have been proposed. In principle, they all in common in regard to the monitoring of the execution behavior of a program (e.g., control-flow or dataflow) running on the machine to find symptoms of attacks. Among the proposed monitoring schemes, software-based ones are known for their adaptability on the commercial products, but there have been concerns that they may suffer from nonnegligible runtime overhead. On the other hand, hardware-based solutions are recognized for their high performance. However, most of them have an inherent problem in that they usually mandate drastic changes to the internal processor architecture. More recent ones have strived to minimize such modifications by employing external hardware security monitors in the system. However, these approaches intrinsically suffer from the overhead caused by communication between the host and the external monitor. Our solution also relies on external hardware for security monitoring, but unlike the others, ours tackles the communication overhead by using the core debug interface (CDI), which is readily available in most commercial processors for debugging. We build our system simply by plugging our monitoring hardware into the processor via CDI, precluding the need for altering the processor internals. To validate the effectiveness of our approach, we implement two well-known monitoring techniques on our proposed framework: dynamic information flow tracking and branch regulation. The experimental results on our FPGA prototype show that our external hardware monitors efficiently perform monitoring tasks with negligible performance overhead, mainly with thanks to the support of CDI, which helps us reduce communication costs substantially.",
        "acm_key": "2947658",
        "bib_stats": {
            "cites": 0,
            "dl": 86,
            "dl_52": 86,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Wang:2016:ADC:2948199.2947658,\n author = {Wang, Yi and Qin, Zhiwei and Chen, Renhai and Shao, Zili and Yang, Laurence T.},\n title = {An Adaptive Demand-Based Caching Mechanism for NAND Flash Memory Storage Systems},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {December 2016},\n volume = {22},\n number = {1},\n month = dec,\n year = {2016},\n issn = {1084-4309},\n pages = {18:1--18:22},\n articleno = {18},\n numpages = {22},\n url = {http://doi.acm.org/10.1145/2947658},\n doi = {10.1145/2947658},\n acmid = {2947658},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, flash translation layer, garbage collection, on demand, storage systems},\n} \r\n",
        "key": "2947658",
        "pub_year": "2016",
        "text": "Yi Wang , Zhiwei Qin , Renhai Chen , Zili Shao , Laurence T. Yang, An Adaptive Demand-Based Caching Mechanism for NAND Flash Memory Storage Systems, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.22 n.1, p.1-22, December 2016"
    },
    "2950060": {
        "abstract": "Upcoming reconfigurable Multiprocessor Systems-on-Chip (MPSoCs) present new challenges for the design and early estimation of technology requirements due to their runtime adaptive hardware architecture. The usage of simulators offers capabilities to overcome these issues. In this article, MPSoCSim, a SystemC simulator for Network-on-Chip (NoC) based MPSoCs is extended to support the simulation of reconfigurable MPSoCs. Processors, such as ARM and MicroBlaze, and peripheral models used within the virtual platform are provided by Imperas/OVP and attached to the NoC. Moreover, traffic generators are available to analyze the system. The virtual platform currently supports mesh topology with wormhole switching and several routing algorithms such as XY-, a minimal West-First algorithm, and an adaptive West-First algorithm. Amongst the impact of routing algorithms regarding performance, reconfiguration processes can be examined using the presented simulator. A mechanism for dynamic partial reconfiguration is implemented that is oriented towards the reconfiguration scheme on real FPGA platforms. It includes the simulation of the undefined behavior of the hardware region during reconfiguration and allows the adjustment of parameters. During runtime, dynamic partial reconfiguration interfaces are used to connect the Network-on-Chip infrastructure with reconfigurable regions. The configuration access ports can be modeled by the controller for the dynamic partial reconfiguration in form of an application programming interface. An additional SystemC component enables the readout of simulation time from within the application. For evaluation of the simulator timing and power consumption of the simulated hardware are estimated and compared with a real hardware implementation on a Xilinx Zynq FPGA. The comparison shows that the simulator improves the development of reconfigurable MPSoCs by early estimation of system requirements. The power estimations show a maximum deviation of 9mW at 1.9W total power consumption.",
        "acm_key": "2950060",
        "bib_stats": {
            "cites": 0,
            "dl": 65,
            "dl_52": 65,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Kuan:2016:SIS:3008024.2950060,\n author = {Kuan, Yuan-Hung and Chang, Yuan-Hao and Chen, Tseng-Yi and Huang, Po-Chun and Lam, Kam-Yiu},\n title = {Space-Efficient Index Scheme for PCM-Based Multiversion Databases in Cyber-Physical Systems},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {November 2016},\n volume = {16},\n number = {1},\n month = oct,\n year = {2016},\n issn = {1539-9087},\n pages = {21:1--21:26},\n articleno = {21},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/2950060},\n doi = {10.1145/2950060},\n acmid = {2950060},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Multiversion index, cyber-physical systems, embedded database, phase-change memory (PCM)},\n} \r\n",
        "key": "2950060",
        "pub_year": "2016",
        "text": "Yuan-Hung Kuan , Yuan-Hao Chang , Tseng-Yi Chen , Po-Chun Huang , Kam-Yiu Lam, Space-Efficient Index Scheme for PCM-Based Multiversion Databases in Cyber-Physical Systems, ACM Transactions on Embedded Computing Systems (TECS), v.16 n.1, November 2016"
    },
    "2963444": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2963444",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{EnGad:2016:AEC:2963136.2963444,\n author = {En Gad, Eyal and Li, Yue and Kliewer, Jorg and Langberg, Michael and Jiang, Anxiao Andrew and Bruck, Jehoshua},\n title = {Asymmetric Error Correction and Flash-Memory Rewriting Using Polar Codes},\n journal = {IEEE Trans. Inf. Theor.},\n issue_date = {July 2016},\n volume = {62},\n number = {7},\n month = jul,\n year = {2016},\n issn = {0018-9448},\n pages = {4024--4038},\n numpages = {15},\n url = {http://dx.doi.org/10.1109/TIT.2016.2539967},\n doi = {10.1109/TIT.2016.2539967},\n acmid = {2963444},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2963444",
        "pub_year": "2016",
        "text": "Eyal En Gad , Yue Li , Jorg Kliewer , Michael Langberg , Anxiao Andrew Jiang , Jehoshua Bruck, Asymmetric Error Correction and Flash-Memory Rewriting Using Polar Codes, IEEE Transactions on Information Theory, v.62 n.7, p.4024-4038, July 2016"
    },
    "2964267": {
        "abstract": "Non-volatile memories NVMs have emerged as the primary replacement of hard-disk drives for a variety of storage applications, including personal electronics, mobile computing, intelligent vehicles, enterprise storage, data warehousing, and data-intensive computing systems. Channel coding schemes are a necessary tool for ensuring target reliability and performance of NVMs. However, due to operational asymmetries in NVMs, conventional coding approaches - commonly based on designing for the Hamming metric - no longer apply. Given the immediate need for practical solutions and the shortfalls of existing methods, the fast-growing discipline of coding for NVMs has resulted in several key innovations that not only answer the needs of modern storage systems but also directly contribute to the analytical toolbox of coding theory at large. This monograph discusses recent advances in coding for NVMs, covering topics such as error correction coding based on novel algebraic and graph-based methods, rank modulation, rewriting codes, and constrained coding. Our goal for this work is multifold: to illuminate the advantages - as well as challenges - associated with modern NVMs, to present a succinct overview of several exciting recent developments in coding for memories, and, by presenting numerous potential research directions, to inspire other researchers to contribute to this timely and thriving discipline.",
        "acm_key": "2964267",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Dolecek:2016:CCM:2964266.2964267,\n author = {Dolecek, Lara and Sala, Frederic},\n title = {Channel Coding Methods for Non-Volatile Memories},\n journal = {Found. Trends Commun. Inf. Theory},\n issue_date = {2 2016},\n volume = {13},\n number = {1},\n month = feb,\n year = {2016},\n issn = {1567-2190},\n pages = {1--128},\n numpages = {128},\n url = {http://dx.doi.org/10.1561/0100000084},\n doi = {10.1561/0100000084},\n acmid = {2964267},\n publisher = {Now Publishers Inc.},\n address = {Hanover, MA, USA},\n} \r\n",
        "key": "2964267",
        "pub_year": "2016",
        "text": "Lara Dolecek , Frederic Sala, Channel Coding Methods for Non-Volatile Memories, Foundations and Trends in Communications and Information Theory, v.13 n.1, p.1-128, 2 2016"
    },
    "2965102": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2965102",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Pu:2016:NPB:2965088.2965102,\n author = {Pu, Libei and Doshi, Kshitij and Giles, Ellis and Varman, Peter},\n title = {Non-Intrusive Persistence with a Backend NVM Controller},\n journal = {IEEE Comput. Archit. Lett.},\n issue_date = {January 2016},\n volume = {15},\n number = {1},\n month = jan,\n year = {2016},\n issn = {1556-6056},\n pages = {29--32},\n numpages = {4},\n url = {http://dx.doi.org/10.1109/LCA.2015.2443105},\n doi = {10.1109/LCA.2015.2443105},\n acmid = {2965102},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "2965102",
        "pub_year": "2016",
        "text": "Libei Pu , Kshitij Doshi , Ellis Giles , Peter Varman, Non-Intrusive Persistence with a Backend NVM Controller, IEEE Computer Architecture Letters, v.15 n.1, p.29-32, January 2016"
    },
    "2965119": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2965119",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Ha:2016:IAM:2965089.2965119,\n author = {Ha, Keonsoo and Jeong, Jaeyong and Kim, Jihong},\n title = {An Integrated Approach for Managing Read Disturbs in High-Density NAND Flash Memory},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {July 2016},\n volume = {35},\n number = {7},\n month = jul,\n year = {2016},\n issn = {0278-0070},\n pages = {1079--1091},\n numpages = {13},\n url = {https://doi.org/10.1109/TCAD.2015.2504868},\n doi = {10.1109/TCAD.2015.2504868},\n acmid = {2965119},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "2965119",
        "pub_year": "2016",
        "text": "Keonsoo Ha , Jaeyong Jeong , Jihong Kim, An Integrated Approach for Managing Read Disturbs in High-Density NAND Flash Memory, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.35 n.7, p.1079-1091, July 2016"
    },
    "2966990": {
        "abstract": "In this article, we propose a new dynamic reliability management (DRM) techniques at the system level for emerging low power dark silicon manycore microprocessors operating in near-threshold region. We mainly consider the electromigration (EM) failures. To leverage the EM recovery effects, which was ignored in the past, at the system-level, we propose a new equivalent DC current model to consider recovery effects for general time-varying current waveforms so that existing compact EM model can be applied. The new equivalent DC current is calculated in two steps: firstly, the equivalent square waveform is calculated so that peak and terminal stresses are matched, secondly, the parameterized equivalent DC current is derived in terms of the parameters of the periodic fitted square waveforms from the first step. The new recovery EM model can allow EM-induced lifetime to be better managed at the system level. The system level energy optimization problem considering EM lifetime subject to power and performance constraints is framed by seeking the best dark silicon cores' voltage and on/off status. The resulting problem is solved by the State-Action-Reward-State-Action (SARSA) reinforcement learning algorithm. Experimental results on a 64-core near-threshold dark silicon processor show that the new equivalent EM DC currents can fully exhibit the recovery effects at the system-level so that trade-off between EM lifetime and energy/performance can be easily made. We further show that the proposed learning-based energy optimization can effectively manage and optimize energy subject to reliability, given power budget and performance limits. When the recovery effects are considered, the new optimization method can achieve 8.6",
        "acm_key": "2966990",
        "bib_stats": {
            "cites": 1,
            "dl": 64,
            "dl_52": 64,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Abusultan:2016:FDC:2966986.2966990,\n author = {Abusultan, Monther and Khatri, Sunil P.},\n title = {A Flash-based Digital Circuit Design Flow},\n booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},\n series = {ICCAD '16},\n year = {2016},\n isbn = {978-1-4503-4466-1},\n location = {Austin, Texas},\n pages = {6:1--6:6},\n articleno = {6},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2966986.2966990},\n doi = {10.1145/2966986.2966990},\n acmid = {2966990},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {flash-based circuits, logic synthesis},\n} \r\n",
        "key": "2966990",
        "pub_year": "2016",
        "text": "Monther Abusultan , Sunil P. Khatri, A flash-based digital circuit design flow, Proceedings of the 35th International Conference on Computer-Aided Design, p.1-6, November 07-10, 2016, Austin, Texas"
    },
    "2967037": {
        "abstract": "In this article, we propose a new dynamic reliability management (DRM) techniques at the system level for emerging low power dark silicon manycore microprocessors operating in near-threshold region. We mainly consider the electromigration (EM) failures. To leverage the EM recovery effects, which was ignored in the past, at the system-level, we propose a new equivalent DC current model to consider recovery effects for general time-varying current waveforms so that existing compact EM model can be applied. The new equivalent DC current is calculated in two steps: firstly, the equivalent square waveform is calculated so that peak and terminal stresses are matched, secondly, the parameterized equivalent DC current is derived in terms of the parameters of the periodic fitted square waveforms from the first step. The new recovery EM model can allow EM-induced lifetime to be better managed at the system level. The system level energy optimization problem considering EM lifetime subject to power and performance constraints is framed by seeking the best dark silicon cores' voltage and on/off status. The resulting problem is solved by the State-Action-Reward-State-Action (SARSA) reinforcement learning algorithm. Experimental results on a 64-core near-threshold dark silicon processor show that the new equivalent EM DC currents can fully exhibit the recovery effects at the system-level so that trade-off between EM lifetime and energy/performance can be easily made. We further show that the proposed learning-based energy optimization can effectively manage and optimize energy subject to reliability, given power budget and performance limits. When the recovery effects are considered, the new optimization method can achieve 8.6",
        "acm_key": "2967037",
        "bib_stats": {
            "cites": 1,
            "dl": 117,
            "dl_52": 117,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Yin:2016:EFF:2966986.2967037,\n author = {Yin, Xunzhao and Aziz, Ahmedullah and Nahas, Joseph and Datta, Suman and Gupta, Sumeet and Niemier, Michael and Hu, Xiaobo Sharon},\n title = {Exploiting Ferroelectric FETs for Low-power Non-volatile Logic-in-memory Circuits},\n booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},\n series = {ICCAD '16},\n year = {2016},\n isbn = {978-1-4503-4466-1},\n location = {Austin, Texas},\n pages = {121:1--121:8},\n articleno = {121},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2966986.2967037},\n doi = {10.1145/2966986.2967037},\n acmid = {2967037},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2967037",
        "pub_year": "2016",
        "text": "Xunzhao Yin , Ahmedullah Aziz , Joseph Nahas , Suman Datta , Sumeet Gupta , Michael Niemier , Xiaobo Sharon Hu, Exploiting ferroelectric FETs for low-power non-volatile logic-in-memory circuits, Proceedings of the 35th International Conference on Computer-Aided Design, p.1-8, November 07-10, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2967059": {
        "abstract": "In this article, we propose a new dynamic reliability management (DRM) techniques at the system level for emerging low power dark silicon manycore microprocessors operating in near-threshold region. We mainly consider the electromigration (EM) failures. To leverage the EM recovery effects, which was ignored in the past, at the system-level, we propose a new equivalent DC current model to consider recovery effects for general time-varying current waveforms so that existing compact EM model can be applied. The new equivalent DC current is calculated in two steps: firstly, the equivalent square waveform is calculated so that peak and terminal stresses are matched, secondly, the parameterized equivalent DC current is derived in terms of the parameters of the periodic fitted square waveforms from the first step. The new recovery EM model can allow EM-induced lifetime to be better managed at the system level. The system level energy optimization problem considering EM lifetime subject to power and performance constraints is framed by seeking the best dark silicon cores' voltage and on/off status. The resulting problem is solved by the State-Action-Reward-State-Action (SARSA) reinforcement learning algorithm. Experimental results on a 64-core near-threshold dark silicon processor show that the new equivalent EM DC currents can fully exhibit the recovery effects at the system-level so that trade-off between EM lifetime and energy/performance can be easily made. We further show that the proposed learning-based energy optimization can effectively manage and optimize energy subject to reliability, given power budget and performance limits. When the recovery effects are considered, the new optimization method can achieve 8.6",
        "acm_key": "2967059",
        "bib_stats": {
            "cites": 0,
            "dl": 158,
            "dl_52": 158,
            "dl_6": 10
        },
        "bibtex": "\r\n@inproceedings{Li:2016:NCS:2966986.2967059,\n author = {Li, Shuangchen and Liu, Liu and Gu, Peng and Xu, Cong and Xie, Yuan},\n title = {NVSim-CAM: A Circuit-level Simulator for Emerging Nonvolatile Memory Based Content-addressable Memory},\n booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},\n series = {ICCAD '16},\n year = {2016},\n isbn = {978-1-4503-4466-1},\n location = {Austin, Texas},\n pages = {2:1--2:7},\n articleno = {2},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2966986.2967059},\n doi = {10.1145/2966986.2967059},\n acmid = {2967059},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2967059",
        "pub_year": "2016",
        "text": "Shuangchen Li , Liu Liu , Peng Gu , Cong Xu , Yuan Xie, NVSim-CAM: a circuit-level simulator for emerging nonvolatile memory based content-addressable memory, Proceedings of the 35th International Conference on Computer-Aided Design, p.1-7, November 07-10, 2016, Austin, Texas"
    },
    "2967060": {
        "abstract": "In this article, we propose a new dynamic reliability management (DRM) techniques at the system level for emerging low power dark silicon manycore microprocessors operating in near-threshold region. We mainly consider the electromigration (EM) failures. To leverage the EM recovery effects, which was ignored in the past, at the system-level, we propose a new equivalent DC current model to consider recovery effects for general time-varying current waveforms so that existing compact EM model can be applied. The new equivalent DC current is calculated in two steps: firstly, the equivalent square waveform is calculated so that peak and terminal stresses are matched, secondly, the parameterized equivalent DC current is derived in terms of the parameters of the periodic fitted square waveforms from the first step. The new recovery EM model can allow EM-induced lifetime to be better managed at the system level. The system level energy optimization problem considering EM lifetime subject to power and performance constraints is framed by seeking the best dark silicon cores' voltage and on/off status. The resulting problem is solved by the State-Action-Reward-State-Action (SARSA) reinforcement learning algorithm. Experimental results on a 64-core near-threshold dark silicon processor show that the new equivalent EM DC currents can fully exhibit the recovery effects at the system-level so that trade-off between EM lifetime and energy/performance can be easily made. We further show that the proposed learning-based energy optimization can effectively manage and optimize energy subject to reliability, given power budget and performance limits. When the recovery effects are considered, the new optimization method can achieve 8.6",
        "acm_key": "2967060",
        "bib_stats": {
            "cites": 0,
            "dl": 65,
            "dl_52": 65,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Xue:2016:ONC:2966986.2967060,\n author = {Xue, Linuo and Cheng, Yuanqing and Yang, Jianlei and Wang, Peiyuan and Xie, Yuan},\n title = {ODESY: A Novel 3T-3MTJ Cell Design with Optimized Area DEnsity, Scalability and latencY},\n booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},\n series = {ICCAD '16},\n year = {2016},\n isbn = {978-1-4503-4466-1},\n location = {Austin, Texas},\n pages = {118:1--118:8},\n articleno = {118},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2966986.2967060},\n doi = {10.1145/2966986.2967060},\n acmid = {2967060},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2967060",
        "pub_year": "2016",
        "text": "Linuo Xue , Yuanqing Cheng , Jianlei Yang , Peiyuan Wang , Yuan Xie, ODESY: a novel 3T-3MTJ cell design with optimized area DEnsity, scalability and latencY, Proceedings of the 35th International Conference on Computer-Aided Design, p.1-8, November 07-10, 2016, Austin, Texas"
    },
    "2967074": {
        "abstract": "In this article, we propose a new dynamic reliability management (DRM) techniques at the system level for emerging low power dark silicon manycore microprocessors operating in near-threshold region. We mainly consider the electromigration (EM) failures. To leverage the EM recovery effects, which was ignored in the past, at the system-level, we propose a new equivalent DC current model to consider recovery effects for general time-varying current waveforms so that existing compact EM model can be applied. The new equivalent DC current is calculated in two steps: firstly, the equivalent square waveform is calculated so that peak and terminal stresses are matched, secondly, the parameterized equivalent DC current is derived in terms of the parameters of the periodic fitted square waveforms from the first step. The new recovery EM model can allow EM-induced lifetime to be better managed at the system level. The system level energy optimization problem considering EM lifetime subject to power and performance constraints is framed by seeking the best dark silicon cores' voltage and on/off status. The resulting problem is solved by the State-Action-Reward-State-Action (SARSA) reinforcement learning algorithm. Experimental results on a 64-core near-threshold dark silicon processor show that the new equivalent EM DC currents can fully exhibit the recovery effects at the system-level so that trade-off between EM lifetime and energy/performance can be easily made. We further show that the proposed learning-based energy optimization can effectively manage and optimize energy subject to reliability, given power budget and performance limits. When the recovery effects are considered, the new optimization method can achieve 8.6",
        "acm_key": "2967074",
        "bib_stats": {
            "cites": 1,
            "dl": 117,
            "dl_52": 117,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Yang:2016:SNC:2966986.2967074,\n author = {Yang, Chaofei and Liu, Beiye and Li, Hai and Chen, Yiran and Wen, Wujie and Barnell, Mark and Wu, Qing and Rajendran, Jeyavijayan},\n title = {Security of Neuromorphic Computing: Thwarting Learning Attacks Using Memristor's Obsolescence Effect},\n booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},\n series = {ICCAD '16},\n year = {2016},\n isbn = {978-1-4503-4466-1},\n location = {Austin, Texas},\n pages = {97:1--97:6},\n articleno = {97},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2966986.2967074},\n doi = {10.1145/2966986.2967074},\n acmid = {2967074},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2967074",
        "pub_year": "2016",
        "text": "Chaofei Yang , Beiye Liu , Hai Li , Yiran Chen , Wujie Wen , Mark Barnell , Qing Wu , Jeyavijayan Rajendran, Security of neuromorphic computing: thwarting learning attacks using memristor's obsolescence effect, Proceedings of the 35th International Conference on Computer-Aided Design, p.1-6, November 07-10, 2016, Austin, Texas  \u00a0[doi>"
    },
    "2967374": {
        "abstract": "3D printing is an emerging technique in product manufacturing. Its applications have been expanding vastly in home-based production. Compared to traditional manufacturing techniques, such as Computerized Numeric Control (CNC) machine tools, it is believed that 3D printing is more cost-effective in fabricating personalized products. The product cost estimation in 3D printing mainly takes material expenditure into account, and extensive studies have been performed for reducing filament expense or development of recyclable filaments. However, electricity expenditure is another inevitable cost in the 3D printing process yet an omitted factor in the cost estimation. To this end, this paper introduces the first in-depth study to understand the energy consumption in 3D printing. Specifically, our study comprises of two parts. The first part quantifies both material and electricity use in the 3D printing, and find that the electricity takes upto 32% of the total cost. The second part characterizes the energy consumption and identifies the sensitivity of various parameters. We also share insights and potential solutions to optimize the power consumption of 3D printers.",
        "acm_key": "2967374",
        "bib_stats": {
            "cites": 0,
            "dl": 248,
            "dl_52": 248,
            "dl_6": 18
        },
        "bibtex": "\r\n@inproceedings{Wu:2016:NNK:2967360.2967374,\n author = {Wu, Xingbo and Ni, Fan and Zhang, Li and Wang, Yandong and Ren, Yufei and Hack, Michel and Shao, Zili and Jiang, Song},\n title = {NVMcached: An NVM-based Key-Value Cache},\n booktitle = {Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems},\n series = {APSys '16},\n year = {2016},\n isbn = {978-1-4503-4265-0},\n location = {Hong Kong, Hong Kong},\n pages = {18:1--18:7},\n articleno = {18},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/2967360.2967374},\n doi = {10.1145/2967360.2967374},\n acmid = {2967374},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2967374",
        "pub_year": "2016",
        "text": "Xingbo Wu , Fan Ni , Li Zhang , Yandong Wang , Yufei Ren , Michel Hack , Zili Shao , Song Jiang, NVMcached: An NVM-based Key-Value Cache, Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems, August 04-05, 2016, Hong Kong, Hong Kong"
    },
    "2967953": {
        "abstract": "Dynamic task-parallel programming models are popular on shared-memory systems, promising enhanced scalability, load balancing and locality. Yet these promises are undermined by non-uniform memory access (NUMA). We show that using NUMA-aware task and data placement, it is possible to preserve the uniform abstraction of both computing and memory resources for task-parallel programming models while achieving high data locality. Our data placement scheme guarantees that all accesses to task output data target the local memory of the accessing core. The complementary task placement heuristic improves the locality of task input data on a best effort basis. Our algorithms take advantage of data-flow style task parallelism, where the privatization of task data enhances scalability by eliminating false dependences and enabling fine-grained dynamic control over data placement. The algorithms are fully automatic, application-independent, performance-portable across NUMA machines, and adapt to dynamic changes. Placement decisions use information about inter-task data dependences readily available in the run-time system and placement information from the operating system. We achieve 94% of local memory accesses on a 192-core system with 24 NUMA nodes, up to 5x higher performance than NUMA-aware hierarchical work-stealing, and even 5.6x compared to static interleaved allocation. Finally, we show that state-of-the-art dynamic page migration by the operating system cannot catch up with frequent affinity changes between cores and data and thus fails to accelerate task-parallel applications.",
        "acm_key": "2967953",
        "bib_stats": {
            "cites": 1,
            "dl": 224,
            "dl_52": 224,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Kannan:2016:EAP:2967938.2967953,\n author = {Kannan, Sudarsun and Qureshi, Moinuddin and Gavrilovska, Ada and Schwan, Karsten},\n title = {Energy Aware Persistence: Reducing Energy Overheads of Memory-based Persistence in NVMs},\n booktitle = {Proceedings of the 2016 International Conference on Parallel Architectures and Compilation},\n series = {PACT '16},\n year = {2016},\n isbn = {978-1-4503-4121-9},\n location = {Haifa, Israel},\n pages = {165--177},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/2967938.2967953},\n doi = {10.1145/2967938.2967953},\n acmid = {2967953},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {acid, end-user device, energy overheads, heap-based persistence, logging, memory-persistence, nvm, storage},\n} \r\n",
        "key": "2967953",
        "pub_year": "2016",
        "text": "Sudarsun Kannan , Moinuddin Qureshi , Ada Gavrilovska , Karsten Schwan, Energy Aware Persistence: Reducing Energy Overheads of Memory-based Persistence in NVMs, Proceedings of the 2016 International Conference on Parallel Architectures and Compilation, September 11-15, 2016, Haifa, Israel"
    },
    "2968462": {
        "abstract": "Deep Neural Networks (DNNs) are a set of powerful yet computationally complex learning mechanisms that are projected to dominate various artificial intelligence and massive data analytic domains. Physical viability, such as timing, memory, or energy efficiency, are standing challenges in realizing the true potential of DNNs. We propose DeLight, a set of novel methodologies which aim to bring physical constraints as design parameters in the training and execution of DNN architectures. We use physical profiling to bound the network size in accordance to the pertinent platform's characteristics. An automated customization methodology is proposed to adaptively conform the DNN configurations to meet the characterization of the underlying hardware while minimally affecting the inference accuracy. The key to our approach is a new content- and resource-aware transformation of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data transformation to enable the training of multiple DNN architectures that can be aggregated to further boost the inference accuracy. An accompanying API is also developed, which can be used for rapid prototyping of an arbitrary DNN application customized to the platform. Proof-of concept evaluations for deployment of different imaging, audio, and smart-sensing applications demonstrate up to 100-fold performance improvement compared to the state-of-the-art DNN solutions.",
        "acm_key": "2968462",
        "bib_stats": {
            "cites": 1,
            "dl": 73,
            "dl_52": 73,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Chang:2016:RES:2968456.2968462,\n author = {Chang, Yu-Ming and Li, Yung-Chun and Lin, Ping-Hsien and Li, Hsiang-Pang and Chang, Yuan-Hao},\n title = {Realizing Erase-free SLC Flash Memory with Rewritable Programming Design},\n booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '16},\n year = {2016},\n isbn = {978-1-4503-4483-8},\n location = {Pittsburgh, Pennsylvania},\n pages = {7:1--7:10},\n articleno = {7},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968456.2968462},\n doi = {10.1145/2968456.2968462},\n acmid = {2968462},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2968462",
        "pub_year": "2016",
        "text": "Yu-Ming Chang , Yung-Chun Li , Ping-Hsien Lin , Hsiang-Pang Li , Yuan-Hao Chang, Realizing erase-free SLC flash memory with rewritable programming design, Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania  \u00a0[doi>"
    },
    "2968465": {
        "abstract": "Deep Neural Networks (DNNs) are a set of powerful yet computationally complex learning mechanisms that are projected to dominate various artificial intelligence and massive data analytic domains. Physical viability, such as timing, memory, or energy efficiency, are standing challenges in realizing the true potential of DNNs. We propose DeLight, a set of novel methodologies which aim to bring physical constraints as design parameters in the training and execution of DNN architectures. We use physical profiling to bound the network size in accordance to the pertinent platform's characteristics. An automated customization methodology is proposed to adaptively conform the DNN configurations to meet the characterization of the underlying hardware while minimally affecting the inference accuracy. The key to our approach is a new content- and resource-aware transformation of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data transformation to enable the training of multiple DNN architectures that can be aggregated to further boost the inference accuracy. An accompanying API is also developed, which can be used for rapid prototyping of an arbitrary DNN application customized to the platform. Proof-of concept evaluations for deployment of different imaging, audio, and smart-sensing applications demonstrate up to 100-fold performance improvement compared to the state-of-the-art DNN solutions.",
        "acm_key": "2968465",
        "bib_stats": {
            "cites": 1,
            "dl": 74,
            "dl_52": 74,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Guo:2016:DRW:2968456.2968465,\n author = {Guo, Jie and Min, Chuhan and Cai, Tao and Chen, Yiran},\n title = {A Design to Reduce Write Amplification in Object-based NAND Flash Devices},\n booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '16},\n year = {2016},\n isbn = {978-1-4503-4483-8},\n location = {Pittsburgh, Pennsylvania},\n pages = {5:1--5:10},\n articleno = {5},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968456.2968465},\n doi = {10.1145/2968456.2968465},\n acmid = {2968465},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memories, write amplification},\n} \r\n",
        "key": "2968465",
        "pub_year": "2016",
        "text": "Jie Guo , Chuhan Min , Tao Cai , Yiran Chen, A design to reduce write amplification in object-based NAND flash devices, Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2968466": {
        "abstract": "Deep Neural Networks (DNNs) are a set of powerful yet computationally complex learning mechanisms that are projected to dominate various artificial intelligence and massive data analytic domains. Physical viability, such as timing, memory, or energy efficiency, are standing challenges in realizing the true potential of DNNs. We propose DeLight, a set of novel methodologies which aim to bring physical constraints as design parameters in the training and execution of DNN architectures. We use physical profiling to bound the network size in accordance to the pertinent platform's characteristics. An automated customization methodology is proposed to adaptively conform the DNN configurations to meet the characterization of the underlying hardware while minimally affecting the inference accuracy. The key to our approach is a new content- and resource-aware transformation of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data transformation to enable the training of multiple DNN architectures that can be aggregated to further boost the inference accuracy. An accompanying API is also developed, which can be used for rapid prototyping of an arbitrary DNN application customized to the platform. Proof-of concept evaluations for deployment of different imaging, audio, and smart-sensing applications demonstrate up to 100-fold performance improvement compared to the state-of-the-art DNN solutions.",
        "acm_key": "2968466",
        "bib_stats": {
            "cites": 0,
            "dl": 77,
            "dl_52": 77,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Chang:2016:DSD:2968456.2968466,\n author = {Chang, Hung-Sheng and Chang, Yuan-Hao and Kuo, Tei-Wei and Chang, Yu-Ming and Li, Hsiang-Pang},\n title = {A Disturbance-aware Sub-block Design to Improve Reliability of 3D MLC Flash Memory},\n booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '16},\n year = {2016},\n isbn = {978-1-4503-4483-8},\n location = {Pittsburgh, Pennsylvania},\n pages = {20:1--20:10},\n articleno = {20},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968456.2968466},\n doi = {10.1145/2968456.2968466},\n acmid = {2968466},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2968466",
        "pub_year": "2016",
        "text": "Hung-Sheng Chang , Yuan-Hao Chang , Tei-Wei Kuo , Yu-Ming Chang , Hsiang-Pang Li, A disturbance-aware sub-block design to improve reliability of 3D MLC flash memory, Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2968475": {
        "abstract": "Deep Neural Networks (DNNs) are a set of powerful yet computationally complex learning mechanisms that are projected to dominate various artificial intelligence and massive data analytic domains. Physical viability, such as timing, memory, or energy efficiency, are standing challenges in realizing the true potential of DNNs. We propose DeLight, a set of novel methodologies which aim to bring physical constraints as design parameters in the training and execution of DNN architectures. We use physical profiling to bound the network size in accordance to the pertinent platform's characteristics. An automated customization methodology is proposed to adaptively conform the DNN configurations to meet the characterization of the underlying hardware while minimally affecting the inference accuracy. The key to our approach is a new content- and resource-aware transformation of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data transformation to enable the training of multiple DNN architectures that can be aggregated to further boost the inference accuracy. An accompanying API is also developed, which can be used for rapid prototyping of an arbitrary DNN application customized to the platform. Proof-of concept evaluations for deployment of different imaging, audio, and smart-sensing applications demonstrate up to 100-fold performance improvement compared to the state-of-the-art DNN solutions.",
        "acm_key": "2968475",
        "bib_stats": {
            "cites": 0,
            "dl": 66,
            "dl_52": 66,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Chang:2016:ESI:2968456.2968475,\n author = {Chang, Hsin-Yu and Ho, Chien-Chung and Chang, Yuan-Hao and Chang, Yu-Ming and Kuo, Tei-Wei},\n title = {How to Enable Software Isolation and Boost System Performance with Sub-block Erase over 3D Flash Memory},\n booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '16},\n year = {2016},\n isbn = {978-1-4503-4483-8},\n location = {Pittsburgh, Pennsylvania},\n pages = {6:1--6:10},\n articleno = {6},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968456.2968475},\n doi = {10.1145/2968456.2968475},\n acmid = {2968475},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2968475",
        "pub_year": "2016",
        "text": "Hsin-Yu Chang , Chien-Chung Ho , Yuan-Hao Chang , Yu-Ming Chang , Tei-Wei Kuo, How to enable software isolation and boost system performance with sub-block erase over 3D flash memory, Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2968477": {
        "abstract": "Deep Neural Networks (DNNs) are a set of powerful yet computationally complex learning mechanisms that are projected to dominate various artificial intelligence and massive data analytic domains. Physical viability, such as timing, memory, or energy efficiency, are standing challenges in realizing the true potential of DNNs. We propose DeLight, a set of novel methodologies which aim to bring physical constraints as design parameters in the training and execution of DNN architectures. We use physical profiling to bound the network size in accordance to the pertinent platform's characteristics. An automated customization methodology is proposed to adaptively conform the DNN configurations to meet the characterization of the underlying hardware while minimally affecting the inference accuracy. The key to our approach is a new content- and resource-aware transformation of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data transformation to enable the training of multiple DNN architectures that can be aggregated to further boost the inference accuracy. An accompanying API is also developed, which can be used for rapid prototyping of an arbitrary DNN application customized to the platform. Proof-of concept evaluations for deployment of different imaging, audio, and smart-sensing applications demonstrate up to 100-fold performance improvement compared to the state-of-the-art DNN solutions.",
        "acm_key": "2968477",
        "bib_stats": {
            "cites": 0,
            "dl": 146,
            "dl_52": 146,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Xie:2016:CAH:2968456.2968477,\n author = {Xie, Mimi and Zhao, Mengying and Pan, Chen and Li, Hehe and Liu, Yongpan and Zhang, Youtao and Xue, Chun Jason and Hu, Jingtong},\n title = {Checkpoint Aware Hybrid Cache Architecture for NV Processor in Energy Harvesting Powered Systems},\n booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},\n series = {CODES '16},\n year = {2016},\n isbn = {978-1-4503-4483-8},\n location = {Pittsburgh, Pennsylvania},\n pages = {22:1--22:10},\n articleno = {22},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968456.2968477},\n doi = {10.1145/2968456.2968477},\n acmid = {2968477},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {IoT, checkpointing, energy harvesting, hybrid cache, non-volatile processor},\n} \r\n",
        "key": "2968477",
        "pub_year": "2016",
        "text": "Mimi Xie , Mengying Zhao , Chen Pan , Hehe Li , Yongpan Liu , Youtao Zhang , Chun Jason Xue , Jingtong Hu, Checkpoint aware hybrid cache architecture for NV processor in energy harvesting powered systems, Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2968497": {
        "abstract": "Time-triggered (TT) switched networks are a deterministic communication infrastructure used by real-time distributed embedded systems. These networks rely on the notion of globally discretized time (i.e. time slots) and a static TT schedule that prescribes which message is sent through which link at every time slot, such that all messages reach their destination before a global timeout. These schedules are generated offline, assuming a static network with fault-free links, and entrusting all error-handling functions to the end user. Assuming the network is static is an over-optimistic view, and indeed links tend to fail in practice. We study synthesis of TT schedules on a network in which links fail over time and we assume the switches run a very simple error-recovery protocol once they detect a crashed link. We address the problem of finding a (\u03ba, &ell;)-resistant schedule; namely, one that, assuming the switches run a fixed error-recovery protocol, guarantees that the number of messages that arrive at their destination by the timeout is at least &ell;, no matter what sequence of at most \u03ba links fail. Thus, we maintain the simplicity of the switches while giving a guarantee on the number of messages that meet the timeout. We show how a (\u03ba, &ell;)-resistant schedule can be obtained using a CEGAR-like approach: find a schedule, decide whether it is (\u03ba, &ell;)-resistant, and if it is not, use the witnessing fault sequence to generate a constraint that is added to the program. The newly added constraint disallows the schedule to be regenerated in a future iteration while also eliminating several other schedules that are not (\u03ba, &ell;)-resistant. We illustrate the applicability of our approach using an SMT-based implementation.",
        "acm_key": "2968497",
        "bib_stats": {
            "cites": 0,
            "dl": 62,
            "dl_52": 62,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:DES:2968478.2968497,\n author = {Chen, Xianzhang and Sha, Edwin H.-M. and Jiang, Weiwen and Zhuge, Qingfeng and Chen, Junxi and Qin, Jiejie and Zeng, Yuansong},\n title = {The Design of an Efficient Swap Mechanism for Hybrid DRAM-NVM Systems},\n booktitle = {Proceedings of the 13th International Conference on Embedded Software},\n series = {EMSOFT '16},\n year = {2016},\n isbn = {978-1-4503-4485-2},\n location = {Pittsburgh, Pennsylvania},\n pages = {22:1--22:10},\n articleno = {22},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968478.2968497},\n doi = {10.1145/2968478.2968497},\n acmid = {2968497},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2968497",
        "pub_year": "2016",
        "text": "Xianzhang Chen , Edwin H.-M. Sha , Weiwen Jiang , Qingfeng Zhuge , Junxi Chen , Jiejie Qin , Yuansong Zeng, The design of an efficient swap mechanism for hybrid DRAM-NVM systems, Proceedings of the 13th International Conference on Embedded Software, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2968503": {
        "abstract": "Time-triggered (TT) switched networks are a deterministic communication infrastructure used by real-time distributed embedded systems. These networks rely on the notion of globally discretized time (i.e. time slots) and a static TT schedule that prescribes which message is sent through which link at every time slot, such that all messages reach their destination before a global timeout. These schedules are generated offline, assuming a static network with fault-free links, and entrusting all error-handling functions to the end user. Assuming the network is static is an over-optimistic view, and indeed links tend to fail in practice. We study synthesis of TT schedules on a network in which links fail over time and we assume the switches run a very simple error-recovery protocol once they detect a crashed link. We address the problem of finding a (\u03ba, &ell;)-resistant schedule; namely, one that, assuming the switches run a fixed error-recovery protocol, guarantees that the number of messages that arrive at their destination by the timeout is at least &ell;, no matter what sequence of at most \u03ba links fail. Thus, we maintain the simplicity of the switches while giving a guarantee on the number of messages that meet the timeout. We show how a (\u03ba, &ell;)-resistant schedule can be obtained using a CEGAR-like approach: find a schedule, decide whether it is (\u03ba, &ell;)-resistant, and if it is not, use the witnessing fault sequence to generate a constraint that is added to the program. The newly added constraint disallows the schedule to be regenerated in a future iteration while also eliminating several other schedules that are not (\u03ba, &ell;)-resistant. We illustrate the applicability of our approach using an SMT-based implementation.",
        "acm_key": "2968503",
        "bib_stats": {
            "cites": 0,
            "dl": 87,
            "dl_52": 87,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Ji:2016:ISM:2968478.2968503,\n author = {Ji, Cheng and Wu, Chao and Chang, Li-Pin and Shi, Liang and Xue, Chun Jason},\n title = {I/O Scheduling with Mapping Cache Awareness for Flash Based Storage Systems},\n booktitle = {Proceedings of the 13th International Conference on Embedded Software},\n series = {EMSOFT '16},\n year = {2016},\n isbn = {978-1-4503-4485-2},\n location = {Pittsburgh, Pennsylvania},\n pages = {21:1--21:10},\n articleno = {21},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2968478.2968503},\n doi = {10.1145/2968478.2968503},\n acmid = {2968503},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2968503",
        "pub_year": "2016",
        "text": "Cheng Ji , Chao Wu , Li-Pin Chang , Liang Shi , Chun Jason Xue, I/O scheduling with mapping cache awareness for flash based storage systems, Proceedings of the 13th International Conference on Embedded Software, p.1-10, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2971897": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2971897",
        "bib_stats": {
            "cites": 1,
            "dl": 5,
            "dl_52": 3,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Di:2016:EPV:2971808.2971897,\n author = {Di, Yejia and Shi, Liang and Wu, Kaijie and Xue, Chun Jason},\n title = {Exploiting Process Variation for Retention Induced Refresh Minimization on Flash Memory},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {391--396},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2971897},\n acmid = {2971897},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2971897",
        "pub_year": "2016",
        "text": "Yejia Di , Liang Shi , Kaijie Wu , Chun Jason Xue, Exploiting process variation for retention induced refresh minimization on flash memory, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2971917": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2971917",
        "bib_stats": {
            "cites": 3,
            "dl": 7,
            "dl_52": 6,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Xia:2016:MSP:2971808.2971917,\n author = {Xia, Lixue and Li, Boxun and Tang, Tianqi and Gu, Peng and Yin, Xiling and Huangfu, Wenqin and Chen, Pai-Yu and Yu, Shimeng and Cao, Yu and Wang, Yu and Xie, Yuan and Yang, Huazhong},\n title = {MNSIM: Simulation Platform for Memristor-based Neuromorphic Computing System},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {469--474},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2971917},\n acmid = {2971917},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2971917",
        "pub_year": "2016",
        "text": "Lixue Xia , Boxun Li , Tianqi Tang , Peng Gu , Xiling Yin , Wenqin Huangfu , Pai-Yu Chen , Shimeng Yu , Yu Cao , Yu Wang , Yuan Xie , Huazhong Yang, MNSIM: simulation platform for memristor-based neuromorphic computing system, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2971982": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2971982",
        "bib_stats": {
            "cites": 2,
            "dl": 13,
            "dl_52": 12,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:LAR:2971808.2971982,\n author = {Zhang, Hang and Xiao, Nong and Liu, Fang and Chen, Zhiguang},\n title = {Leader: Accelerating Reram-based Main Memory by Leveraging Access Latency Discrepancy in Crossbar Arrays},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {756--761},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2971982},\n acmid = {2971982},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2971982",
        "pub_year": "2016",
        "text": "Hang Zhang , Nong Xiao , Fang Liu , Zhiguang Chen, Leader: accelerating reram-based main memory by leveraging access latency discrepancy in crossbar arrays, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2971983": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2971983",
        "bib_stats": {
            "cites": 0,
            "dl": 4,
            "dl_52": 3,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wang:2016:SBA:2971808.2971983,\n author = {Wang, Xue and Mao, Mengjie and Eken, Enes and Wen, Wujie and Li, Hai and Chen, Yiran},\n title = {Sliding Basket: An Adaptive ECC Scheme for Runtime Write Failure Suppression of STT-RAM Cache},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {762--767},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2971983},\n acmid = {2971983},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2971983",
        "pub_year": "2016",
        "text": "Xue Wang , Mengjie Mao , Enes Eken , Wujie Wen , Hai Li , Yiran Chen, Sliding basket: an adaptive ECC scheme for runtime write failure suppression of STT-RAM cache, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2971984": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2971984",
        "bib_stats": {
            "cites": 1,
            "dl": 16,
            "dl_52": 15,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Li:2016:EMP:2971808.2971984,\n author = {Li, Zheng and Wang, Fang and Hua, Yu and Tong, Wei and Liu, Jingning and Chen, Yu and Feng, Dan},\n title = {Exploiting More Parallelism from Write Operations on PCM},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {768--773},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2971984},\n acmid = {2971984},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n keywords = {PCM, write energy, write performance},\n} \r\n",
        "key": "2971984",
        "pub_year": "2016",
        "text": "Zheng Li , Fang Wang , Yu Hua , Wei Tong , Jingning Liu , Yu Chen , Dan Feng, Exploiting more parallelism from write operations on PCM, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972024": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972024",
        "bib_stats": {
            "cites": 0,
            "dl": 25,
            "dl_52": 23,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Salkhordeh:2016:OSL:2971808.2972024,\n author = {Salkhordeh, Reza and Asadi, Hossein},\n title = {An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {936--941},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972024},\n acmid = {2972024},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972024",
        "pub_year": "2016",
        "text": "Reza Salkhordeh , Hossein Asadi, An operating system level data migration scheme in hybrid DRAM-NVM memory architecture, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972025": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972025",
        "bib_stats": {
            "cites": 1,
            "dl": 24,
            "dl_52": 22,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:UDN:2971808.2972025,\n author = {Zhang, Zhiyong and Ju, Lei and Jia, Zhiping},\n title = {Unified DRAM and NVM Hybrid Buffer Cache Architecture for Reducing Journaling Overhead},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {942--947},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972025},\n acmid = {2972025},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972025",
        "pub_year": "2016",
        "text": "Zhiyong Zhang , Lei Ju , Zhiping Jia, Unified DRAM and NVM hybrid buffer cache architecture for reducing journaling overhead, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972068": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972068",
        "bib_stats": {
            "cites": 0,
            "dl": 3,
            "dl_52": 2,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Jalili:2016:CRP:2971808.2972068,\n author = {Jalili, Majid and Sarbazi-Azad, Hamid},\n title = {Captopril: Reducing the Pressure of Bit Flips on Hot Locations in Non-volatile Main Memories},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {1116--1119},\n numpages = {4},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972068},\n acmid = {2972068},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972068",
        "pub_year": "2016",
        "text": "Majid Jalili , Hamid Sarbazi-Azad, Captopril: reducing the pressure of bit flips on hot locations in non-volatile main memories, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972101": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972101",
        "bib_stats": {
            "cites": 2,
            "dl": 2,
            "dl_52": 1,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Liu:2016:MMC:2971808.2972101,\n author = {Liu, Ming and Jun, Sang-Woo and Lee, Sungjin and Hicks, Jamey and Arvind},\n title = {minFlash: A Minimalistic Clustered Flash Array},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {1255--1260},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972101},\n acmid = {2972101},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972101",
        "pub_year": "2016",
        "text": "Ming Liu , Sang-Woo Jun , Sungjin Lee , Jamey Hicks , Arvind, minFlash: a minimalistic clustered flash array, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972108": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972108",
        "bib_stats": {
            "cites": 1,
            "dl": 4,
            "dl_52": 4,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wen:2016:HTM:2971808.2972108,\n author = {Wen, Wujie and Mao, Mengjie and Li, Hai and Chen, Yiran and Pei, Yukui and Ge, Ning},\n title = {A Holistic Tri-region MLC STT-RAM Design with Combined Performance, Energy, and Reliability Optimizations},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {1285--1290},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972108},\n acmid = {2972108},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972108",
        "pub_year": "2016",
        "text": "Wujie Wen , Mengjie Mao , Hai Li , Yiran Chen , Yukui Pei , Ning Ge, A holistic tri-region MLC STT-RAM design with combined performance, energy, and reliability optimizations, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2972173": {
        "abstract": "Multilayered artificial neural networks have found widespread utility in classification and recognition applications. The scale and complexity of such networks together with the inadequacies of general purpose computing platforms have led to a significant interest in the development of efficient hardware implementations. In this work, we focus on designing energy-efficient on-chip storage for the synaptic weights, motivated primarily by the observation that the number of synapses is orders of magnitude larger than the number of neurons. Typical digital CMOS implementations of such large-scale networks are power hungry. In order to minimize the power consumption, the digital neurons could be operated reliably at scaled voltages by reducing the clock frequency. On the contrary, the on-chip synaptic storage designed using a conventional 6T SRAM is susceptible to bitcell failures at reduced voltages. However, the intrinsic error resiliency of neural networks to small synaptic weight perturbations enables us to scale the operating voltage of the 6T SRAM. Our analysis on a widely used digit recognition dataset indicates that the voltage can be scaled by 200 mV from the nominal operating voltage (950 mV) for practically no loss (less than 0.5%) in accuracy (22 nm predictive technology). Scaling beyond that causes substantial performance degradation owing to increased probability of failures in the MSBs of the synaptic weights. We, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the sensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due to decoupled read and write paths. In an effort to further minimize the area penalty, we present a synaptic-sensitivity driven hybrid memory architecture consisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation framework shows that the proposed synaptic-sensitivity driven architecture provides a 30.91% reduction in the memory access power with a 10.41% area overhead, for less than 1 % loss in the classification accuracy.",
        "acm_key": "2972173",
        "bib_stats": {
            "cites": 0,
            "dl": 7,
            "dl_52": 7,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhong:2016:FFL:2971808.2972173,\n author = {Zhong, Kan and Liu, Duo and Liang, Liang and Long, Linbo and Lin, Yi and Shao, Zili},\n title = {FLIC: Fast, Lightweight Checkpointing for Mobile Virtualization Using NVRAM},\n booktitle = {Proceedings of the 2016 Conference on Design, Automation \\& Test in Europe},\n series = {DATE '16},\n year = {2016},\n isbn = {978-3-9815370-6-2},\n location = {Dresden, Germany},\n pages = {1562--1567},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=2971808.2972173},\n acmid = {2972173},\n publisher = {EDA Consortium},\n address = {San Jose, CA, USA},\n} \r\n",
        "key": "2972173",
        "pub_year": "2016",
        "text": "Kan Zhong , Duo Liu , Liang Liang , Linbo Long , Yi Lin , Zili Shao, FLIC: fast, lightweight checkpointing for mobile virtualization using NVRAM, Proceedings of the 2016 Conference on Design, Automation & Test in Europe, March 14-18, 2016, Dresden, Germany"
    },
    "2974113": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "2974113",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Chen:2016:UFD:2974065.2974113,\n author = {Chen, Xianzhang and Sha, Edwin H.-M. and Zhuge, Qingfeng and Jiang, Weiwen and Chen, Junxi and Chen, Jun and Xu, Jun},\n title = {A Unified Framework for Designing High Performance In-memory and Hybrid Memory File Systems},\n journal = {J. Syst. Archit.},\n issue_date = {August 2016},\n volume = {68},\n number = {C},\n month = aug,\n year = {2016},\n issn = {1383-7621},\n pages = {51--64},\n numpages = {14},\n url = {http://dx.doi.org/10.1016/j.sysarc.2016.05.004},\n doi = {10.1016/j.sysarc.2016.05.004},\n acmid = {2974113},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Flash memory, Hybrid memory file systems, In-memory file systems, Non-volatile memory, Performance},\n} \r\n",
        "key": "2974113",
        "pub_year": "2016",
        "text": "Xianzhang Chen , Edwin H.-M. Sha , Qingfeng Zhuge , Weiwen Jiang , Junxi Chen , Jun Chen , Jun Xu, A unified framework for designing high performance in-memory and hybrid memory file systems, Journal of Systems Architecture: the EUROMICRO Journal, v.68 n.C, p.51-64, August 2016"
    },
    "2974434": {
        "abstract": "Number of node cardinality is an important parameter for a networks proper operation and this parameter can be determined using conventional protocol-based techniques, but these techniques have several limitations in underwater environment due to large propagation latency, high error rate, node mobility, non-negligible capture effect and high path loss. To develop a suitable cardinality estimation technique in presence of unique characteristics of underwater network, a statistical signal processing approach based on cross-correlation of Gaussian signals received at multiple sensors has been proposed in our previous works. In the initial formulation of this approach, a simplified model has been investigated without considering the multipath propagation effect. One of the common challenges for underwater wireless communication is multipath propagation of signals which result in inter-symbol interference ISI. An important feature of cross-correlation is its ability to mitigate the multipath effect which is demonstrated in this paper and applied to our previously proposed estimation scheme for multipath compensation. It is shown that, due to high dispersion coefficient of the medium, multipath effects on estimation results are negligible and a generalised process of multipath compensation for any dispersion factor is obtained to improve the robustness of this scheme.",
        "acm_key": "2974434",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Chakraoui:2016:EID:2974432.2974434,\n author = {Chakraoui, Mohamed and Elkalay, Abderrafiaa},\n title = {Efficiency of Indexing Database Systems and Optimising Its Implementation in NAND Flash Memory},\n journal = {Int. J. Syst., Control Commun.},\n issue_date = {January 2016},\n volume = {7},\n number = {3},\n month = jan,\n year = {2016},\n issn = {1755-9340},\n pages = {221--239},\n numpages = {19},\n url = {http://dx.doi.org/10.1504/IJSCC.2016.077406},\n doi = {10.1504/IJSCC.2016.077406},\n acmid = {2974434},\n publisher = {Inderscience Publishers},\n address = {Inderscience Publishers, Geneva, SWITZERLAND},\n keywords = {B\\&\\#42;, B\\&\\#43;, flash memory, indexing databases, indexing key partitioning, optimisation, table partitioning, tree, tree index, tuning},\n} \r\n",
        "key": "2974434",
        "pub_year": "2016",
        "text": "Mohamed Chakraoui , Abderrafiaa Elkalay, Efficiency of indexing database systems and optimising its implementation in NAND flash memory, International Journal of Systems, Control and Communications, v.7 n.3, p.221-239, January 2016"
    },
    "2974683": {
        "abstract": "As the volumes of spatiotemporal trajectory data continue to grow at a rapid pace; a new generation of data management techniques is needed in order to be able to utilize these data to provide a range of data-driven services, including geographic-type services. Key challenges posed by spatiotemporal data include the massive data volumes, the high velocity with which the data are captured, the need for interactive response times, and the inherent inaccuracy of the data. We propose an infrastructure, Elite, that leverages peer-to-peer and parallel computing techniques to address these challenges. The infrastructure offers efficient, parallel update and query processing by organizing the data into a layered index structure that is logically centralized, but physically distributed among computing nodes. The infrastructure is elastic with respect to storage, meaning that it adapts to fluctuations in the storage volume, and with respect to computation, meaning that the degree of parallelism can be adapted to best match the computational requirements. Further, the infrastructure offers advanced functionality, including probabilistic simulations, for contending with the inaccuracy of the underlying data in query processing. Extensive empirical studies offer insight into properties of the infrastructure and indicate that it meets its design goals, thus enabling the effective management of big spatiotemporal data.",
        "acm_key": "2974683",
        "bib_stats": {
            "cites": 0,
            "dl": 44,
            "dl_52": 35,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Kanza:2016:ESF:2974649.2974683,\n author = {Kanza, Yaron and Yaari, Hadas},\n title = {External Sorting on Flash Storage: Reducing Cell Wearing and Increasing Efficiency by Avoiding Intermediate Writes},\n journal = {The VLDB Journal},\n issue_date = {August    2016},\n volume = {25},\n number = {4},\n month = aug,\n year = {2016},\n issn = {1066-8888},\n pages = {495--518},\n numpages = {24},\n url = {http://dx.doi.org/10.1007/s00778-016-0426-5},\n doi = {10.1007/s00778-016-0426-5},\n acmid = {2974683},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {Cell wearing, External sorting, Flash memory, Merge Sort, SSD, Solid-state drive, Sort algorithms, Write endurance},\n} \r\n",
        "key": "2974683",
        "pub_year": "2016",
        "text": "Yaron Kanza , Hadas Yaari, External sorting on flash storage: reducing cell wearing and increasing efficiency by avoiding intermediate writes, The VLDB Journal \u2014 The International Journal on Very Large Data Bases, v.25 n.4, p.495-518, August    2016"
    },
    "2977149": {
        "abstract": "Detecting deadlocks has been considered an important problem in distributed systems. Many approaches are proposed to handle this issue; however, little attention has been paid on coordinating concurrent execution of distributed deadlock detection algorithms. Previous approaches may report incorrect results false negatives, and they are inefficient due to lack of proper coordination of concurrent execution. In this paper, we present a novel concurrent coordination algorithm for distributed generalized deadlock detection. The proposed algorithm aims to avoid false negatives and improve the performance when concurrently executing deadlock detection in a distributed system. Our algorithm adopts diffusion computation to distribute probe messages and employs priority-based method to coordinate concurrent algorithm instances. Priority carried in the received probe messages will be locally recorded by each initiator. Instead of being suspended by higher priority algorithm instances, lower priority algorithm instances can accomplish deadlock detection locally. The initiator with the highest priority will receive and collect all related resource requests information from lower priority instances in a hierarchical manner and perform global deadlock detection at last. We evaluate our algorithm on a bunch of event-driven simulations. The experimental results show that our approach can achieve better accuracy and efficiency compared to previous approaches.",
        "acm_key": "2977149",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Zhou:2015:PPH:2977147.2977149,\n author = {Zhou, Wei and Feng, Dan and Tan, Zhipeng and Zheng, Yingfei},\n title = {PAHDFS: Preference-Aware HDFS for Hybrid Storage},\n booktitle = {Proceedings, Part II, of the 15th International Conference on Algorithms and Architectures for Parallel Processing - Volume 9529},\n series = {ICA3PP 2015},\n year = {2015},\n isbn = {978-3-319-27121-7},\n location = {Zhangjiajie, China},\n pages = {3--17},\n numpages = {15},\n url = {http://dx.doi.org/10.1007/978-3-319-27122-4_1},\n doi = {10.1007/978-3-319-27122-4_1},\n acmid = {2977149},\n publisher = {Springer-Verlag New York, Inc.},\n address = {New York, NY, USA},\n keywords = {Access characteristics, Big data, HDFS, Hybrid storage, Preference-aware},\n} \r\n",
        "key": "2977149",
        "pub_year": "2015",
        "text": "Wei Zhou , Dan Feng , Zhipeng Tan , Yingfei Zheng, PAHDFS: Preference-Aware HDFS for Hybrid Storage, Proceedings, Part II, of the 15th International Conference on Algorithms and Architectures for Parallel Processing, November 18-20, 2015, Zhangjiajie, China"
    },
    "2977169": {
        "abstract": "Detecting deadlocks has been considered an important problem in distributed systems. Many approaches are proposed to handle this issue; however, little attention has been paid on coordinating concurrent execution of distributed deadlock detection algorithms. Previous approaches may report incorrect results false negatives, and they are inefficient due to lack of proper coordination of concurrent execution. In this paper, we present a novel concurrent coordination algorithm for distributed generalized deadlock detection. The proposed algorithm aims to avoid false negatives and improve the performance when concurrently executing deadlock detection in a distributed system. Our algorithm adopts diffusion computation to distribute probe messages and employs priority-based method to coordinate concurrent algorithm instances. Priority carried in the received probe messages will be locally recorded by each initiator. Instead of being suspended by higher priority algorithm instances, lower priority algorithm instances can accomplish deadlock detection locally. The initiator with the highest priority will receive and collect all related resource requests information from lower priority instances in a hierarchical manner and perform global deadlock detection at last. We evaluate our algorithm on a bunch of event-driven simulations. The experimental results show that our approach can achieve better accuracy and efficiency compared to previous approaches.",
        "acm_key": "2977169",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Chen:2015:FRC:2977147.2977169,\n author = {Chen, Xian and Chen, Wenzhi and Lu, Zhongyong},\n title = {Fusion-Cache: A Refactored Content-Aware Host-Side SSD Cache},\n booktitle = {Proceedings, Part II, of the 15th International Conference on Algorithms and Architectures for Parallel Processing - Volume 9529},\n series = {ICA3PP 2015},\n year = {2015},\n isbn = {978-3-319-27121-7},\n location = {Zhangjiajie, China},\n pages = {297--314},\n numpages = {18},\n url = {http://dx.doi.org/10.1007/978-3-319-27122-4_21},\n doi = {10.1007/978-3-319-27122-4_21},\n acmid = {2977169},\n publisher = {Springer-Verlag New York, Inc.},\n address = {New York, NY, USA},\n keywords = {Cache replacement strategy, Data deduplication, Host-side SSD Cache},\n} \r\n",
        "key": "2977169",
        "pub_year": "2015",
        "text": "Xian Chen , Wenzhi Chen , Zhongyong Lu, Fusion-Cache: A Refactored Content-Aware Host-Side SSD Cache, Proceedings, Part II, of the 15th International Conference on Algorithms and Architectures for Parallel Processing, November 18-20, 2015, Zhangjiajie, China"
    },
    "2979143": {
        "abstract": "Many algorithms have recently been studied for scheduling mixed-criticality (MC) tasks. However, most existing MC scheduling algorithms guarantee the timely executions of high-criticality (HC) tasks at the expense of discarding low-criticality (LC) tasks, which can cause serious service interruption for such tasks. In this work, aiming at providing guaranteed services for LC tasks, we study an elastic mixed-criticality (E-MC) task model for dual-criticality systems. Specifically, the model allows each LC task to specify its maximum period (i.e., minimum service level) and a set of early-release points. We propose an early-release (ER) mechanism that enables LC tasks to be released more frequently and thus improve their service levels at runtime, with both conservative and aggressive approaches to exploiting system slack being considered, which is applied to both earliest deadline first (EDF) and preference-oriented earliest-deadline schedulers. We formally prove the correctness of the proposed early-release--earliest deadline first scheduler on guaranteeing the timeliness of all tasks through judicious management of the early releases of LC tasks. The proposed model and schedulers are evaluated through extensive simulations. The results show that by moderately relaxing the service requirements of LC tasks in MC task sets (i.e., by having LC tasks\u2019 maximum periods in the E-MC model be two to three times their desired MC periods), most transformed E-MC task sets can be successfully scheduled without sacrificing the timeliness of HC tasks. Moreover, with the proposed ER mechanism, the runtime performance of tasks (e.g., execution frequencies of LC tasks, response times, and jitters of HC tasks) can be significantly improved under the ER schedulers when compared to that of the state-of-the-art earliest deadline first\u2014virtual deadline scheduler.",
        "acm_key": "2979143",
        "bib_stats": {
            "cites": 0,
            "dl": 98,
            "dl_52": 98,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Lin:2016:HDB:3029795.2979143,\n author = {Lin, Ye-Jyun and Yang, Chia-Lin and Li, Hsiang-Pang and Wang, Cheng-Yuan Michael},\n title = {A Hybrid DRAM/PCM Buffer Cache Architecture for Smartphones with QoS Consideration},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {March 2017},\n volume = {22},\n number = {2},\n month = dec,\n year = {2016},\n issn = {1084-4309},\n pages = {27:1--27:22},\n articleno = {27},\n numpages = {22},\n url = {http://doi.acm.org/10.1145/2979143},\n doi = {10.1145/2979143},\n acmid = {2979143},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Buffer cache, phase change memory (PCM), smartphone},\n} \r\n",
        "key": "2979143",
        "pub_year": "2017",
        "text": "Ye-Jyun Lin , Chia-Lin Yang , Hsiang-Pang Li , Cheng-Yuan Michael Wang, A Hybrid DRAM/PCM Buffer Cache Architecture for Smartphones with QoS Consideration, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.22 n.2, p.1-22, December 2016"
    },
    "2981124": {
        "abstract": "Off-the-shelf accelerator-based embedded platforms offer a competitive energy-efficient solution for lightweight deep learning computations over CPU-based systems. Low-complexity classifiers used in power-constrained and performance-limited scenarios are characterized by operations on small image maps with 2-3 deep layers and few class labels. For these use cases, we consider a range of embedded systems with 5--20 W power budgets such as the Xilinx ZC706 board (with MXP soft vector processor), NVIDIA Jetson TX1 (GPU), TI Keystone II (DSP) as well as the Adapteva Parallella board (custom multi-core with NoC). Deep Learning computations push the capabilities of these platforms to the limit through compute-intensive evaluations of multiple 2D convolution filters per layer, and high communication requirements arising from the movement of intermediate maps across layers. We present CaffePresso, a Caffe-compatible framework for generating optimized mappings of user-supplied ConvNet specifications to target various accelerators such as FPGAs, DSPs, GPUs, RISC-multicores. We use an automated code generation and auto-tuning approach based on knowledge of the ConvNet requirements, as well as platform-specific constraints such as on-chip memory capacity, bandwidth and ALU potential. While one may expect the Jetson TX1 + cuDNN to deliver high performance for ConvNet configurations, (1) we observe a flipped result with slower GPU processing compared to most other systems for smaller embedded-friendly datasets such as MNIST and CIFAR10, and (2) faster and more energy efficient implementation on the older 28nm TI Keystone II DSP over the newer 20nm NVIDIA TX1 SoC in all cases.",
        "acm_key": "2981124",
        "bib_stats": {
            "cites": 0,
            "dl": 65,
            "dl_52": 65,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Wang:2016:RBL:2968455.2981124,\n author = {Wang, Yu and Xia, Lixue and Cheng, Ming and Tang, Tianqi and Li, Boxun and Yang, Huazhong},\n title = {RRAM Based Learning Acceleration},\n booktitle = {Proceedings of the International Conference on Compilers, Architectures and Synthesis for Embedded Systems},\n series = {CASES '16},\n year = {2016},\n isbn = {978-1-4503-4482-1},\n location = {Pittsburgh, Pennsylvania},\n pages = {9:1--9:2},\n articleno = {9},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2968455.2981124},\n doi = {10.1145/2968455.2981124},\n acmid = {2981124},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2981124",
        "pub_year": "2016",
        "text": "Yu Wang , Lixue Xia , Ming Cheng , Tianqi Tang , Boxun Li , Huazhong Yang, RRAM based learning acceleration, Proceedings of the International Conference on Compilers, Architectures and Synthesis for Embedded Systems, p.1-2, October 01-07, 2016, Pittsburgh, Pennsylvania"
    },
    "2984019": {
        "abstract": " Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the defi- nition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record val- ues contain type information to specify the values that can be correctly stored in fields. Such a model, and the correspond- ing subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation. ",
        "acm_key": "2984019",
        "bib_stats": {
            "cites": 1,
            "dl": 183,
            "dl_52": 183,
            "dl_6": 24
        },
        "bibtex": "\r\n@article{Bhandari:2016:MFR:3022671.2984019,\n author = {Bhandari, Kumud and Chakrabarti, Dhruva R. and Boehm, Hans-J.},\n title = {Makalu: Fast Recoverable Allocation of Non-volatile Memory},\n journal = {SIGPLAN Not.},\n issue_date = {October 2016},\n volume = {51},\n number = {10},\n month = oct,\n year = {2016},\n issn = {0362-1340},\n pages = {677--694},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/3022671.2984019},\n doi = {10.1145/3022671.2984019},\n acmid = {2984019},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {allocation, deallocation, garbage collection, non-volatile memory, persistent memory management},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=2984019&parent_id=3022671&expformat=bibtex&CFID=982032268&CFTOKEN=41024170\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"2984019\">\r\n@inproceedings{Bhandari:2016:MFR:2983990.2984019,\n author = {Bhandari, Kumud and Chakrabarti, Dhruva R. and Boehm, Hans-J.},\n title = {Makalu: Fast Recoverable Allocation of Non-volatile Memory},\n booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},\n series = {OOPSLA 2016},\n year = {2016},\n isbn = {978-1-4503-4444-9},\n location = {Amsterdam, Netherlands},\n pages = {677--694},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/2983990.2984019},\n doi = {10.1145/2983990.2984019},\n acmid = {2984019},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {allocation, deallocation, garbage collection, non-volatile memory, persistent memory management},\n} \r\n",
        "key": "2984019",
        "pub_year": "2016",
        "text": "Kumud Bhandari , Dhruva R. Chakrabarti , Hans-J. Boehm, Makalu: fast recoverable allocation of non-volatile memory, ACM SIGPLAN Notices, v.51 n.10, October 2016"
    },
    "2987395": {
        "abstract": "In this paper, we propose a method of intensity-based image matching evaluation to achieve efficient planar object detection with small number of feature points. To detect target object from a camera image, establishing matches between feature points of camera image and those of objects is processed. As correctness in matching procedure effects overall performance of detection task, it is important to determine error-prone matches and filter them out. In previous researches, they have usually focused on probabilistic approaches to figure out error of matches. In their approaches, with large number of matched feature points, it performs optimization process which is iterating estimation of projectivity with randomly selected matched feature points until it finds converging projectivity result. The matched feature points which contribute the projectivity result is assumed to be correct. In these approaches, to acquire reliable result, there should be large number of matched feature points and most of matches should be correct. In this paper, we propose an efficient way to detect the target object with small number of matches. It becomes possible by filtering out wrong matches and increasing reliability of set of matches which is small. To filter out error matches, we exploit intensity information of image. To make intensity information usable, we have devised a method to define geometric structure between feature points and model the intensity information based on it. The experimental results show that it is possible to acquire reliable projectivity with small number of correct matches and enhance overall performance by minimizing the burden for optimization process.",
        "acm_key": "2987395",
        "bib_stats": {
            "cites": 0,
            "dl": 16,
            "dl_52": 16,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Sung:2016:CMO:2987386.2987395,\n author = {Sung, Hung-Yi and Wu, Chin-Hsien and Tekilu, Dereje},\n title = {Collaboration of Merge Operations in Hybrid-Mapped Flash Translation Layers with the Multi-Controller Design},\n booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},\n series = {RACS '16},\n year = {2016},\n isbn = {978-1-4503-4455-5},\n location = {Odense, Denmark},\n pages = {181--186},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2987386.2987395},\n doi = {10.1145/2987386.2987395},\n acmid = {2987395},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Flash Translation Layers, Multi-Controller Parallelism, NAND Flash Memory},\n} \r\n",
        "key": "2987395",
        "pub_year": "2016",
        "text": "Hung-Yi Sung , Chin-Hsien Wu , Dereje Tekilu, Collaboration of Merge Operations in Hybrid-Mapped Flash Translation Layers with the Multi-Controller Design, Proceedings of the International Conference on Research in Adaptive and Convergent Systems, October 11-14, 2016, Odense, Denmark"
    },
    "2987398": {
        "abstract": "In this paper, we propose a method of intensity-based image matching evaluation to achieve efficient planar object detection with small number of feature points. To detect target object from a camera image, establishing matches between feature points of camera image and those of objects is processed. As correctness in matching procedure effects overall performance of detection task, it is important to determine error-prone matches and filter them out. In previous researches, they have usually focused on probabilistic approaches to figure out error of matches. In their approaches, with large number of matched feature points, it performs optimization process which is iterating estimation of projectivity with randomly selected matched feature points until it finds converging projectivity result. The matched feature points which contribute the projectivity result is assumed to be correct. In these approaches, to acquire reliable result, there should be large number of matched feature points and most of matches should be correct. In this paper, we propose an efficient way to detect the target object with small number of matches. It becomes possible by filtering out wrong matches and increasing reliability of set of matches which is small. To filter out error matches, we exploit intensity information of image. To make intensity information usable, we have devised a method to define geometric structure between feature points and model the intensity information based on it. The experimental results show that it is possible to acquire reliable projectivity with small number of correct matches and enhance overall performance by minimizing the burden for optimization process.",
        "acm_key": "2987398",
        "bib_stats": {
            "cites": 0,
            "dl": 49,
            "dl_52": 49,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Chang:2016:EHP:2987386.2987398,\n author = {Chang, Yu-Ming and Chang, Yuan-Hao and Chen, Hsiu-Chang and Kuo, Tei-Wei},\n title = {Enabling Hybrid PCM Memory System with Inherent Memory Management},\n booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},\n series = {RACS '16},\n year = {2016},\n isbn = {978-1-4503-4455-5},\n location = {Odense, Denmark},\n pages = {193--200},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/2987386.2987398},\n doi = {10.1145/2987386.2987398},\n acmid = {2987398},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, memory management, phase change memory, wear leveling},\n} \r\n",
        "key": "2987398",
        "pub_year": "2016",
        "text": "Yu-Ming Chang , Yuan-Hao Chang , Hsiu-Chang Chen , Tei-Wei Kuo, Enabling Hybrid PCM Memory System with Inherent Memory Management, Proceedings of the International Conference on Research in Adaptive and Convergent Systems, October 11-14, 2016, Odense, Denmark"
    },
    "2987551": {
        "abstract": "Failure is inevitable in cloud environments. Finding the root cause of a failure can be very complex or at times nearly impossible. Different cloud customers have varying availability demands as well as a diverse willingness to pay for availability. In contrast to existing solutions that try to provide higher and higher availability in the cloud, we propose the Availability Knob (AK). AK provides flexible, user-defined, availability in IaaS clouds, allowing the IaaS cloud customer to express their desire for availability to the cloud provider. Complementary to existing high-reliability solutions and not requiring hardware changes, AK enables more efficient markets. This leads to reduced provider costs, increased provider profit, and improved user satisfaction when compared to an IaaS cloud with no ability to convey availability needs. We leverage game theory to derive incentive compatible pricing, which not only enables AK to function with no knowledge of the root cause of failure but also function under adversarial situations where users deliberately cause downtime. We develop a high-level stochastic simulator to test AK in large-scale IaaS clouds over long time periods. We also prototype AK in OpenStack to explore availability-API tradeoffs and to provide a grounded, real-world, implementation. Our results show that deploying AK leads to more than 10% cost reduction for providers and improves user satisfaction. It also enables providers to set variable profit margins based on the risk of not meeting availability guarantees and the disparity in availability supply/demand. Variable profit margins enable cloud providers to improve their profit by as much as 20%.",
        "acm_key": "2987551",
        "bib_stats": {
            "cites": 0,
            "dl": 443,
            "dl_52": 443,
            "dl_6": 41
        },
        "bibtex": "\r\n@inproceedings{Liang:2016:CVP:2987550.2987551,\n author = {Liang, Liang and Chen, Rong and Chen, Haibo and Xia, Yubin and Park, KwanJong and Zang, Binyu and Guan, Haibing},\n title = {A Case for Virtualizing Persistent Memory},\n booktitle = {Proceedings of the Seventh ACM Symposium on Cloud Computing},\n series = {SoCC '16},\n year = {2016},\n isbn = {978-1-4503-4525-5},\n location = {Santa Clara, CA, USA},\n pages = {126--140},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2987550.2987551},\n doi = {10.1145/2987550.2987551},\n acmid = {2987551},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Para-virtualization, Persistent Memory, Virtualization},\n} \r\n",
        "key": "2987551",
        "pub_year": "2016",
        "text": "Liang Liang , Rong Chen , Haibo Chen , Yubin Xia , KwanJong Park , Binyu Zang , Haibing Guan, A Case for Virtualizing Persistent Memory, Proceedings of the Seventh ACM Symposium on Cloud Computing, October 05-07, 2016, Santa Clara, CA, USA"
    },
    "2987570": {
        "abstract": "Failure is inevitable in cloud environments. Finding the root cause of a failure can be very complex or at times nearly impossible. Different cloud customers have varying availability demands as well as a diverse willingness to pay for availability. In contrast to existing solutions that try to provide higher and higher availability in the cloud, we propose the Availability Knob (AK). AK provides flexible, user-defined, availability in IaaS clouds, allowing the IaaS cloud customer to express their desire for availability to the cloud provider. Complementary to existing high-reliability solutions and not requiring hardware changes, AK enables more efficient markets. This leads to reduced provider costs, increased provider profit, and improved user satisfaction when compared to an IaaS cloud with no ability to convey availability needs. We leverage game theory to derive incentive compatible pricing, which not only enables AK to function with no knowledge of the root cause of failure but also function under adversarial situations where users deliberately cause downtime. We develop a high-level stochastic simulator to test AK in large-scale IaaS clouds over long time periods. We also prototype AK in OpenStack to explore availability-API tradeoffs and to provide a grounded, real-world, implementation. Our results show that deploying AK leads to more than 10% cost reduction for providers and improves user satisfaction. It also enables providers to set variable profit margins based on the risk of not meeting availability guarantees and the disparity in availability supply/demand. Variable profit margins enable cloud providers to improve their profit by as much as 20%.",
        "acm_key": "2987570",
        "bib_stats": {
            "cites": 0,
            "dl": 650,
            "dl_52": 650,
            "dl_6": 41
        },
        "bibtex": "\r\n@inproceedings{Hirofuchi:2016:RHV:2987550.2987570,\n author = {Hirofuchi, Takahiro and Takano, Ryousei},\n title = {RAMinate: Hypervisor-based Virtualization for Hybrid Main Memory Systems},\n booktitle = {Proceedings of the Seventh ACM Symposium on Cloud Computing},\n series = {SoCC '16},\n year = {2016},\n isbn = {978-1-4503-4525-5},\n location = {Santa Clara, CA, USA},\n pages = {112--125},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/2987550.2987570},\n doi = {10.1145/2987550.2987570},\n acmid = {2987570},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Hybrid Memory, Hypervisor, Non-volatile Memory, STT-MRAM, Virtual Machine},\n} \r\n",
        "key": "2987570",
        "pub_year": "2016",
        "text": "Takahiro Hirofuchi , Ryousei Takano, RAMinate: Hypervisor-based Virtualization for Hybrid Main Memory Systems, Proceedings of the Seventh ACM Symposium on Cloud Computing, October 05-07, 2016, Santa Clara, CA, USA"
    },
    "2989082": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989082",
        "bib_stats": {
            "cites": 0,
            "dl": 74,
            "dl_52": 74,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Asifuzzaman:2016:PIS:2989081.2989082,\n author = {Asifuzzaman, Kazi and Pavlovic, Milan and Radulovic, Milan and Zaragoza, David and Kwon, Ohseong and Ryoo, Kyung-Chang and Radojkovi\\'{c}, Petar},\n title = {Performance Impact of a Slower Main Memory: A Case Study of STT-MRAM in HPC},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {40--49},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2989081.2989082},\n doi = {10.1145/2989081.2989082},\n acmid = {2989082},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {High-performance computing, Main memory, STT-MRAM},\n} \r\n",
        "key": "2989082",
        "pub_year": "2016",
        "text": "Kazi Asifuzzaman , Milan Pavlovic , Milan Radulovic , David Zaragoza , Ohseong Kwon , Kyung-Chang Ryoo , Petar Radojkovi\u0107, Performance Impact of a Slower Main Memory: A case study of STT-MRAM in HPC, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989085": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989085",
        "bib_stats": {
            "cites": 1,
            "dl": 49,
            "dl_52": 49,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Beigi:2016:TTA:2989081.2989085,\n author = {Beigi, Majed Valad and Memik, Gokhan},\n title = {TAPAS: Temperature-aware Adaptive Placement for 3D Stacked Hybrid Caches},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {415--426},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2989081.2989085},\n doi = {10.1145/2989081.2989085},\n acmid = {2989085},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3D stacking, Data Migration, Non-Volatile Memories, Temperature},\n} \r\n",
        "key": "2989085",
        "pub_year": "2016",
        "text": "Majed Valad Beigi , Gokhan Memik, TAPAS: Temperature-aware Adaptive Placement for 3D Stacked Hybrid Caches, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989086": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989086",
        "bib_stats": {
            "cites": 1,
            "dl": 64,
            "dl_52": 64,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Imani:2016:PAR:2989081.2989086,\n author = {Imani, Mohsen and Cheng, Yan and Rosing, Tajana},\n title = {Processing Acceleration with Resistive Memory-based Computation},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {208--210},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/2989081.2989086},\n doi = {10.1145/2989081.2989086},\n acmid = {2989086},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Approximate computing, Associative memory, Non-volatile memory, Resistive computing},\n} \r\n",
        "key": "2989086",
        "pub_year": "2016",
        "text": "Mohsen Imani , Yan Cheng , Tajana Rosing, Processing Acceleration with Resistive Memory-based Computation, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989089": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989089",
        "bib_stats": {
            "cites": 0,
            "dl": 70,
            "dl_52": 70,
            "dl_6": 3
        },
        "bibtex": "\r\n@inproceedings{Farmahini-Farahani:2016:ASB:2989081.2989089,\n author = {Farmahini-Farahani, Amin and Roberts, David and Jayasena, Nuwan},\n title = {Analytical Study on Bandwidth Efficiency of Heterogeneous Memory Systems},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {104--118},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/2989081.2989089},\n doi = {10.1145/2989081.2989089},\n acmid = {2989089},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2989089",
        "pub_year": "2016",
        "text": "Amin Farmahini-Farahani , David Roberts , Nuwan Jayasena, Analytical Study on Bandwidth Efficiency of Heterogeneous Memory Systems, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989091": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989091",
        "bib_stats": {
            "cites": 0,
            "dl": 57,
            "dl_52": 57,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Li:2016:ASM:2989081.2989091,\n author = {Li, Yin and Wang, Hao and Zhao, Xiaoqing and Sun, Hongbin and Zhang, Tong},\n title = {Applying Software-based Memory Error Correction for In-Memory Key-Value Store: Case Studies on Memcached and RAMCloud},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {268--278},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2989081.2989091},\n doi = {10.1145/2989081.2989091},\n acmid = {2989091},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Error Correction, In-memory Key-value Store, Memory Fault Tolerance},\n} \r\n",
        "key": "2989091",
        "pub_year": "2016",
        "text": "Yin Li , Hao Wang , Xiaoqing Zhao , Hongbin Sun , Tong Zhang, Applying Software-based Memory Error Correction for In-Memory Key-Value Store: Case Studies on Memcached and RAMCloud, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989095": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989095",
        "bib_stats": {
            "cites": 0,
            "dl": 47,
            "dl_52": 47,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Wang:2016:MMI:2989081.2989095,\n author = {Wang, Wei and Pan, Wen and Xie, Tao and Zhou, Deng},\n title = {How Many MLCs Should Impersonate SLCs to Optimize SSD Performance?},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {238--247},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2989081.2989095},\n doi = {10.1145/2989081.2989095},\n acmid = {2989095},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MLC, NAND, Partitioning, SLC, Solid State Disk},\n} \r\n",
        "key": "2989095",
        "pub_year": "2016",
        "text": "Wei Wang , Wen Pan , Tao Xie , Deng Zhou, How Many MLCs Should Impersonate SLCs to Optimize SSD Performance?, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989110": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989110",
        "bib_stats": {
            "cites": 0,
            "dl": 56,
            "dl_52": 56,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Malladi:2016:DMD:2989081.2989110,\n author = {Malladi, Krishna T. and Awasthi, Manu and Zheng, Hongzhong},\n title = {DRAMPersist: Making DRAM Systems Persistent},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {94--95},\n numpages = {2},\n url = {http://doi.acm.org/10.1145/2989081.2989110},\n doi = {10.1145/2989081.2989110},\n acmid = {2989110},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {DRAM, NVRAM, Persistent, Replication, Systems},\n} \r\n",
        "key": "2989110",
        "pub_year": "2016",
        "text": "Krishna T. Malladi , Manu Awasthi , Hongzhong Zheng, DRAMPersist: Making DRAM Systems Persistent, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989115": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989115",
        "bib_stats": {
            "cites": 0,
            "dl": 53,
            "dl_52": 53,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Goglin:2016:ELH:2989081.2989115,\n author = {Goglin, Brice},\n title = {Exposing the Locality of Heterogeneous Memory Architectures to HPC Applications},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {30--39},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/2989081.2989115},\n doi = {10.1145/2989081.2989115},\n acmid = {2989115},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Heterogeneous memory, Linux, affinity, high-performance computing, locality, structural modeling, user-space runtimes},\n} \r\n",
        "key": "2989115",
        "pub_year": "2016",
        "text": "Brice Goglin, Exposing the Locality of Heterogeneous Memory Architectures to HPC Applications, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989119": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989119",
        "bib_stats": {
            "cites": 0,
            "dl": 71,
            "dl_52": 71,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:WLO:2989081.2989119,\n author = {Chen, Dong and Ye, Chencheng and Ding, Chen},\n title = {Write Locality and Optimization for Persistent Memory},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {77--87},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/2989081.2989119},\n doi = {10.1145/2989081.2989119},\n acmid = {2989119},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Cache-sharing optimization, Write locality},\n} \r\n",
        "key": "2989119",
        "pub_year": "2016",
        "text": "Dong Chen , Chencheng Ye , Chen Ding, Write Locality and Optimization for Persistent Memory, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989122": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989122",
        "bib_stats": {
            "cites": 0,
            "dl": 51,
            "dl_52": 51,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Guo:2016:LME:2989081.2989122,\n author = {Guo, Xiaochen and Shrivastava, Aviral and Spear, Michael and Tan, Gang},\n title = {Languages Must Expose Memory Heterogeneity},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {251--256},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2989081.2989122},\n doi = {10.1145/2989081.2989122},\n acmid = {2989122},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Concurrency, Nonvolatile Memory, Sandboxing, Scratchpad Memory, Security, Transactional Memory},\n} \r\n",
        "key": "2989122",
        "pub_year": "2016",
        "text": "Xiaochen Guo , Aviral Shrivastava , Michael Spear , Gang Tan, Languages Must Expose Memory Heterogeneity, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989123": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989123",
        "bib_stats": {
            "cites": 0,
            "dl": 62,
            "dl_52": 62,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Brock:2016:RPH:2989081.2989123,\n author = {Brock, Jacob and Ye, Chencheng and Ding, Chen},\n title = {Replacement Policies for Heterogeneous Memories},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {232--237},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/2989081.2989123},\n doi = {10.1145/2989081.2989123},\n acmid = {2989123},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Heterogeneous Memory, Locality, Replacement Policies},\n} \r\n",
        "key": "2989123",
        "pub_year": "2016",
        "text": "Jacob Brock , Chencheng Ye , Chen Ding, Replacement Policies for Heterogeneous Memories, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989126": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989126",
        "bib_stats": {
            "cites": 0,
            "dl": 44,
            "dl_52": 44,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Stevens:2016:FFS:2989081.2989126,\n author = {Stevens, Jim and Tschirhart, Paul and Jacob, Bruce},\n title = {Fast Full System Memory Checkpointing with SSD-aware Memory Controller},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {96--98},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/2989081.2989126},\n doi = {10.1145/2989081.2989126},\n acmid = {2989126},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "2989126",
        "pub_year": "2016",
        "text": "Jim Stevens , Paul Tschirhart , Bruce Jacob, Fast full system memory checkpointing with SSD-aware memory controller, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2989129": {
        "abstract": "In current practice, DRAM manufacturers apply redundancy-repair to decommission all the weak cells that cannot satisfy the target data retention time under the worse-case operational conditions (e.g., the highest operating temperature). However, as the DRAM scaling enters sub-20nm regime, it becomes increasingly challenging to repair all the weak cells at reasonable cost. This work studies how one could use DRAM chips with unrepaired weak cells in computing systems. In particular, this work is based upon the simple idea that OS reserves all the error-prone pages, which contain at least one unrepaired weak cell, from being used. Under a relatively high error-prone page rate (e.g., 8%), this basic idea is subject to two issues: (1) Simply reserving all the error-prone pages could make it almost impossible for OS to allocate a continuous fragmentation-free physical memory space for some critical operations such as OS booting and DMA buffering. (2) Since most error-prone pages may only contain few unrepaired weak cells, reserving all the error-prone pages from practical usage could cause noticeable memory resource waste. Aiming to address these issues, this paper presents a controller-based selective page re-mapping strategy to ensure a continuous critical memory region for OS, and develops a software-based memory error tolerance scheme to re-cycle all the error-prone pages for the zRAM function in Linux. Since the first scheme only eliminates the fragmentation in the critical memory region (e.g., 128MB in Linux), the remaining non-critical memory region is still subject to severe fragmentation. Hence, we carried out experiments using SPEC CPU2006 to quantitatively demonstrate that highly fragmented non-critical memory region may not cause significant computing system performance degradation. We further study the latency and hardware cost of implementing the controller-based page re-mapping, and the effectiveness of re-cycling error-prone pages for zRAM in Linux. The experimental results show that our proposed software-based error tolerance scheme degrades the speed performance of zRAM by only up to 7%.",
        "acm_key": "2989129",
        "bib_stats": {
            "cites": 0,
            "dl": 70,
            "dl_52": 70,
            "dl_6": 10
        },
        "bibtex": "\r\n@inproceedings{Islam:2016:PPE:2989081.2989129,\n author = {Islam, Mahzabeen and Banerjee, Soumik and Meswani, Mitesh and Kavi, Krishna},\n title = {Prefetching As a Potentially Effective Technique for Hybrid Memory Optimization},\n booktitle = {Proceedings of the Second International Symposium on Memory Systems},\n series = {MEMSYS '16},\n year = {2016},\n isbn = {978-1-4503-4305-3},\n location = {Alexandria, VA, USA},\n pages = {220--231},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2989081.2989129},\n doi = {10.1145/2989081.2989129},\n acmid = {2989129},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Prefetching, hybrid memory system},\n} \r\n",
        "key": "2989129",
        "pub_year": "2016",
        "text": "Mahzabeen Islam , Soumik Banerjee , Mitesh Meswani , Krishna Kavi, Prefetching as a Potentially Effective Technique for Hybrid Memory Optimization, Proceedings of the Second International Symposium on Memory Systems, October 03-06, 2016, Alexandria, VA, USA"
    },
    "2991101": {
        "abstract": "Implantable Medical Devices (IMDs) typically use proprietary protocols with no or limited security to wirelessly communicate with a device programmer. These protocols enable doctors to carry out critical functions, such as changing the IMD's therapy or collecting telemetry data, without having to perform surgery on the patient. In this paper, we fully reverse-engineer the proprietary communication protocol between a device programmer and the latest generation of a widely used Implantable Cardioverter Defibrillator (ICD) which communicate over a long-range RF channel (from two to five meters). For this we follow a black-box reverse-engineering approach and use inexpensive Commercial Off-The-Shelf (COTS) equipment. We demonstrate that reverse-engineering is feasible by a weak adversary who has limited resources and capabilities without physical access to the devices. Our analysis of the proprietary protocol results in the identification of several protocol and implementation weaknesses. Unlike previous studies, which found no security measures, this article discovers the first known attempt to obfuscate the data that is transmitted over the air. Furthermore, we conduct privacy and Denial-of-Service (DoS) attacks and give evidence of other attacks that can compromise the patient's safety. All these attacks can be performed without needing to be in close proximity to the patient. We validate that our findings apply to (at least) 10 types of ICDs that are currently on the market. Finally, we propose several practical short- and long-term countermeasures to mitigate or prevent existing vulnerabilities.",
        "acm_key": "2991101",
        "bib_stats": {
            "cites": 0,
            "dl": 72,
            "dl_52": 72,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Chen:2016:SDE:2991079.2991101,\n author = {Chen, Bo and Jia, Shijie and Xia, Luning and Liu, Peng},\n title = {Sanitizing Data is Not Enough!: Towards Sanitizing Structural Artifacts in Flash Media},\n booktitle = {Proceedings of the 32Nd Annual Conference on Computer Security Applications},\n series = {ACSAC '16},\n year = {2016},\n isbn = {978-1-4503-4771-6},\n location = {Los Angeles, California, USA},\n pages = {496--507},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/2991079.2991101},\n doi = {10.1145/2991079.2991101},\n acmid = {2991101},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash, flash translation layer, truely secure deletion},\n} \r\n",
        "key": "2991101",
        "pub_year": "2016",
        "text": "Bo Chen , Shijie Jia , Luning Xia , Peng Liu, Sanitizing data is not enough!: towards sanitizing structural artifacts in flash media, Proceedings of the 32nd Annual Conference on Computer Security Applications, December 05-08, 2016, Los Angeles, California"
    },
    "2992782": {
        "abstract": "Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chips\u2019 thermal limits and the rack\u2019s power limits. Moreover, we present the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4--6\u00d7 over prior greedy heuristics and performs within 90% of an upper bound on throughput from a globally optimized policy.",
        "acm_key": "2992782",
        "bib_stats": {
            "cites": 1,
            "dl": 345,
            "dl_52": 345,
            "dl_6": 25
        },
        "bibtex": "\r\n@article{Zheng:2016:RAS:3014162.2992782,\n author = {Zheng, Mai and Tucek, Joseph and Qin, Feng and Lillibridge, Mark and Zhao, Bill W. and Yang, Elizabeth S.},\n title = {Reliability Analysis of SSDs Under Power Fault},\n journal = {ACM Trans. Comput. Syst.},\n issue_date = {January 2017},\n volume = {34},\n number = {4},\n month = nov,\n year = {2016},\n issn = {0734-2071},\n pages = {10:1--10:28},\n articleno = {10},\n numpages = {28},\n url = {http://doi.acm.org/10.1145/2992782},\n doi = {10.1145/2992782},\n acmid = {2992782},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {SSD, Storage systems, fault injection, flash memory, power failure},\n} \r\n",
        "key": "2992782",
        "pub_year": "2017",
        "text": "Mai Zheng , Joseph Tucek , Feng Qin , Mark Lillibridge , Bill W. Zhao , Elizabeth S. Yang, Reliability Analysis of SSDs Under Power Fault, ACM Transactions on Computer Systems (TOCS), v.34 n.4, p.1-28, December 2016"
    },
    "2994698": {
        "abstract": "Volume 45 Issue PB, September 2016 \r\n\r\n",
        "acm_key": "2994698",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Chamazcoti:2016:DEA:2994677.2994698,\n author = {Chamazcoti, Saeideh Alinezhad and Miremadi, Seyed Ghassem},\n title = {On Designing Endurance Aware Erasure Code for SSD-based Storage Systems},\n journal = {Microprocess. Microsyst.},\n issue_date = {September 2016},\n volume = {45},\n number = {PB},\n month = sep,\n year = {2016},\n issn = {0141-9331},\n pages = {283--296},\n numpages = {14},\n url = {http://dx.doi.org/10.1016/j.micpro.2016.06.003},\n doi = {10.1016/j.micpro.2016.06.003},\n acmid = {2994698},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Endurance, Erasure code, Program/Erase (P/E) cycles, Solid state drive (SSD), Storage system},\n} \r\n",
        "key": "2994698",
        "pub_year": "2016",
        "text": "Saeideh Alinezhad Chamazcoti , Seyed Ghassem Miremadi, On designing endurance aware erasure code for SSD-based storage systems, Microprocessors & Microsystems, v.45 n.PB, p.283-296, September 2016"
    },
    "2995888": {
        "abstract": "In processing voice with environment noise, the noise must be eliminated to improve the vocabulary recognition rate. In this process, noise elimination and feature extraction for model-estimate technologies are utilized. Concerning these noise-elimination and model-estimate technologies, the most important part is to estimate mixed noise in the source signal and eliminate it. In a vocabulary recognition system, if unexpected noise appears in the signal, or if quantization noise is basically added to digital signals, the source signal is changed or damaged, which decreases the recognition rate. If a source signal is transformed or changed by being mixed with diverse kinds of noise, the hidden Markov model (HMM) is used for effective noise elimination. The HMM forms a model by extracting features to flexibly respond to diverse vocabulary changes found in voice and text, etc. The method is applicable to data changing over time, and can establish a more effective model as the number of parameters constituting the model grows larger. It can provide a robust model estimate by using a parameter set for structured models. HMM-based vocabulary recognition shows discriminating distribution of recognition probability regarding recognition vocabulary models, and has lower computational complexity for recognition. But it produces a relatively lower recognition rate. To solve that problem, a vocabulary recognition-model optimization method is proposed based on a similar phoneme---recognition process and efficient feature extraction. In vocabulary recognition, a similar phoneme---recognition process is applied to HMM to recognize models adjacent to the model group. Efficient feature extraction is used to optimize the recognition model to enhance the recognition rate. For vocabulary composition, a Gaussian-mixture feature-extraction model is optimized and used as a vocabulary recognition model. Then, it is processed with similar-phoneme recognition regarding the vocabulary recognition model.",
        "acm_key": "2995888",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Son:2016:EEA:2995816.2995888,\n author = {Son, Yongseok and Kang, Hara and Han, Hyuck and Yeom, Heon Young},\n title = {An Empirical Evaluation and Analysis of the Performance of NVM Express Solid State Drive},\n journal = {Cluster Computing},\n issue_date = {September 2016},\n volume = {19},\n number = {3},\n month = sep,\n year = {2016},\n issn = {1386-7857},\n pages = {1541--1553},\n numpages = {13},\n url = {http://dx.doi.org/10.1007/s10586-016-0591-8},\n doi = {10.1007/s10586-016-0591-8},\n acmid = {2995888},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Flash SSD, NVM express, Performance evaluation},\n} \r\n",
        "key": "2995888",
        "pub_year": "2016",
        "text": "Yongseok Son , Hara Kang , Hyuck Han , Heon Young Yeom, An empirical evaluation and analysis of the performance of NVM express solid state drive, Cluster Computing, v.19 n.3, p.1541-1553, September 2016"
    },
    "2995930": {
        "abstract": "Multiversion databases store both current and historical data. Rows are typically annotated with timestamps representing the period when the row is/was valid. We develop novel techniques to reduce index maintenance in multiversion databases, so that indexes can be used effectively for analytical queries over current data without being a heavy burden on transaction throughput. To achieve this end, we re-design persistent index data structures in the storage hierarchy to employ an extra level of indirection. The indirection level is stored on solid-state disks that can support very fast random I/Os, so that traversing the extra level of indirection incurs a relatively small overhead. The extra level of indirection dramatically reduces the number of magnetic disk I/Os that are needed for index updates and localizes maintenance to indexes on updated attributes. Additionally, we batch insertions within the indirection layer in order to reduce physical disk I/Os for indexing new records. In this work, we further exploit SSDs by introducing novel DeltaBlock techniques for storing the recent changes to data on SSDs. Using our DeltaBlock, we propose an efficient method to periodically flush the recently changed data from SSDs to HDDs such that, on the one hand, we keep track of every change (or delta) for every record, and, on the other hand, we avoid redundantly storing the unchanged portion of updated records. By reducing the index maintenance overhead on transactions, we enable operational data stores to create more indexes to support queries. We have developed a prototype of our indirection proposal by extending the widely used generalized search tree open-source project, which is also employed in PostgreSQL. Our working implementation demonstrates that we can significantly reduce index maintenance and/or query processing cost by a factor of 3. For the insertion of new records, our novel batching technique can save up to 90 % of the insertion time. For updates, our prototype demonstrates that we can significantly reduce the database size by up to 80 % even with a modest space allocated for DeltaBlocks on SSDs.",
        "acm_key": "2995930",
        "bib_stats": {
            "cites": 0,
            "dl": 41,
            "dl_52": 41,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Jin:2016:RTI:2995819.2995930,\n author = {Jin, Peiquan and Yang, Chengcheng and Jensen, Christian S. and Yang, Puyuan and Yue, Lihua},\n title = {Read/Write-optimized Tree Indexing for Solid-state Drives},\n journal = {The VLDB Journal},\n issue_date = {October   2016},\n volume = {25},\n number = {5},\n month = oct,\n year = {2016},\n issn = {1066-8888},\n pages = {695--717},\n numpages = {23},\n url = {http://dx.doi.org/10.1007/s00778-015-0406-1},\n doi = {10.1007/s00778-015-0406-1},\n acmid = {2995930},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {B+-tree, Bloom filter, Flash memory, Index, Solid-state drives},\n} \r\n",
        "key": "2995930",
        "pub_year": "2016",
        "text": "Peiquan Jin , Chengcheng Yang , Christian S. Jensen , Puyuan Yang , Lihua Yue, Read/write-optimized tree indexing for solid-state drives, The VLDB Journal \u2014 The International Journal on Very Large Data Bases, v.25 n.5, p.695-717, October   2016"
    },
    "2995932": {
        "abstract": "Multiversion databases store both current and historical data. Rows are typically annotated with timestamps representing the period when the row is/was valid. We develop novel techniques to reduce index maintenance in multiversion databases, so that indexes can be used effectively for analytical queries over current data without being a heavy burden on transaction throughput. To achieve this end, we re-design persistent index data structures in the storage hierarchy to employ an extra level of indirection. The indirection level is stored on solid-state disks that can support very fast random I/Os, so that traversing the extra level of indirection incurs a relatively small overhead. The extra level of indirection dramatically reduces the number of magnetic disk I/Os that are needed for index updates and localizes maintenance to indexes on updated attributes. Additionally, we batch insertions within the indirection layer in order to reduce physical disk I/Os for indexing new records. In this work, we further exploit SSDs by introducing novel DeltaBlock techniques for storing the recent changes to data on SSDs. Using our DeltaBlock, we propose an efficient method to periodically flush the recently changed data from SSDs to HDDs such that, on the one hand, we keep track of every change (or delta) for every record, and, on the other hand, we avoid redundantly storing the unchanged portion of updated records. By reducing the index maintenance overhead on transactions, we enable operational data stores to create more indexes to support queries. We have developed a prototype of our indirection proposal by extending the widely used generalized search tree open-source project, which is also employed in PostgreSQL. Our working implementation demonstrates that we can significantly reduce index maintenance and/or query processing cost by a factor of 3. For the insertion of new records, our novel batching technique can save up to 90 % of the insertion time. For updates, our prototype demonstrates that we can significantly reduce the database size by up to 80 % even with a modest space allocated for DeltaBlocks on SSDs.",
        "acm_key": "2995932",
        "bib_stats": {
            "cites": 2,
            "dl": 67,
            "dl_52": 67,
            "dl_6": 15
        },
        "bibtex": "\r\n@article{Sadoghi:2016:ESO:2995819.2995932,\n author = {Sadoghi, Mohammad and Ross, Kenneth A. and Canim, Mustafa and Bhattacharjee, Bishwaranjan},\n title = {Exploiting SSDs in Operational Multiversion Databases},\n journal = {The VLDB Journal},\n issue_date = {October   2016},\n volume = {25},\n number = {5},\n month = oct,\n year = {2016},\n issn = {1066-8888},\n pages = {651--672},\n numpages = {22},\n url = {http://dx.doi.org/10.1007/s00778-015-0410-5},\n doi = {10.1007/s00778-015-0410-5},\n acmid = {2995932},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {Flash storage, Index maintenance, Multiversion databases, SSD},\n} \r\n",
        "key": "2995932",
        "pub_year": "2016",
        "text": "Mohammad Sadoghi , Kenneth A. Ross , Mustafa Canim , Bishwaranjan Bhattacharjee, Exploiting SSDs in operational multiversion databases, The VLDB Journal \u2014 The International Journal on Very Large Data Bases, v.25 n.5, p.651-672, October   2016"
    },
    "2995934": {
        "abstract": "Multiversion databases store both current and historical data. Rows are typically annotated with timestamps representing the period when the row is/was valid. We develop novel techniques to reduce index maintenance in multiversion databases, so that indexes can be used effectively for analytical queries over current data without being a heavy burden on transaction throughput. To achieve this end, we re-design persistent index data structures in the storage hierarchy to employ an extra level of indirection. The indirection level is stored on solid-state disks that can support very fast random I/Os, so that traversing the extra level of indirection incurs a relatively small overhead. The extra level of indirection dramatically reduces the number of magnetic disk I/Os that are needed for index updates and localizes maintenance to indexes on updated attributes. Additionally, we batch insertions within the indirection layer in order to reduce physical disk I/Os for indexing new records. In this work, we further exploit SSDs by introducing novel DeltaBlock techniques for storing the recent changes to data on SSDs. Using our DeltaBlock, we propose an efficient method to periodically flush the recently changed data from SSDs to HDDs such that, on the one hand, we keep track of every change (or delta) for every record, and, on the other hand, we avoid redundantly storing the unchanged portion of updated records. By reducing the index maintenance overhead on transactions, we enable operational data stores to create more indexes to support queries. We have developed a prototype of our indirection proposal by extending the widely used generalized search tree open-source project, which is also employed in PostgreSQL. Our working implementation demonstrates that we can significantly reduce index maintenance and/or query processing cost by a factor of 3. For the insertion of new records, our novel batching technique can save up to 90 % of the insertion time. For updates, our prototype demonstrates that we can significantly reduce the database size by up to 80 % even with a modest space allocated for DeltaBlocks on SSDs.",
        "acm_key": "2995934",
        "bib_stats": {
            "cites": 1,
            "dl": 93,
            "dl_52": 93,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Kang:2016:FCE:2995819.2995934,\n author = {Kang, Woon-Hak and Lee, Sang-Won and Moon, Bongki},\n title = {Flash As Cache Extension for Online Transactional Workloads},\n journal = {The VLDB Journal},\n issue_date = {October   2016},\n volume = {25},\n number = {5},\n month = oct,\n year = {2016},\n issn = {1066-8888},\n pages = {673--694},\n numpages = {22},\n url = {http://dx.doi.org/10.1007/s00778-015-0414-1},\n doi = {10.1007/s00778-015-0414-1},\n acmid = {2995934},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {Cache, Flash memory SSDs, Recovery},\n} \r\n",
        "key": "2995934",
        "pub_year": "2016",
        "text": "Woon-Hak Kang , Sang-Won Lee , Bongki Moon, Flash as cache extension for online transactional workloads, The VLDB Journal \u2014 The International Journal on Very Large Data Bases, v.25 n.5, p.673-694, October   2016"
    },
    "2996191": {
        "abstract": "The number of chip pins is limited due to the cost and reliability issues of sophisticated packages, and it is predicted that the chip pin count will be overstretched to satisfy the requirements of both power delivery and memory access. The gap between the achievable pin count and the demand will increase as the technology scales, due to the increasing computation resources and supply current. Pin reduction techniques are thus required for continued computing performance growth. In this article, we propose a chip pin constraint alleviation strategy, through on/off-chip power delivery system co-design, to effectively reduce the demand for power pins. An analytical model of a power delivery system, consisting of on/off-chip regulators and a power delivery network, is proposed to evaluate the influence of regulator design and package conduction loss. By combining this model with a multi-core processor model of performance and memory bandwidth requirements, we characterize the entire multi-core processor system to investigate the relationship between the chip pin constraint and performance in multi-core processor scaling and the effectiveness of our strategy. Experiments show that with the conventional power delivery system design, the chip pin constraint severely limits the performance growth as the technology scales. Using the on/off-chip power delivery system co-design, our strategy achieves a significant pin count reduction, for example, 31.3% at the 8nm technology node, compared to the conventional design with the same chip performance, while, provided with the same chip pin count, it is able to improve, by 35.0%, the chip performance at 8nm compared to the conventional design. For real applications of different parallelism, our strategy outperforms its counterpart, with a 23.7% performance improvement on average at the 8nm technology node.",
        "acm_key": "2996191",
        "bib_stats": {
            "cites": 0,
            "dl": 93,
            "dl_52": 93,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Zhang:2016:SSB:3014160.2996191,\n author = {Zhang, Hang and Chen, Xuhao and Xiao, Nong and Wang, Lei and Liu, Fang and Chen, Wei and Chen, Zhiguang},\n title = {Shielding STT-RAM Based Register Files on GPUs Against Read Disturbance},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {March 2017},\n volume = {13},\n number = {2},\n month = nov,\n year = {2016},\n issn = {1550-4832},\n pages = {27:1--27:17},\n articleno = {27},\n numpages = {17},\n url = {http://doi.acm.org/10.1145/2996191},\n doi = {10.1145/2996191},\n acmid = {2996191},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {GPU, STT-RAM, read disturbance, register file},\n} \r\n",
        "key": "2996191",
        "pub_year": "2017",
        "text": "Hang Zhang , Xuhao Chen , Nong Xiao , Lei Wang , Fang Liu , Wei Chen , Zhiguang Chen, Shielding STT-RAM Based Register Files on GPUs against Read Disturbance, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.2, November 2016"
    },
    "2997451": {
        "abstract": "Fault localization is an important and challenging task during software testing. Among techniques studied in this field, program spectrum based fault localization is a promising approach. To perform spectrum based fault localization, a set of test oracles should be provided, and the effectiveness of fault localization depends highly on the quality of test oracles. Moreover, their effectiveness is usually affected when multiple simultaneous faults are present. Faced with multiple faults it is difficult for developers to determine when to stop the fault localization process. To address these issues, we propose an iterative fault localization process, i.e., an iterative process of selecting test cases for effective fault localization (IPSETFUL), to identify as many faults as possible in the program until the stopping criterion is satisfied. It is performed based on a concept lattice of program spectrum (CLPS) proposed in our previous work. Based on the labeling approach of CLPS, program statements are categorized as dangerous statements, safe statements, and sensitive statements. To identify the faults, developers need to check the dangerous statements. Meantime, developers need to select a set of test cases covering the dangerous or sensitive statements from the original test suite, and a new CLPS is generated for the next iteration. The same process is proceeded in the same way. This iterative process ends until there are no failing tests in the test suite and all statements on the CLPS become safe statements. We conduct an empirical study on several subject programs, and the results show that IPSETFUL can help identifymost of the faults in the program with the given test suite. Moreover, it can save much effort in inspecting unfaulty program statements compared with the existing spectrum based fault localization techniques and the relevant state of the art technique.",
        "acm_key": "2997451",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Zhou:2016:PES:2997414.2997451,\n author = {Zhou, Wen and Feng, Dan and Hua, Yu and Liu, Jingning and Huang, Fangting and Chen, Yu and Zhang, Shuangwu},\n title = {Prober: Exploiting Sequential Characteristics in Buffer for Improving SSDs Write Performance},\n journal = {Front. Comput. Sci.},\n issue_date = {October   2016},\n volume = {10},\n number = {5},\n month = oct,\n year = {2016},\n issn = {2095-2228},\n pages = {951--964},\n numpages = {14},\n url = {http://dx.doi.org/10.1007/s11704-016-5286-z},\n doi = {10.1007/s11704-016-5286-z},\n acmid = {2997451},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {SSDs, buffer management, sequential write requests, storage system},\n} \r\n",
        "key": "2997451",
        "pub_year": "2016",
        "text": "Wen Zhou , Dan Feng , Yu Hua , Jingning Liu , Fangting Huang , Yu Chen , Shuangwu Zhang, Prober: exploiting sequential characteristics in buffer for improving SSDs write performance, Frontiers of Computer Science: Selected Publications from Chinese Universities, v.10 n.5, p.951-964, October   2016"
    },
    "2997648": {
        "abstract": "As we approach the limits of traditional Moore\u2019s-Law scaling, alternative computing techniques that consume energy more efficiently become attractive. Stochastic computing (SC), as a re-emerging computing technique, is a low-cost and error-tolerant alternative to conventional binary circuits in several important applications such as image processing and communications. SC allows a natural accuracy-energy tradeoff that has been exploited in the past. This article presents an accuracy-energy tradeoff technique for SC circuits that reduces their energy consumption with virtually no accuracy loss. To this end, we employ voltage or frequency scaling, which normally reduce energy consumption at the cost of timing errors. Then we show that due to their inherent error tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling. This significantly improves their energy efficiency. In contrast, conventional binary circuits quickly fail as the supply voltage decreases. To find the most energy-efficient operating point of an SC circuit, we propose an error estimation method that allows us to quickly explore the circuit\u2019s design space. The error estimation method is based on Markov chain and least-squares regression. Furthermore, we investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be combined to significantly expand the already-powerful accuracy-energy tradeoff possibilities of SC. In particular, we demonstrate that careful adjustment of path delays can lead to significant error reduction under voltage and frequency scaling. We perform buffer insertion and route detouring to achieve more balanced path delays. These techniques differ from conventional path-balancing techniques whose goal is to minimize power consumption by resizing the non-critical paths. The goal of our path-balancing approach is to increase error cancellation chances in voltage-/frequency-scaled SC circuits. Our circuit optimization comprehends the tradeoff between power overheads due to inserted buffers and wires versus the energy reduction from supply voltage downscaling enabled by more balanced path delays. Simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant signal-to-noise ratio (SNR) degradation. In one example, a 40% supply voltage reduction (1V to 0.6V) on the SC circuit leads to 66% energy saving (20.7pJ to 6.9pJ) and makes it more efficient than its conventional binary counterpart. In the same example, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation. We also show that process variation and temperature variation have limited impact on optimized SC circuits. The error change is less than 5% when temperature changes by 100\u00b0C or process condition changes from worst case to best case.",
        "acm_key": "2997648",
        "bib_stats": {
            "cites": 0,
            "dl": 31,
            "dl_52": 31,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Li:2017:PWM:3051701.2997648,\n author = {Li, Bing and HU, YU and Wang, Ying and Ye, Jing and Li, Xiaowei},\n title = {Power-Utility-Driven Write Management for MLC PCM},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {May 2017},\n volume = {13},\n number = {3},\n month = apr,\n year = {2017},\n issn = {1550-4832},\n pages = {50:1--50:22},\n articleno = {50},\n numpages = {22},\n url = {http://doi.acm.org/10.1145/2997648},\n doi = {10.1145/2997648},\n acmid = {2997648},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Phase change memory, main memory, multi-level, optimization, power, write management},\n} \r\n",
        "key": "2997648",
        "pub_year": "2017",
        "text": "Bing Li , YU HU , Ying Wang , Jing Ye , Xiaowei Li, Power-Utility-Driven Write Management for MLC PCM, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.3, April 2017"
    },
    "2997650": {
        "abstract": "As we approach the limits of traditional Moore\u2019s-Law scaling, alternative computing techniques that consume energy more efficiently become attractive. Stochastic computing (SC), as a re-emerging computing technique, is a low-cost and error-tolerant alternative to conventional binary circuits in several important applications such as image processing and communications. SC allows a natural accuracy-energy tradeoff that has been exploited in the past. This article presents an accuracy-energy tradeoff technique for SC circuits that reduces their energy consumption with virtually no accuracy loss. To this end, we employ voltage or frequency scaling, which normally reduce energy consumption at the cost of timing errors. Then we show that due to their inherent error tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling. This significantly improves their energy efficiency. In contrast, conventional binary circuits quickly fail as the supply voltage decreases. To find the most energy-efficient operating point of an SC circuit, we propose an error estimation method that allows us to quickly explore the circuit\u2019s design space. The error estimation method is based on Markov chain and least-squares regression. Furthermore, we investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be combined to significantly expand the already-powerful accuracy-energy tradeoff possibilities of SC. In particular, we demonstrate that careful adjustment of path delays can lead to significant error reduction under voltage and frequency scaling. We perform buffer insertion and route detouring to achieve more balanced path delays. These techniques differ from conventional path-balancing techniques whose goal is to minimize power consumption by resizing the non-critical paths. The goal of our path-balancing approach is to increase error cancellation chances in voltage-/frequency-scaled SC circuits. Our circuit optimization comprehends the tradeoff between power overheads due to inserted buffers and wires versus the energy reduction from supply voltage downscaling enabled by more balanced path delays. Simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant signal-to-noise ratio (SNR) degradation. In one example, a 40% supply voltage reduction (1V to 0.6V) on the SC circuit leads to 66% energy saving (20.7pJ to 6.9pJ) and makes it more efficient than its conventional binary counterpart. In the same example, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation. We also show that process variation and temperature variation have limited impact on optimized SC circuits. The error change is less than 5% when temperature changes by 100\u00b0C or process condition changes from worst case to best case.",
        "acm_key": "2997650",
        "bib_stats": {
            "cites": 0,
            "dl": 70,
            "dl_52": 70,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Salehi:2017:SSC:3051701.2997650,\n author = {Salehi, Soheil and Fan, Deliang and Demara, Ronald F.},\n title = {Survey of STT-MRAM Cell Design Strategies: Taxonomy and Sense Amplifier Tradeoffs for Resiliency},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {May 2017},\n volume = {13},\n number = {3},\n month = apr,\n year = {2017},\n issn = {1550-4832},\n pages = {48:1--48:16},\n articleno = {48},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/2997650},\n doi = {10.1145/2997650},\n acmid = {2997650},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {STT-MRAM, Spin-transfer torque storage elements, design, magnetic tunnel junction (MTJ), performance, process variation, read/write reliability, reliability, sense amplifier},\n} \r\n",
        "key": "2997650",
        "pub_year": "2017",
        "text": "Soheil Salehi , Deliang Fan , Ronald F. Demara, Survey of STT-MRAM Cell Design Strategies: Taxonomy and Sense Amplifier Tradeoffs for Resiliency, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.3, April 2017"
    },
    "2997651": {
        "abstract": "As we approach the limits of traditional Moore\u2019s-Law scaling, alternative computing techniques that consume energy more efficiently become attractive. Stochastic computing (SC), as a re-emerging computing technique, is a low-cost and error-tolerant alternative to conventional binary circuits in several important applications such as image processing and communications. SC allows a natural accuracy-energy tradeoff that has been exploited in the past. This article presents an accuracy-energy tradeoff technique for SC circuits that reduces their energy consumption with virtually no accuracy loss. To this end, we employ voltage or frequency scaling, which normally reduce energy consumption at the cost of timing errors. Then we show that due to their inherent error tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling. This significantly improves their energy efficiency. In contrast, conventional binary circuits quickly fail as the supply voltage decreases. To find the most energy-efficient operating point of an SC circuit, we propose an error estimation method that allows us to quickly explore the circuit\u2019s design space. The error estimation method is based on Markov chain and least-squares regression. Furthermore, we investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be combined to significantly expand the already-powerful accuracy-energy tradeoff possibilities of SC. In particular, we demonstrate that careful adjustment of path delays can lead to significant error reduction under voltage and frequency scaling. We perform buffer insertion and route detouring to achieve more balanced path delays. These techniques differ from conventional path-balancing techniques whose goal is to minimize power consumption by resizing the non-critical paths. The goal of our path-balancing approach is to increase error cancellation chances in voltage-/frequency-scaled SC circuits. Our circuit optimization comprehends the tradeoff between power overheads due to inserted buffers and wires versus the energy reduction from supply voltage downscaling enabled by more balanced path delays. Simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant signal-to-noise ratio (SNR) degradation. In one example, a 40% supply voltage reduction (1V to 0.6V) on the SC circuit leads to 66% energy saving (20.7pJ to 6.9pJ) and makes it more efficient than its conventional binary counterpart. In the same example, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation. We also show that process variation and temperature variation have limited impact on optimized SC circuits. The error change is less than 5% when temperature changes by 100\u00b0C or process condition changes from worst case to best case.",
        "acm_key": "2997651",
        "bib_stats": {
            "cites": 0,
            "dl": 78,
            "dl_52": 78,
            "dl_6": 8
        },
        "bibtex": "\r\n@article{Yu:2017:RMA:3051701.2997651,\n author = {Yu, Songping and Xiao, Nong and Deng, Mingzhu and Liu, Fang and Chen, Wei},\n title = {Redesign the Memory Allocator for Non-Volatile Main Memory},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {May 2017},\n volume = {13},\n number = {3},\n month = apr,\n year = {2017},\n issn = {1550-4832},\n pages = {49:1--49:26},\n articleno = {49},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/2997651},\n doi = {10.1145/2997651},\n acmid = {2997651},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Non-volatile memory, memory allocator, virtual memory, wear-aware},\n} \r\n",
        "key": "2997651",
        "pub_year": "2017",
        "text": "Songping Yu , Nong Xiao , Mingzhu Deng , Fang Liu , Wei Chen, Redesign the Memory Allocator for Non-Volatile Main Memory, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.3, April 2017"
    },
    "3001140": {
        "abstract": "Memory bandwidth severely limits the scalability and performance of multicore and manycore systems. Application performance can be very sensitive to both the delivered memory bandwidth and latency. In multicore systems, a memory channel is usually shared by multiple cores. Having the ability to precisely provision, schedule, and isolate memory bandwidth and latency on a per-core basis is particularly important when different memory guarantees are needed on a per-customer, per-application, or per-core basis. Infrastructure as a Service (IaaS) Cloud systems, and even general purpose multicores optimized for application throughput or fairness all benefit from the ability to control and schedule memory access on a fine-grain basis. In this paper, we propose MITTS (Memory Inter-arrival Time Traffic Shaping), a simple, distributed hardware mechanism which limits memory traffic at the source (Core or LLC). MITTS shapes memory traffic based on memory request inter-arrival time, enabling fine-grain bandwidth allocation. In an IaaS system, MITTS enables Cloud customers to express their memory distribution needs and pay commensurately. For instance, MITTS enables charging customers that have bursty memory traffic more than customers with uniform memory traffic for the same aggregate bandwidth. Beyond IaaS systems, MITTS can also be used to optimize for throughput or fairness in a general purpose multi-program workload. MITTS uses an online genetic algorithm to configure hardware bins, which can adapt for program phases and variable input sets. We have implemented MITTS in Verilog and have taped-out the design in a 25-core 32nm processor and find that MITTS requires less than 0.9% of core area. We evaluate across SPECint, PARSEC, Apache, and bhm Mail Server workloads, and find that MITTS achieves an average 1.18\u00d7 performance gain compared to the best static bandwidth allocation, a 2.69\u00d7 average performance/cost advantage in an IaaS setting, and up to 1.17\u00d7 better throughput and 1.52\u00d7 better fairness when compared to conventional memory bandwidth provisioning techniques.",
        "acm_key": "3001140",
        "bib_stats": {
            "cites": 16,
            "dl": 450,
            "dl_52": 450,
            "dl_6": 71
        },
        "bibtex": "\r\n@inproceedings{Chi:2016:PNP:3001136.3001140,\n author = {Chi, Ping and Li, Shuangchen and Xu, Cong and Zhang, Tao and Zhao, Jishen and Liu, Yongpan and Wang, Yu and Xie, Yuan},\n title = {PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory},\n booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},\n series = {ISCA '16},\n year = {2016},\n isbn = {978-1-4673-8947-1},\n location = {Seoul, Republic of Korea},\n pages = {27--39},\n numpages = {13},\n url = {https://doi.org/10.1109/ISCA.2016.13},\n doi = {10.1109/ISCA.2016.13},\n acmid = {3001140},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {neural network, processing in memory, resistive random access memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3001140&parent_id=3001136&expformat=bibtex&CFID=982042852&CFTOKEN=55990607\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3001140\">\r\n@article{Chi:2016:PNP:3007787.3001140,\n author = {Chi, Ping and Li, Shuangchen and Xu, Cong and Zhang, Tao and Zhao, Jishen and Liu, Yongpan and Wang, Yu and Xie, Yuan},\n title = {PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2016},\n volume = {44},\n number = {3},\n month = jun,\n year = {2016},\n issn = {0163-5964},\n pages = {27--39},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/3007787.3001140},\n doi = {10.1145/3007787.3001140},\n acmid = {3001140},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {neural network, processing in memory, resistive random access memory},\n} \r\n",
        "key": "3001140",
        "pub_year": "2016",
        "text": "Ping Chi , Shuangchen Li , Cong Xu , Tao Zhang , Jishen Zhao , Yongpan Liu , Yu Wang , Yuan Xie, PRIME: a novel processing-in-memory architecture for neural network computation in ReRAM-based main memory, Proceedings of the 43rd International Symposium on Computer Architecture, June 18-22, 2016, Seoul, Republic of Korea  \u00a0[doi>"
    },
    "3001192": {
        "abstract": "Memory bandwidth severely limits the scalability and performance of multicore and manycore systems. Application performance can be very sensitive to both the delivered memory bandwidth and latency. In multicore systems, a memory channel is usually shared by multiple cores. Having the ability to precisely provision, schedule, and isolate memory bandwidth and latency on a per-core basis is particularly important when different memory guarantees are needed on a per-customer, per-application, or per-core basis. Infrastructure as a Service (IaaS) Cloud systems, and even general purpose multicores optimized for application throughput or fairness all benefit from the ability to control and schedule memory access on a fine-grain basis. In this paper, we propose MITTS (Memory Inter-arrival Time Traffic Shaping), a simple, distributed hardware mechanism which limits memory traffic at the source (Core or LLC). MITTS shapes memory traffic based on memory request inter-arrival time, enabling fine-grain bandwidth allocation. In an IaaS system, MITTS enables Cloud customers to express their memory distribution needs and pay commensurately. For instance, MITTS enables charging customers that have bursty memory traffic more than customers with uniform memory traffic for the same aggregate bandwidth. Beyond IaaS systems, MITTS can also be used to optimize for throughput or fairness in a general purpose multi-program workload. MITTS uses an online genetic algorithm to configure hardware bins, which can adapt for program phases and variable input sets. We have implemented MITTS in Verilog and have taped-out the design in a 25-core 32nm processor and find that MITTS requires less than 0.9% of core area. We evaluate across SPECint, PARSEC, Apache, and bhm Mail Server workloads, and find that MITTS achieves an average 1.18\u00d7 performance gain compared to the best static bandwidth allocation, a 2.69\u00d7 average performance/cost advantage in an IaaS setting, and up to 1.17\u00d7 better throughput and 1.52\u00d7 better fairness when compared to conventional memory bandwidth provisioning techniques.",
        "acm_key": "3001192",
        "bib_stats": {
            "cites": 2,
            "dl": 74,
            "dl_52": 74,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:MWE:3001136.3001192,\n author = {Zhang, Lunkai and Neely, Brian and Franklin, Diana and Strukov, Dmitri and Xie, Yuan and Chong, Frederic T.},\n title = {Mellow Writes: Extending Lifetime in Resistive Memories Through Selective Slow Write Backs},\n booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},\n series = {ISCA '16},\n year = {2016},\n isbn = {978-1-4673-8947-1},\n location = {Seoul, Republic of Korea},\n pages = {519--531},\n numpages = {13},\n url = {https://doi.org/10.1109/ISCA.2016.52},\n doi = {10.1109/ISCA.2016.52},\n acmid = {3001192},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {endurance, non-volatile memory, write latency},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3001192&parent_id=3001136&expformat=bibtex&CFID=982044470&CFTOKEN=97110629\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3001192\">\r\n@article{Zhang:2016:MWE:3007787.3001192,\n author = {Zhang, Lunkai and Neely, Brian and Franklin, Diana and Strukov, Dmitri and Xie, Yuan and Chong, Frederic T.},\n title = {Mellow Writes: Extending Lifetime in Resistive Memories Through Selective Slow Write Backs},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2016},\n volume = {44},\n number = {3},\n month = jun,\n year = {2016},\n issn = {0163-5964},\n pages = {519--531},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/3007787.3001192},\n doi = {10.1145/3007787.3001192},\n acmid = {3001192},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {endurance, non-volatile memory, write latency},\n} \r\n",
        "key": "3001192",
        "pub_year": "2016",
        "text": "Lunkai Zhang , Brian Neely , Diana Franklin , Dmitri Strukov , Yuan Xie , Frederic T. Chong, Mellow writes: extending lifetime in resistive memories through selective slow write backs, ACM SIGARCH Computer Architecture News, v.44 n.3, June 2016"
    },
    "3001211": {
        "abstract": "Memory bandwidth severely limits the scalability and performance of multicore and manycore systems. Application performance can be very sensitive to both the delivered memory bandwidth and latency. In multicore systems, a memory channel is usually shared by multiple cores. Having the ability to precisely provision, schedule, and isolate memory bandwidth and latency on a per-core basis is particularly important when different memory guarantees are needed on a per-customer, per-application, or per-core basis. Infrastructure as a Service (IaaS) Cloud systems, and even general purpose multicores optimized for application throughput or fairness all benefit from the ability to control and schedule memory access on a fine-grain basis. In this paper, we propose MITTS (Memory Inter-arrival Time Traffic Shaping), a simple, distributed hardware mechanism which limits memory traffic at the source (Core or LLC). MITTS shapes memory traffic based on memory request inter-arrival time, enabling fine-grain bandwidth allocation. In an IaaS system, MITTS enables Cloud customers to express their memory distribution needs and pay commensurately. For instance, MITTS enables charging customers that have bursty memory traffic more than customers with uniform memory traffic for the same aggregate bandwidth. Beyond IaaS systems, MITTS can also be used to optimize for throughput or fairness in a general purpose multi-program workload. MITTS uses an online genetic algorithm to configure hardware bins, which can adapt for program phases and variable input sets. We have implemented MITTS in Verilog and have taped-out the design in a 25-core 32nm processor and find that MITTS requires less than 0.9% of core area. We evaluate across SPECint, PARSEC, Apache, and bhm Mail Server workloads, and find that MITTS achieves an average 1.18\u00d7 performance gain compared to the best static bandwidth allocation, a 2.69\u00d7 average performance/cost advantage in an IaaS setting, and up to 1.17\u00d7 better throughput and 1.52\u00d7 better fairness when compared to conventional memory bandwidth provisioning techniques.",
        "acm_key": "3001211",
        "bib_stats": {
            "cites": 0,
            "dl": 142,
            "dl_52": 142,
            "dl_6": 7
        },
        "bibtex": "\r\n@article{Arjomand:2016:BAP:3007787.3001211,\n author = {Arjomand, Mohammad and Kandemir, Mahmut T. and Sivasubramaniam, Anand and Das, Chita R.},\n title = {Boosting Access Parallelism to PCM-based Main Memory},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {June 2016},\n volume = {44},\n number = {3},\n month = jun,\n year = {2016},\n issn = {0163-5964},\n pages = {695--706},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/3007787.3001211},\n doi = {10.1145/3007787.3001211},\n acmid = {3001211},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {phase change memory, write performance},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3001211&parent_id=3007787&expformat=bibtex&CFID=982044097&CFTOKEN=33914760\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3001211\">\r\n@inproceedings{Arjomand:2016:BAP:3001136.3001211,\n author = {Arjomand, Mohammad and Kandemir, Mahmut T. and Sivasubramaniam, Anand and Das, Chita R.},\n title = {Boosting Access Parallelism to PCM-based Main Memory},\n booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},\n series = {ISCA '16},\n year = {2016},\n isbn = {978-1-4673-8947-1},\n location = {Seoul, Republic of Korea},\n pages = {695--706},\n numpages = {12},\n url = {https://doi.org/10.1109/ISCA.2016.66},\n doi = {10.1109/ISCA.2016.66},\n acmid = {3001211},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {phase change memory, write performance},\n} \r\n",
        "key": "3001211",
        "pub_year": "2016",
        "text": "Mohammad Arjomand , Mahmut T. Kandemir , Anand Sivasubramaniam , Chita R. Das, Boosting access parallelism to PCM-based main memory, ACM SIGARCH Computer Architecture News, v.44 n.3, June 2016"
    },
    "3001861": {
        "abstract": "The rise of smart mobile devices presents increasing opportunities for health monitoring outside the clinic. Through the use of sensors and wearables, innovative Connected Health applications can be developed. In particular, Digital Therapeutics (DT), a type of technology-enabled intervention, can be made possible through continuous data capture, aiding users through gaining feedback on their lifestyle choices and engagement with programs of recovery, and supplementing conventional treatments for chronic disease management such as in diabetes, epilepsy, and mental health. Unfortunately, patient-facing professionals capable of articulating appropriate sensor-enabled solutions, generally lack the full range of skills to develop such systems. A connected health application may involve mobile development, data services, visualisation, machine learning, and sensor signal processing, needing multidisciplinary teams, including professional software engineers. The cost of maintaining a software team across the research and development stages may prove prohibitive for many, hindering innovation. This paper focuses on gathering requirements for ",
        "acm_key": "3001861",
        "bib_stats": {
            "cites": 0,
            "dl": 76,
            "dl_52": 76,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Bhandari:2016:MPH:3001854.3001861,\n author = {Bhandari, Kumud},\n title = {Managing Persistent Heap in NVRAM},\n booktitle = {Proceedings of the 1st International Workshop on Mobile Development},\n series = {Mobile! 2016},\n year = {2016},\n isbn = {978-1-4503-4643-6},\n location = {Amsterdam, Netherlands},\n pages = {6--8},\n numpages = {3},\n url = {http://doi.acm.org/10.1145/3001854.3001861},\n doi = {10.1145/3001854.3001861},\n acmid = {3001861},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {allocation, deallocation, garbage collection, mobile devices, non-volatile memory, persistent memory management},\n} \r\n",
        "key": "3001861",
        "pub_year": "2016",
        "text": "Kumud Bhandari, Managing persistent heap in NVRAM, Proceedings of the 1st International Workshop on Mobile Development, October 31-31, 2016, Amsterdam, Netherlands"
    },
    "3001936": {
        "abstract": "The number of chip pins is limited due to the cost and reliability issues of sophisticated packages, and it is predicted that the chip pin count will be overstretched to satisfy the requirements of both power delivery and memory access. The gap between the achievable pin count and the demand will increase as the technology scales, due to the increasing computation resources and supply current. Pin reduction techniques are thus required for continued computing performance growth. In this article, we propose a chip pin constraint alleviation strategy, through on/off-chip power delivery system co-design, to effectively reduce the demand for power pins. An analytical model of a power delivery system, consisting of on/off-chip regulators and a power delivery network, is proposed to evaluate the influence of regulator design and package conduction loss. By combining this model with a multi-core processor model of performance and memory bandwidth requirements, we characterize the entire multi-core processor system to investigate the relationship between the chip pin constraint and performance in multi-core processor scaling and the effectiveness of our strategy. Experiments show that with the conventional power delivery system design, the chip pin constraint severely limits the performance growth as the technology scales. Using the on/off-chip power delivery system co-design, our strategy achieves a significant pin count reduction, for example, 31.3% at the 8nm technology node, compared to the conventional design with the same chip performance, while, provided with the same chip pin count, it is able to improve, by 35.0%, the chip performance at 8nm compared to the conventional design. For real applications of different parallelism, our strategy outperforms its counterpart, with a 23.7% performance improvement on average at the 8nm technology node.",
        "acm_key": "3001936",
        "bib_stats": {
            "cites": 0,
            "dl": 199,
            "dl_52": 199,
            "dl_6": 18
        },
        "bibtex": "\r\n@article{Senni:2016:NPB:3014160.3001936,\n author = {Senni, Sophiane and Torres, Lionel and Sassatelli, Gilles and Gamatie, Abdoulaye},\n title = {Non-Volatile Processor Based on MRAM for Ultra-Low-Power IoT Devices},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {March 2017},\n volume = {13},\n number = {2},\n month = dec,\n year = {2016},\n issn = {1550-4832},\n pages = {17:1--17:23},\n articleno = {17},\n numpages = {23},\n url = {http://doi.acm.org/10.1145/3001936},\n doi = {10.1145/3001936},\n acmid = {3001936},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MRAM, embedded systems, internet of things, non-volatility},\n} \r\n",
        "key": "3001936",
        "pub_year": "2017",
        "text": "Sophiane Senni , Lionel Torres , Gilles Sassatelli , Abdoulaye Gamatie, Non-Volatile Processor Based on MRAM for Ultra-Low-Power IoT Devices, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.2, February 2017"
    },
    "3004157": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3004157",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Xue:2016:LVN:3004145.3004157,\n author = {Xue, Xiaoyong and Yang, Jianguo and Lin, Yinyin and Huang, Ryan and Zou, Qingtian and Wu, Jingang},\n title = {Low-Power Variation-Tolerant Nonvolatile Lookup Table Design},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {March 2016},\n volume = {24},\n number = {3},\n month = mar,\n year = {2016},\n issn = {1063-8210},\n pages = {1174--1178},\n numpages = {5},\n url = {http://dx.doi.org/10.1109/TVLSI.2015.2426876},\n doi = {10.1109/TVLSI.2015.2426876},\n acmid = {3004157},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3004157",
        "pub_year": "2016",
        "text": "Xiaoyong Xue , Jianguo Yang , Yinyin Lin , Ryan Huang , Qingtian Zou , Jingang Wu, Low-Power Variation-Tolerant Nonvolatile Lookup Table Design, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.24 n.3, p.1174-1178, March 2016  \u00a0[doi>"
    },
    "3004198": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3004198",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Yang:2016:RSE:3004146.3004198,\n author = {Yang, Jianlei and Wang, Peiyuan and Zhang, Yaojun and Cheng, Yuanqing and Zhao, Weisheng and Chen, Yiran and Li, Hai Helen},\n title = {Radiation-Induced Soft Error Analysis of STT-MRAM: A Device to Circuit Approach},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {March 2016},\n volume = {35},\n number = {3},\n month = mar,\n year = {2016},\n issn = {0278-0070},\n pages = {380--393},\n numpages = {14},\n url = {http://dx.doi.org/10.1109/TCAD.2015.2474366},\n doi = {10.1109/TCAD.2015.2474366},\n acmid = {3004198},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3004198",
        "pub_year": "2016",
        "text": "Jianlei Yang , Peiyuan Wang , Yaojun Zhang , Yuanqing Cheng , Weisheng Zhao , Yiran Chen , Hai Helen Li, Radiation-Induced Soft Error Analysis of STT-MRAM: A Device to Circuit Approach, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.35 n.3, p.380-393, March 2016  \u00a0[doi>"
    },
    "3005761": {
        "abstract": "Programmable switches potentially make it easier to perform flexible network monitoring queries at line rate, and scalable stream processors make it possible to fuse data streams to answer more sophisticated queries about the network in real-time. However, processing such network monitoring queries at high traffic rates requires both the switches and the stream processors to filter the traffic iteratively and adaptively so as to extract only that traffic that is of interest to the query at hand. While the realization that network monitoring is a streaming analytics problem has been made earlier, our main contribution in this paper is the design and implementation of Sonata, a closed-loop system that enables network operators to perform streaming analytics for network monitoring applications at scale. To achieve this objective, Sonata allows operators to express a network monitoring query by considering each packet as a tuple. More importantly, Sonata allows them to partition the query across both the switches and the stream processor, and through iterative refinement, Sonata's runtime attempts to extract only the traffic that pertains to the query, thus ensuring that the stream processor can scale to satisfy a large number of queries for traffic at very high rates. We show with a simple example query involving DNS reflection attacks and traffic traces from one of the world's largest IXPs that Sonata can capture 95% of all traffic pertaining to the query, while reducing the overall data rate by a factor of about 400 and the number of required counters by four orders of magnitude.",
        "acm_key": "3005761",
        "bib_stats": {
            "cites": 0,
            "dl": 253,
            "dl_52": 253,
            "dl_6": 23
        },
        "bibtex": "\r\n@inproceedings{Honda:2016:PNS:3005745.3005761,\n author = {Honda, Michio and Eggert, Lars and Santry, Douglas},\n title = {PASTE: Network Stacks Must Integrate with NVMM Abstractions},\n booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},\n series = {HotNets '16},\n year = {2016},\n isbn = {978-1-4503-4661-0},\n location = {Atlanta, GA, USA},\n pages = {183--189},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/3005745.3005761},\n doi = {10.1145/3005745.3005761},\n acmid = {3005761},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3005761",
        "pub_year": "2016",
        "text": "Michio Honda , Lars Eggert , Douglas Santry, PASTE: Network Stacks Must Integrate with NVMM Abstractions, Proceedings of the 15th ACM Workshop on Hot Topics in Networks, p.183-189, November 09-10, 2016, Atlanta, GA, USA"
    },
    "3006017": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3006017",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{El-Hassan:2016:ITS:3005952.3006017,\n author = {El-Hassan, Nemat H. and Kumar, T. Nandha and Almurib, Haider Abbas F.},\n title = {Implementation of Time-aware Sensing Technique for Multilevel Phase Change Memory Cell},\n journal = {Microelectron. J.},\n issue_date = {October 2016},\n volume = {56},\n number = {C},\n month = oct,\n year = {2016},\n issn = {0026-2692},\n pages = {74--80},\n numpages = {7},\n url = {https://doi.org/10.1016/j.mejo.2016.08.007},\n doi = {10.1016/j.mejo.2016.08.007},\n acmid = {3006017},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Chalcogenide, Drift, Half adder, Joule heat, LUT, Multilevel, Non-volatile, Phase change},\n} \r\n",
        "key": "3006017",
        "pub_year": "2016",
        "text": "Nemat H. El-Hassan , T. Nandha Kumar , Haider Abbas F. Almurib, Implementation of time-aware sensing technique for multilevel phase change memory cell, Microelectronics Journal, v.56 n.C, p.74-80, October 2016"
    },
    "3006318": {
        "abstract": "As a novel concept, \"Informed Design\" is being practiced in the Future Cities Laboratory at the Singapore-ETH Centre to innovate place design from empirical to evidential by harnessing geo-referenced \"Big Data\" for a responsive design. Initially, potentials of people sensing data derived from multi-sources, such as social networks, dedicated applications, sensors, etc., shall be explored to measure place utilization for a better understanding of design contexts and elicitation of design requirements. Therefore, an \"Activities in Places\" service is required to detect frequently used places, called hot places (HPs), and measure their utilizations in various dimensions. In order to fulfill emerging requirements and properly handle big and heterogeneous geo-located data in a near-real time manner for a responsive design, a unsupervised method, called <u>S</u>calable \"<u>A</u>ctivities in <u>P</u>laces\" <u>A</u>nalysis <u>M</u>echanism (SAPAM), is proposed with two main analysis mechanisms, namely 1) a scalable density-based spatial clustering of applications with noise (SDBSCAN), which dramatically improves the performance of DBSCAN through concurrent clusterings on data partitions, 2) a hot place detection procedure (HPDP) to extract HPs from clusters based on a continuous place usage pattern (CPUP), and analyze performed activities through a topic model trained by a corpus of daily documents of places. As proved by a comprehensive evaluation, 1) SDBSCAN, indeed, greatly improves the performance as shown by its best performance 4.71s, which is 11 times faster than DBSCAN, 2) HPDP can precisely detect HPs with a high recall of Singaporean regional centers, main transportation hubs and famous attractions, and 3) the utilization of HPs can be unveiled by three indicators, namely the number of visitors, the size of influence area, and the density of people, and also by performed activities in HPs. As a case study, three top 10 HP lists of three utilization indexes are created, and performed activities in a regional center Jurong East are analyzed.",
        "acm_key": "3006318",
        "bib_stats": {
            "cites": 0,
            "dl": 94,
            "dl_52": 94,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Zhou:2016:NEK:3006299.3006318,\n author = {Zhou, Jie and Shen, Yanyan and Li, Sumin and Huang, Linpeng},\n title = {NVHT: An Efficient Key-value Storage Library for Non-volatile Memory},\n booktitle = {Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies},\n series = {BDCAT '16},\n year = {2016},\n isbn = {978-1-4503-4617-7},\n location = {Shanghai, China},\n pages = {227--236},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/3006299.3006318},\n doi = {10.1145/3006299.3006318},\n acmid = {3006318},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {in-memory system, key-value store, non-volatile memory},\n} \r\n",
        "key": "3006318",
        "pub_year": "2016",
        "text": "Jie Zhou , Yanyan Shen , Sumin Li , Linpeng Huang, NVHT: an efficient key-value storage library for non-volatile memory, Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies, December 06-09, 2016, Shanghai, China"
    },
    "3007650": {
        "abstract": "As we approach the limits of traditional Moore\u2019s-Law scaling, alternative computing techniques that consume energy more efficiently become attractive. Stochastic computing (SC), as a re-emerging computing technique, is a low-cost and error-tolerant alternative to conventional binary circuits in several important applications such as image processing and communications. SC allows a natural accuracy-energy tradeoff that has been exploited in the past. This article presents an accuracy-energy tradeoff technique for SC circuits that reduces their energy consumption with virtually no accuracy loss. To this end, we employ voltage or frequency scaling, which normally reduce energy consumption at the cost of timing errors. Then we show that due to their inherent error tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling. This significantly improves their energy efficiency. In contrast, conventional binary circuits quickly fail as the supply voltage decreases. To find the most energy-efficient operating point of an SC circuit, we propose an error estimation method that allows us to quickly explore the circuit\u2019s design space. The error estimation method is based on Markov chain and least-squares regression. Furthermore, we investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be combined to significantly expand the already-powerful accuracy-energy tradeoff possibilities of SC. In particular, we demonstrate that careful adjustment of path delays can lead to significant error reduction under voltage and frequency scaling. We perform buffer insertion and route detouring to achieve more balanced path delays. These techniques differ from conventional path-balancing techniques whose goal is to minimize power consumption by resizing the non-critical paths. The goal of our path-balancing approach is to increase error cancellation chances in voltage-/frequency-scaled SC circuits. Our circuit optimization comprehends the tradeoff between power overheads due to inserted buffers and wires versus the energy reduction from supply voltage downscaling enabled by more balanced path delays. Simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant signal-to-noise ratio (SNR) degradation. In one example, a 40% supply voltage reduction (1V to 0.6V) on the SC circuit leads to 66% energy saving (20.7pJ to 6.9pJ) and makes it more efficient than its conventional binary counterpart. In the same example, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation. We also show that process variation and temperature variation have limited impact on optimized SC circuits. The error change is less than 5% when temperature changes by 100\u00b0C or process condition changes from worst case to best case.",
        "acm_key": "3007650",
        "bib_stats": {
            "cites": 0,
            "dl": 99,
            "dl_52": 99,
            "dl_6": 19
        },
        "bibtex": "\r\n@article{Yoon:2017:MUM:3051701.3007650,\n author = {Yoon, Su-Kyung and Youn, Young-Sun and Park, Kihyun and Kim, Shin-Dug},\n title = {Mobile Unified Memory-Storage Structure Based on Hybrid Non-Volatile Memories},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {May 2017},\n volume = {13},\n number = {3},\n month = apr,\n year = {2017},\n issn = {1550-4832},\n pages = {40:1--40:18},\n articleno = {40},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/3007650},\n doi = {10.1145/3007650},\n acmid = {3007650},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Emerging technologies, memory-storage hierarchy, mobile memory-storage system},\n} \r\n",
        "key": "3007650",
        "pub_year": "2017",
        "text": "Su-Kyung Yoon , Young-Sun Youn , Kihyun Park , Shin-Dug Kim, Mobile Unified Memory-Storage Structure Based on Hybrid Non-Volatile Memories, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.3, April 2017"
    },
    "3007830": {
        "abstract": "Healthcare and the treatment of illnesses are one of the most fundamental aspects of modern human life, and drugs are the easiest way to approach to healthcare. Consuming drugs lead to diverse effects however. For instance, drugs reduce our pain, cure diseases, and maintain our healthy life. Unfortunately, due to the high price of drugs, not everyone can enjoy the same benefits. We propose using the generic medicine names, which are used to identify drugs that contain similar chemical ingredients and therefore perform similar purposes, to alleviate such concerns. That is, people will have the opportunity to select drugs that are suitable to their preferences. It is important to note that drugs with the same generic name do serve similar purposes, but may result in different side-effects at the same time. Drugs affect the human body in many different ways that are not all necessarily good. The side effects of drugs posed a major problem, and its negative effects sometimes take form in serious ways. This paper will present a way to address the issue of side effects by recommending alternative drugs that have the same effect, but with less detrimental effects. In the healthcare group, which is the platform of social networks, users share their comments and experiences about drugs, from which we can extract numerical ratings of various drugs. By integrating the generic names of drugs and data from social networks, we can get more data to draw meaningful conclusions. The process involves identifying a group of drugs under the same generic name, and comparing the user review-based ratings to determine which drug has less side effects. This paper will present a way to collect, process, and make use of data from social networks, as well as provide one solution to the issue of drug side effects.",
        "acm_key": "3007830",
        "bib_stats": {
            "cites": 0,
            "dl": 33,
            "dl_52": 33,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Shim:2016:LAM:3007818.3007830,\n author = {Shim, Hyun-Jeong and Li, Xian-Shu and Yoon, Su-Kyung and Kim, Shin-Dug},\n title = {Locality Aware Management on NAND Flash-based Main Memory for In-memory Database Systems},\n booktitle = {Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory},\n series = {EDB '16},\n year = {2016},\n isbn = {978-1-4503-4754-9},\n location = {Jeju, Republic of Korea},\n pages = {90--94},\n numpages = {5},\n url = {http://doi.acm.org/10.1145/3007818.3007830},\n doi = {10.1145/3007818.3007830},\n acmid = {3007830},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NAND flash memory, data warehousing, hybrid memory, in-memory database, locality aware management},\n} \r\n",
        "key": "3007830",
        "pub_year": "2016",
        "text": "Hyun-Jeong Shim , Xian-Shu Li , Su-Kyung Yoon , Shin-Dug Kim, Locality aware management on NAND flash-based main memory for in-memory database systems, Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory, p.90-94, October 17-19, 2016, Jeju, Repbulic of Korea"
    },
    "3007844": {
        "abstract": "Healthcare and the treatment of illnesses are one of the most fundamental aspects of modern human life, and drugs are the easiest way to approach to healthcare. Consuming drugs lead to diverse effects however. For instance, drugs reduce our pain, cure diseases, and maintain our healthy life. Unfortunately, due to the high price of drugs, not everyone can enjoy the same benefits. We propose using the generic medicine names, which are used to identify drugs that contain similar chemical ingredients and therefore perform similar purposes, to alleviate such concerns. That is, people will have the opportunity to select drugs that are suitable to their preferences. It is important to note that drugs with the same generic name do serve similar purposes, but may result in different side-effects at the same time. Drugs affect the human body in many different ways that are not all necessarily good. The side effects of drugs posed a major problem, and its negative effects sometimes take form in serious ways. This paper will present a way to address the issue of side effects by recommending alternative drugs that have the same effect, but with less detrimental effects. In the healthcare group, which is the platform of social networks, users share their comments and experiences about drugs, from which we can extract numerical ratings of various drugs. By integrating the generic names of drugs and data from social networks, we can get more data to draw meaningful conclusions. The process involves identifying a group of drugs under the same generic name, and comparing the user review-based ratings to determine which drug has less side effects. This paper will present a way to collect, process, and make use of data from social networks, as well as provide one solution to the issue of drug side effects.",
        "acm_key": "3007844",
        "bib_stats": {
            "cites": 0,
            "dl": 41,
            "dl_52": 41,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Nguyen:2016:ICM:3007818.3007844,\n author = {Nguyen, Trong-Dat and Lee, Sang-Won},\n title = {I/O Characteristics of MongoDB and Trim-based Optimization in Flash SSDs},\n booktitle = {Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory},\n series = {EDB '16},\n year = {2016},\n isbn = {978-1-4503-4754-9},\n location = {Jeju, Republic of Korea},\n pages = {139--144},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3007818.3007844},\n doi = {10.1145/3007818.3007844},\n acmid = {3007844},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O characteristics, I/O pattern, MongoDB, NoSQL, SSD, TRIM command, WiredTiger, YCSB},\n} \r\n",
        "key": "3007844",
        "pub_year": "2016",
        "text": "Trong-Dat Nguyen , Sang-Won Lee, I/O characteristics of MongoDB and trim-based optimization in flash SSDs, Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory, p.139-144, October 17-19, 2016, Jeju, Repbulic of Korea"
    },
    "3012002": {
        "abstract": "The number of chip pins is limited due to the cost and reliability issues of sophisticated packages, and it is predicted that the chip pin count will be overstretched to satisfy the requirements of both power delivery and memory access. The gap between the achievable pin count and the demand will increase as the technology scales, due to the increasing computation resources and supply current. Pin reduction techniques are thus required for continued computing performance growth. In this article, we propose a chip pin constraint alleviation strategy, through on/off-chip power delivery system co-design, to effectively reduce the demand for power pins. An analytical model of a power delivery system, consisting of on/off-chip regulators and a power delivery network, is proposed to evaluate the influence of regulator design and package conduction loss. By combining this model with a multi-core processor model of performance and memory bandwidth requirements, we characterize the entire multi-core processor system to investigate the relationship between the chip pin constraint and performance in multi-core processor scaling and the effectiveness of our strategy. Experiments show that with the conventional power delivery system design, the chip pin constraint severely limits the performance growth as the technology scales. Using the on/off-chip power delivery system co-design, our strategy achieves a significant pin count reduction, for example, 31.3% at the 8nm technology node, compared to the conventional design with the same chip performance, while, provided with the same chip pin count, it is able to improve, by 35.0%, the chip performance at 8nm compared to the conventional design. For real applications of different parallelism, our strategy outperforms its counterpart, with a 23.7% performance improvement on average at the 8nm technology node.",
        "acm_key": "3012002",
        "bib_stats": {
            "cites": 0,
            "dl": 65,
            "dl_52": 65,
            "dl_6": 6
        },
        "bibtex": "\r\n@article{Wang:2017:OSF:3014160.3012002,\n author = {Wang, Yao and Rong, Liang and Wang, Haibo and Wen, Guangjun},\n title = {One-Step Sneak-Path Free Read Scheme for Resistive Crossbar Memory},\n journal = {J. Emerg. Technol. Comput. Syst.},\n issue_date = {March 2017},\n volume = {13},\n number = {2},\n month = feb,\n year = {2017},\n issn = {1550-4832},\n pages = {25:1--25:18},\n articleno = {25},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/3012002},\n doi = {10.1145/3012002},\n acmid = {3012002},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Sneak-path, crossbar array, read scheme, resistive memory},\n} \r\n",
        "key": "3012002",
        "pub_year": "2017",
        "text": "Yao Wang , Liang Rong , Haibo Wang , Guangjun Wen, One-Step Sneak-Path Free Read Scheme for Resistive Crossbar Memory, ACM Journal on Emerging Technologies in Computing Systems (JETC), v.13 n.2, February 2017"
    },
    "3012007": {
        "abstract": "Every HPC system consists of numerous processing nodes interconnect using a number of different inter-process communication protocols such as Messaging Passing Interface (MPI) and Global Arrays (GA). Traditionally, research has focused on optimizing these protocols and identifying the most suitable ones for each system and/or application. Recently, there has been a proposal to unify the primitive operations of the different inter-processor communication protocols through the Portals library. Portals offer a set of low-level communication routines which can be composed in order to implement the functionality of different intercommunication protocols. However, Portals modularity comes at a performance cost, since it adds one more layer in the actual protocol implementation. This work aims at closing the performance gap between a generic and reusable intercommunication layer, such as Portals, and the several monolithic and highly optimized intercommunication protocols. This is achieved through the development of a novel hardware offload engine efficiently implementing the basic Portals\u2019 modules. Our innovative system is up to two2 orders of magnitude faster than the conventional software implementation of Portals\u2019 while the speedup achieved over the conventional monolithic software implementations of MPI and GAs is more than an order of magnitude. The power consumption of our hardware system is less than 1/100th of what a low-power CPU consumes when executing the Portal's software while its silicon cost is less than 1/10th of that of a very simple RISC CPU. Moreover, our design process is also innovative since we have first modeled the hardware within an untimed virtual prototype which allowed for rapid design space exploration; then we applied a novel methodology to transform the untimed description into an efficient timed hardware description, which was then transformed into a hardware netlist through a High-Level Synthesis (HLS) tool.",
        "acm_key": "3012007",
        "bib_stats": {
            "cites": 0,
            "dl": 105,
            "dl_52": 105,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Li:2016:MAP:3012405.3012007,\n author = {Li, Zheng and Wang, Fang and Feng, Dan and Hua, Yu and Liu, Jingning and Tong, Wei},\n title = {MaxPB: Accelerating PCM Write by Maximizing the Power Budget Utilization},\n journal = {ACM Trans. Archit. Code Optim.},\n issue_date = {December 2016},\n volume = {13},\n number = {4},\n month = dec,\n year = {2016},\n issn = {1544-3566},\n pages = {46:1--46:26},\n articleno = {46},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/3012007},\n doi = {10.1145/3012007},\n acmid = {3012007},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {PCM, power budget, write scheme, write unit},\n} \r\n",
        "key": "3012007",
        "pub_year": "2016",
        "text": "Zheng Li , Fang Wang , Dan Feng , Yu Hua , Jingning Liu , Wei Tong, MaxPB: Accelerating PCM Write by Maximizing the Power Budget Utilization, ACM Transactions on Architecture and Code Optimization (TACO), v.13 n.4, p.1-26, December 2016"
    },
    "3014969": {
        "abstract": "Supercomputers offer new opportunities for scientific computing as they grow in size. However, their growth also poses new challenges. Resilience has been recognized as one of the most pressing issues to solve for extreme scale computing. Transistor scaling in the single-digit nanometer era and power constraints might dramatically increase the failure rate of next generation machines. DRAM errors have been analyzed in the past for different supercomputers but those studies are usually based on job scheduler logs and counters produced by hardware-level error correcting codes. Consequently, little is known about errors escaping hardware checks, which lead to silent data corruption. This work attempts to fill that gap by analyzing memory errors for over a year on a cluster with about 1000 nodes featuring low-power memory without error correction. The study gathered millions of events recording detailed information of thousands of memory errors, many of them corrupting multiple bits. Several factors are analyzed, such as temporal and spatial correlation between errors, but also the influence of temperature and even the position of the sun in the sky. The study showed that most multi-bit errors corrupted non-adjacent bits in the memory word and that most errors flipped memory bits from 1 to 0. In addition, we observed thousands of cases of multiple single-bit errors occurring simultaneously in different regions of the memory. These new observations would not be possible by simply analyzing error correction counters on classical systems. We propose several directions in which the findings of this study can help the design of more reliable systems in the future.",
        "acm_key": "3014969",
        "bib_stats": {
            "cites": 0,
            "dl": 165,
            "dl_52": 165,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Shahidi:2016:EPP:3014904.3014969,\n author = {Shahidi, Narges and Arjomand, Mohammad and Jung, Myoungsoo and Kandemir, Mahmut T. and Das, Chita R. and Sivasubramaniam, Anand},\n title = {Exploring the Potentials of Parallel Garbage Collection in SSDs for Enterprise Storage Systems},\n booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},\n series = {SC '16},\n year = {2016},\n isbn = {978-1-4673-8815-3},\n location = {Salt Lake City, Utah},\n pages = {48:1--48:12},\n articleno = {48},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=3014904.3014969},\n acmid = {3014969},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3014969",
        "pub_year": "2016",
        "text": "Narges Shahidi , Mohammad Arjomand , Myoungsoo Jung , Mahmut T. Kandemir , Chita R. Das , Anand Sivasubramaniam, Exploring the potentials of parallel garbage collection in SSDs for enterprise storage systems, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, November 13-18, 2016, Salt Lake City, Utah"
    },
    "3017430": {
        "abstract": "Existing storage stacks are top heavy and expect little from block storage. As a result, new high-level storage abstractions\u2014and new designs for existing abstractions\u2014are difficult to realize, requiring developers to implement from scratch complex functionality such as failure atomicity and fine-grained concurrency control. In this article, we argue that pushing transactional isolation into the block store (in addition to atomicity and durability) is both viable and broadly useful, resulting in simpler high-level storage systems that provide strong semantics without sacrificing performance. We present Isotope, a new block store that supports ACID transactions over block reads and writes. Internally, Isotope uses a new multiversion concurrency control protocol that exploits fine-grained, subblock parallelism in workloads and offers both strict serializability and snapshot isolation guarantees. We implemented several high-level storage systems over Isotope, including two key-value stores that implement the LevelDB API over a hash table and B-tree, respectively, and a POSIX file system. We show that Isotope\u2019s block-level transactions enable systems that are simple (100s of lines of code), robust (i.e., providing ACID guarantees), and fast (e.g., 415MB/s for random file writes). We also show that these systems can be composed using Isotope, providing applications with transactions across different high-level constructs such as files, directories, and key-value pairs.",
        "acm_key": "3017430",
        "bib_stats": {
            "cites": 0,
            "dl": 170,
            "dl_52": 170,
            "dl_6": 18
        },
        "bibtex": "\r\n@article{Qi:2017:CNE:3054178.3017430,\n author = {Qi, Shigui and Feng, Dan and Su, Nan and Mei, Linjun and Liu, Jingning},\n title = {CDF-LDPC: A New Error Correction Method for SSD to Improve the Read Performance},\n journal = {Trans. Storage},\n issue_date = {March 2017},\n volume = {13},\n number = {1},\n month = feb,\n year = {2017},\n issn = {1553-3077},\n pages = {7:1--7:22},\n articleno = {7},\n numpages = {22},\n url = {http://doi.acm.org/10.1145/3017430},\n doi = {10.1145/3017430},\n acmid = {3017430},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Solid-state drives, error correction code, error detection code, low density parity check, read performance},\n} \r\n",
        "key": "3017430",
        "pub_year": "2017",
        "text": "Shigui Qi , Dan Feng , Nan Su , Linjun Mei , Jingning Liu, CDF-LDPC: A New Error Correction Method for SSD to Improve the Read Performance, ACM Transactions on Storage (TOS), v.13 n.1, March 2017"
    },
    "3017445": {
        "abstract": "Recently, phase change memory (PCM) has been emerging as a strong replacement for DRAM owing to its many advantages such as nonvolatility, high capacity, low leakage power, and so on. However, PCM is still restricted for use as main memory because of its limited write endurance. There have been many methods introduced to resolve the problem by either reducing or spreading out bit flips. Although many previous studies have significantly contributed to reducing bit flips, they still have the drawback that lower bits are flipped more often than higher bits because the lower bits frequently change their bit values. Also, interblock wear-leveling schemes are commonly employed for spreading out bit flips by shifting input data, but they increase the number of bit flips per write. In this article, we propose a noble content-aware bit shuffling (CABS) technique that minimizes bit flips and evenly distributes them to maximize the lifetime of PCM at the bit level. We also introduce two additional optimizations, namely, addition of an inversion bit and use of an XOR key, to further reduce bit flips. Moreover, CABS is capable of recovering from stuck-at faults by restricting the change in values of stuck-at cells. Experimental results showed that CABS outperformed the existing state-of-the-art methods in the aspect of PCM lifetime extension with minimal overhead. CABS achieved up to 48.5% enhanced lifetime compared to the data comparison write (DCW) method only with a few metadata bits. Moreover, CABS obtained approximately 9.7% of improved write throughput than DCW because it significantly reduced bit flips and evenly distributed them. Also, CABS reduced about 5.4% of write dynamic energy compared to DCW. Finally, we have also confirmed that CABS is fully applicable to BCH codes as it was able to reduce the maximum number of bit flips in metadata cells by 32.1%.",
        "acm_key": "3017445",
        "bib_stats": {
            "cites": 0,
            "dl": 140,
            "dl_52": 140,
            "dl_6": 19
        },
        "bibtex": "\r\n@article{Han:2017:CBS:3062395.3017445,\n author = {Han, Miseon and Han, Youngsun and Kim, Seon Wook and Lee, Hokyoon and Park, Il},\n title = {Content-Aware Bit Shuffling for Maximizing PCM Endurance},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {May 2017},\n volume = {22},\n number = {3},\n month = may,\n year = {2017},\n issn = {1084-4309},\n pages = {48:1--48:26},\n articleno = {48},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/3017445},\n doi = {10.1145/3017445},\n acmid = {3017445},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Bit shuffling, PCM, bit flips, endurance, lifetime, stuck-at fault},\n} \r\n",
        "key": "3017445",
        "pub_year": "2017",
        "text": "Miseon Han , Youngsun Han , Seon Wook Kim , Hokyoon Lee , Il Park, Content-Aware Bit Shuffling for Maximizing PCM Endurance, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.22 n.3, p.1-26, May 2017"
    },
    "3019050": {
        "abstract": "Modern High-Performance Computing (HPC) clusters are equipped with advanced technological resources that need to be properly utilized to achieve supreme performance for end applications. One such example, Non-Volatile Memory (NVM), provides the opportunity for fast scalable performance through its DRAM-like performance characteristics. On the other hand, distributed processing engines, such as MapReduce, are continuously being enhanced with features enabling high-performance technologies. In this paper, we present a novel MapReduce framework with NVRAM-assisted map output spill approach. We have designed our framework on top of the existing RDMA-enhanced Hadoop MapReduce to ensure both map and reduce phase performance enhancements to be present for end applications. Our proposed approach significantly enhances map phase performance proven by a wide variety of MapReduce benchmarks and workloads from Intel HiBench [9] and PUMA [18] suites. Our performance evaluation illustrates that NVRAM-based spill approach can improve map execution performance by 2.73x which contributes to the overall execution improvement of 55% for Sort. Our design also guarantees significant performance benefits for other workloads: 54% for TeraSort, 21% for PageRank, 58% for SelfJoin, etc. To the best of our knowledge, this is the first approach towards leveraging NVRAM in MapReduce execution frameworks for applications on HPC clusters.",
        "acm_key": "3019050",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@inproceedings{Wasi-ur-Rahman:2016:NMB:3019046.3019050,\n author = {Wasi-ur-Rahman, Md. and Islam, Nusrat Sharmin and Lu, Xiaoyi and Panda, Dhabaleswar K. (DK)},\n title = {Can Non-volatile Memory Benefit Mapreduce Applications on HPC Clusters?},\n booktitle = {Proceedings of the 1st Joint International Workshop on Parallel Data Storage \\& Data Intensive Scalable Computing Systems},\n series = {PDSW-DISCS '16},\n year = {2016},\n isbn = {978-1-5090-5216-5},\n location = {Salt Lake City, Utah},\n pages = {19--24},\n numpages = {6},\n url = {https://doi.org/10.1109/PDSW-DISCS.2016.7},\n doi = {10.1109/PDSW-DISCS.2016.7},\n acmid = {3019050},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3019050",
        "pub_year": "2016",
        "text": "Md. Wasi-ur-Rahman , Nusrat Sharmin Islam , Xiaoyi Lu , Dhabaleswar K. (DK) Panda, Can non-volatile memory benefit mapreduce applications on HPC clusters?, Proceedings of the 1st Joint International Workshop on Parallel Data Storage & Data Intensive Scalable Computing Systems, p.19-24, November 13-18, 2016, Salt Lake City, Utah"
    },
    "3019675": {
        "abstract": "Co-location pattern mining is a spatial data mining technique which can be used to find associations among spatial features. Our work is motivated by an application in environmental health where the goal is to investigate whether the maternal exposure during pregnancy to air pollutants could be potentially associated with adverse birth outcomes. Discovering such relationships can be defined as finding spatial associations (i.e. co-location patterns) between adverse birth outcomes and air pollutant emissions. In particular, our application problem requires to find specific co-location patterns which are common to many spatial groups and co-location patterns which can discriminate one spatial group from the others. Traditional co-location pattern mining methods are not capable of finding such specific patterns. Hence, to achieve the spatial group comparison task, we introduce two new spatial patterns: spatial contrast sets and spatial common sets, and techniques to efficiently mine them based on co-location pattern mining. Traditional co-location pattern mining methods rely on frequency based thresholds which discard rare patterns and find exaggerated noisy patterns which may not be equally prevalent in unseen data. Addressing these limitations, we propose to use statistical significance tests instead of frequency to quantify the strength of a pattern. Towards this end, we propose to apply Fisher's exact test to efficiently find statistically significant co-location rules and use them to discover spatial contrast and common sets. Our experiments reveal that the Fisher's test based method could indeed help in finding co-location patterns with a better statistical significance leading to find valid spatial contrast and common sets. With the proposed methods we discovered that air pollutants such as heavy metals, NO",
        "acm_key": "3019675",
        "bib_stats": {
            "cites": 0,
            "dl": 61,
            "dl_52": 61,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Son:2017:LBD:3019612.3019675,\n author = {Son, Yongseok and Kang, Hara and Yeom, Heon Young and Han, Hyuck},\n title = {A Log-structured Buffer for Database Systems Using Non-volatile Memory},\n booktitle = {Proceedings of the Symposium on Applied Computing},\n series = {SAC '17},\n year = {2017},\n isbn = {978-1-4503-4486-9},\n location = {Marrakech, Morocco},\n pages = {880--886},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/3019612.3019675},\n doi = {10.1145/3019612.3019675},\n acmid = {3019675},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database system, flash-based SSD, non-volatile memory},\n} \r\n",
        "key": "3019675",
        "pub_year": "2017",
        "text": "Yongseok Son , Hara Kang , Heon Young Yeom , Hyuck Han, A log-structured buffer for database systems using non-volatile memory, Proceedings of the Symposium on Applied Computing, April 03-07, 2017, Marrakech, Morocco"
    },
    "3019680": {
        "abstract": "Co-location pattern mining is a spatial data mining technique which can be used to find associations among spatial features. Our work is motivated by an application in environmental health where the goal is to investigate whether the maternal exposure during pregnancy to air pollutants could be potentially associated with adverse birth outcomes. Discovering such relationships can be defined as finding spatial associations (i.e. co-location patterns) between adverse birth outcomes and air pollutant emissions. In particular, our application problem requires to find specific co-location patterns which are common to many spatial groups and co-location patterns which can discriminate one spatial group from the others. Traditional co-location pattern mining methods are not capable of finding such specific patterns. Hence, to achieve the spatial group comparison task, we introduce two new spatial patterns: spatial contrast sets and spatial common sets, and techniques to efficiently mine them based on co-location pattern mining. Traditional co-location pattern mining methods rely on frequency based thresholds which discard rare patterns and find exaggerated noisy patterns which may not be equally prevalent in unseen data. Addressing these limitations, we propose to use statistical significance tests instead of frequency to quantify the strength of a pattern. Towards this end, we propose to apply Fisher's exact test to efficiently find statistically significant co-location rules and use them to discover spatial contrast and common sets. Our experiments reveal that the Fisher's test based method could indeed help in finding co-location patterns with a better statistical significance leading to find valid spatial contrast and common sets. With the proposed methods we discovered that air pollutants such as heavy metals, NO",
        "acm_key": "3019680",
        "bib_stats": {
            "cites": 0,
            "dl": 26,
            "dl_52": 26,
            "dl_6": 8
        },
        "bibtex": "\r\n@inproceedings{Chen:2017:PWS:3019612.3019680,\n author = {Chen, Tseng-Yi and Chang, Yuan-Hao and Kuan, Yuan-Hung and Yang, Ming-Chang and Chang, Yu-Ming and Hsiu, Pi-Cheng},\n title = {A Pattern-aware Write Strategy to Enhance the Reliability of Flash-memory Storage Systems},\n booktitle = {Proceedings of the Symposium on Applied Computing},\n series = {SAC '17},\n year = {2017},\n isbn = {978-1-4503-4486-9},\n location = {Marrakech, Morocco},\n pages = {1460--1466},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/3019612.3019680},\n doi = {10.1145/3019612.3019680},\n acmid = {3019680},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {bit error, bit-flip, flash memory, flash reliability, pattern-aware},\n} \r\n",
        "key": "3019680",
        "pub_year": "2017",
        "text": "Tseng-Yi Chen , Yuan-Hao Chang , Yuan-Hung Kuan , Ming-Chang Yang , Yu-Ming Chang , Pi-Cheng Hsiu, A pattern-aware write strategy to enhance the reliability of flash-memory storage systems, Proceedings of the Symposium on Applied Computing, April 03-07, 2017, Marrakech, Morocco"
    },
    "3022262": {
        "abstract": "The underlying element that supports the device communication in the MANET is the wireless connection capability. Each node has the ability to communicate with other nodes via the creation of routing path. However, due to the fact that nodes in MANET are autonomous and the routing paths created are only based on current condition of the network, some of the paths are extremely instable. In light of these shortcomings, many research works emphasizes on the improvement of routing path algorithm. Regardless of the application the MANET can support, the MANET possesses unique characteristics, which enables mobile nodes to form dynamic communication irrespective the availability of a fixed network. However the inherent nature of MANET has led to nodes in MANET to be vulnerable to denied services. A typical Denial of Service (DoS) in MANET is the Black Hole attack, caused by a malicious node, or a set of nodes advertising false routing updates. Typically, the malicious nodes are difficult to be detected. Each node is equipped with a particular type of routing protocol and voluntarily participates in relaying the packets. However, some nodes may not be genuine and has been tampered to behave maliciously, which causes the Black Hole attack. Several on demand routing protocol e.g. Ad hoc On Demand Distance Vector (AODV) and Dynamic Source Routing (DSR) are susceptible to such attack. In principle, the attack exploits the Route Request (RREQ) discovery operation and falsifies the sequence number and the shortest path information. The malicious nodes are able to utilize the loophole in the RREQ discovery process due to the absence of validation process. As a result, genuine RREQ packets are exploited and erroneously relayed to a false node(s). This paper highlights the effect Black Hole nodes to the network performance and therefore substantiates the previous work done [1]. In this paper, several simulation experiments are iterated using NS-2, which employed various scenarios and traffic loads. The simulation results show the presence of Black Hole nodes in a network can substantially affects the packet delivery ratio and throughput by as much as 100%.",
        "acm_key": "3022262",
        "bib_stats": {
            "cites": 0,
            "dl": 100,
            "dl_52": 100,
            "dl_6": 18
        },
        "bibtex": "\r\n@inproceedings{Lee:2017:IRP:3022227.3022262,\n author = {Lee, Minkyeong and Kang, Dong Hyun and Lee, Minho and Eom, Young Ik},\n title = {Improving Read Performance by Isolating Multiple Queues in NVMe SSDs},\n booktitle = {Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication},\n series = {IMCOM '17},\n year = {2017},\n isbn = {978-1-4503-4888-1},\n location = {Beppu, Japan},\n pages = {36:1--36:6},\n articleno = {36},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3022227.3022262},\n doi = {10.1145/3022227.3022262},\n acmid = {3022262},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVMe SSD, multi-queue, read/write isolation, write interference},\n} \r\n",
        "key": "3022262",
        "pub_year": "2017",
        "text": "Minkyeong Lee , Dong Hyun Kang , Minho Lee , Young Ik Eom, Improving read performance by isolating multiple queues in NVMe SSDs, Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication, p.1-6, January 05-07, 2017, Beppu, Japan"
    },
    "3022313": {
        "abstract": "The underlying element that supports the device communication in the MANET is the wireless connection capability. Each node has the ability to communicate with other nodes via the creation of routing path. However, due to the fact that nodes in MANET are autonomous and the routing paths created are only based on current condition of the network, some of the paths are extremely instable. In light of these shortcomings, many research works emphasizes on the improvement of routing path algorithm. Regardless of the application the MANET can support, the MANET possesses unique characteristics, which enables mobile nodes to form dynamic communication irrespective the availability of a fixed network. However the inherent nature of MANET has led to nodes in MANET to be vulnerable to denied services. A typical Denial of Service (DoS) in MANET is the Black Hole attack, caused by a malicious node, or a set of nodes advertising false routing updates. Typically, the malicious nodes are difficult to be detected. Each node is equipped with a particular type of routing protocol and voluntarily participates in relaying the packets. However, some nodes may not be genuine and has been tampered to behave maliciously, which causes the Black Hole attack. Several on demand routing protocol e.g. Ad hoc On Demand Distance Vector (AODV) and Dynamic Source Routing (DSR) are susceptible to such attack. In principle, the attack exploits the Route Request (RREQ) discovery operation and falsifies the sequence number and the shortest path information. The malicious nodes are able to utilize the loophole in the RREQ discovery process due to the absence of validation process. As a result, genuine RREQ packets are exploited and erroneously relayed to a false node(s). This paper highlights the effect Black Hole nodes to the network performance and therefore substantiates the previous work done [1]. In this paper, several simulation experiments are iterated using NS-2, which employed various scenarios and traffic loads. The simulation results show the presence of Black Hole nodes in a network can substantially affects the packet delivery ratio and throughput by as much as 100%.",
        "acm_key": "3022313",
        "bib_stats": {
            "cites": 0,
            "dl": 51,
            "dl_52": 51,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Yi:2017:CIS:3022227.3022313,\n author = {Yi, Minhoon and Lee, Minho and Eom, Young Ik},\n title = {CFFQ: I/O Scheduler for Providing Fairness and High Performance in SSD Devices},\n booktitle = {Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication},\n series = {IMCOM '17},\n year = {2017},\n isbn = {978-1-4503-4888-1},\n location = {Beppu, Japan},\n pages = {87:1--87:6},\n articleno = {87},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3022227.3022313},\n doi = {10.1145/3022227.3022313},\n acmid = {3022313},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FIFO, I/O bandwidth, Linux I/O scheduler, SSD, fairness, latency, round-robin},\n} \r\n",
        "key": "3022313",
        "pub_year": "2017",
        "text": "Minhoon Yi , Minho Lee , Young Ik Eom, CFFQ: I/O scheduler for providing fairness and high performance in SSD devices, Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication, p.1-6, January 05-07, 2017, Beppu, Japan"
    },
    "3024750": {
        "abstract": "Volume 65 Issue 12, December 2016 \r\n\r\n",
        "acm_key": "3024750",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Farbeh:2016:FDR:3024718.3024750,\n author = {Farbeh, Hamed and Kim, Hyeonggyu and Miremadi, Seyed Ghassem and Kim, Soontae},\n title = {Floating-ECC: Dynamic Repositioning of Error Correcting Code Bits for Extending the Lifetime of STT-RAM Caches},\n journal = {IEEE Trans. Comput.},\n issue_date = {December 2016},\n volume = {65},\n number = {12},\n month = dec,\n year = {2016},\n issn = {0018-9340},\n pages = {3661--3675},\n numpages = {15},\n url = {https://doi.org/10.1109/TC.2016.2557326},\n doi = {10.1109/TC.2016.2557326},\n acmid = {3024750},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3024750",
        "pub_year": "2016",
        "text": "Hamed Farbeh , Hyeonggyu Kim , Seyed Ghassem Miremadi , Soontae Kim, Floating-ECC: Dynamic Repositioning of Error Correcting Code Bits for Extending the Lifetime of STT-RAM Caches, IEEE Transactions on Computers, v.65 n.12, p.3661-3675, December 2016  \u00a0[doi>"
    },
    "3025113": {
        "abstract": "As data volumes continue to grow, modern database systems increasingly rely on data skipping mechanisms to improve performance by avoiding access to irrelevant data. Recent work [39] proposed a fine-grained partitioning scheme that was shown to improve the opportunities for data skipping in row-oriented systems. Modern analytics and big data systems increasingly adopt columnar storage schemes, and in such systems, a row-based approach misses important opportunities for further improving data skipping. The flexibility of column-oriented organizations, however, comes with the additional cost of tuple reconstruction. In this paper, we develop Generalized Skipping-Oriented Partitioning (GSOP), a novel hybrid data skipping framework that takes into account these row-based and column-based tradeoffs. In contrast to previous column-oriented physical design work, GSOP considers the tradeoffs between horizontal data skipping and vertical partitioning jointly. Our experiments using two public benchmarks and a real-world workload show that GSOP can significantly reduce the amount of data scanned and improve end-to-end query response times over the state-of-the- art techniques.",
        "acm_key": "3025113",
        "bib_stats": {
            "cites": 0,
            "dl": 112,
            "dl_52": 112,
            "dl_6": 13
        },
        "bibtex": "\r\n@article{Xu:2016:BSD:3025111.3025113,\n author = {Xu, Shuotao and Lee, Sungjin and Jun, Sang-Woo and Liu, Ming and Hicks, Jamey and Arvind},\n title = {Bluecache: A Scalable Distributed Flash-based Key-value Store},\n journal = {Proc. VLDB Endow.},\n issue_date = {November 2016},\n volume = {10},\n number = {4},\n month = nov,\n year = {2016},\n issn = {2150-8097},\n pages = {301--312},\n numpages = {12},\n url = {https://doi.org/10.14778/3025111.3025113},\n doi = {10.14778/3025111.3025113},\n acmid = {3025113},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "3025113",
        "pub_year": "2016",
        "text": "Shuotao Xu , Sungjin Lee , Sang-Woo Jun , Ming Liu , Jamey Hicks , Arvind, Bluecache: a scalable distributed flash-based key-value store, Proceedings of the VLDB Endowment, v.10 n.4, p.301-312, November 2016"
    },
    "3025122": {
        "abstract": "As data volumes continue to grow, modern database systems increasingly rely on data skipping mechanisms to improve performance by avoiding access to irrelevant data. Recent work [39] proposed a fine-grained partitioning scheme that was shown to improve the opportunities for data skipping in row-oriented systems. Modern analytics and big data systems increasingly adopt columnar storage schemes, and in such systems, a row-based approach misses important opportunities for further improving data skipping. The flexibility of column-oriented organizations, however, comes with the additional cost of tuple reconstruction. In this paper, we develop Generalized Skipping-Oriented Partitioning (GSOP), a novel hybrid data skipping framework that takes into account these row-based and column-based tradeoffs. In contrast to previous column-oriented physical design work, GSOP considers the tradeoffs between horizontal data skipping and vertical partitioning jointly. Our experiments using two public benchmarks and a real-world workload show that GSOP can significantly reduce the amount of data scanned and improve end-to-end query response times over the state-of-the- art techniques.",
        "acm_key": "3025122",
        "bib_stats": {
            "cites": 3,
            "dl": 56,
            "dl_52": 56,
            "dl_6": 2
        },
        "bibtex": "\r\n@article{Avni:2016:PHT:3025111.3025122,\n author = {Avni, Hillel and Brown, Trevor},\n title = {Persistent Hybrid Transactional Memory for Databases},\n journal = {Proc. VLDB Endow.},\n issue_date = {November 2016},\n volume = {10},\n number = {4},\n month = nov,\n year = {2016},\n issn = {2150-8097},\n pages = {409--420},\n numpages = {12},\n url = {https://doi.org/10.14778/3025111.3025122},\n doi = {10.14778/3025111.3025122},\n acmid = {3025122},\n publisher = {VLDB Endowment},\n} \r\n",
        "key": "3025122",
        "pub_year": "2016",
        "text": "Hillel Avni , Trevor Brown, Persistent hybrid transactional memory for databases, Proceedings of the VLDB Endowment, v.10 n.4, p.409-420, November 2016"
    },
    "3026193": {
        "abstract": "Volume 65 Issue 11, November 2016 \r\n\r\n",
        "acm_key": "3026193",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Sun:2016:SCB:3026126.3026193,\n author = {Sun, Guangyu and Zhang, Chao and Li, Peng and Wang, Tao and Chen, Yiran},\n title = {Statistical Cache Bypassing for Non-Volatile Memory},\n journal = {IEEE Trans. Comput.},\n issue_date = {November 2016},\n volume = {65},\n number = {11},\n month = nov,\n year = {2016},\n issn = {0018-9340},\n pages = {3427--3440},\n numpages = {14},\n url = {https://doi.org/10.1109/TC.2016.2529621},\n doi = {10.1109/TC.2016.2529621},\n acmid = {3026193},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3026193",
        "pub_year": "2016",
        "text": "Guangyu Sun , Chao Zhang , Peng Li , Tao Wang , Yiran Chen, Statistical Cache Bypassing for Non-Volatile Memory, IEEE Transactions on Computers, v.65 n.11, p.3427-3440, November 2016"
    },
    "3026393": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026393",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Berman:2016:MMP:3026371.3026393,\n author = {Berman, Amit and Birk, Yitzhak},\n title = {Minimal Maximum-Level Programming\\&\\#x2014;Combined Cell Mapping and Coding for Faster MLC Memory},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2416--2429},\n numpages = {14},\n url = {https://doi.org/10.1109/JSAC.2016.2603791},\n doi = {10.1109/JSAC.2016.2603791},\n acmid = {3026393},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026393",
        "pub_year": "2016",
        "text": "Amit Berman , Yitzhak Birk, Minimal Maximum-Level Programming\u2014Combined Cell Mapping and Coding for Faster MLC Memory, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2416-2429, September 2016"
    },
    "3026394": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026394",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Cao:2016:MII:3026371.3026394,\n author = {Cao, Congzhe and Fair, Ivan},\n title = {Mitigation of Inter-Cell Interference in Flash Memory With Capacity-Approaching Variable-Length Constrained Sequence Codes},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2366--2377},\n numpages = {12},\n url = {https://doi.org/10.1109/JSAC.2016.2603663},\n doi = {10.1109/JSAC.2016.2603663},\n acmid = {3026394},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026394",
        "pub_year": "2016",
        "text": "Congzhe Cao , Ivan Fair, Mitigation of Inter-Cell Interference in Flash Memory With Capacity-Approaching Variable-Length Constrained Sequence Codes, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2366-2377, September 2016"
    },
    "3026397": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026397",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Hemo:2016:DIW:3026371.3026397,\n author = {Hemo, Evyatar and Cassuto, Yuval},\n title = { \\$D\\$ -Imbalance WOM Codes for Reduced Inter-Cell Interference in Multi-Level NVMs},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2378--2390},\n numpages = {13},\n url = {https://doi.org/10.1109/JSAC.2016.2603621},\n doi = {10.1109/JSAC.2016.2603621},\n acmid = {3026397},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026397",
        "pub_year": "2016",
        "text": "Evyatar Hemo , Yuval Cassuto,  <inline-formula> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula>-Imbalance WOM Codes for Reduced Inter-Cell Interference in Multi-Level NVMs, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2378-2390, September 2016&#13;\n\t\t\t\t\t\t-Imbalance WOM Codes for Reduced Inter-Cell Interference in Multi-Level NVMs, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2378-2390, September 2016"
    },
    "3026398": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026398",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Parnell:2016:CMN:3026371.3026398,\n author = {Parnell, Thomas and Dunner, Celestine and Mittelholzer, Thomas and Papandreou, Nikolaos},\n title = {Capacity of the MLC NAND Flash Channel},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2354--2365},\n numpages = {12},\n url = {https://doi.org/10.1109/JSAC.2016.2603722},\n doi = {10.1109/JSAC.2016.2603722},\n acmid = {3026398},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026398",
        "pub_year": "2016",
        "text": "Thomas Parnell , Celestine Dunner , Thomas Mittelholzer , Nikolaos Papandreou, Capacity of the MLC NAND Flash Channel, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2354-2365, September 2016"
    },
    "3026399": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026399",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Huang:2016:PMF:3026371.3026399,\n author = {Huang, Pengfei and Siegel, Paul H. and Yaakobi, Eitan},\n title = {Performance of Multilevel Flash Memories With Different Binary Labelings: A Multi-User Perspective},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2336--2353},\n numpages = {18},\n url = {https://doi.org/10.1109/JSAC.2016.2603658},\n doi = {10.1109/JSAC.2016.2603658},\n acmid = {3026399},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026399",
        "pub_year": "2016",
        "text": "Pengfei Huang , Paul H. Siegel , Eitan Yaakobi, Performance of Multilevel Flash Memories With Different Binary Labelings: A Multi-User Perspective, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2336-2353, September 2016"
    },
    "3026401": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026401",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Hareedy:2016:GNL:3026371.3026401,\n author = {Hareedy, Ahmed and Lanka, Chinmayi and Dolecek, Lara},\n title = {A General Non-Binary LDPC Code Optimization Framework Suitable for Dense Flash Memory and Magnetic Storage},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2402--2415},\n numpages = {14},\n url = {https://doi.org/10.1109/JSAC.2016.2603719},\n doi = {10.1109/JSAC.2016.2603719},\n acmid = {3026401},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026401",
        "pub_year": "2016",
        "text": "Ahmed Hareedy , Chinmayi Lanka , Lara Dolecek, A General Non-Binary LDPC Code Optimization Framework Suitable for Dense Flash Memory and Magnetic Storage, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2402-2415, September 2016"
    },
    "3026403": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026403",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Kim:2016:LRC:3026371.3026403,\n author = {Kim, Yongjune and Sharma, Abhishek A. and Mateescu, Robert and Song, Seung-Hwan and Bandic, Zvonimir Z. and Bain, James A. and Vijaya Kumar, B. V. K.},\n title = {Locally Rewritable Codes for Resistive Memories},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2470--2485},\n numpages = {16},\n url = {https://doi.org/10.1109/JSAC.2016.2603683},\n doi = {10.1109/JSAC.2016.2603683},\n acmid = {3026403},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026403",
        "pub_year": "2016",
        "text": "Yongjune Kim , Abhishek A. Sharma , Robert Mateescu , Seung-Hwan Song , Zvonimir Z. Bandic , James A. Bain , B. V. K. Vijaya Kumar, Locally Rewritable Codes for Resistive Memories, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2470-2485, September 2016"
    },
    "3026406": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026406",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Luo:2016:EAP:3026371.3026406,\n author = {Luo, Yixin and Ghose, Saugata and Cai, Yu and Haratsch, Erich F. and Mutlu, Onur},\n title = {Enabling Accurate and Practical Online Flash Channel Modeling for Modern MLC NAND Flash Memory},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2294--2311},\n numpages = {18},\n url = {https://doi.org/10.1109/JSAC.2016.2603608},\n doi = {10.1109/JSAC.2016.2603608},\n acmid = {3026406},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026406",
        "pub_year": "2016",
        "text": "Yixin Luo , Saugata Ghose , Yu Cai , Erich F. Haratsch , Onur Mutlu, Enabling Accurate and Practical Online Flash Channel Modeling for Modern MLC NAND Flash Memory, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2294-2311, September 2016"
    },
    "3026411": {
        "abstract": "Volume 34 Issue 9, September 2016 \r\n\r\n",
        "acm_key": "3026411",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Asadi:2016:FMI:3026371.3026411,\n author = {Asadi, Meysam and Haratsch, Erich F. and Kavcic, Aleksandar and Santhanam, Narayana Prasad},\n title = {Flash Memories: ISPP Renewal Theory and Flash Design Tradeoffs},\n journal = {IEEE J.Sel. A. Commun.},\n issue_date = {September 2016},\n volume = {34},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0733-8716},\n pages = {2325--2335},\n numpages = {11},\n url = {https://doi.org/10.1109/JSAC.2016.2604058},\n doi = {10.1109/JSAC.2016.2604058},\n acmid = {3026411},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3026411",
        "pub_year": "2016",
        "text": "Meysam Asadi , Erich F. Haratsch , Aleksandar Kavcic , Narayana Prasad Santhanam, Flash Memories: ISPP Renewal Theory and Flash Design Tradeoffs, IEEE Journal on Selected Areas in Communications, v.34 n.9, p.2325-2335, September 2016"
    },
    "3026860": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026860",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Yadgar:2016:ASE:3026852.3026860,\n author = {Yadgar, Gala and Gabel, Moshe},\n title = {Avoiding the Streetlight Effect: I/O Workload Analysis with SSDs in Mind},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {36--40},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026860},\n acmid = {3026860},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026860",
        "pub_year": "2016",
        "text": "Gala Yadgar , Moshe Gabel, Avoiding the streetlight effect: I/O workload analysis with SSDs in mind, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.36-40, June 20-21, 2016, Denver, CO"
    },
    "3026861": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026861",
        "bib_stats": {
            "cites": 1,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2016:NUI:3026852.3026861,\n author = {Kim, Hyeong-Jun and Lee, Young-Sik and Kim, Jin-Soo},\n title = {NVMeDirect: A User-space I/O Framework for Application-specific Optimization on NVMe SSDs},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {41--45},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026861},\n acmid = {3026861},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026861",
        "pub_year": "2016",
        "text": "Hyeong-Jun Kim , Young-Sik Lee , Jin-Soo Kim, NVMeDirect: a user-space I/O framework for application-specific optimization on NVMe SSDs, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.41-45, June 20-21, 2016, Denver, CO"
    },
    "3026862": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026862",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Shen:2016:OFK:3026852.3026862,\n author = {Shen, Zhaoyan and Chen, Feng and Jia, Yichen and Shao, Zili},\n title = {Optimizing Flash-based Key-value Cache Systems},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {46--50},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026862},\n acmid = {3026862},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026862",
        "pub_year": "2016",
        "text": "Zhaoyan Shen , Feng Chen , Yichen Jia , Zili Shao, Optimizing flash-based key-value cache systems, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.46-50, June 20-21, 2016, Denver, CO"
    },
    "3026864": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026864",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Wei:2016:SSD:3026852.3026864,\n author = {Wei, Michael and Tai, Amy and Rossbach, Chris and Abraham, Ittai and Wieder, Udi and Swanson, Steven and Malkhi, Dahlia},\n title = {Silver: A Scalable, Distributed, Multi-versioning, Always Growing (Ag) File System},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {56--60},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026864},\n acmid = {3026864},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026864",
        "pub_year": "2016",
        "text": "Michael Wei , Amy Tai , Chris Rossbach , Ittai Abraham , Udi Wieder , Steven Swanson , Dahlia Malkhi, Silver: a scalable, distributed, multi-versioning, always growing (Ag) file system, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.56-60, June 20-21, 2016, Denver, CO"
    },
    "3026868": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026868",
        "bib_stats": {
            "cites": 2,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ji:2016:ESF:3026852.3026868,\n author = {Ji, Cheng and Chang, Li-Pin and Shi, Liang and Wu, Chao and Li, Qiao and Xue, Chun Jason},\n title = {An Empirical Study of File-system Fragmentation in Mobile Storage Systems},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {76--80},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026868},\n acmid = {3026868},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026868",
        "pub_year": "2016",
        "text": "Cheng Ji , Li-Pin Chang , Liang Shi , Chao Wu , Qiao Li , Chun Jason Xue, An empirical study of file-system fragmentation in mobile storage systems, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.76-80, June 20-21, 2016, Denver, CO"
    },
    "3026873": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026873",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Marmol:2016:NMT:3026852.3026873,\n author = {M\\'{a}rmol, Leonardo and Guerra, Jorge and Aguilera, Marcos K.},\n title = {Non-volatile Memory Through Customized Key-value Stores},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {101--105},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026873},\n acmid = {3026873},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026873",
        "pub_year": "2016",
        "text": "Leonardo M\u00e1rmol , Jorge Guerra , Marcos K. Aguilera, Non-volatile memory through customized key-value stores, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.101-105, June 20-21, 2016, Denver, CO"
    },
    "3026875": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026875",
        "bib_stats": {
            "cites": 1,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ahn:2016:IIR:3026852.3026875,\n author = {Ahn, Sungyong and La, Kwanghyun and Kim, Jihong},\n title = {Improving I/O Resource Sharing of Linux Cgroup for NVMe SSDs on Multi-core Systems},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {111--115},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026875},\n acmid = {3026875},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026875",
        "pub_year": "2016",
        "text": "Sungyong Ahn , Kwanghyun La , Jihong Kim, Improving I/O resource sharing of Linux Cgroup for NVMe SSDs on multi-core systems, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.111-115, June 20-21, 2016, Denver, CO"
    },
    "3026876": {
        "abstract": "In container-based virtualization where multiple isolated containers share I/O resources on top of a single operating system, efficient and proportional I/O resource sharing is an important system requirement. Motivated by a lack of adequate support for I/O resource sharing in Linux Cgroup for high-performance NVMe SSDs, we developed a new weight-based dynamic throttling technique which can provide proportional I/O sharing for container-based virtualization solutions running on NUMA multi-core systems with NVMe SSDs. By intelligently predicting the future I/O bandwidth requirement of containers based on past I/O service rates of I/O-active containers, and modifying the current Linux Cgroup implementation for better NUMA-scalable performance, our scheme achieves highly accurate I/O resource sharing while reducing wasted I/O bandwidth. Based on a Linux kernel 4.0.4 implementation running on a 4-node NUMA multi-core systems with NVMe SSDs, our experimental results show that the proposed technique can efficiently share the I/O bandwidth of NVMe SSDs among multiple containers according to given I/O weights.",
        "acm_key": "3026876",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Shin:2016:UOO:3026852.3026876,\n author = {Shin, Woong and Park, Jaehyun and Yeom, Heon Y.},\n title = {Unblinding the OS to Optimize User-perceived Flash SSD Latency},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems},\n series = {HotStorage'16},\n year = {2016},\n location = {Denver, CO},\n pages = {116--120},\n numpages = {5},\n url = {http://dl.acm.org/citation.cfm?id=3026852.3026876},\n acmid = {3026876},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026876",
        "pub_year": "2016",
        "text": "Woong Shin , Jaehyun Park , Heon Y. Yeom, Unblinding the OS to optimize user-perceived flash SSD latency, Proceedings of the 8th USENIX Conference on Hot Topics in Storage and File Systems, p.116-120, June 20-21, 2016, Denver, CO"
    },
    "3026968": {
        "abstract": "Multicore processors are not energy proportional: the first running CPU core that activates shared resources incurs much higher power cost than each additional core does. On the other hand, typical smartphone applications exhibit little parallelism and therefore when one core is activated by an interactive application, computing resources at other cores are available at a deep energy discount. By non-work-conserving scheduling, we exploit energy-discounted co-run opportunities to process best-effort smartphone tasks that involve no direct user interaction (e.g., data compression / encryption for cloud backup, background sensing, and offline bytecode compilation). We show that, for optimal co-run energy discount, the best-effort processing must not elevate the overall system power state (specifically, no reduction of the multicore CPU idle state, no increase of the core frequency, and no impact on the system suspension period). In addition, we use available ARM performance counters to identify co-run resource contention on the multicore processor and throttle best-effort task when it interferes with interactivity. Experimental results on a multicore smartphone show that we can reach up to 63% energy discount in the best-effort task processing with little performance impact on the interactive applications.",
        "acm_key": "3026968",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Zhang:2016:PLF:3026959.3026968,\n author = {Zhang, Jiacheng and Shu, Jiwu and Lu, Youyou},\n title = {ParaFS: A Log-structured File System to Exploit the Internal Parallelism of Flash Devices},\n booktitle = {Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '16},\n year = {2016},\n isbn = {978-1-931971-30-0},\n location = {Denver, CO, USA},\n pages = {87--100},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=3026959.3026968},\n acmid = {3026968},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026968",
        "pub_year": "2016",
        "text": "Jiacheng Zhang , Jiwu Shu , Youyou Lu, ParaFS: a log-structured file system to exploit the internal parallelism of flash devices, Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference, June 22-24, 2016, Denver, CO, USA"
    },
    "3026994": {
        "abstract": "Multicore processors are not energy proportional: the first running CPU core that activates shared resources incurs much higher power cost than each additional core does. On the other hand, typical smartphone applications exhibit little parallelism and therefore when one core is activated by an interactive application, computing resources at other cores are available at a deep energy discount. By non-work-conserving scheduling, we exploit energy-discounted co-run opportunities to process best-effort smartphone tasks that involve no direct user interaction (e.g., data compression / encryption for cloud backup, background sensing, and offline bytecode compilation). We show that, for optimal co-run energy discount, the best-effort processing must not elevate the overall system power state (specifically, no reduction of the multicore CPU idle state, no increase of the core frequency, and no impact on the system suspension period). In addition, we use available ARM performance counters to identify co-run resource contention on the multicore processor and throttle best-effort task when it interferes with interactivity. Experimental results on a multicore smartphone show that we can reach up to 63% energy discount in the best-effort task processing with little performance impact on the interactive applications.",
        "acm_key": "3026994",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Cheng:2016:EBL:3026959.3026994,\n author = {Cheng, Yue and Douglis, Fred and Shilane, Philip and Trachtman, Michael and Wallace, Grant and Desnoyers, Peter and Li, Kai},\n title = {Erasing Belady's Limitations: In Search of Flash Cache Offline Optimality},\n booktitle = {Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference},\n series = {USENIX ATC '16},\n year = {2016},\n isbn = {978-1-931971-30-0},\n location = {Denver, CO, USA},\n pages = {379--392},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=3026959.3026994},\n acmid = {3026994},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3026994",
        "pub_year": "2016",
        "text": "Yue Cheng , Fred Douglis , Philip Shilane , Michael Trachtman , Grant Wallace , Peter Desnoyers , Kai Li, Erasing Belady's limitations: in search of flash cache offline optimality, Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference, June 22-24, 2016, Denver, CO, USA"
    },
    "3027051": {
        "abstract": "Cloud providers have begun to allow users to bid for surplus servers on a spot market. These servers are allocated if a user's bid price is higher than their market price and revoked otherwise. Thus, analyzing price data to derive optimal bidding strategies has become a popular research topic. In this paper, we argue that sophisticated bidding strategies, in practice, do not provide any advantages over simple strategies for multiple reasons. First, due to price characteristics, there are a wide range of bid prices that yield the optimal cost and availability. Second, given the large number of spot markets, there is always a market with available surplus resources. Thus, if resources become unavailable due to a price spike, users need not wait until the spike subsides, but can instead provision a new spot resource elsewhere and migrate to it. Third, current spot market rules enable users to place maximum bids for resources without any penalty. Given bidding's irrelevance, users can adopt trivial bidding strategies and focus instead on modifying applications to efficiently seek out and migrate to the lowest cost resources.",
        "acm_key": "3027051",
        "bib_stats": {
            "cites": 1,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Choi:2016:MMD:3027041.3027051,\n author = {Choi, I. Stephen and Ahn, Byoung Young and Kee, Yang-Suk},\n title = {Mlcached: Multi-level DRAM-NAND Key-value Cache},\n booktitle = {Proceedings of the 8th USENIX Conference on Hot Topics in Cloud Computing},\n series = {HotCloud'16},\n year = {2016},\n location = {Denver, CO},\n pages = {58--63},\n numpages = {6},\n url = {http://dl.acm.org/citation.cfm?id=3027041.3027051},\n acmid = {3027051},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3027051",
        "pub_year": "2016",
        "text": "I. Stephen Choi , Byoung Young Ahn , Yang-Suk Kee, Mlcached: multi-level DRAM-NAND key-value cache, Proceedings of the 8th USENIX Conference on Hot Topics in Cloud Computing, p.58-63, June 20-21, 2016, Denver, CO"
    },
    "3030080": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3030080",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Ho:2017:CML:3030051.3030080,\n author = {Ho, Patrick W.C. and Almurib, Haider Abbas F. and Kumar, T. Nandha},\n title = {Configurable Memristive Logic Block for Memristive-based FPGA Architectures},\n journal = {Integr. VLSI J.},\n issue_date = {January 2017},\n volume = {56},\n number = {C},\n month = jan,\n year = {2017},\n issn = {0167-9260},\n pages = {61--69},\n numpages = {9},\n url = {https://doi.org/10.1016/j.vlsi.2016.09.003},\n doi = {10.1016/j.vlsi.2016.09.003},\n acmid = {3030080},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Configurable logic block, FPGA Architecture, Logic block, Memristor, Switch block},\n} \r\n",
        "key": "3030080",
        "pub_year": "2017",
        "text": "Patrick W.C. Ho , Haider Abbas F. Almurib , T. Nandha Kumar, Configurable memristive logic block for memristive-based FPGA architectures, Integration, the VLSI Journal, v.56 n.C, p.61-69, January 2017"
    },
    "3030219": {
        "abstract": "The evolution of cloud-computing imposes many challenges on performance testing and requires not only a different approach and methodology of performance evaluation and analysis, but also specialized tools and frameworks to support such work. In traditional performance testing, typically a single workload was run against a static test configuration. The main metrics derived from such experiments included throughput, response times, and system utilization at steady-state. While this may have been sufficient in the past, where in many cases a single application was run on dedicated hardware, this approach is no longer suitable for cloud-based deployments. Whether private or public cloud, such environments typically host a variety of applications on distributed shared hardware resources, simultaneously accessed by a large number of tenants running heterogeneous workloads. The number of tenants as well as their activity and resource needs dynamically change over time, and the cloud infrastructure reacts to this by reallocating existing or provisioning new resources. Besides metrics such as the number of tenants and overall resource utilization, performance testing in the cloud must be able to answer many more questions: How is the quality of service of a tenant impacted by the constantly changing activity of other tenants? How long does it take the cloud infrastructure to react to changes in demand, and what is the effect on tenants while it does so? How well are service level agreements met? What is the resource consumption of individual tenants? How can global performance metrics on application- and system-level in a distributed system be correlated to an individual tenant's perceived performance?",
        "acm_key": "3030219",
        "bib_stats": {
            "cites": 0,
            "dl": 47,
            "dl_52": 47,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Park:2017:PIA:3030207.3030219,\n author = {Park, Changhyun and Lee, Seongjin and Won, Youjip and Ahn, Soohan},\n title = {Practical Implication of Analytical Models for SSD Write Amplification},\n booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},\n series = {ICPE '17},\n year = {2017},\n isbn = {978-1-4503-4404-3},\n location = {L'Aquila, Italy},\n pages = {257--262},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3030207.3030219},\n doi = {10.1145/3030207.3030219},\n acmid = {3030219},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {overprovisioning, solid state drive, write amplification},\n} \r\n",
        "key": "3030219",
        "pub_year": "2017",
        "text": "Changhyun Park , Seongjin Lee , Youjip Won , Soohan Ahn, Practical Implication of Analytical Models for SSD Write Amplification, Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering, April 22-26, 2017, L'Aquila, Italy"
    },
    "3033273": {
        "abstract": "Existing storage stacks are top heavy and expect little from block storage. As a result, new high-level storage abstractions\u2014and new designs for existing abstractions\u2014are difficult to realize, requiring developers to implement from scratch complex functionality such as failure atomicity and fine-grained concurrency control. In this article, we argue that pushing transactional isolation into the block store (in addition to atomicity and durability) is both viable and broadly useful, resulting in simpler high-level storage systems that provide strong semantics without sacrificing performance. We present Isotope, a new block store that supports ACID transactions over block reads and writes. Internally, Isotope uses a new multiversion concurrency control protocol that exploits fine-grained, subblock parallelism in workloads and offers both strict serializability and snapshot isolation guarantees. We implemented several high-level storage systems over Isotope, including two key-value stores that implement the LevelDB API over a hash table and B-tree, respectively, and a POSIX file system. We show that Isotope\u2019s block-level transactions enable systems that are simple (100s of lines of code), robust (i.e., providing ACID guarantees), and fast (e.g., 415MB/s for random file writes). We also show that these systems can be composed using Isotope, providing applications with transactions across different high-level constructs such as files, directories, and key-value pairs.",
        "acm_key": "3033273",
        "bib_stats": {
            "cites": 0,
            "dl": 117,
            "dl_52": 117,
            "dl_6": 26
        },
        "bibtex": "\r\n@article{Lu:2017:WSK:3054178.3033273,\n author = {Lu, Lanyue and Pillai, Thanumalayan Sankaranarayana and Gopalakrishnan, Hariharan and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},\n title = {WiscKey: Separating Keys from Values in SSD-Conscious Storage},\n journal = {Trans. Storage},\n issue_date = {March 2017},\n volume = {13},\n number = {1},\n month = mar,\n year = {2017},\n issn = {1553-3077},\n pages = {5:1--5:28},\n articleno = {5},\n numpages = {28},\n url = {http://doi.acm.org/10.1145/3033273},\n doi = {10.1145/3033273},\n acmid = {3033273},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {LevelDB, WiscKey, flash-based SSDs},\n} \r\n",
        "key": "3033273",
        "pub_year": "2017",
        "text": "Lanyue Lu , Thanumalayan Sankaranarayana Pillai , Hariharan Gopalakrishnan , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-Dusseau, WiscKey: Separating Keys from Values in SSD-Conscious Storage, ACM Transactions on Storage (TOS), v.13 n.1, March 2017"
    },
    "3034144": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3034144",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Jiang:2017:PDM:3033799.3034144,\n author = {Jiang, Ping and Zeng, Zhigang and Chen, Jiejie},\n title = {On the Periodic Dynamics of Memristor-based Neural Networks with Leakage and Time-varying Delays},\n journal = {Neurocomput.},\n issue_date = {January 2017},\n volume = {219},\n number = {C},\n month = jan,\n year = {2017},\n issn = {0925-2312},\n pages = {163--173},\n numpages = {11},\n url = {https://doi.org/10.1016/j.neucom.2016.09.029},\n doi = {10.1016/j.neucom.2016.09.029},\n acmid = {3034144},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Global exponential stability, Leakage delays, Memristor-based neural networks, Periodic solution, Time-varying delays},\n} \r\n",
        "key": "3034144",
        "pub_year": "2017",
        "text": "Ping Jiang , Zhigang Zeng , Jiejie Chen, On the periodic dynamics of memristor-based neural networks with leakage and time-varying delays, Neurocomputing, v.219 n.C, p.163-173, January 2017"
    },
    "3035081": {
        "abstract": "NAND flash memory has become the major storage media in mobile devices, such as smartphones. However, the random write operations of NAND flash memory heavily affect the I/O performance, thus seriously degrading the application performance in mobile devices. The main reason for slow random write operations is the out-of-place update feature of NAND flash memory. Newly emerged non-volatile memory, such as phase-change memory, spin transfer torque, supports in-place updates and presents much better I/O performance than that of flash memory. All these good features make non-volatile memory NVM as a promising solution to improve the random write performance for NAND flash memory. In this paper, we propose a non-volatile memory for random access NVMRA scheme to utilize NVM to improve the I/O performance in mobile devices. NVMRA exploits the I/O behaviors of applications to improve the random write performance for each application. Based on different I/O behaviors, such as random write-dominant I/O behavior, NVMRA adopts different storing decisions. The scheme is evaluated on a real Android 4.2 platform. The experimental results show that the proposed scheme can effectively improve the I/O performance and reduce the I/O energy consumption for mobile devices. Copyright \u00a9 2015 John Wiley & Sons, Ltd.",
        "acm_key": "3035081",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Chen:2016:NUN:3035074.3035081,\n author = {Chen, Renhai and Shen, Zhaoyan and Ma, Chenlin and Shao, Zili and Guan, Yong},\n title = {NVMRA: Utilizing NVM to Improve the Random Write Operations for NAND-flash-based Mobile Devices},\n journal = {Softw. Pract. Exper.},\n issue_date = {September 2016},\n volume = {46},\n number = {9},\n month = sep,\n year = {2016},\n issn = {0038-0644},\n pages = {1263--1284},\n numpages = {22},\n url = {https://doi.org/10.1002/spe.2378},\n doi = {10.1002/spe.2378},\n acmid = {3035081},\n publisher = {John Wiley \\&amp; Sons, Inc.},\n address = {New York, NY, USA},\n keywords = {I/O behaviors, NVM, NVMRA, applications, flash memory, mobile devices, random write operations},\n} \r\n",
        "key": "3035081",
        "pub_year": "2016",
        "text": "Renhai Chen , Zhaoyan Shen , Chenlin Ma , Zili Shao , Yong Guan, NVMRA: utilizing NVM to improve the random write operations for NAND-flash-based mobile devices, Software\u2014Practice & Experience, v.46 n.9, p.1263-1284, September 2016"
    },
    "3035958": {
        "abstract": "Sorting is at the core of many database operations, such as index creation, sort-merge joins, and user-requested output sorting. As GPUs are emerging as a promising platform to accelerate various operations, sorting on GPUs becomes a viable endeavour. Over the past few years, several improvements have been proposed for sorting on GPUs, leading to the first radix sort implementations that achieve a sorting rate of over one billion 32-bit keys per second. Yet, state-of-the-art approaches are heavily memory bandwidth-bound, as they require substantially more memory transfers than their CPU-based counterparts. Our work proposes a novel approach that almost halves the amount of memory transfers and, therefore, considerably lifts the memory bandwidth limitation. Being able to sort two gigabytes of eight-byte records in as little as 50 milliseconds, our approach achieves a 2.32-fold improvement over the state-of-the-art GPU-based radix sort for uniform distributions, sustaining a minimum speed-up of no less than a factor of 1.66 for skewed distributions. To address inputs that either do not reside on the GPU or exceed the available device memory, we build on our efficient GPU sorting approach with a pipelined heterogeneous sorting algorithm that mitigates the overhead associated with PCIe data transfers. Comparing the end-to-end sorting performance to the state-of-the-art CPU-based radix sort running 16 threads, our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for sorting 64 GB key-value pairs with a skewed and a uniform distribution, respectively.",
        "acm_key": "3035958",
        "bib_stats": {
            "cites": 0,
            "dl": 219,
            "dl_52": 219,
            "dl_6": 29
        },
        "bibtex": "\r\n@inproceedings{Hardock:2017:IUI:3035918.3035958,\n author = {Hardock, Sergey and Petrov, Ilia and Gottstein, Robert and Buchmann, Alejandro},\n title = {From In-Place Updates to In-Place Appends: Revisiting Out-of-Place Updates on Flash},\n booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},\n series = {SIGMOD '17},\n year = {2017},\n isbn = {978-1-4503-4197-4},\n location = {Chicago, Illinois, USA},\n pages = {1571--1586},\n numpages = {16},\n url = {http://doi.acm.org/10.1145/3035918.3035958},\n doi = {10.1145/3035918.3035958},\n acmid = {3035958},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {dbms, delta-record, in-page appends, native flash, noftl, oltp, page-layout, write-amplification, write_delta},\n} \r\n",
        "key": "3035958",
        "pub_year": "2017",
        "text": "Sergey Hardock , Ilia Petrov , Robert Gottstein , Alejandro Buchmann, From In-Place Updates to In-Place Appends: Revisiting Out-of-Place Updates on Flash, Proceedings of the 2017 ACM International Conference on Management of Data, May 14-19, 2017, Chicago, Illinois, USA"
    },
    "3037706": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037706",
        "bib_stats": {
            "cites": 1,
            "dl": 179,
            "dl_52": 179,
            "dl_6": 32
        },
        "bibtex": "\r\n@inproceedings{Agarwal:2017:TAP:3037697.3037706,\n author = {Agarwal, Neha and Wenisch, Thomas F.},\n title = {Thermostat: Application-transparent Page Management for Two-tiered Main Memory},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {631--644},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3037697.3037706},\n doi = {10.1145/3037697.3037706},\n acmid = {3037706},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cloud computing, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037706&parent_id=3037697&expformat=bibtex&CFID=982037171&CFTOKEN=82502444\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037706\">\r\n@article{Agarwal:2017:TAP:3093337.3037706,\n author = {Agarwal, Neha and Wenisch, Thomas F.},\n title = {Thermostat: Application-transparent Page Management for Two-tiered Main Memory},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {631--644},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093337.3037706},\n doi = {10.1145/3093337.3037706},\n acmid = {3037706},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cloud computing, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037706&parent_id=3093337&expformat=bibtex&CFID=982037171&CFTOKEN=82502444\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037706\">\r\n@article{Agarwal:2017:TAP:3093315.3037706,\n author = {Agarwal, Neha and Wenisch, Thomas F.},\n title = {Thermostat: Application-transparent Page Management for Two-tiered Main Memory},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {631--644},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093315.3037706},\n doi = {10.1145/3093315.3037706},\n acmid = {3037706},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cloud computing, operating systems},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037706&parent_id=3093315&expformat=bibtex&CFID=982037171&CFTOKEN=82502444\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037706\">\r\n@article{Agarwal:2017:TAP:3093336.3037706,\n author = {Agarwal, Neha and Wenisch, Thomas F.},\n title = {Thermostat: Application-transparent Page Management for Two-tiered Main Memory},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {631--644},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093336.3037706},\n doi = {10.1145/3093336.3037706},\n acmid = {3037706},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {cloud computing, operating systems},\n} \r\n",
        "key": "3037706",
        "pub_year": "2017",
        "text": "Neha Agarwal , Thomas F. Wenisch, Thermostat: Application-transparent Page Management for Two-tiered Main Memory, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China"
    },
    "3037714": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037714",
        "bib_stats": {
            "cites": 1,
            "dl": 177,
            "dl_52": 177,
            "dl_6": 37
        },
        "bibtex": "\r\n@inproceedings{Liu:2017:DBD:3037697.3037714,\n author = {Liu, Mengxing and Zhang, Mingxing and Chen, Kang and Qian, Xuehai and Wu, Yongwei and Zheng, Weimin and Ren, Jinglei},\n title = {DudeTM: Building Durable Transactions with Decoupling for Persistent Memory},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {329--343},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3037697.3037714},\n doi = {10.1145/3037697.3037714},\n acmid = {3037714},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {emerging memory technologies, storage systems, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037714&parent_id=3037697&expformat=bibtex&CFID=982040981&CFTOKEN=68515026\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037714\">\r\n@article{Liu:2017:DBD:3093336.3037714,\n author = {Liu, Mengxing and Zhang, Mingxing and Chen, Kang and Qian, Xuehai and Wu, Yongwei and Zheng, Weimin and Ren, Jinglei},\n title = {DudeTM: Building Durable Transactions with Decoupling for Persistent Memory},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {329--343},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093336.3037714},\n doi = {10.1145/3093336.3037714},\n acmid = {3037714},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {emerging memory technologies, storage systems, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037714&parent_id=3093336&expformat=bibtex&CFID=982040981&CFTOKEN=68515026\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037714\">\r\n@article{Liu:2017:DBD:3093315.3037714,\n author = {Liu, Mengxing and Zhang, Mingxing and Chen, Kang and Qian, Xuehai and Wu, Yongwei and Zheng, Weimin and Ren, Jinglei},\n title = {DudeTM: Building Durable Transactions with Decoupling for Persistent Memory},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {329--343},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093315.3037714},\n doi = {10.1145/3093315.3037714},\n acmid = {3037714},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {emerging memory technologies, storage systems, transactional memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037714&parent_id=3093315&expformat=bibtex&CFID=982040981&CFTOKEN=68515026\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037714\">\r\n@article{Liu:2017:DBD:3093337.3037714,\n author = {Liu, Mengxing and Zhang, Mingxing and Chen, Kang and Qian, Xuehai and Wu, Yongwei and Zheng, Weimin and Ren, Jinglei},\n title = {DudeTM: Building Durable Transactions with Decoupling for Persistent Memory},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {329--343},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093337.3037714},\n doi = {10.1145/3093337.3037714},\n acmid = {3037714},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {emerging memory technologies, storage systems, transactional memory},\n} \r\n",
        "key": "3037714",
        "pub_year": "2017",
        "text": "Mengxing Liu , Mingxing Zhang , Kang Chen , Xuehai Qian , Yongwei Wu , Weimin Zheng , Jinglei Ren, DudeTM: Building Durable Transactions with Decoupling for Persistent Memory, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China"
    },
    "3037728": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037728",
        "bib_stats": {
            "cites": 0,
            "dl": 306,
            "dl_52": 306,
            "dl_6": 56
        },
        "bibtex": "\r\n@article{Elyasi:2017:EIS:3093337.3037728,\n author = {Elyasi, Nima and Arjomand, Mohammad and Sivasubramaniam, Anand and Kandemir, Mahmut T. and Das, Chita R. and Jung, Myoungsoo},\n title = {Exploiting Intra-Request Slack to Improve SSD Performance},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {375--388},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093337.3037728},\n doi = {10.1145/3093337.3037728},\n acmid = {3037728},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {intra-request slack, scheduling, ssd},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037728&parent_id=3093337&expformat=bibtex&CFID=982048068&CFTOKEN=61205145\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037728\">\r\n@inproceedings{Elyasi:2017:EIS:3037697.3037728,\n author = {Elyasi, Nima and Arjomand, Mohammad and Sivasubramaniam, Anand and Kandemir, Mahmut T. and Das, Chita R. and Jung, Myoungsoo},\n title = {Exploiting Intra-Request Slack to Improve SSD Performance},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {375--388},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3037697.3037728},\n doi = {10.1145/3037697.3037728},\n acmid = {3037728},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {intra-request slack, scheduling, ssd},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037728&parent_id=3037697&expformat=bibtex&CFID=982048068&CFTOKEN=61205145\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037728\">\r\n@article{Elyasi:2017:EIS:3093315.3037728,\n author = {Elyasi, Nima and Arjomand, Mohammad and Sivasubramaniam, Anand and Kandemir, Mahmut T. and Das, Chita R. and Jung, Myoungsoo},\n title = {Exploiting Intra-Request Slack to Improve SSD Performance},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {375--388},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093315.3037728},\n doi = {10.1145/3093315.3037728},\n acmid = {3037728},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {intra-request slack, scheduling, ssd},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037728&parent_id=3093315&expformat=bibtex&CFID=982048068&CFTOKEN=61205145\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037728\">\r\n@article{Elyasi:2017:EIS:3093336.3037728,\n author = {Elyasi, Nima and Arjomand, Mohammad and Sivasubramaniam, Anand and Kandemir, Mahmut T. and Das, Chita R. and Jung, Myoungsoo},\n title = {Exploiting Intra-Request Slack to Improve SSD Performance},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {375--388},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093336.3037728},\n doi = {10.1145/3093336.3037728},\n acmid = {3037728},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {intra-request slack, scheduling, ssd},\n} \r\n",
        "key": "3037728",
        "pub_year": "2017",
        "text": "Nima Elyasi , Mohammad Arjomand , Anand Sivasubramaniam , Mahmut T. Kandemir , Chita R. Das , Myoungsoo Jung, Exploiting Intra-Request Slack to Improve SSD Performance, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China"
    },
    "3037730": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037730",
        "bib_stats": {
            "cites": 1,
            "dl": 221,
            "dl_52": 221,
            "dl_6": 42
        },
        "bibtex": "\r\n@article{Nalli:2017:APM:3093315.3037730,\n author = {Nalli, Sanketh and Haria, Swapnil and Hill, Mark D. and Swift, Michael M. and Volos, Haris and Keeton, Kimberly},\n title = {An Analysis of Persistent Memory Use with WHISPER},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {135--148},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093315.3037730},\n doi = {10.1145/3093315.3037730},\n acmid = {3037730},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {benchmark, caches, non-volatile memory (nvm), persistent memory (pm), storage-class memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037730&parent_id=3093315&expformat=bibtex&CFID=982049909&CFTOKEN=10180407\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037730\">\r\n@article{Nalli:2017:APM:3093336.3037730,\n author = {Nalli, Sanketh and Haria, Swapnil and Hill, Mark D. and Swift, Michael M. and Volos, Haris and Keeton, Kimberly},\n title = {An Analysis of Persistent Memory Use with WHISPER},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {135--148},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093336.3037730},\n doi = {10.1145/3093336.3037730},\n acmid = {3037730},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {benchmark, caches, non-volatile memory (nvm), persistent memory (pm), storage-class memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037730&parent_id=3093336&expformat=bibtex&CFID=982049909&CFTOKEN=10180407\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037730\">\r\n@article{Nalli:2017:APM:3093337.3037730,\n author = {Nalli, Sanketh and Haria, Swapnil and Hill, Mark D. and Swift, Michael M. and Volos, Haris and Keeton, Kimberly},\n title = {An Analysis of Persistent Memory Use with WHISPER},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {135--148},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093337.3037730},\n doi = {10.1145/3093337.3037730},\n acmid = {3037730},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {benchmark, caches, non-volatile memory (nvm), persistent memory (pm), storage-class memory},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037730&parent_id=3093337&expformat=bibtex&CFID=982049909&CFTOKEN=10180407\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037730\">\r\n@inproceedings{Nalli:2017:APM:3037697.3037730,\n author = {Nalli, Sanketh and Haria, Swapnil and Hill, Mark D. and Swift, Michael M. and Volos, Haris and Keeton, Kimberly},\n title = {An Analysis of Persistent Memory Use with WHISPER},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {135--148},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3037697.3037730},\n doi = {10.1145/3037697.3037730},\n acmid = {3037730},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {benchmark, caches, non-volatile memory (nvm), persistent memory (pm), storage-class memory},\n} \r\n",
        "key": "3037730",
        "pub_year": "2017",
        "text": "Sanketh Nalli , Swapnil Haria , Mark D. Hill , Michael M. Swift , Haris Volos , Kimberly Keeton, An Analysis of Persistent Memory Use with WHISPER, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China"
    },
    "3037732": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037732",
        "bib_stats": {
            "cites": 1,
            "dl": 173,
            "dl_52": 173,
            "dl_6": 34
        },
        "bibtex": "\r\n@article{Klimovic:2017:RRF:3093336.3037732,\n author = {Klimovic, Ana and Litz, Heiner and Kozyrakis, Christos},\n title = {ReFlex: Remote Flash \\&\\#8776; Local Flash},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {345--359},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093336.3037732},\n doi = {10.1145/3093336.3037732},\n acmid = {3037732},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenter storage, flash, i/o scheduling, network storage, qos},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037732&parent_id=3093336&expformat=bibtex&CFID=982054040&CFTOKEN=70095651\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037732\">\r\n@article{Klimovic:2017:RRF:3093337.3037732,\n author = {Klimovic, Ana and Litz, Heiner and Kozyrakis, Christos},\n title = {ReFlex: Remote Flash \\&\\#8776; Local Flash},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {345--359},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093337.3037732},\n doi = {10.1145/3093337.3037732},\n acmid = {3037732},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenter storage, flash, i/o scheduling, network storage, qos},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037732&parent_id=3093337&expformat=bibtex&CFID=982054040&CFTOKEN=70095651\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037732\">\r\n@inproceedings{Klimovic:2017:RRF:3037697.3037732,\n author = {Klimovic, Ana and Litz, Heiner and Kozyrakis, Christos},\n title = {ReFlex: Remote Flash \\&\\#8776; Local Flash},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {345--359},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3037697.3037732},\n doi = {10.1145/3037697.3037732},\n acmid = {3037732},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenter storage, flash, i/o scheduling, network storage, qos},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037732&parent_id=3037697&expformat=bibtex&CFID=982054040&CFTOKEN=70095651\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037732\">\r\n@article{Klimovic:2017:RRF:3093315.3037732,\n author = {Klimovic, Ana and Litz, Heiner and Kozyrakis, Christos},\n title = {ReFlex: Remote Flash \\&\\#8776; Local Flash},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {345--359},\n numpages = {15},\n url = {http://doi.acm.org/10.1145/3093315.3037732},\n doi = {10.1145/3093315.3037732},\n acmid = {3037732},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {datacenter storage, flash, i/o scheduling, network storage, qos},\n} \r\n",
        "key": "3037732",
        "pub_year": "2017",
        "text": "Ana Klimovic , Heiner Litz , Christos Kozyrakis, ReFlex: Remote Flash \u2248 Local Flash, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China  \u00a0[doi>"
    },
    "3037737": {
        "abstract": "Cache is designed to exploit locality; however, the role of on-chip L1 data caches on modern GPUs is often awkward. The locality among global memory requests from different SMs (Streaming Multiprocessors) is predominantly harvested by the commonly-shared L2 with long access latency; while the in-core locality, which is crucial for performance delivery, is handled explicitly by user-controlled scratchpad memory. In this work, we disclose another type of data locality that has been long ignored but with performance boosting potential --- the inter-CTA locality. Exploiting such locality is rather challenging due to unclear hardware feasibility, unknown and inaccessible underlying CTA scheduler, and small in-core cache capacity. To address these issues, we first conduct a thorough empirical exploration on various modern GPUs and demonstrate that inter-CTA locality can be harvested, both spatially and temporally, on L1 or L1/Tex unified cache. Through further quantification process, we prove the significance and commonality of such locality among GPU applications, and discuss whether such reuse is exploitable. By leveraging these insights, we propose the concept of CTA-Clustering and its associated software-based techniques to reshape the default CTA scheduling in order to group the CTAs with potential reuse together on the same SM. Our techniques require no hardware modification and can be directly deployed on existing GPUs. In addition, we incorporate these techniques into an integrated framework for automatic inter-CTA locality optimization. We evaluate our techniques using a wide range of popular GPU applications on all modern generations of NVIDIA GPU architectures. The results show that our proposed techniques significantly improve cache performance through reducing L2 cache transactions by 55%, 65%, 29%, 28% on average for Fermi, Kepler, Maxwell and Pascal, respectively, leading to an average of 1.46x, 1.48x, 1.45x, 1.41x (up to 3.8x, 3.6x, 3.1x, 3.3x) performance speedups for applications with algorithm-related inter-CTA reuse.",
        "acm_key": "3037737",
        "bib_stats": {
            "cites": 0,
            "dl": 248,
            "dl_52": 248,
            "dl_6": 46
        },
        "bibtex": "\r\n@article{Seo:2017:FSP:3093336.3037737,\n author = {Seo, Jihye and Kim, Wook-Hee and Baek, Woongki and Nam, Beomseok and Noh, Sam H.},\n title = {Failure-Atomic Slotted Paging for Persistent Memory},\n journal = {SIGPLAN Not.},\n issue_date = {April 2017},\n volume = {52},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0362-1340},\n pages = {91--104},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093336.3037737},\n doi = {10.1145/3093336.3037737},\n acmid = {3037737},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database buffer caching, database recovery, non-volatile memory, slotted page structure},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037737&parent_id=3093336&expformat=bibtex&CFID=982054134&CFTOKEN=84884570\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037737\">\r\n@article{Seo:2017:FSP:3093337.3037737,\n author = {Seo, Jihye and Kim, Wook-Hee and Baek, Woongki and Nam, Beomseok and Noh, Sam H.},\n title = {Failure-Atomic Slotted Paging for Persistent Memory},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {March 2017},\n volume = {45},\n number = {1},\n month = apr,\n year = {2017},\n issn = {0163-5964},\n pages = {91--104},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093337.3037737},\n doi = {10.1145/3093337.3037737},\n acmid = {3037737},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database buffer caching, database recovery, non-volatile memory, slotted page structure},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037737&parent_id=3093337&expformat=bibtex&CFID=982054134&CFTOKEN=84884570\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037737\">\r\n@inproceedings{Seo:2017:FSP:3037697.3037737,\n author = {Seo, Jihye and Kim, Wook-Hee and Baek, Woongki and Nam, Beomseok and Noh, Sam H.},\n title = {Failure-Atomic Slotted Paging for Persistent Memory},\n booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS '17},\n year = {2017},\n isbn = {978-1-4503-4465-4},\n location = {Xi'an, China},\n pages = {91--104},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3037697.3037737},\n doi = {10.1145/3037697.3037737},\n acmid = {3037737},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database buffer caching, database recovery, non-volatile memory, slotted page structure},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=3037737&parent_id=3037697&expformat=bibtex&CFID=982054134&CFTOKEN=84884570\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"3037737\">\r\n@article{Seo:2017:FSP:3093315.3037737,\n author = {Seo, Jihye and Kim, Wook-Hee and Baek, Woongki and Nam, Beomseok and Noh, Sam H.},\n title = {Failure-Atomic Slotted Paging for Persistent Memory},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {June 2017},\n volume = {51},\n number = {2},\n month = apr,\n year = {2017},\n issn = {0163-5980},\n pages = {91--104},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3093315.3037737},\n doi = {10.1145/3093315.3037737},\n acmid = {3037737},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database buffer caching, database recovery, non-volatile memory, slotted page structure},\n} \r\n",
        "key": "3037737",
        "pub_year": "2017",
        "text": "Jihye Seo , Wook-Hee Kim , Woongki Baek , Beomseok Nam , Sam H. Noh, Failure-Atomic Slotted Paging for Persistent Memory, Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, April 08-12, 2017, Xi'an, China"
    },
    "3040557": {
        "abstract": "Present article highlights the researches provided during the development of holographic memory system based on application of computational methods to encode binary data pages as amplitude computer generated Fourier holograms (CGFH). Using electro-optical micro-display and projection optics CGFH can be recorded onto photosensitive medium. The type of display that is used in data recorder determines the specificities of optical scheme architecture with its own limitations and advantages. There are three projection schemes of binary data recorder discussed in the paper. A linear scheme based on transparency-type liquid crystal spatial light modulator (LC SLM), a scheme based on reflection-type liquid crystal on silicon spatial light modulator (LCoS SLM) which uses a beamsplitting cube, and the most compact and simple scheme based on self-emitting OLED-display. The results of experimental implementation of all the three projection schemes for CGFH of binary data pages record onto the holographic carrier and consequent optical reconstruction and analysis of the encoded data are presented.",
        "acm_key": "3040557",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Tarkov:2016:ONA:3040498.3040557,\n author = {Tarkov, Mikhail S.},\n title = {Oscillatory Neural Associative Memories with Synapses Based on Memristor Bridges},\n journal = {Opt. Mem. Neural Netw.},\n issue_date = {October   2016},\n volume = {25},\n number = {4},\n month = oct,\n year = {2016},\n issn = {1060-992X},\n pages = {219--227},\n numpages = {9},\n url = {https://doi.org/10.3103/S1060992X16040068},\n doi = {10.3103/S1060992X16040068},\n acmid = {3040557},\n publisher = {Springer-Verlag New York, Inc.},\n address = {Secaucus, NJ, USA},\n keywords = {Hopfield network, LTSPICE, bidirectional associative memory, bridge, memristance, memristor, weight matrix},\n} \r\n",
        "key": "3040557",
        "pub_year": "2016",
        "text": "Mikhail S. Tarkov, Oscillatory neural associative memories with synapses based on memristor bridges, Optical Memory and Neural Networks, v.25 n.4, p.219-227, October   2016"
    },
    "3041713": {
        "abstract": "System software overheads in the I/O path, including VFS and file system code, become more pronounced with emerging low-latency storage devices. Currently, these overheads constitute the main bottleneck in the I/O path and they limit efficiency of modern storage systems. In this paper we present a taxonomy of the current state-of-the-art systems on accelerating accesses to fast storage devices. Furthermore, we present Iris, a new I/O path for applications, that minimizes overheads from system software in the common I/O path. The main idea is the separation of the control and data planes. The control plane consists of an unmodified Linux kernel and is responsible for handling data plane initialization and the normal processing path through the kernel for non-file related operations. The data plane is a lightweight mechanism to provide direct access to storage devices with minimum overheads and without sacrificing strong protection semantics. Iris requires neither hardware support from the storage devices nor changes in user applications. We evaluate our early prototype and we find that it achieves on a single core up to 1:7x and 2:2x better read and write random IOPS, respectively, compared to the XFS and EXT4 file systems. It also scales with the number of cores; using 4 cores Iris achieves 1:84x and 1:96x better read and write random IOPS, respectively. In sequential reads we provide similar performance and in sequential writes we are about 20% better compared to other file systems.",
        "acm_key": "3041713",
        "bib_stats": {
            "cites": 0,
            "dl": 166,
            "dl_52": 166,
            "dl_6": 16
        },
        "bibtex": "\r\n@article{Papagiannis:2017:IOI:3041710.3041713,\n author = {Papagiannis, Anastasios and Saloustros, Giorgos and Marazakis, Manolis and Bilas, Angelos},\n title = {Iris: An Optimized I/O Stack for Low-latency Storage Devices},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {December 2016},\n volume = {50},\n number = {3},\n month = jan,\n year = {2017},\n issn = {0163-5980},\n pages = {3--11},\n numpages = {9},\n url = {http://doi.acm.org/10.1145/3041710.3041713},\n doi = {10.1145/3041710.3041713},\n acmid = {3041713},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {I/O, NVM, low latency, protection, storage systems},\n} \r\n",
        "key": "3041713",
        "pub_year": "2017",
        "text": "Anastasios Papagiannis , Giorgos Saloustros , Manolis Marazakis , Angelos Bilas, Iris: An optimized I/O stack for low-latency storage devices, ACM SIGOPS Operating Systems Review, v.50 n.1, December 2016"
    },
    "3043633": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3043633",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Cai:2016:EET:3043551.3043633,\n author = {Cai, Xiaojun and Ju, Lei and Li, Xin and Zhang, Zhiyong and Jia, Zhiping},\n title = {Energy Efficient Task Allocation for Hybrid Main Memory Architecture},\n journal = {J. Syst. Archit.},\n issue_date = {November 2016},\n volume = {71},\n number = {C},\n month = nov,\n year = {2016},\n issn = {1383-7621},\n pages = {12--22},\n numpages = {11},\n url = {https://doi.org/10.1016/j.sysarc.2016.06.001},\n doi = {10.1016/j.sysarc.2016.06.001},\n acmid = {3043633},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {DRAM, Hybrid main memory architecture, PRAM, Task allocation},\n} \r\n",
        "key": "3043633",
        "pub_year": "2016",
        "text": "Xiaojun Cai , Lei Ju , Xin Li , Zhiyong Zhang , Zhiping Jia, Energy efficient task allocation for hybrid main memory architecture, Journal of Systems Architecture: the EUROMICRO Journal, v.71 n.C, p.12-22, November 2016"
    },
    "3043634": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3043634",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Long:2016:CAW:3043551.3043634,\n author = {Long, Linbo and Sha, Edwin H.-M. and Liu, Duo and Liang, Liang and Zhong, Kan and Zhu, Xiao},\n title = {A Compiler Assisted Wear Leveling for Morphable PCM in Embedded Systems},\n journal = {J. Syst. Archit.},\n issue_date = {November 2016},\n volume = {71},\n number = {C},\n month = nov,\n year = {2016},\n issn = {1383-7621},\n pages = {32--43},\n numpages = {12},\n url = {https://doi.org/10.1016/j.sysarc.2016.06.007},\n doi = {10.1016/j.sysarc.2016.06.007},\n acmid = {3043634},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Embedded systems, Endurance, Phase change memory, Wear-leveling},\n} \r\n",
        "key": "3043634",
        "pub_year": "2016",
        "text": "Linbo Long , Edwin H.-M. Sha , Duo Liu , Liang Liang , Kan Zhong , Xiao Zhu, A compiler assisted wear leveling for morphable PCM in embedded systems, Journal of Systems Architecture: the EUROMICRO Journal, v.71 n.C, p.32-43, November 2016"
    },
    "3043635": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3043635",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Luo:2016:WRW:3043551.3043635,\n author = {Luo, Huizhang and Dai, Penglin and Shi, Liang and Xue, Chun Jason and Zhuge, Qingfeng and Sha, Edwin H.M.},\n title = {Write Reconstruction for Write Throughput Improvement on MLC PCM Based Main Memory},\n journal = {J. Syst. Archit.},\n issue_date = {November 2016},\n volume = {71},\n number = {C},\n month = nov,\n year = {2016},\n issn = {1383-7621},\n pages = {62--72},\n numpages = {11},\n url = {https://doi.org/10.1016/j.sysarc.2016.05.006},\n doi = {10.1016/j.sysarc.2016.05.006},\n acmid = {3043635},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Phase change memory (PCM), Write reconstruction, Write throughput},\n} \r\n",
        "key": "3043635",
        "pub_year": "2016",
        "text": "Huizhang Luo , Penglin Dai , Liang Shi , Chun Jason Xue , Qingfeng Zhuge , Edwin H.M. Sha, Write reconstruction for write throughput improvement on MLC PCM based main memory, Journal of Systems Architecture: the EUROMICRO Journal, v.71 n.C, p.62-72, November 2016"
    },
    "3050372": {
        "abstract": "Large-scale scientific applications spend a significant amount of time in reading and writing data. These simulations run on supercomputers which are architected with high-bandwidth, low-latency, and complex topology interconnects. Yet, few efforts exist that fully exploit the interconnect features for I/O. MPI-IO optimizations suffer from significant network contention at large core counts making I/O a critical bottleneck at extreme scales. We propose HieRO, which leverages the fast interconnect and performs hierarchical optimizations for I/O in scientific applications with structured datasets. HieRO performs reads/writes in multiple stages using carefully chosen leader processes who invoke the MPI-IO calls. Additionally, HieRO considers the application's domain decomposition and access patterns and fully utilizes the on-chip interconnect at each multicore node. We evaluate the efficacy of our optimizations with two scientific applications, WRF and S3D, with I/O access patterns commonly used in a wide gamut of applications. We evaluate our approaches on two supercomputers, the Edison Cray XC30 and the Mira Blue Gene/Q, representing systems with diverse interconnects and parallel filesystems. We demonstrate that algorithmic changes can lead to significant improvements in parallel read/write. HieRO is able to achieve more than $$40\\times $$40\u00d7 read time improvements for WRF and achieve up to $$40\\times $$40\u00d7 read and $$13\\times $$13\u00d7 write time improvements for S3D on 524288 cores.",
        "acm_key": "3050372",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Zhang:2017:OPP:3050330.3050372,\n author = {Zhang, Jinbao and Liao, Xiaofei and Jin, Hai and Liu, Dong and Lin, Li and Zhao, Kao},\n title = {An Optimal Page-Level Power Management Strategy in PCM---DRAM Hybrid Memory},\n journal = {Int. J. Parallel Program.},\n issue_date = {February  2017},\n volume = {45},\n number = {1},\n month = feb,\n year = {2017},\n issn = {0885-7458},\n pages = {4--16},\n numpages = {13},\n url = {https://doi.org/10.1007/s10766-015-0382-5},\n doi = {10.1007/s10766-015-0382-5},\n acmid = {3050372},\n publisher = {Kluwer Academic Publishers},\n address = {Norwell, MA, USA},\n keywords = {Energy consumption, Hybrid memory, PCM},\n} \r\n",
        "key": "3050372",
        "pub_year": "2017",
        "text": "Jinbao Zhang , Xiaofei Liao , Hai Jin , Dong Liu , Li Lin , Kao Zhao, An Optimal Page-Level Power Management Strategy in PCM---DRAM Hybrid Memory, International Journal of Parallel Programming, v.45 n.1, p.4-16, February  2017"
    },
    "3050440": {
        "abstract": "Caches are widely used in embedded systems to bridge the increasing speed gap between processors and off-chip memory. However, caches make it significantly harder to compute the worst-case execution time (WCET) of a task. To alleviate this problem, cache locking has been proposed. We investigate the WCET-aware I-cache locking problem and propose a novel dynamic I-cache locking heuristic approach for reducing the WCET of a task. For a nonnested loop, our approach aims at selecting a minimum set of memory blocks of the loop as locked cache contents by using the min-cut algorithm. For a loop nest, our approach not only aims at selecting a minimum set of memory blocks of the loop nest as locked cache contents but also finds a good loading point for each selected memory block. We propose two algorithms for finding a good loading point for each selected memory block, a polynomial-time heuristic algorithm and an integer linear programming (ILP)-based algorithm, further reducing the WCET of each loop nest. We have implemented our approach and compared it to two state-of-the-art I-cache locking approaches by using a set of benchmarks from the MRTC benchmark suite. The experimental results show that the polynomial-time heuristic algorithm for finding a good loading point for each selected memory block performs almost equally as well as the ILP-based algorithm. Compared to the partial locking approach proposed in Ding et al. [2012], our approach using the heuristic algorithm achieves the average improvements of 33%, 15%, 9%, 3%, 8%, and 11% for the 256B, 512B, 1KB, 4KB, 8KB, and 16KB caches, respectively. Compared to the dynamic locking approach proposed in Puaut [2006], it achieves the average improvements of 9%, 19%, 18%, 5%, 11%, and 16% for the 256B, 512B, 1KB, 4KB, 8KB, and 16KB caches, respectively.",
        "acm_key": "3050440",
        "bib_stats": {
            "cites": 0,
            "dl": 65,
            "dl_52": 65,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Palangappa:2017:CCC:3058793.3050440,\n author = {Palangappa, Poovaiah M. and Mohanram, Kartik},\n title = {CompEx++: Compression-Expansion Coding for Energy, Latency, and Lifetime Improvements in MLC/TLC NVMs},\n journal = {ACM Trans. Archit. Code Optim.},\n issue_date = {April 2017},\n volume = {14},\n number = {1},\n month = apr,\n year = {2017},\n issn = {1544-3566},\n pages = {10:1--10:30},\n articleno = {10},\n numpages = {30},\n url = {http://doi.acm.org/10.1145/3050440},\n doi = {10.1145/3050440},\n acmid = {3050440},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Nonvolatile memories, compression, energy, latency, main memory},\n} \r\n",
        "key": "3050440",
        "pub_year": "2017",
        "text": "Poovaiah M. Palangappa , Kartik Mohanram, CompEx++: Compression-Expansion Coding for Energy, Latency, and Lifetime Improvements in MLC/TLC NVMs, ACM Transactions on Architecture and Code Optimization (TACO), v.14 n.1, p.1-30, April 2017"
    },
    "3050931": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3050931",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Wang:2017:FGD:3043548.3050931,\n author = {Wang, Yi and Wang, Tianzheng and Liu, Duo and Shao, Zili and Xue, Jingling},\n title = {Fine Grained, Direct Access File System Support for Storage Class Memory},\n journal = {J. Syst. Archit.},\n issue_date = {January 2017},\n volume = {72},\n number = {C},\n month = jan,\n year = {2017},\n issn = {1383-7621},\n pages = {80--92},\n numpages = {13},\n url = {https://doi.org/10.1016/j.sysarc.2016.07.003},\n doi = {10.1016/j.sysarc.2016.07.003},\n acmid = {3050931},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Block device support, Byte-addressable direct I/O,, Memory management, Phase change memory, Storage class memory},\n} \r\n",
        "key": "3050931",
        "pub_year": "2017",
        "text": "Yi Wang , Tianzheng Wang , Duo Liu , Zili Shao , Jingling Xue, Fine grained, direct access file system support for storage class memory, Journal of Systems Architecture: the EUROMICRO Journal, v.72 n.C, p.80-92, January 2017"
    },
    "3051123": {
        "abstract": "Multi-tiered storage, where each tier consists of one type of storage device (e.g., SSD, HDD, or disk arrays), is a commonly used approach to achieve both high performance and cost efficiency in large-scale systems that need to store data with vastly different access characteristics. By aligning the access characteristics of the data, either fixed-sized extents or variable-sized files, to the characteristics of the storage devices, a higher performance can be achieved for any given cost. This article presents ExaPlan, a method to determine both the data-to-tier assignment and the number of devices in each tier that minimize the system\u2019s mean response time for a given budget and workload. In contrast to other methods that constrain or minimize the system load, ExaPlan directly minimizes the system\u2019s mean response time estimated by a queueing model. Minimizing the mean response time is typically intractable as the resulting optimization problem is both nonconvex and combinatorial in nature. ExaPlan circumvents this intractability by introducing a parameterized data placement approach that makes it a highly scalable method that can be easily applied to exascale systems. Through experiments that use parameters from real-world storage systems, such as CERN and LOFAR, it is demonstrated that ExaPlan provides solutions that yield lower mean response times than previous works. It supports standalone SSDs and HDDs as well as disk arrays as storage tiers, and although it uses a static workload representation, we provide empirical evidence that underlying dynamic workloads have invariant properties that can be deemed static for the purpose of provisioning a storage system. ExaPlan is also effective as a load-balancing tool used for placing data across devices within a tier, resulting in an up to 3.6-fold reduction of response time compared with a traditional load-balancing algorithm, such as the Longest Processing Time heuristic.",
        "acm_key": "3051123",
        "bib_stats": {
            "cites": 0,
            "dl": 90,
            "dl_52": 90,
            "dl_6": 33
        },
        "bibtex": "\r\n@article{Zhou:2017:UAI:3098275.3051123,\n author = {Zhou, You and Wu, Fei and Huang, Ping and He, Xubin and Xie, Changsheng and Zhou, Jian},\n title = {Understanding and Alleviating the Impact of the Flash Address Translation on Solid State Devices},\n journal = {Trans. Storage},\n issue_date = {June 2017},\n volume = {13},\n number = {2},\n month = may,\n year = {2017},\n issn = {1553-3077},\n pages = {14:1--14:29},\n articleno = {14},\n numpages = {29},\n url = {http://doi.acm.org/10.1145/3051123},\n doi = {10.1145/3051123},\n acmid = {3051123},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {FTL, NAND flash memory, SSD, address translation},\n} \r\n",
        "key": "3051123",
        "pub_year": "2017",
        "text": "You Zhou , Fei Wu , Ping Huang , Xubin He , Changsheng Xie , Jian Zhou, Understanding and Alleviating the Impact of the Flash Address Translation on Solid State Devices, ACM Transactions on Storage (TOS), v.13 n.2, May 2017"
    },
    "3054777": {
        "abstract": "Sorting is at the core of many database operations, such as index creation, sort-merge joins, and user-requested output sorting. As GPUs are emerging as a promising platform to accelerate various operations, sorting on GPUs becomes a viable endeavour. Over the past few years, several improvements have been proposed for sorting on GPUs, leading to the first radix sort implementations that achieve a sorting rate of over one billion 32-bit keys per second. Yet, state-of-the-art approaches are heavily memory bandwidth-bound, as they require substantially more memory transfers than their CPU-based counterparts. Our work proposes a novel approach that almost halves the amount of memory transfers and, therefore, considerably lifts the memory bandwidth limitation. Being able to sort two gigabytes of eight-byte records in as little as 50 milliseconds, our approach achieves a 2.32-fold improvement over the state-of-the-art GPU-based radix sort for uniform distributions, sustaining a minimum speed-up of no less than a factor of 1.66 for skewed distributions. To address inputs that either do not reside on the GPU or exceed the available device memory, we build on our efficient GPU sorting approach with a pipelined heterogeneous sorting algorithm that mitigates the overhead associated with PCIe data transfers. Comparing the end-to-end sorting performance to the state-of-the-art CPU-based radix sort running 16 threads, our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for sorting 64 GB key-value pairs with a skewed and a uniform distribution, respectively.",
        "acm_key": "3054777",
        "bib_stats": {
            "cites": 0,
            "dl": 312,
            "dl_52": 312,
            "dl_6": 53
        },
        "bibtex": "\r\n@inproceedings{Oukid:2017:DSE:3035918.3054777,\n author = {Oukid, Ismail and Lehner, Wolfgang},\n title = {Data Structure Engineering For Byte-Addressable Non-Volatile Memory},\n booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},\n series = {SIGMOD '17},\n year = {2017},\n isbn = {978-1-4503-4197-4},\n location = {Chicago, Illinois, USA},\n pages = {1759--1764},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3035918.3054777},\n doi = {10.1145/3035918.3054777},\n acmid = {3054777},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {crash simulation, data structures, dram, emulation, main memory, memory management, non-volatile memory, programming model, storage-class memory, testing},\n} \r\n",
        "key": "3054777",
        "pub_year": "2017",
        "text": "Ismail Oukid , Wolfgang Lehner, Data Structure Engineering For Byte-Addressable Non-Volatile Memory, Proceedings of the 2017 ACM International Conference on Management of Data, May 14-19, 2017, Chicago, Illinois, USA"
    },
    "3054780": {
        "abstract": "Sorting is at the core of many database operations, such as index creation, sort-merge joins, and user-requested output sorting. As GPUs are emerging as a promising platform to accelerate various operations, sorting on GPUs becomes a viable endeavour. Over the past few years, several improvements have been proposed for sorting on GPUs, leading to the first radix sort implementations that achieve a sorting rate of over one billion 32-bit keys per second. Yet, state-of-the-art approaches are heavily memory bandwidth-bound, as they require substantially more memory transfers than their CPU-based counterparts. Our work proposes a novel approach that almost halves the amount of memory transfers and, therefore, considerably lifts the memory bandwidth limitation. Being able to sort two gigabytes of eight-byte records in as little as 50 milliseconds, our approach achieves a 2.32-fold improvement over the state-of-the-art GPU-based radix sort for uniform distributions, sustaining a minimum speed-up of no less than a factor of 1.66 for skewed distributions. To address inputs that either do not reside on the GPU or exceed the available device memory, we build on our efficient GPU sorting approach with a pipelined heterogeneous sorting algorithm that mitigates the overhead associated with PCIe data transfers. Comparing the end-to-end sorting performance to the state-of-the-art CPU-based radix sort running 16 threads, our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for sorting 64 GB key-value pairs with a skewed and a uniform distribution, respectively.",
        "acm_key": "3054780",
        "bib_stats": {
            "cites": 0,
            "dl": 408,
            "dl_52": 408,
            "dl_6": 57
        },
        "bibtex": "\r\n@inproceedings{Arulraj:2017:BNM:3035918.3054780,\n author = {Arulraj, Joy and Pavlo, Andrew},\n title = {How to Build a Non-Volatile Memory Database Management System},\n booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},\n series = {SIGMOD '17},\n year = {2017},\n isbn = {978-1-4503-4197-4},\n location = {Chicago, Illinois, USA},\n pages = {1753--1758},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3035918.3054780},\n doi = {10.1145/3035918.3054780},\n acmid = {3054780},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {database management systems, non-volatile memory},\n} \r\n",
        "key": "3054780",
        "pub_year": "2017",
        "text": "Joy Arulraj , Andrew Pavlo, How to Build a Non-Volatile Memory Database Management System, Proceedings of the 2017 ACM International Conference on Management of Data, May 14-19, 2017, Chicago, Illinois, USA"
    },
    "3057968": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3057968",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Jung:2017:EPD:3057932.3057968,\n author = {Jung, Myoungsoo},\n title = {Exploring Parallel Data Access Methods in Emerging Non-Volatile Memory Systems},\n journal = {IEEE Trans. Parallel Distrib. Syst.},\n issue_date = {March 2017},\n volume = {28},\n number = {3},\n month = mar,\n year = {2017},\n issn = {1045-9219},\n pages = {746--759},\n numpages = {14},\n url = {https://doi.org/10.1109/TPDS.2016.2588491},\n doi = {10.1109/TPDS.2016.2588491},\n acmid = {3057968},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3057968",
        "pub_year": "2017",
        "text": "Myoungsoo Jung, Exploring Parallel Data Access Methods in Emerging Non-Volatile Memory Systems, IEEE Transactions on Parallel and Distributed Systems, v.28 n.3, p.746-759, March 2017"
    },
    "3060147": {
        "abstract": "Multi-tiered storage, where each tier consists of one type of storage device (e.g., SSD, HDD, or disk arrays), is a commonly used approach to achieve both high performance and cost efficiency in large-scale systems that need to store data with vastly different access characteristics. By aligning the access characteristics of the data, either fixed-sized extents or variable-sized files, to the characteristics of the storage devices, a higher performance can be achieved for any given cost. This article presents ExaPlan, a method to determine both the data-to-tier assignment and the number of devices in each tier that minimize the system\u2019s mean response time for a given budget and workload. In contrast to other methods that constrain or minimize the system load, ExaPlan directly minimizes the system\u2019s mean response time estimated by a queueing model. Minimizing the mean response time is typically intractable as the resulting optimization problem is both nonconvex and combinatorial in nature. ExaPlan circumvents this intractability by introducing a parameterized data placement approach that makes it a highly scalable method that can be easily applied to exascale systems. Through experiments that use parameters from real-world storage systems, such as CERN and LOFAR, it is demonstrated that ExaPlan provides solutions that yield lower mean response times than previous works. It supports standalone SSDs and HDDs as well as disk arrays as storage tiers, and although it uses a static workload representation, we provide empirical evidence that underlying dynamic workloads have invariant properties that can be deemed static for the purpose of provisioning a storage system. ExaPlan is also effective as a load-balancing tool used for placing data across devices within a tier, resulting in an up to 3.6-fold reduction of response time compared with a traditional load-balancing algorithm, such as the Longest Processing Time heuristic.",
        "acm_key": "3060147",
        "bib_stats": {
            "cites": 0,
            "dl": 125,
            "dl_52": 125,
            "dl_6": 38
        },
        "bibtex": "\r\n@article{Chen:2017:OFS:3098275.3060147,\n author = {Chen, Cheng and Yang, Jun and Wei, Qingsong and Wang, Chundong and Xue, Mingdi},\n title = {Optimizing File Systems with Fine-grained Metadata Journaling on Byte-addressable NVM},\n journal = {Trans. Storage},\n issue_date = {June 2017},\n volume = {13},\n number = {2},\n month = may,\n year = {2017},\n issn = {1553-3077},\n pages = {13:1--13:25},\n articleno = {13},\n numpages = {25},\n url = {http://doi.acm.org/10.1145/3060147},\n doi = {10.1145/3060147},\n acmid = {3060147},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {File system, metadata journaling, non-volatile memory},\n} \r\n",
        "key": "3060147",
        "pub_year": "2017",
        "text": "Cheng Chen , Jun Yang , Qingsong Wei , Chundong Wang , Mingdi Xue, Optimizing File Systems with Fine-grained Metadata Journaling on Byte-addressable NVM, ACM Transactions on Storage (TOS), v.13 n.2, May 2017"
    },
    "3060412": {
        "abstract": "Abstract-Efficiently and reliably managing high quality power is a primary challenge in Internet of Things (IoT) systems. Based on current projections, future IoT will provide vast interconnectedness of embedded devices and sensors, many of which will be powered up wirelessly from spatially distributed power supplies or locally from energy harvesting sources. The energy budget, constrained by inherently lower quality of power of these non-traditional power sources, will become a critical system resource and a primary limiting factor for scalability of future IoT systems. Distributed on-chip power regulation is necessary for efficiently delivering high quality power to high performance heterogeneous integrated circuits (ICs). A multi- feedback system with distributed on-chip power supplies deliver- ing current to billions of non-linear circuits is characterized by complex interactions among the heterogeneous power supplies and loads. These modern multi-feedback systems exhibit high design complexity and degraded stability. No straightforward method exists to efficiently design a stable multi-feedback power delivery system. An automated design and analysis flow for stable, high quality power delivery is proposed in this work based on the passivity of heterogeneous integrated systems. The algorithm is evaluated based on ISPD benchmark circuits and shows that the generated power delivery system addresses both the quality of power (QoP) and stability requirements. A distributed power delivery system is designed based on the passivity criterion and fabricated in 28 nm CMOS technology. The system is tested under a wide range of load, voltage, and temperature variations that are typical for modern heterogeneous ICs. The system exhibits high performance and stable response.",
        "acm_key": "3060412",
        "bib_stats": {
            "cites": 0,
            "dl": 46,
            "dl_52": 46,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Jiang:2017:BFP:3060403.3060412,\n author = {Jiang, Lei and Mittal, Sparsh and Wen, Wujie},\n title = {Building a Fast and Power Efficient Inductive Charge Pump System for 3D Stacked Phase Change Memories},\n booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},\n series = {GLSVLSI '17},\n year = {2017},\n isbn = {978-1-4503-4972-7},\n location = {Banff, Alberta, Canada},\n pages = {275--280},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3060403.3060412},\n doi = {10.1145/3060403.3060412},\n acmid = {3060412},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3d stacking technology, charge pumps, phase change memory},\n} \r\n",
        "key": "3060412",
        "pub_year": "2017",
        "text": "Lei Jiang , Sparsh Mittal , Wujie Wen, Building a Fast and Power Efficient Inductive Charge Pump System for 3D Stacked Phase Change Memories, Proceedings of the on Great Lakes Symposium on VLSI 2017, May 10-12, 2017, Banff, Alberta, Canada"
    },
    "3060459": {
        "abstract": "Abstract-Efficiently and reliably managing high quality power is a primary challenge in Internet of Things (IoT) systems. Based on current projections, future IoT will provide vast interconnectedness of embedded devices and sensors, many of which will be powered up wirelessly from spatially distributed power supplies or locally from energy harvesting sources. The energy budget, constrained by inherently lower quality of power of these non-traditional power sources, will become a critical system resource and a primary limiting factor for scalability of future IoT systems. Distributed on-chip power regulation is necessary for efficiently delivering high quality power to high performance heterogeneous integrated circuits (ICs). A multi- feedback system with distributed on-chip power supplies deliver- ing current to billions of non-linear circuits is characterized by complex interactions among the heterogeneous power supplies and loads. These modern multi-feedback systems exhibit high design complexity and degraded stability. No straightforward method exists to efficiently design a stable multi-feedback power delivery system. An automated design and analysis flow for stable, high quality power delivery is proposed in this work based on the passivity of heterogeneous integrated systems. The algorithm is evaluated based on ISPD benchmark circuits and shows that the generated power delivery system addresses both the quality of power (QoP) and stability requirements. A distributed power delivery system is designed based on the passivity criterion and fabricated in 28 nm CMOS technology. The system is tested under a wide range of load, voltage, and temperature variations that are typical for modern heterogeneous ICs. The system exhibits high performance and stable response.",
        "acm_key": "3060459",
        "bib_stats": {
            "cites": 0,
            "dl": 83,
            "dl_52": 83,
            "dl_6": 11
        },
        "bibtex": "\r\n@inproceedings{Angizi:2017:EEI:3060403.3060459,\n author = {Angizi, Shaahin and He, Zhezhi and Fan, Deliang},\n title = {Energy Efficient In-Memory Computing Platform Based on 4-Terminal Spin Hall Effect-Driven Domain Wall Motion Devices},\n booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},\n series = {GLSVLSI '17},\n year = {2017},\n isbn = {978-1-4503-4972-7},\n location = {Banff, Alberta, Canada},\n pages = {77--82},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3060403.3060459},\n doi = {10.1145/3060403.3060459},\n acmid = {3060459},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {domain wall motion device, in-memory computing, spin hall effect},\n} \r\n",
        "key": "3060459",
        "pub_year": "2017",
        "text": "Shaahin Angizi , Zhezhi He , Deliang Fan, Energy Efficient In-Memory Computing Platform Based on 4-Terminal Spin Hall Effect-Driven Domain Wall Motion Devices, Proceedings of the on Great Lakes Symposium on VLSI 2017, May 10-12, 2017, Banff, Alberta, Canada"
    },
    "3060589": {
        "abstract": "Abstract-Efficiently and reliably managing high quality power is a primary challenge in Internet of Things (IoT) systems. Based on current projections, future IoT will provide vast interconnectedness of embedded devices and sensors, many of which will be powered up wirelessly from spatially distributed power supplies or locally from energy harvesting sources. The energy budget, constrained by inherently lower quality of power of these non-traditional power sources, will become a critical system resource and a primary limiting factor for scalability of future IoT systems. Distributed on-chip power regulation is necessary for efficiently delivering high quality power to high performance heterogeneous integrated circuits (ICs). A multi- feedback system with distributed on-chip power supplies deliver- ing current to billions of non-linear circuits is characterized by complex interactions among the heterogeneous power supplies and loads. These modern multi-feedback systems exhibit high design complexity and degraded stability. No straightforward method exists to efficiently design a stable multi-feedback power delivery system. An automated design and analysis flow for stable, high quality power delivery is proposed in this work based on the passivity of heterogeneous integrated systems. The algorithm is evaluated based on ISPD benchmark circuits and shows that the generated power delivery system addresses both the quality of power (QoP) and stability requirements. A distributed power delivery system is designed based on the passivity criterion and fabricated in 28 nm CMOS technology. The system is tested under a wide range of load, voltage, and temperature variations that are typical for modern heterogeneous ICs. The system exhibits high performance and stable response.",
        "acm_key": "3060589",
        "bib_stats": {
            "cites": 0,
            "dl": 124,
            "dl_52": 124,
            "dl_6": 18
        },
        "bibtex": "\r\n@inproceedings{Kang:2017:ALP:3060403.3060589,\n author = {Kang, Wang and Wang, Zhaohao and Zhang, He and Li, Sai and Zhang, Youguang and Zhao, Weisheng},\n title = {Advanced Low Power Spintronic Memories Beyond STT-MRAM},\n booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},\n series = {GLSVLSI '17},\n year = {2017},\n isbn = {978-1-4503-4972-7},\n location = {Banff, Alberta, Canada},\n pages = {299--304},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3060403.3060589},\n doi = {10.1145/3060403.3060589},\n acmid = {3060589},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {magnetic skyrmions, racetrack memory., she-mram, spintronic memory, stt-mram, voltage-driven mram},\n} \r\n",
        "key": "3060589",
        "pub_year": "2017",
        "text": "Wang Kang , Zhaohao Wang , He Zhang , Sai Li , Youguang Zhang , Weisheng Zhao, Advanced Low Power Spintronic Memories beyond STT-MRAM, Proceedings of the on Great Lakes Symposium on VLSI 2017, May 10-12, 2017, Banff, Alberta, Canada"
    },
    "3062191": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062191",
        "bib_stats": {
            "cites": 0,
            "dl": 57,
            "dl_52": 57,
            "dl_6": 22
        },
        "bibtex": "\r\n@inproceedings{Zhang:2017:NRM:3061639.3062191,\n author = {Zhang, Yang and Feng, Dan and Liu, Jingning and Tong, Wei and Wu, Bing and Fang, Caihua},\n title = {A Novel ReRAM-based Main Memory Structure for Optimizing Access Latency and Reliability},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {82:1--82:6},\n articleno = {82},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062191},\n doi = {10.1145/3061639.3062191},\n acmid = {3062191},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {IR drop, ReRAM, crossbar, data patterns, non-uniform access latency},\n} \r\n",
        "key": "3062191",
        "pub_year": "2017",
        "text": "Yang Zhang , Dan Feng , Jingning Liu , Wei Tong , Bing Wu , Caihua Fang, A Novel ReRAM-based Main Memory Structure for Optimizing Access Latency and Reliability, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062197": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062197",
        "bib_stats": {
            "cites": 0,
            "dl": 40,
            "dl_52": 40,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Li:2017:ATM:3061639.3062197,\n author = {Li, Dawei and Zhang, Kaicheng and Guliani, Akhil and Ogrenci-Memik, Seda},\n title = {Adaptive Thermal Management for 3D ICs with Stacked DRAM Caches},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {3:1--3:6},\n articleno = {3},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062197},\n doi = {10.1145/3061639.3062197},\n acmid = {3062197},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3D-IC, DRAM, cache, low power design, thermal management},\n} \r\n",
        "key": "3062197",
        "pub_year": "2017",
        "text": "Dawei Li , Kaicheng Zhang , Akhil Guliani , Seda Ogrenci-Memik, Adaptive Thermal Management for 3D ICs with Stacked DRAM Caches, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062198": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062198",
        "bib_stats": {
            "cites": 0,
            "dl": 75,
            "dl_52": 75,
            "dl_6": 25
        },
        "bibtex": "\r\n@inproceedings{Xue:2017:ALM:3061639.3062198,\n author = {Xue, Yuan and Yang, Chengmo and Hu, Jingtong},\n title = {Age-aware Logic and Memory Co-Placement for RRAM-FPGAs},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {1:1--1:6},\n articleno = {1},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062198},\n doi = {10.1145/3061639.3062198},\n acmid = {3062198},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062198",
        "pub_year": "2017",
        "text": "Yuan Xue , Chengmo Yang , Jingtong Hu, Age-aware Logic and Memory Co-Placement for RRAM-FPGAs, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062205": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062205",
        "bib_stats": {
            "cites": 0,
            "dl": 61,
            "dl_52": 61,
            "dl_6": 27
        },
        "bibtex": "\r\n@inproceedings{Rakshit:2017:AAS:3061639.3062205,\n author = {Rakshit, Joydeep and Mohanram, Kartik},\n title = {ASSURE: Authentication Scheme for SecURE Energy Efficient Non-Volatile Memories},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {11:1--11:6},\n articleno = {11},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062205},\n doi = {10.1145/3061639.3062205},\n acmid = {3062205},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Authentication, Merkle Tree, Non-volatile Memories},\n} \r\n",
        "key": "3062205",
        "pub_year": "2017",
        "text": "Joydeep Rakshit , Kartik Mohanram, ASSURE: Authentication Scheme for SecURE Energy Efficient Non-Volatile Memories, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062209": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062209",
        "bib_stats": {
            "cites": 0,
            "dl": 53,
            "dl_52": 53,
            "dl_6": 30
        },
        "bibtex": "\r\n@inproceedings{Chen:2017:BPC:3061639.3062209,\n author = {Chen, Shuo-Han and Chen, Yen-Ting and Wei, Hsin-Wen and Shih, Wei-Kuan},\n title = {Boosting the Performance of 3D Charge Trap NAND Flash with Asymmetric Feature Process Size Characteristic},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {83:1--83:6},\n articleno = {83},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062209},\n doi = {10.1145/3061639.3062209},\n acmid = {3062209},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3D NAND flash, flash storage, hot/cold identification},\n} \r\n",
        "key": "3062209",
        "pub_year": "2017",
        "text": "Shuo-Han Chen , Yen-Ting Chen , Hsin-Wen Wei , Wei-Kuan Shih, Boosting the Performance of 3D Charge Trap NAND Flash with Asymmetric Feature Process Size Characteristic, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062232": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062232",
        "bib_stats": {
            "cites": 0,
            "dl": 38,
            "dl_52": 38,
            "dl_6": 13
        },
        "bibtex": "\r\n@inproceedings{Yin:2017:DAM:3061639.3062232,\n author = {Yin, Shouyi and Xie, Zhicong and Wei, Shaojun},\n title = {Disturbance Aware Memory Partitioning for Parallel Data Access in STT-RAM},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {84:1--84:6},\n articleno = {84},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062232},\n doi = {10.1145/3061639.3062232},\n acmid = {3062232},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062232",
        "pub_year": "2017",
        "text": "Shouyi Yin , Zhicong Xie , Shaojun Wei, Disturbance Aware Memory Partitioning for Parallel Data Access in STT-RAM, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062236": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062236",
        "bib_stats": {
            "cites": 0,
            "dl": 50,
            "dl_52": 50,
            "dl_6": 24
        },
        "bibtex": "\r\n@inproceedings{Chen:2017:EWS:3061639.3062236,\n author = {Chen, Tseng-Yi and Chang, Yuan-Hao and Chen, Shuo-Han and Kuo, Chih-Ching and Yang, Ming-Chang and Wei, Hsin-Wen and Shih, Wei-Kuan},\n title = {Enabling Write-Reduction Strategy for Journaling File Systems over Byte-addressable NVRAM},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {44:1--44:6},\n articleno = {44},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062236},\n doi = {10.1145/3061639.3062236},\n acmid = {3062236},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {NVRAM, journaling file system, write reduction},\n} \r\n",
        "key": "3062236",
        "pub_year": "2017",
        "text": "Tseng-Yi Chen , Yuan-Hao Chang , Shuo-Han Chen , Chih-Ching Kuo , Ming-Chang Yang , Hsin-Wen Wei , Wei-Kuan Shih, Enabling Write-Reduction Strategy for Journaling File Systems over Byte-addressable NVRAM, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062248": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062248",
        "bib_stats": {
            "cites": 0,
            "dl": 87,
            "dl_52": 87,
            "dl_6": 32
        },
        "bibtex": "\r\n@inproceedings{Xia:2017:FTO:3061639.3062248,\n author = {Xia, Lixue and Liu, Mengyun and Ning, Xuefei and Chakrabarty, Krishnendu and Wang, Yu},\n title = {Fault-Tolerant Training with On-Line Fault Detection for RRAM-Based Neural Computing Systems},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {33:1--33:6},\n articleno = {33},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062248},\n doi = {10.1145/3061639.3062248},\n acmid = {3062248},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062248",
        "pub_year": "2017",
        "text": "Lixue Xia , Mengyun Liu , Xuefei Ning , Krishnendu Chakrabarty , Yu Wang, Fault-Tolerant Training with On-Line Fault Detection for RRAM-Based Neural Computing Systems, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062264": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062264",
        "bib_stats": {
            "cites": 0,
            "dl": 54,
            "dl_52": 54,
            "dl_6": 20
        },
        "bibtex": "\r\n@inproceedings{Kim:2017:IPL:3061639.3062264,\n author = {Kim, Myungsuk and Lee, Jaehoon and Lee, Sungjin and Park, Jisung and Kim, Jihong},\n title = {Improving Performance and Lifetime of Large-Page NAND Storages Using Erase-Free Subpage Programming},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {24:1--24:6},\n articleno = {24},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062264},\n doi = {10.1145/3061639.3062264},\n acmid = {3062264},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062264",
        "pub_year": "2017",
        "text": "Myungsuk Kim , Jaehoon Lee , Sungjin Lee , Jisung Park , Jihong Kim, Improving Performance and Lifetime of Large-Page NAND Storages Using Erase-Free Subpage Programming, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062282": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062282",
        "bib_stats": {
            "cites": 0,
            "dl": 42,
            "dl_52": 42,
            "dl_6": 18
        },
        "bibtex": "\r\n@inproceedings{Li:2017:MFP:3061639.3062282,\n author = {Li, Jing and Zhao, Mengying and Ju, Lei and Xue, Chun Jason and Jia, Zhiping},\n title = {Maximizing Forward Progress with Cache-aware Backup for Self-powered Non-volatile Processors},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {2:1--2:6},\n articleno = {2},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062282},\n doi = {10.1145/3061639.3062282},\n acmid = {3062282},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Non-volatile Processor, cache persistence, forward progress},\n} \r\n",
        "key": "3062282",
        "pub_year": "2017",
        "text": "Jing Li , Mengying Zhao , Lei Ju , Chun Jason Xue , Zhiping Jia, Maximizing Forward Progress with Cache-aware Backup for Self-powered Non-volatile Processors, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062309": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062309",
        "bib_stats": {
            "cites": 0,
            "dl": 37,
            "dl_52": 37,
            "dl_6": 15
        },
        "bibtex": "\r\n@inproceedings{Du:2017:RLS:3061639.3062309,\n author = {Du, Yajuan and Li, Qiao and Shi, Liang and Zou, Deqing and Jin, Hai and Xue, Chun Jason},\n title = {Reducing LDPC Soft Sensing Latency by Lightweight Data Refresh for Flash Read Performance Improvement},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {23:1--23:6},\n articleno = {23},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062309},\n doi = {10.1145/3061639.3062309},\n acmid = {3062309},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Data Refresh, Flash Read Performance, LDPC Codes},\n} \r\n",
        "key": "3062309",
        "pub_year": "2017",
        "text": "Yajuan Du , Qiao Li , Liang Shi , Deqing Zou , Hai Jin , Chun Jason Xue, Reducing LDPC Soft Sensing Latency by Lightweight Data Refresh for Flash Read Performance Improvement, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062317": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062317",
        "bib_stats": {
            "cites": 0,
            "dl": 35,
            "dl_52": 35,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Zhu:2017:SHU:3061639.3062317,\n author = {Zhu, Xiao and Liu, Duo and Zhong, Kan and Ren, Jinting and Li, Tao},\n title = {SmartSwap: High-Performance and User Experience Friendly Swapping in Mobile Systems},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {22:1--22:6},\n articleno = {22},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062317},\n doi = {10.1145/3061639.3062317},\n acmid = {3062317},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062317",
        "pub_year": "2017",
        "text": "Xiao Zhu , Duo Liu , Kan Zhong , Jinting Ren , Tao Li, SmartSwap: High-Performance and User Experience Friendly Swapping in Mobile Systems, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062326": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062326",
        "bib_stats": {
            "cites": 0,
            "dl": 116,
            "dl_52": 116,
            "dl_6": 44
        },
        "bibtex": "\r\n@inproceedings{Cheng:2017:TTA:3061639.3062326,\n author = {Cheng, Ming and Xia, Lixue and Zhu, Zhenhua and Cai, Yi and Xie, Yuan and Wang, Yu and Yang, Huazhong},\n title = {TIME: A Training-in-memory Architecture for Memristor-based Deep Neural Networks},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {26:1--26:6},\n articleno = {26},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062326},\n doi = {10.1145/3061639.3062326},\n acmid = {3062326},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062326",
        "pub_year": "2017",
        "text": "Ming Cheng , Lixue Xia , Zhenhua Zhu , Yi Cai , Yuan Xie , Yu Wang , Huazhong Yang, TIME: A Training-in-memory Architecture for Memristor-based Deep Neural Networks, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062329": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062329",
        "bib_stats": {
            "cites": 0,
            "dl": 45,
            "dl_52": 45,
            "dl_6": 21
        },
        "bibtex": "\r\n@inproceedings{Zhang:2017:TWL:3061639.3062329,\n author = {Zhang, Xian and Sun, Guangyu},\n title = {Toss-up Wear Leveling: Protecting Phase-Change Memories from Inconsistent Write Patterns},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {3:1--3:6},\n articleno = {3},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062329},\n doi = {10.1145/3061639.3062329},\n acmid = {3062329},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3062329",
        "pub_year": "2017",
        "text": "Xian Zhang , Guangyu Sun, Toss-up Wear Leveling: Protecting Phase-Change Memories from Inconsistent Write Patterns, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062339": {
        "abstract": "Detection of malicious software at the hardware level is emerging as an effective solution to increasing security threats. Hardware based detectors rely on Machine Learning(ML) classifiers to detect malware-like execution pattern based on Hardware Performance Counters(HPC) information at runtime. The effectiveness of these learning methods mainly relies on the information provided by expensive-to-implement limited number of HPC. This paper is the first attempt to thoroughly analyze various robust machine learning methods to classify benign and malware applications. Given the limited availability of HPC the analysis results help guiding architectural decision on what hardware performance counters are needed most to effectively improve ML classification accuracy. For software implementation we fully implemented these classifier at OS Kernel to understand various software overheads. The software implementation of these classifiers are found to be relatively slow with the execution time in the range of milliseconds, order of magnitude higher than the latency needed to capture malware at runtime. This is calling for hardware accelerated implementation of these algorithms. For hardware implementation, we have synthesized the studied classifier models on FPGA to compare various design parameters including logic area, power, and latency. The results show that while complex ML classifier such as MultiLayerPerceptron and logistics are achieving close to 90% accuracy, after taking into consideration their implementation overheads, they perform worst in terms of PDP, accuracy/area and latency compared to simpler but slightly less accurate rule based and tree based classifiers. Our results further show OneR to be the most cost-effective classifier with more than 80% accuracy and fast execution time of less than 10ns, achieving highest accuracy per logic area, while mainly relying on only a single branch-instruction HPC information.",
        "acm_key": "3062339",
        "bib_stats": {
            "cites": 0,
            "dl": 33,
            "dl_52": 33,
            "dl_6": 15
        },
        "bibtex": "\r\n@inproceedings{Chen:2017:VEE:3061639.3062339,\n author = {Chen, Tseng-Yi and Chang, Yuan-Hao and Kuan, Yuan-Hung and Chang, Yu-Ming},\n title = {VirtualGC: Enabling Erase-free Garbage Collection to Upgrade the Performance of Rewritable SLC NAND Flash Memory},\n booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},\n series = {DAC '17},\n year = {2017},\n isbn = {978-1-4503-4927-7},\n location = {Austin, TX, USA},\n pages = {25:1--25:6},\n articleno = {25},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3061639.3062339},\n doi = {10.1145/3061639.3062339},\n acmid = {3062339},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Rewritable SLC, erase-free scheme, garbage collection},\n} \r\n",
        "key": "3062339",
        "pub_year": "2017",
        "text": "Tseng-Yi Chen , Yuan-Hao Chang , Yuan-Hung Kuan , Yu-Ming Chang, VirtualGC: Enabling Erase-free Garbage Collection to Upgrade the Performance of Rewritable SLC NAND Flash Memory, Proceedings of the 54th Annual Design Automation Conference 2017, p.1-6, June 18-22, 2017, Austin, TX, USA"
    },
    "3062926": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3062926",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Ahmad:2017:OIC:3062912.3062926,\n author = {Ahmad, Imtiaz and Hamouda, Areej and Alfailakawi, Mohammad Gh.},\n title = {Odd/Even Invert Coding for Phase Change Memory with Thermal Crosstalk},\n journal = {Microprocess. Microsyst.},\n issue_date = {March 2017},\n volume = {49},\n number = {C},\n month = mar,\n year = {2017},\n issn = {0141-9331},\n pages = {150--163},\n numpages = {14},\n url = {https://doi.org/10.1016/j.micpro.2016.11.015},\n doi = {10.1016/j.micpro.2016.11.015},\n acmid = {3062926},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Coding, Lifetime, Memory write performance, Phase-change memory, Write endurance},\n} \r\n",
        "key": "3062926",
        "pub_year": "2017",
        "text": "Imtiaz Ahmad , Areej Hamouda , Mohammad Gh. Alfailakawi, Odd/Even Invert coding for phase change memory with thermal crosstalk, Microprocessors & Microsystems, v.49 n.C, p.150-163, March 2017"
    },
    "3063130": {
        "abstract": "In Network-on-Chip (NoC)-based multicore systems, task allocation and scheduling are known to be important problems, as they affect the performance of applications in terms of energy consumption and timing. Advancement of deep submicron technology has made it possible to scale the transistor feature size to the nanometer range, which has enabled multiple processing elements to be integrated onto a single chip. On the flipside, it has made the integrated entities on the chip more susceptible to different faults. Although a significant amount of work has been done in the domain of fault-tolerant mapping and scheduling, existing algorithms either precompute reconfigured mapping solutions at design time while anticipating fault(s) scenarios or adopt a hybrid approach wherein a part of the fault mitigation strategy relies on the design-time solution. The complexity of the problem rises further for real-time dynamic systems where new applications can arrive in the multicore platform at any time instant. For real-time systems, the validity of computation depends both on the correctness of results and on temporal constraint satisfaction. This article presents an improved fault-tolerant dynamic solution to the integrated problem of application mapping and scheduling for NoC-based multicore platforms. The developed algorithm provides a unified mapping and scheduling method for real-time systems focusing on meeting application deadlines and minimizing communication energy. A predictive model has been used to determine the failure-prone cores in the system for which a fault-tolerant resource allocation with task redundancy has been performed. By selectively using a task replication policy, the reliability of the application, executing on a given NoC platform, is improved. A detailed evaluation of the performance of the proposed algorithm has been conducted for both real and synthetic applications. When compared with other fault-tolerant algorithms reported in the literature, performance of the proposed algorithm shows an average reduction of 56.95% in task re-execution time overhead and an average improvement of 31% in communication energy. Further, for time-constrained tasks, deadline satisfaction has also been achieved for most of the test cases by the developed algorithm, whereas the techniques reported in the literature failed to meet deadline in about 45% test cases.",
        "acm_key": "3063130",
        "bib_stats": {
            "cites": 0,
            "dl": 46,
            "dl_52": 46,
            "dl_6": 5
        },
        "bibtex": "\r\n@article{Pan:2017:EMW:3092956.3063130,\n author = {Pan, Chen and Xie, Mimi and Yang, Chengmo and Chen, Yiran and Hu, Jingtong},\n title = {Exploiting Multiple Write Modes of Nonvolatile Main Memory in Embedded Systems},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {August 2017},\n volume = {16},\n number = {4},\n month = may,\n year = {2017},\n issn = {1539-9087},\n pages = {110:1--110:26},\n articleno = {110},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/3063130},\n doi = {10.1145/3063130},\n acmid = {3063130},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Nonvolatile memory, multilevel cell (MLC), multiwrite modes, wear leveling},\n} \r\n",
        "key": "3063130",
        "pub_year": "2017",
        "text": "Chen Pan , Mimi Xie , Chengmo Yang , Yiran Chen , Jingtong Hu, Exploiting Multiple Write Modes of Nonvolatile Main Memory in Embedded Systems, ACM Transactions on Embedded Computing Systems (TECS), v.16 n.4, May 2017"
    },
    "3063978": {
        "abstract": "Online advertisement is a significant element of the Web browsing experience. A good advertising can not only bring benefits to publisher but also improve user satisfaction and extends advertiser's product marketing. To satisfy the desire of all three parties, the click through rate (CTR) prediction of a user to a specified ad in a specific context is of great importance. This challenging problem plays a key role in online advertising system and has to deal with several hard issues. Firstly, the model must process very high dimensional features from frequently changing ad, user and context, most of which are category features having large cardinality and sparse nature extending the dimensionality by two orders of magnitude. Secondly, nonlinear features such as conjunction information must be integrated into the model for a better prediction accuracy. Finally, the model must be able to parallelized efficiently to train from very large scale data sets. To address these problems, we proposed a novel model called Coupled Logistic Regression (CLR), for accurate and efficient CTR prediction. CLR can exploit all features from ad, user, context and nonlinear features among them by seamlessly integrate the conjunction information by employing factorization machine to achieve precise prediction result. And the high-dimensional problem is avoided by decomposing the decision function into two sub ones. Scalability of CLR is ensured through a newly invited MapReduce parallelization strategy, which can reduce communication and waiting time between nodes. Experimental results on real-world data set show that our CLR model can guarantee both accuracy and efficiency on large scale CTR prediction problems.",
        "acm_key": "3063978",
        "bib_stats": {
            "cites": 0,
            "dl": 10,
            "dl_52": 10,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Wang:2017:FIF:3063955.3063978,\n author = {Wang, Huiying and Feng, Jianhua},\n title = {FlashSkipList: Indexing on Flash Devices},\n booktitle = {Proceedings of the ACM Turing 50th Celebration Conference - China},\n series = {ACM TUR-C '17},\n year = {2017},\n isbn = {978-1-4503-4873-7},\n location = {Shanghai, China},\n pages = {23:1--23:10},\n articleno = {23},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/3063955.3063978},\n doi = {10.1145/3063955.3063978},\n acmid = {3063978},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3063978",
        "pub_year": "2017",
        "text": "Huiying Wang , Jianhua Feng, FlashSkipList: indexing on flash devices, Proceedings of the ACM Turing 50th Celebration Conference - China, p.1-10, May 12-14, 2017, Shanghai, China"
    },
    "3064187": {
        "abstract": "The combination of the explosive growth in digital data and the need to preserve much of this data in the long term has made it an imperative to find a more cost-effective way than HDD arrays and more easily accessible way than tape libraries to store massive amounts of data. While modern optical discs are capable of guaranteeing more than 50-year data preservation without migration, individual optical disks' lack of the performance and capacity relative to HDDs or tapes has significantly limited their use in datacenters. This paper presents a Rack-scale Optical disc library System, or ROS in short, that provides a PB-level total capacity and inline accessibility on thousands of optical discs built within a 42U Rack. A rotatable roller and robotic arm separating and fetching the discs are designed to improve disc placement density and simplify the mechanical structure. A hierarchical storage system based on SSD, hard disks and optical discs are presented to hide the delay of mechanical operation. On the other hand, an optical library file system is proposed to schedule mechanical operation and organize data on the tiered storage with a POSIX user interface to provide an illusion of inline data accessibility. We evaluate ROS on a few key performance metrics including operation delays of the mechanical structure and software overhead in a prototype PB-level ROS system. The results show that ROS stacked on Samba and FUSE can provide almost 323MB/s read and 236MB/s write throughput, about 53ms file write and 15ms read latency via 10GbE network for external users, exhibiting its inline accessibility. Besides, ROS is able to effectively hide and virtualize internal complex operational behaviors and be easily deployable in datacenters.",
        "acm_key": "3064187",
        "bib_stats": {
            "cites": 0,
            "dl": 264,
            "dl_52": 264,
            "dl_6": 54
        },
        "bibtex": "\r\n@inproceedings{He:2017:UCS:3064176.3064187,\n author = {He, Jun and Kannan, Sudarsun and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},\n title = {The Unwritten Contract of Solid State Drives},\n booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},\n series = {EuroSys '17},\n year = {2017},\n isbn = {978-1-4503-4938-3},\n location = {Belgrade, Serbia},\n pages = {127--144},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/3064176.3064187},\n doi = {10.1145/3064176.3064187},\n acmid = {3064187},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3064187",
        "pub_year": "2017",
        "text": "Jun He , Sudarsun Kannan , Andrea C. Arpaci-Dusseau , Remzi H. Arpaci-Dusseau, The Unwritten Contract of Solid State Drives, Proceedings of the Twelfth European Conference on Computer Systems, April 23-26, 2017, Belgrade, Serbia"
    },
    "3064215": {
        "abstract": "The combination of the explosive growth in digital data and the need to preserve much of this data in the long term has made it an imperative to find a more cost-effective way than HDD arrays and more easily accessible way than tape libraries to store massive amounts of data. While modern optical discs are capable of guaranteeing more than 50-year data preservation without migration, individual optical disks' lack of the performance and capacity relative to HDDs or tapes has significantly limited their use in datacenters. This paper presents a Rack-scale Optical disc library System, or ROS in short, that provides a PB-level total capacity and inline accessibility on thousands of optical discs built within a 42U Rack. A rotatable roller and robotic arm separating and fetching the discs are designed to improve disc placement density and simplify the mechanical structure. A hierarchical storage system based on SSD, hard disks and optical discs are presented to hide the delay of mechanical operation. On the other hand, an optical library file system is proposed to schedule mechanical operation and organize data on the tiered storage with a POSIX user interface to provide an illusion of inline data accessibility. We evaluate ROS on a few key performance metrics including operation delays of the mechanical structure and software overhead in a prototype PB-level ROS system. The results show that ROS stacked on Samba and FUSE can provide almost 323MB/s read and 236MB/s write throughput, about 53ms file write and 15ms read latency via 10GbE network for external users, exhibiting its inline accessibility. Besides, ROS is able to effectively hide and virtualize internal complex operational behaviors and be easily deployable in datacenters.",
        "acm_key": "3064215",
        "bib_stats": {
            "cites": 0,
            "dl": 255,
            "dl_52": 255,
            "dl_6": 12
        },
        "bibtex": "\r\n@inproceedings{Memaripour:2017:AIU:3064176.3064215,\n author = {Memaripour, Amirsaman and Badam, Anirudh and Phanishayee, Amar and Zhou, Yanqi and Alagappan, Ramnatthan and Strauss, Karin and Swanson, Steven},\n title = {Atomic In-place Updates for Non-volatile Main Memories with Kamino-Tx},\n booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},\n series = {EuroSys '17},\n year = {2017},\n isbn = {978-1-4503-4938-3},\n location = {Belgrade, Serbia},\n pages = {499--512},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3064176.3064215},\n doi = {10.1145/3064176.3064215},\n acmid = {3064215},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3064215",
        "pub_year": "2017",
        "text": "Amirsaman Memaripour , Anirudh Badam , Amar Phanishayee , Yanqi Zhou , Ramnatthan Alagappan , Karin Strauss , Steven Swanson, Atomic In-place Updates for Non-volatile Main Memories with Kamino-Tx, Proceedings of the Twelfth European Conference on Computer Systems, April 23-26, 2017, Belgrade, Serbia"
    },
    "3066872": {
        "abstract": "Abstract-Efficiently and reliably managing high quality power is a primary challenge in Internet of Things (IoT) systems. Based on current projections, future IoT will provide vast interconnectedness of embedded devices and sensors, many of which will be powered up wirelessly from spatially distributed power supplies or locally from energy harvesting sources. The energy budget, constrained by inherently lower quality of power of these non-traditional power sources, will become a critical system resource and a primary limiting factor for scalability of future IoT systems. Distributed on-chip power regulation is necessary for efficiently delivering high quality power to high performance heterogeneous integrated circuits (ICs). A multi- feedback system with distributed on-chip power supplies deliver- ing current to billions of non-linear circuits is characterized by complex interactions among the heterogeneous power supplies and loads. These modern multi-feedback systems exhibit high design complexity and degraded stability. No straightforward method exists to efficiently design a stable multi-feedback power delivery system. An automated design and analysis flow for stable, high quality power delivery is proposed in this work based on the passivity of heterogeneous integrated systems. The algorithm is evaluated based on ISPD benchmark circuits and shows that the generated power delivery system addresses both the quality of power (QoP) and stability requirements. A distributed power delivery system is designed based on the passivity criterion and fabricated in 28 nm CMOS technology. The system is tested under a wide range of load, voltage, and temperature variations that are typical for modern heterogeneous ICs. The system exhibits high performance and stable response.",
        "acm_key": "3066872",
        "bib_stats": {
            "cites": 0,
            "dl": 20,
            "dl_52": 20,
            "dl_6": 7
        },
        "bibtex": "\r\n@inproceedings{Perricone:2017:ENI:3060403.3066872,\n author = {Perricone, Robert and Tang, Li and Niemier, Michael and Hu, X. Sharon},\n title = {Exploiting Non-Volatility for Information Processing},\n booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},\n series = {GLSVLSI '17},\n year = {2017},\n isbn = {978-1-4503-4972-7},\n location = {Banff, Alberta, Canada},\n pages = {305--310},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3060403.3066872},\n doi = {10.1145/3060403.3066872},\n acmid = {3066872},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {c-states, emerging technologies, energy harvesting, non-volatility, spintronics},\n} \r\n",
        "key": "3066872",
        "pub_year": "2017",
        "text": "Robert Perricone , Li Tang , Michael Niemier , X. Sharon Hu, Exploiting Non-Volatility for Information Processing, Proceedings of the on Great Lakes Symposium on VLSI 2017, May 10-12, 2017, Banff, Alberta, Canada"
    },
    "3069303": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3069303",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Roh:2017:ABN:3069278.3069303,\n author = {Roh, Hongchan and Shin, Mincheol and Jung, Wonmook and Park, Sanghyun},\n title = {Advanced Block Nested Loop Join for Extending SSD Lifetime},\n journal = {IEEE Trans. on Knowl. and Data Eng.},\n issue_date = {April 2017},\n volume = {29},\n number = {4},\n month = apr,\n year = {2017},\n issn = {1041-4347},\n pages = {743--756},\n numpages = {14},\n url = {https://doi.org/10.1109/TKDE.2017.2651803},\n doi = {10.1109/TKDE.2017.2651803},\n acmid = {3069303},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3069303",
        "pub_year": "2017",
        "text": "Hongchan Roh , Mincheol Shin , Wonmook Jung , Sanghyun Park, Advanced Block Nested Loop Join for Extending SSD Lifetime, IEEE Transactions on Knowledge and Data Engineering, v.29 n.4, p.743-756, April 2017"
    },
    "3070776": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3070776",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Jeong:2017:DEV:3070724.3070776,\n author = {Jeong, Jaeyong and Song, Youngsun and Hahn, Sangwook Shane and Lee, Sungjin and Kim, Jihong},\n title = {Dynamic Erase Voltage and Time Scaling for Extending Lifetime of NAND Flash-Based SSDs},\n journal = {IEEE Trans. Comput.},\n issue_date = {April 2017},\n volume = {66},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0018-9340},\n pages = {616--630},\n numpages = {15},\n url = {https://doi.org/10.1109/TC.2016.2615038},\n doi = {10.1109/TC.2016.2615038},\n acmid = {3070776},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3070776",
        "pub_year": "2017",
        "text": "Jaeyong Jeong , Youngsun Song , Sangwook Shane Hahn , Sungjin Lee , Jihong Kim, Dynamic Erase Voltage and Time Scaling for Extending Lifetime of NAND Flash-Based SSDs, IEEE Transactions on Computers, v.66 n.4, p.616-630, April 2017"
    },
    "3071373": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3071373",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Paik:2017:DAM:3071349.3071373,\n author = {Paik, Joon-Young and Chung, Tae-Sun and Cho, Eun-Sun},\n title = {Dynamic Allocation Mechanism to Reduce Read Latency in Collaboration With a Device Queue in Multichannel Solid-State Devices},\n journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},\n issue_date = {April 2017},\n volume = {36},\n number = {4},\n month = apr,\n year = {2017},\n issn = {0278-0070},\n pages = {600--613},\n numpages = {14},\n url = {https://doi.org/10.1109/TCAD.2016.2589901},\n doi = {10.1109/TCAD.2016.2589901},\n acmid = {3071373},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3071373",
        "pub_year": "2017",
        "text": "Joon-Young Paik , Tae-Sun Chung , Eun-Sun Cho, Dynamic Allocation Mechanism to Reduce Read Latency in Collaboration With a Device Queue in Multichannel Solid-State Devices, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, v.36 n.4, p.600-613, April 2017"
    },
    "3073136": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3073136",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Liu:2017:DAT:3046068.3073136,\n author = {Liu, Duo and Zhong, Kan and Wang, Tianzheng and Wang, Yi and Shao, Zili and Sha, Edwin Hsing-Mean and Xue, Jingling},\n title = {Durable Address Translation in PCM-Based Flash Storage Systems},\n journal = {IEEE Trans. Parallel Distrib. Syst.},\n issue_date = {February 2017},\n volume = {28},\n number = {2},\n month = feb,\n year = {2017},\n issn = {1045-9219},\n pages = {475--490},\n numpages = {16},\n url = {https://doi.org/10.1109/TPDS.2016.2586059},\n doi = {10.1109/TPDS.2016.2586059},\n acmid = {3073136},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3073136",
        "pub_year": "2017",
        "text": "Duo Liu , Kan Zhong , Tianzheng Wang , Yi Wang , Zili Shao , Edwin Hsing-Mean Sha , Jingling Xue, Durable Address Translation in PCM-Based Flash Storage Systems, IEEE Transactions on Parallel and Distributed Systems, v.28 n.2, p.475-490, February 2017"
    },
    "3073143": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3073143",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Zand:2017:ENR:3073109.3073143,\n author = {Zand, Ramtin and Roohi, Arman and Fan, Deliang and DeMara, Ronald F.},\n title = {Energy-Efficient Nonvolatile Reconfigurable Logic Using Spin Hall Effect-Based Lookup Tables},\n journal = {IEEE Trans. Nanotechnol.},\n issue_date = {January 2017},\n volume = {16},\n number = {1},\n month = jan,\n year = {2017},\n issn = {1536-125X},\n pages = {32--43},\n numpages = {12},\n url = {https://doi.org/10.1109/TNANO.2016.2625749},\n doi = {10.1109/TNANO.2016.2625749},\n acmid = {3073143},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3073143",
        "pub_year": "2017",
        "text": "Ramtin Zand , Arman Roohi , Deliang Fan , Ronald F. DeMara, Energy-Efficient Nonvolatile Reconfigurable Logic Using Spin Hall Effect-Based Lookup Tables, IEEE Transactions on Nanotechnology, v.16 n.1, p.32-43, January 2017"
    },
    "3073159": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3073159",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Kang:2017:LSP:3073109.3073159,\n author = {Kang, Wang and Lv, Weifeng and Zhang, Youguang and Zhao, Weisheng},\n title = {Low Store Power High-Speed High-Density Nonvolatile SRAM Design With Spin Hall Effect-Driven Magnetic Tunnel Junctions},\n journal = {IEEE Trans. Nanotechnol.},\n issue_date = {January 2017},\n volume = {16},\n number = {1},\n month = jan,\n year = {2017},\n issn = {1536-125X},\n pages = {148--154},\n numpages = {7},\n url = {https://doi.org/10.1109/TNANO.2016.2640338},\n doi = {10.1109/TNANO.2016.2640338},\n acmid = {3073159},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3073159",
        "pub_year": "2017",
        "text": "Wang Kang , Weifeng Lv , Youguang Zhang , Weisheng Zhao, Low Store Power High-Speed High-Density Nonvolatile SRAM Design With Spin Hall Effect-Driven Magnetic Tunnel Junctions, IEEE Transactions on Nanotechnology, v.16 n.1, p.148-154, January 2017  \u00a0[doi>"
    },
    "3073200": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3073200",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Chen:2017:HDS:3073112.3073200,\n author = {Chen, Renhai and Wang, Yi and Liu, Duo and Shao, Zili and Jiang, Song},\n title = {Heating Dispersal for Self-Healing NAND Flash Memory},\n journal = {IEEE Trans. Comput.},\n issue_date = {February 2017},\n volume = {66},\n number = {2},\n month = feb,\n year = {2017},\n issn = {0018-9340},\n pages = {361--367},\n numpages = {7},\n url = {https://doi.org/10.1109/TC.2016.2595572},\n doi = {10.1109/TC.2016.2595572},\n acmid = {3073200},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3073200",
        "pub_year": "2017",
        "text": "Renhai Chen , Yi Wang , Duo Liu , Zili Shao , Song Jiang, Heating Dispersal for Self-Healing NAND Flash Memory, IEEE Transactions on Computers, v.66 n.2, p.361-367, February 2017"
    },
    "3075170": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3075170",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Kim:2017:WMP:3075129.3075170,\n author = {Kim, Hyeonggyu and Kim, Soontae and Lee, Jooheung},\n title = {Write-Amount-Aware Management Policies for STT-RAM Caches},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {April 2017},\n volume = {25},\n number = {4},\n month = apr,\n year = {2017},\n issn = {1063-8210},\n pages = {1588--1592},\n numpages = {5},\n url = {https://doi.org/10.1109/TVLSI.2016.2620168},\n doi = {10.1109/TVLSI.2016.2620168},\n acmid = {3075170},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3075170",
        "pub_year": "2017",
        "text": "Hyeonggyu Kim , Soontae Kim , Jooheung Lee, Write-Amount-Aware Management Policies for STT-RAM Caches, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.25 n.4, p.1588-1592, April 2017"
    },
    "3075191": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3075191",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Choi:2017:FWB:3075129.3075191,\n author = {Choi, Ju Hee and Kwak, Jong Wook},\n title = {Fast Writeable Block-Aware Cache Update Policy for Spin-Transfer-Torque RAM},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {April 2017},\n volume = {25},\n number = {4},\n month = apr,\n year = {2017},\n issn = {1063-8210},\n pages = {1236--1249},\n numpages = {14},\n url = {https://doi.org/10.1109/TVLSI.2016.2637897},\n doi = {10.1109/TVLSI.2016.2637897},\n acmid = {3075191},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3075191",
        "pub_year": "2017",
        "text": "Ju Hee Choi , Jong Wook Kwak, Fast Writeable Block-Aware Cache Update Policy for Spin-Transfer-Torque RAM, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.25 n.4, p.1236-1249, April 2017"
    },
    "3075208": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3075208",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Song:2017:SBD:3075129.3075208,\n author = {Song, Lili and Wang, Ying and Han, Yinhe and Li, Huawei and Cheng, Yuanqing and Li, Xiaowei},\n title = {STT-RAM Buffer Design for Precision-Tunable General-Purpose Neural Network Accelerator},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {April 2017},\n volume = {25},\n number = {4},\n month = apr,\n year = {2017},\n issn = {1063-8210},\n pages = {1285--1296},\n numpages = {12},\n url = {https://doi.org/10.1109/TVLSI.2016.2644279},\n doi = {10.1109/TVLSI.2016.2644279},\n acmid = {3075208},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3075208",
        "pub_year": "2017",
        "text": "Lili Song , Ying Wang , Yinhe Han , Huawei Li , Yuanqing Cheng , Xiaowei Li, STT-RAM Buffer Design for Precision-Tunable General-Purpose Neural Network Accelerator, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.25 n.4, p.1285-1296, April 2017"
    },
    "3076443": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3076443",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{El-Hassan:2017:PCM:3076272.3076443,\n author = {El-Hassan, Nemat H. and Kumar, T. Nandha and Almurib, Haider Abbas F.},\n title = {Phase Change Memory Cell Emulator Circuit Design},\n journal = {Microelectron. J.},\n issue_date = {April 2017},\n volume = {62},\n number = {C},\n month = apr,\n year = {2017},\n issn = {0026-2692},\n pages = {65--71},\n numpages = {7},\n url = {https://doi.org/10.1016/j.mejo.2017.02.006},\n doi = {10.1016/j.mejo.2017.02.006},\n acmid = {3076443},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Chalcogenide, Discrete component, Emulator, Non-volatile memory, Ovonic memory, Phase Change Memory, Threshold switching},\n} \r\n",
        "key": "3076443",
        "pub_year": "2017",
        "text": "Nemat H. El-Hassan , T. Nandha Kumar , Haider Abbas F. Almurib, Phase change memory cell emulator circuit design, Microelectronics Journal, v.62 n.C, p.65-71, April 2017"
    },
    "3077575": {
        "abstract": "In Network-on-Chip (NoC)-based multicore systems, task allocation and scheduling are known to be important problems, as they affect the performance of applications in terms of energy consumption and timing. Advancement of deep submicron technology has made it possible to scale the transistor feature size to the nanometer range, which has enabled multiple processing elements to be integrated onto a single chip. On the flipside, it has made the integrated entities on the chip more susceptible to different faults. Although a significant amount of work has been done in the domain of fault-tolerant mapping and scheduling, existing algorithms either precompute reconfigured mapping solutions at design time while anticipating fault(s) scenarios or adopt a hybrid approach wherein a part of the fault mitigation strategy relies on the design-time solution. The complexity of the problem rises further for real-time dynamic systems where new applications can arrive in the multicore platform at any time instant. For real-time systems, the validity of computation depends both on the correctness of results and on temporal constraint satisfaction. This article presents an improved fault-tolerant dynamic solution to the integrated problem of application mapping and scheduling for NoC-based multicore platforms. The developed algorithm provides a unified mapping and scheduling method for real-time systems focusing on meeting application deadlines and minimizing communication energy. A predictive model has been used to determine the failure-prone cores in the system for which a fault-tolerant resource allocation with task redundancy has been performed. By selectively using a task replication policy, the reliability of the application, executing on a given NoC platform, is improved. A detailed evaluation of the performance of the proposed algorithm has been conducted for both real and synthetic applications. When compared with other fault-tolerant algorithms reported in the literature, performance of the proposed algorithm shows an average reduction of 56.95% in task re-execution time overhead and an average improvement of 31% in communication energy. Further, for time-constrained tasks, deadline satisfaction has also been achieved for most of the test cases by the developed algorithm, whereas the techniques reported in the literature failed to meet deadline in about 45% test cases.",
        "acm_key": "3077575",
        "bib_stats": {
            "cites": 0,
            "dl": 66,
            "dl_52": 66,
            "dl_6": 13
        },
        "bibtex": "\r\n@article{Ma:2017:DPE:3092956.3077575,\n author = {Ma, Kaisheng and Li, Xueqing and Liu, Huichu and Sheng, Xiao and Wang, Yiqun and Swaminathan, Karthik and Liu, Yongpan and Xie, Yuan and Sampson, John and Narayanan, Vijaykrishnan},\n title = {Dynamic Power and Energy Management for Energy Harvesting Nonvolatile Processor Systems},\n journal = {ACM Trans. Embed. Comput. Syst.},\n issue_date = {August 2017},\n volume = {16},\n number = {4},\n month = may,\n year = {2017},\n issn = {1539-9087},\n pages = {107:1--107:23},\n articleno = {107},\n numpages = {23},\n url = {http://doi.acm.org/10.1145/3077575},\n doi = {10.1145/3077575},\n acmid = {3077575},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Nonvolatile processor, dynamic power and energy management, energy harvesting, intermittent power supply},\n} \r\n",
        "key": "3077575",
        "pub_year": "2017",
        "text": "Kaisheng Ma , Xueqing Li , Huichu Liu , Xiao Sheng , Yiqun Wang , Karthik Swaminathan , Yongpan Liu , Yuan Xie , John Sampson , Vijaykrishnan Narayanan, Dynamic Power and Energy Management for Energy Harvesting Nonvolatile Processor Systems, ACM Transactions on Embedded Computing Systems (TECS), v.16 n.4, May 2017"
    },
    "3078469": {
        "abstract": "Despite the growing popularity of enterprise virtual desktop infrastructure (VDI), little is known about its storage traffic characteristics. In addition, no prior work has considered the detailed characteristics of virtual machine (VM) behavior on VDI. In this paper, we analyze the enterprise storage traffic on commercial office VDI using designated VMs. For 28 consecutive days, we gathered various types of traces, including a usage questionnaire and active and passive measurements. To characterize the storage traffic, we focused on two perspectives: fibre channel (FC) traffic and VM behavior. From the FC traffic perspective, we found that read traffic is dominant, although the applications are similar to those in a previous small-scale VDI. In particular, the write response time of large transactions, e.g.,128 KiB, is strongly affected by a slight decrease in cache hits during an update storm. From the VM behavior, we found that all active user VMs generate only 25% of traffic. Although a few VMs generate massive traffic, their impact is small. These characteristics are unique in comparison with the small-scale VDI. Our results have significant implications for designing the next generation of VDI and improving its performance.",
        "acm_key": "3078469",
        "bib_stats": {
            "cites": 0,
            "dl": 134,
            "dl_52": 134,
            "dl_6": 23
        },
        "bibtex": "\r\n@inproceedings{Yang:2017:AAS:3078468.3078469,\n author = {Yang, Jingpei and Pandurangan, Rajinikanth and Choi, Changho and Balakrishnan, Vijay},\n title = {AutoStream: Automatic Stream Management for Multi-streamed SSDs},\n booktitle = {Proceedings of the 10th ACM International Systems and Storage Conference},\n series = {SYSTOR '17},\n year = {2017},\n isbn = {978-1-4503-5035-8},\n location = {Haifa, Israel},\n pages = {3:1--3:11},\n articleno = {3},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/3078468.3078469},\n doi = {10.1145/3078468.3078469},\n acmid = {3078469},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3078469",
        "pub_year": "2017",
        "text": "Jingpei Yang , Rajinikanth Pandurangan , Changho Choi , Vijay Balakrishnan, AutoStream: automatic stream management for multi-streamed SSDs, Proceedings of the 10th ACM International Systems and Storage Conference, May 22-24, 2017, Haifa, Israel"
    },
    "3078471": {
        "abstract": "Despite the growing popularity of enterprise virtual desktop infrastructure (VDI), little is known about its storage traffic characteristics. In addition, no prior work has considered the detailed characteristics of virtual machine (VM) behavior on VDI. In this paper, we analyze the enterprise storage traffic on commercial office VDI using designated VMs. For 28 consecutive days, we gathered various types of traces, including a usage questionnaire and active and passive measurements. To characterize the storage traffic, we focused on two perspectives: fibre channel (FC) traffic and VM behavior. From the FC traffic perspective, we found that read traffic is dominant, although the applications are similar to those in a previous small-scale VDI. In particular, the write response time of large transactions, e.g.,128 KiB, is strongly affected by a slight decrease in cache hits during an update storm. From the VM behavior, we found that all active user VMs generate only 25% of traffic. Although a few VMs generate massive traffic, their impact is small. These characteristics are unique in comparison with the small-scale VDI. Our results have significant implications for designing the next generation of VDI and improving its performance.",
        "acm_key": "3078471",
        "bib_stats": {
            "cites": 0,
            "dl": 113,
            "dl_52": 113,
            "dl_6": 20
        },
        "bibtex": "\r\n@inproceedings{Liu:2017:FCZ:3078468.3078471,\n author = {Liu, Chunyi and Ni, Fan and Wu, Xingbo and Zhang, Xiao and Jiang, Song},\n title = {Freewrite: Creating (Almost) Zero-cost Writes to SSD in Applications},\n booktitle = {Proceedings of the 10th ACM International Systems and Storage Conference},\n series = {SYSTOR '17},\n year = {2017},\n isbn = {978-1-4503-5035-8},\n location = {Haifa, Israel},\n pages = {4:1--4:6},\n articleno = {4},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/3078468.3078471},\n doi = {10.1145/3078468.3078471},\n acmid = {3078471},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3078471",
        "pub_year": "2017",
        "text": "Chunyi Liu , Fan Ni , Xingbo Wu , Xiao Zhang , Song Jiang, Freewrite: creating (almost) zero-cost writes to SSD in applications, Proceedings of the 10th ACM International Systems and Storage Conference, May 22-24, 2017, Haifa, Israel"
    },
    "3078476": {
        "abstract": "Despite the growing popularity of enterprise virtual desktop infrastructure (VDI), little is known about its storage traffic characteristics. In addition, no prior work has considered the detailed characteristics of virtual machine (VM) behavior on VDI. In this paper, we analyze the enterprise storage traffic on commercial office VDI using designated VMs. For 28 consecutive days, we gathered various types of traces, including a usage questionnaire and active and passive measurements. To characterize the storage traffic, we focused on two perspectives: fibre channel (FC) traffic and VM behavior. From the FC traffic perspective, we found that read traffic is dominant, although the applications are similar to those in a previous small-scale VDI. In particular, the write response time of large transactions, e.g.,128 KiB, is strongly affected by a slight decrease in cache hits during an update storm. From the VM behavior, we found that all active user VMs generate only 25% of traffic. Although a few VMs generate massive traffic, their impact is small. These characteristics are unique in comparison with the small-scale VDI. Our results have significant implications for designing the next generation of VDI and improving its performance.",
        "acm_key": "3078476",
        "bib_stats": {
            "cites": 0,
            "dl": 56,
            "dl_52": 56,
            "dl_6": 6
        },
        "bibtex": "\r\n@inproceedings{Chang:2017:RSS:3078468.3078476,\n author = {Chang, Li-Pin and Huang, Sheng-Min and Chou, Kun-Lin},\n title = {Relieving Self-healing SSDs of Heal Storms},\n booktitle = {Proceedings of the 10th ACM International Systems and Storage Conference},\n series = {SYSTOR '17},\n year = {2017},\n isbn = {978-1-4503-5035-8},\n location = {Haifa, Israel},\n pages = {5:1--5:7},\n articleno = {5},\n numpages = {7},\n url = {http://doi.acm.org/10.1145/3078468.3078476},\n doi = {10.1145/3078468.3078476},\n acmid = {3078476},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3078476",
        "pub_year": "2017",
        "text": "Li-Pin Chang , Sheng-Min Huang , Kun-Lin Chou, Relieving self-healing SSDs of heal storms, Proceedings of the 10th ACM International Systems and Storage Conference, May 22-24, 2017, Haifa, Israel"
    },
    "3078477": {
        "abstract": "Despite the growing popularity of enterprise virtual desktop infrastructure (VDI), little is known about its storage traffic characteristics. In addition, no prior work has considered the detailed characteristics of virtual machine (VM) behavior on VDI. In this paper, we analyze the enterprise storage traffic on commercial office VDI using designated VMs. For 28 consecutive days, we gathered various types of traces, including a usage questionnaire and active and passive measurements. To characterize the storage traffic, we focused on two perspectives: fibre channel (FC) traffic and VM behavior. From the FC traffic perspective, we found that read traffic is dominant, although the applications are similar to those in a previous small-scale VDI. In particular, the write response time of large transactions, e.g.,128 KiB, is strongly affected by a slight decrease in cache hits during an update storm. From the VM behavior, we found that all active user VMs generate only 25% of traffic. Although a few VMs generate massive traffic, their impact is small. These characteristics are unique in comparison with the small-scale VDI. Our results have significant implications for designing the next generation of VDI and improving its performance.",
        "acm_key": "3078477",
        "bib_stats": {
            "cites": 0,
            "dl": 200,
            "dl_52": 200,
            "dl_6": 23
        },
        "bibtex": "\r\n@inproceedings{Trivedi:2017:FFS:3078468.3078477,\n author = {Trivedi, Animesh and Ioannou, Nikolas and Metzler, Bernard and Stuedi, Patrick and Pfefferle, Jonas and Koltsidas, Ioannis and Kourtis, Kornilios and Gross, Thomas R.},\n title = {FlashNet: Flash/Network Stack Co-design},\n booktitle = {Proceedings of the 10th ACM International Systems and Storage Conference},\n series = {SYSTOR '17},\n year = {2017},\n isbn = {978-1-4503-5035-8},\n location = {Haifa, Israel},\n pages = {15:1--15:14},\n articleno = {15},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3078468.3078477},\n doi = {10.1145/3078468.3078477},\n acmid = {3078477},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {RDMA, netwoked flash, operating systems, performance},\n} \r\n",
        "key": "3078477",
        "pub_year": "2017",
        "text": "Animesh Trivedi , Nikolas loannou , Bernard Metzler , Patrick Stuedi , Jonas Pfefferle , Ioannis Koltsidas , Kornilios Kourtis , Thomas R. Gross, FlashNet: flash/network stack co-design, Proceedings of the 10th ACM International Systems and Storage Conference, May 22-24, 2017, Haifa, Israel"
    },
    "3079092": {
        "abstract": "The rising popularity of the graphics processing unit (GPU) across various numerical computing applications triggered a breakneck race to optimize key numerical kernels and in particular, the sparse matrix-vector product (SpMV). Despite great strides, most existing GPU-SpMV approaches trade off one aspect of performance against another. They either require preprocessing, exhibit inconsistent behavior, lead to execution divergence, suffer load imbalance or induce detrimental memory access patterns. In this paper, we present an uncompromising approach for SpMV on the GPU. Our approach requires no separate preprocessing or knowledge of the matrix structure and works directly on the standard compressed sparse rows (CSR) data format. From a global perspective, it exhibits a homogeneous behavior reflected in efficient memory access patterns and steady per-thread workload. From a local perspective, it avoids heterogeneous execution paths by adapting its behavior to the work load at hand, it uses an efficient encoding to keep temporary data requirements for on-chip memory low, and leads to divergence-free execution. We evaluate our approach on more than 2500 matrices comparing to vendor provided, and state-of-the-art SpMV implementations. Our approach not only significantly outperforms approaches directly operating on the CSR format ( 20% average performance increase), but also outperforms approaches that preprocess the matrix even when preprocessing time is discarded. Additionally, the same strategies lead to significant performance increase when adapted for transpose SpMV.",
        "acm_key": "3079092",
        "bib_stats": {
            "cites": 0,
            "dl": 109,
            "dl_52": 109,
            "dl_6": 43
        },
        "bibtex": "\r\n@inproceedings{Yu:2017:DIB:3079079.3079092,\n author = {Yu, Seongdae and Park, Seongbeom and Baek, Woongki},\n title = {Design and Implementation of Bandwidth-aware Memory Placement and Migration Policies for Heterogeneous Memory Systems},\n booktitle = {Proceedings of the International Conference on Supercomputing},\n series = {ICS '17},\n year = {2017},\n isbn = {978-1-4503-5020-4},\n location = {Chicago, Illinois},\n pages = {18:1--18:10},\n articleno = {18},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/3079079.3079092},\n doi = {10.1145/3079079.3079092},\n acmid = {3079092},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {bandwidth-aware memory placement and migration policies, heterogeneous memory systems},\n} \r\n",
        "key": "3079092",
        "pub_year": "2017",
        "text": "Seongdae Yu , Seongbeom Park , Woongki Baek, Design and implementation of bandwidth-aware memory placement and migration policies for heterogeneous memory systems, Proceedings of the International Conference on Supercomputing, June 14-16, 2017, Chicago, Illinois"
    },
    "3080226": {
        "abstract": "Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose ScaleDeep, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that ScaleDeep primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which ScaleDeep derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto ScaleDeep, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of ScaleDeep's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of ScaleDeep with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, ScaleDeep demonstrates 6x-28x speedup at iso-power over the state-of-the-art performance on GPUs.",
        "acm_key": "3080226",
        "bib_stats": {
            "cites": 0,
            "dl": 78,
            "dl_52": 78,
            "dl_6": 21
        },
        "bibtex": "\r\n@inproceedings{Deng:2017:LLH:3079856.3080226,\n author = {Deng, Zhaoxia and Feldman, Ariel and Kurtz, Stuart A. and Chong, Frederic T.},\n title = {Lemonade from Lemons: Harnessing Device Wearout to Create Limited-Use Security Architectures},\n booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},\n series = {ISCA '17},\n year = {2017},\n isbn = {978-1-4503-4892-8},\n location = {Toronto, ON, Canada},\n pages = {361--374},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3079856.3080226},\n doi = {10.1145/3079856.3080226},\n acmid = {3080226},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Degradation-based security measures, NEMS, hardware security architectures},\n} \r\n",
        "key": "3080226",
        "pub_year": "2017",
        "text": "Zhaoxia Deng , Ariel Feldman , Stuart A. Kurtz , Frederic T. Chong, Lemonade from Lemons: Harnessing Device Wearout to Create Limited-Use Security Architectures, Proceedings of the 44th Annual International Symposium on Computer Architecture, June 24-28, 2017, Toronto, ON, Canada"
    },
    "3080229": {
        "abstract": "Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose ScaleDeep, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that ScaleDeep primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which ScaleDeep derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto ScaleDeep, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of ScaleDeep's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of ScaleDeep with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, ScaleDeep demonstrates 6x-28x speedup at iso-power over the state-of-the-art performance on GPUs.",
        "acm_key": "3080229",
        "bib_stats": {
            "cites": 0,
            "dl": 196,
            "dl_52": 196,
            "dl_6": 63
        },
        "bibtex": "\r\n@inproceedings{Kolli:2017:LP:3079856.3080229,\n author = {Kolli, Aasheesh and Gogte, Vaibhav and Saidi, Ali and Diestelhorst, Stephan and Chen, Peter M. and Narayanasamy, Satish and Wenisch, Thomas F.},\n title = {Language-level Persistency},\n booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},\n series = {ISCA '17},\n year = {2017},\n isbn = {978-1-4503-4892-8},\n location = {Toronto, ON, Canada},\n pages = {481--493},\n numpages = {13},\n url = {http://doi.acm.org/10.1145/3079856.3080229},\n doi = {10.1145/3079856.3080229},\n acmid = {3080229},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Persistent memories, language-level models, memory persistency},\n} \r\n",
        "key": "3080229",
        "pub_year": "2017",
        "text": "Aasheesh Kolli , Vaibhav Gogte , Ali Saidi , Stephan Diestelhorst , Peter M. Chen , Satish Narayanasamy , Thomas F. Wenisch, Language-level persistency, Proceedings of the 44th Annual International Symposium on Computer Architecture, June 24-28, 2017, Toronto, ON, Canada"
    },
    "3080236": {
        "abstract": "Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose ScaleDeep, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that ScaleDeep primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which ScaleDeep derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto ScaleDeep, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of ScaleDeep's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of ScaleDeep with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, ScaleDeep demonstrates 6x-28x speedup at iso-power over the state-of-the-art performance on GPUs.",
        "acm_key": "3080236",
        "bib_stats": {
            "cites": 0,
            "dl": 74,
            "dl_52": 74,
            "dl_6": 20
        },
        "bibtex": "\r\n@inproceedings{Kateja:2017:VDB:3079856.3080236,\n author = {Kateja, Rajat and Badam, Anirudh and Govindan, Sriram and Sharma, Bikash and Ganger, Greg},\n title = {Viyojit: Decoupling Battery and DRAM Capacities for Battery-Backed DRAM},\n booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},\n series = {ISCA '17},\n year = {2017},\n isbn = {978-1-4503-4892-8},\n location = {Toronto, ON, Canada},\n pages = {613--626},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3079856.3080236},\n doi = {10.1145/3079856.3080236},\n acmid = {3080236},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Battery-backed DRAM, NVM},\n} \r\n",
        "key": "3080236",
        "pub_year": "2017",
        "text": "Rajat Kateja , Anirudh Badam , Sriram Govindan , Bikash Sharma , Greg Ganger, Viyojit: Decoupling Battery and DRAM Capacities for Battery-Backed DRAM, Proceedings of the 44th Annual International Symposium on Computer Architecture, June 24-28, 2017, Toronto, ON, Canada"
    },
    "3080240": {
        "abstract": "Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose ScaleDeep, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that ScaleDeep primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which ScaleDeep derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto ScaleDeep, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of ScaleDeep's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of ScaleDeep with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, ScaleDeep demonstrates 6x-28x speedup at iso-power over the state-of-the-art performance on GPUs.",
        "acm_key": "3080240",
        "bib_stats": {
            "cites": 0,
            "dl": 183,
            "dl_52": 183,
            "dl_6": 51
        },
        "bibtex": "\r\n@inproceedings{Shin:2017:HLL:3079856.3080240,\n author = {Shin, Seunghee and Tuck, James and Solihin, Yan},\n title = {Hiding the Long Latency of Persist Barriers Using Speculative Execution},\n booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},\n series = {ISCA '17},\n year = {2017},\n isbn = {978-1-4503-4892-8},\n location = {Toronto, ON, Canada},\n pages = {175--186},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/3079856.3080240},\n doi = {10.1145/3079856.3080240},\n acmid = {3080240},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Failure Safety, Non-Volatile Main Memory, Speculative Persistence},\n} \r\n",
        "key": "3080240",
        "pub_year": "2017",
        "text": "Seunghee Shin , James Tuck , Yan Solihin, Hiding the Long Latency of Persist Barriers Using Speculative Execution, Proceedings of the 44th Annual International Symposium on Computer Architecture, June 24-28, 2017, Toronto, ON, Canada"
    },
    "3080245": {
        "abstract": "Deep Neural Networks (DNNs) have demonstrated state-of-the-art performance on a broad range of tasks involving natural language, speech, image, and video processing, and are deployed in many real world applications. However, DNNs impose significant computational challenges owing to the complexity of the networks and the amount of data they process, both of which are projected to grow in the future. To improve the efficiency of DNNs, we propose ScaleDeep, a dense, scalable server architecture, whose processing, memory and interconnect subsystems are specialized to leverage the compute and communication characteristics of DNNs. While several DNN accelerator designs have been proposed in recent years, the key difference is that ScaleDeep primarily targets DNN training, as opposed to only inference or evaluation. The key architectural features from which ScaleDeep derives its efficiency are: (i) heterogeneous processing tiles and chips to match the wide diversity in computational characteristics (FLOPs and Bytes/FLOP ratio) that manifest at different levels of granularity in DNNs, (ii) a memory hierarchy and 3-tiered interconnect topology that is suited to the memory access and communication patterns in DNNs, (iii) a low-overhead synchronization mechanism based on hardware data-flow trackers, and (iv) methods to map DNNs to the proposed architecture that minimize data movement and improve core utilization through nested pipelining. We have developed a compiler to allow any DNN topology to be programmed onto ScaleDeep, and a detailed architectural simulator to estimate performance and energy. The simulator incorporates timing and power models of ScaleDeep's components based on synthesis to Intel's 14nm technology. We evaluate an embodiment of ScaleDeep with 7032 processing tiles that operates at 600 MHz and has a peak performance of 680 TFLOPs (single precision) and 1.35 PFLOPs (half-precision) at 1.4KW. Across 11 state-of-the-art DNNs containing 0.65M-14.9M neurons and 6.8M-145.9M weights, including winners from 5 years of the ImageNet competition, ScaleDeep demonstrates 6x-28x speedup at iso-power over the state-of-the-art performance on GPUs.",
        "acm_key": "3080245",
        "bib_stats": {
            "cites": 0,
            "dl": 212,
            "dl_52": 212,
            "dl_6": 67
        },
        "bibtex": "\r\n@inproceedings{Kannan:2017:HOD:3079856.3080245,\n author = {Kannan, Sudarsun and Gavrilovska, Ada and Gupta, Vishal and Schwan, Karsten},\n title = {HeteroOS: OS Design for Heterogeneous Memory Management in Datacenter},\n booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},\n series = {ISCA '17},\n year = {2017},\n isbn = {978-1-4503-4892-8},\n location = {Toronto, ON, Canada},\n pages = {521--534},\n numpages = {14},\n url = {http://doi.acm.org/10.1145/3079856.3080245},\n doi = {10.1145/3079856.3080245},\n acmid = {3080245},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {3D-stacked DRAM, Heterogeneous Memory, Hypervisor, Non-volatile memory, Operating Systems, Virtual Memory, Virtualization},\n} \r\n",
        "key": "3080245",
        "pub_year": "2017",
        "text": "Sudarsun Kannan , Ada Gavrilovska , Vishal Gupta , Karsten Schwan, HeteroOS: OS Design for Heterogeneous Memory Management in Datacenter, Proceedings of the 44th Annual International Symposium on Computer Architecture, June 24-28, 2017, Toronto, ON, Canada"
    },
    "3081038": {
        "abstract": " Modern embedded processors provide hardware support for cache locking, a mechanism used to facilitate the WCET (Worst-Case Execution Time) calculation of a task. We investigate the problem of integrating task scheduling and cache locking for a set of preemptible tasks with individual release times and deadlines on a multi-core processor with two-level caches. We propose a novel integrated approach that schedules the task set and allocates the locked cache contents of each task to the local caches (L1 caches) and the level-two cache (L2 cache). Our approach consists of three major components, the task scheduler, the L1 cache allocator, and the L2 cache allocator. The task scheduler aims at minimizing the number of task preemptions. The L1 cache allocator converts the interference graph of all the tasks scheduled on each core into a DAG by considering the preemptions between tasks and allocates the L1 cache space to each task. The L2 cache allocator converts the interference graph of all the tasks into a DAG by using a k-longest-path-based graph orientation algorithm and allocates the L2 cache space to each task. Both cache allocators significantly improve the cache utilization for all the caches due to the efficient use of the interference graphs of tasks. We have implemented our approach and compared it with the extended version of the preemption tree-based approach and the static analysis approach without cache locking by using a set of benchmarks from the MRTC WCET benchmark suite and SNU real-time benchmarks. Compared to the extended version of the preemption tree-based approach, the maximum WCRT (Worst Case Response Time) improvement of our approach is 15%. Compared to the static analysis approach, the maximum WCRT improvement of our approach is 37%. ",
        "acm_key": "3081038",
        "bib_stats": {
            "cites": 0,
            "dl": 31,
            "dl_52": 31,
            "dl_6": 9
        },
        "bibtex": "\r\n@inproceedings{Pan:2017:LPM:3078633.3081038,\n author = {Pan, Chen and Xie, Mimi and Liu, Yongpan and Wang, Yanzhi and Xue, Chun Jason and Wang, Yuangang and Chen, Yiran and Hu, Jingtong},\n title = {A Lightweight Progress Maximization Scheduler for Non-volatile Processor Under Unstable Energy Harvesting},\n booktitle = {Proceedings of the 18th ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},\n series = {LCTES 2017},\n year = {2017},\n isbn = {978-1-4503-5030-3},\n location = {Barcelona, Spain},\n pages = {101--110},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/3078633.3081038},\n doi = {10.1145/3078633.3081038},\n acmid = {3081038},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Energy Harvesting, Non-volatile Memory, Non-volatile Processor, Progress Maximization, Task Scheduling},\n} \r\n",
        "key": "3081038",
        "pub_year": "2017",
        "text": "Chen Pan , Mimi Xie , Yongpan Liu , Yanzhi Wang , Chun Jason Xue , Yuangang Wang , Yiran Chen , Jingtong Hu, A lightweight progress maximization scheduler for non-volatile processor under unstable energy harvesting, Proceedings of the 18th ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems, June 21-22, 2017, Barcelona, Spain"
    },
    "3081046": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3081046",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{vanZandwijk:2017:BSF:3081043.3081046,\n author = {van Zandwijk, Jan Peter},\n title = {Bit-errors As a Source of Forensic Information in NAND-flash Memory},\n journal = {Digit. Investig.},\n issue_date = {March 2017},\n volume = {20},\n number = {S},\n month = mar,\n year = {2017},\n issn = {1742-2876},\n pages = {S12--S19},\n url = {https://doi.org/10.1016/j.diin.2017.01.005},\n doi = {10.1016/j.diin.2017.01.005},\n acmid = {3081046},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Error-correcting codes, Hardware forensics, NAND-flash reliability, P/E cycles, Retention bit-errors},\n} \r\n",
        "key": "3081046",
        "pub_year": "2017",
        "text": "Jan Peter van Zandwijk, Bit-errors as a source of forensic information in NAND-flash memory, Digital Investigation: The International Journal of Digital Forensics & Incident Response, v.20 n.S, p.S12-S19, March 2017"
    },
    "3083857": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3083857",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Chen:2017:EAR:3083769.3083857,\n author = {Chen, Xunchao and Khoshavi, Navid and DeMara, Ronald F. and Wang, Jun and Huang, Dan and Wen, Wujie and Chen, Yiran},\n title = {Energy-Aware Adaptive Restore Schemes for MLC STT-RAM Cache},\n journal = {IEEE Trans. Comput.},\n issue_date = {May 2017},\n volume = {66},\n number = {5},\n month = may,\n year = {2017},\n issn = {0018-9340},\n pages = {786--798},\n numpages = {13},\n url = {https://doi.org/10.1109/TC.2016.2625245},\n doi = {10.1109/TC.2016.2625245},\n acmid = {3083857},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3083857",
        "pub_year": "2017",
        "text": "Xunchao Chen , Navid Khoshavi , Ronald F. DeMara , Jun Wang , Dan Huang , Wujie Wen , Yiran Chen, Energy-Aware Adaptive Restore Schemes for MLC STT-RAM Cache, IEEE Transactions on Computers, v.66 n.5, p.786-798, May 2017"
    },
    "3083858": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3083858",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Jing:2017:RHM:3083769.3083858,\n author = {Jing, Weiliang and Yang, Kai and Lin, Yinyin and Lee, Beomseop and Yoon, Sangkyu and Ye, Yong and Du, Yuan and Chen, Bomy},\n title = {Retention-Aware Hybrid Main Memory (RAHMM): Big DRAM and Little SCM},\n journal = {IEEE Trans. Comput.},\n issue_date = {May 2017},\n volume = {66},\n number = {5},\n month = may,\n year = {2017},\n issn = {0018-9340},\n pages = {912--918},\n numpages = {7},\n url = {https://doi.org/10.1109/TC.2016.2625795},\n doi = {10.1109/TC.2016.2625795},\n acmid = {3083858},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3083858",
        "pub_year": "2017",
        "text": "Weiliang Jing , Kai Yang , Yinyin Lin , Beomseop Lee , Sangkyu Yoon , Yong Ye , Yuan Du , Bomy Chen, Retention-Aware Hybrid Main Memory (RAHMM): Big DRAM and Little SCM, IEEE Transactions on Computers, v.66 n.5, p.912-918, May 2017"
    },
    "3084458": {
        "abstract": "Storage-class memory (SCM) combines the benefits of a solid-state memory, such as high-performance and robustness, with the archival capabilities and low cost of conventional hard-disk magnetic storage. Among candidate solid-state nonvolatile memory technologies that could potentially be used to construct SCM, flash memory is a well-established technology and have been widely used in commercially available SCM incarnations. Flash-based SCM enables much better tradeoffs between performance, space and power than disk-based systems. However, write endurance is a significant challenge for a flash-based SCM (each act of writing a bit may slightly damage a cell, so one flash cell can be written 10^4-10^5 times, depending on the flash technology, before it becomes unusable). This is a well-documented problem and has received a lot of attention by manufactures that are using some combination of write reduction and wear-leveling techniques for achieving longer lifetime. In an effort to improve flash lifetime, first, by quantifying data longevity in an SCM, we show that a majority of the data stored in a solid-state SCM do not require long retention times provided by flash memory (i.e., up to 10 years in modern devices); second, by exploiting retention time relaxation, we propose a novel mechanism, called Dense-SLC (D-SLC), which enables us perform multiple writes into a cell during each erase cycle for lifetime extension; and finally, we discuss the required changes in the flash management software (FTL) in order to use D-SLC mechanism for extending the lifetime of the solid-state part of an SCM. Using an extensive simulation-based analysis of an SLC flash-based SCM, we demonstrate that D-SLC is able to significantly improve device lifetime (between 5.1X and 8.6X) with no performance overhead and also very small changes at the FTL software.",
        "acm_key": "3084458",
        "bib_stats": {
            "cites": 0,
            "dl": 21,
            "dl_52": 21,
            "dl_6": 11
        },
        "bibtex": "\r\n@article{Choi:2017:EDL:3107080.3084458,\n author = {Choi, Wonil and Arjomand, Mohammad and Jung, Myoungsoo and Kandemir, Mahmut},\n title = {Exploiting Data Longevity for Enhancing the Lifetime of Flash-based Storage Class Memory},\n journal = {Proc. ACM Meas. Anal. Comput. Syst.},\n issue_date = {June 2017},\n volume = {1},\n number = {1},\n month = jun,\n year = {2017},\n issn = {2476-1249},\n pages = {21:1--21:26},\n articleno = {21},\n numpages = {26},\n url = {http://doi.acm.org/10.1145/3084458},\n doi = {10.1145/3084458},\n acmid = {3084458},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {lifetime, retention time, slc flash memory, ssd},\n} \r\n",
        "key": "3084458",
        "pub_year": "2017",
        "text": "Wonil Choi , Mohammad Arjomand , Myoungsoo Jung , Mahmut Kandemir, Exploiting Data Longevity for Enhancing the Lifetime of Flash-based Storage Class Memory, Proceedings of the ACM on Measurement and Analysis of Computing Systems, v.1 n.1, p.1-26, June 2017"
    },
    "3084619": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3084619",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Tavakkol:2016:TTB:3084610.3084619,\n author = {Tavakkol, Arash and Mehrvarzy, Pooyan and Sarbazi-Azad, Hamid},\n title = {TBM: Twin Block Management Policy to Enhance the Utilization of Plane-Level Parallelism in SSDs},\n journal = {IEEE Comput. Archit. Lett.},\n issue_date = {July 2016},\n volume = {15},\n number = {2},\n month = jul,\n year = {2016},\n issn = {1556-6056},\n pages = {121--124},\n numpages = {4},\n url = {https://doi.org/10.1109/LCA.2015.2461162},\n doi = {10.1109/LCA.2015.2461162},\n acmid = {3084619},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3084619",
        "pub_year": "2016",
        "text": "Arash Tavakkol , Pooyan Mehrvarzy , Hamid Sarbazi-Azad, TBM: Twin Block Management Policy to Enhance the Utilization of Plane-Level Parallelism in SSDs, IEEE Computer Architecture Letters, v.15 n.2, p.121-124, July 2016"
    },
    "3084620": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3084620",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Kannan:2016:EAP:3084610.3084620,\n author = {Kannan, Sudarsun and Qureshi, Moinudin and Gavrilovska, Ada and Schwan, Karsten},\n title = {Energy Aware Persistence: Reducing the Energy Overheads of Persistent Memory},\n journal = {IEEE Comput. Archit. Lett.},\n issue_date = {July 2016},\n volume = {15},\n number = {2},\n month = jul,\n year = {2016},\n issn = {1556-6056},\n pages = {89--92},\n numpages = {4},\n url = {https://doi.org/10.1109/LCA.2015.2472410},\n doi = {10.1109/LCA.2015.2472410},\n acmid = {3084620},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "3084620",
        "pub_year": "2016",
        "text": "Sudarsun Kannan , Moinudin Qureshi , Ada Gavrilovska , Karsten Schwan, Energy Aware Persistence: Reducing the Energy Overheads of Persistent Memory, IEEE Computer Architecture Letters, v.15 n.2, p.89-92, July 2016"
    },
    "3084690": {
        "abstract": "Electric vehicles (EVs) have been considered as a solution to the environmental issues caused by transportation, such as air pollution and greenhouse gas emission. However, limited energy capacity, scarce EV supercharging stations, and long recharging time have brought anxiety to drivers who use EVs as their main mean of transportation. Furthermore, EV owners need to deal with a huge battery replacement cost when the battery capacity degrades. Yet in-house EV chargers affect the pattern of the power grid load, which is not favorable to the utilities. The driving route, departure/arrival time of daily trips, and electricity price influence the EV energy consumption, battery lifetime, electricity cost, and EV charger load on the power grid. The EV driving range and battery lifetime issues have been addressed by battery management systems and route optimization methodologies. However, in this article, we are proposing an optimized charge and drive management (OCDM) methodology that selects the optimal driving route, schedules daily trips, and optimizes the EV charging process while considering the driver\u2019s timing preference. Our methodology will improve the EV driving range, extend the battery lifetime, reduce the recharging cost, and diminish the influence of EV chargers on the power grid. The performance of our methodology compared to the state of the art have been analyzed by experimenting on three benchmark EVs and three drivers. Our methodology has decreased EV energy consumption by 27%, improved the battery lifetime by 24.8%, reduced the electricity cost by 35%, and diminished the power grid peak load by 17% while increasing less than 20 minutes of daily driving time. Moreover, the scalability of our OCDM methodology for different parameters (e.g., time resolution and multiday cycles) in terms of execution time and memory usage has been analyzed.",
        "acm_key": "3084690",
        "bib_stats": {
            "cites": 0,
            "dl": 28,
            "dl_52": 28,
            "dl_6": 28
        },
        "bibtex": "\r\n@article{Wang:2017:WPW:3129756.3084690,\n author = {Wang, Shuai and Duan, Guangshan and Li, Yupeng and Dong, Qianhao},\n title = {Word- and Partition-Level Write Variation Reduction for Improving Non-Volatile Cache Lifetime},\n journal = {ACM Trans. Des. Autom. Electron. Syst.},\n issue_date = {August 2017},\n volume = {23},\n number = {1},\n month = aug,\n year = {2017},\n issn = {1084-4309},\n pages = {4:1--4:18},\n articleno = {4},\n numpages = {18},\n url = {http://doi.acm.org/10.1145/3084690},\n doi = {10.1145/3084690},\n acmid = {3084690},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Non-volatile memory, cache partitioning, last-level cache, narrow-width value, wear-leveling},\n} \r\n",
        "key": "3084690",
        "pub_year": "2017",
        "text": "Shuai Wang , Guangshan Duan , Yupeng Li , Qianhao Dong, Word- and Partition-Level Write Variation Reduction for Improving Non-Volatile Cache Lifetime, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.23 n.1, p.1-18, July 2017"
    },
    "3087589": {
        "abstract": "We investigate scheduling algorithms for distributed transactional memory systems where transactions residing at nodes of a communication graph operate on shared, mobile objects. A transaction requests the objects it needs, executes once those objects have been assembled, and then possibly forwards those objects to other waiting transactions. Minimizing execution time in this model is known to be NP-hard for arbitrary communication graphs, and also hard to approximate within any factor smaller than the size of the graph. Nevertheless, networks on chips, multi-core systems, and clusters are not arbitrary. Here, we explore efficient execution schedules in specialized graphs likely to arise in practice: Clique, Line, Grid, Cluster, Hypercube, Butterfly, and Star. In most cases, when individual transactions request k objects, we obtain solutions close to a factor O(k) from optimal, yielding near-optimal solutions for constant k. These execution times approximate the TSP tour lengths of the objects in the graph. We show that for general networks, even for two objects (k=2), it is impossible to obtain execution time close to the objects' optimal TSP tour lengths, which is why it is useful to consider more realistic network models. To our knowledge, this is the first attempt to obtain provably fast schedules for distributed transactional memory.",
        "acm_key": "3087589",
        "bib_stats": {
            "cites": 0,
            "dl": 45,
            "dl_52": 45,
            "dl_6": 45
        },
        "bibtex": "\r\n@inproceedings{Giles:2017:BAH:3087556.3087589,\n author = {Giles, Ellis and Doshi, Kshitij and Varman, Peter},\n title = {Brief Announcement: Hardware Transactional Storage Class Memory},\n booktitle = {Proceedings of the 29th ACM Symposium on Parallelism in Algorithms and Architectures},\n series = {SPAA '17},\n year = {2017},\n isbn = {978-1-4503-4593-4},\n location = {Washington, DC, USA},\n pages = {375--378},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/3087556.3087589},\n doi = {10.1145/3087556.3087589},\n acmid = {3087589},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {HTM, TSX, atomicity, consistency, durability, hardware transactional memory, non-volatile memory, persistent memory, storage class memory},\n} \r\n",
        "key": "3087589",
        "pub_year": "2017",
        "text": "Ellis Giles , Kshitij Doshi , Peter Varman, Brief Announcement: Hardware Transactional Storage Class Memory, Proceedings of the 29th ACM Symposium on Parallelism in Algorithms and Architectures, July 24-26, 2017, Washington, DC, USA"
    },
    "3092270": {
        "abstract": " Heterogeneous systems that integrate a multicore CPU and a GPU on the same die are ubiquitous. On these systems, both the CPU and GPU share the same physical memory as opposed to using separate memory dies. Although integration eliminates the need to copy data between the CPU and the GPU, arranging transparent memory sharing between the two devices can carry large overheads. Memory on CPU/GPU systems is typically managed by a software framework such as OpenCL or CUDA, which includes a runtime library, and communicates with a GPU driver. These frameworks offer a range of memory management methods that vary in ease of use, consistency guarantees and performance. In this study, we analyze some of the common memory management methods of the most widely used software frameworks for heterogeneous systems: CUDA, OpenCL 1.2, OpenCL 2.0, and HSA, on NVIDIA and AMD hardware. We focus on performance/functionality trade-offs, with the goal of exposing their performance impact and simplifying the choice of memory management methods for programmers. ",
        "acm_key": "3092270",
        "bib_stats": {
            "cites": 1,
            "dl": 69,
            "dl_52": 69,
            "dl_6": 24
        },
        "bibtex": "\r\n@inproceedings{Giles:2017:CCH:3092255.3092270,\n author = {Giles, Ellis and Doshi, Kshitij and Varman, Peter},\n title = {Continuous Checkpointing of HTM Transactions in NVM},\n booktitle = {Proceedings of the 2017 ACM SIGPLAN International Symposium on Memory Management},\n series = {ISMM 2017},\n year = {2017},\n isbn = {978-1-4503-5044-0},\n location = {Barcelona, Spain},\n pages = {70--81},\n numpages = {12},\n url = {http://doi.acm.org/10.1145/3092255.3092270},\n doi = {10.1145/3092255.3092270},\n acmid = {3092270},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Checkpointing, HTM, Hardware Transactional Memory, Lock-Free, Persistence, Storage Class Memory, TSX},\n} \r\n",
        "key": "3092270",
        "pub_year": "2017",
        "text": "Ellis Giles , Kshitij Doshi , Peter Varman, Continuous checkpointing of HTM transactions in NVM, Proceedings of the 2017 ACM SIGPLAN International Symposium on Memory Management, June 18-18, 2017, Barcelona, Spain"
    },
    "3095468": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3095468",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Mao:2017:MAD:3095370.3095468,\n author = {Mao, Manqing and Chen, Pai-Yu and Yu, Shimeng and Chakrabarti, Chaitali},\n title = {A Multilayer Approach to Designing Energy-Efficient and Reliable ReRAM Cross-Point Array System},\n journal = {IEEE Trans. Very Large Scale Integr. Syst.},\n issue_date = {May 2017},\n volume = {25},\n number = {5},\n month = may,\n year = {2017},\n issn = {1063-8210},\n pages = {1611--1621},\n numpages = {11},\n url = {https://doi.org/10.1109/TVLSI.2017.2651647},\n doi = {10.1109/TVLSI.2017.2651647},\n acmid = {3095468},\n publisher = {IEEE Educational Activities Department},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3095468",
        "pub_year": "2017",
        "text": "Manqing Mao , Pai-Yu Chen , Shimeng Yu , Chaitali Chakrabarti, A Multilayer Approach to Designing Energy-Efficient and Reliable ReRAM Cross-Point Array System, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, v.25 n.5, p.1611-1621, May 2017"
    },
    "3095835": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3095835",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{M.Emara:2017:NLC:3095818.3095835,\n author = {M. Emara, Ahmed A. and Aboudina, Mohamed M. and Fahmy, Hossam A.H.},\n title = {Non-volatile Low-power Crossbar Memcapacitor-based Memory},\n journal = {Microelectron. J.},\n issue_date = {June 2017},\n volume = {64},\n number = {C},\n month = jun,\n year = {2017},\n issn = {0026-2692},\n pages = {39--44},\n numpages = {6},\n url = {https://doi.org/10.1016/j.mejo.2017.04.005},\n doi = {10.1016/j.mejo.2017.04.005},\n acmid = {3095835},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {Memcapacitor, Memory, Sneak paths},\n} \r\n",
        "key": "3095835",
        "pub_year": "2017",
        "text": "Ahmed A. M. Emara , Mohamed M. Aboudina , Hossam A.H. Fahmy, Non-volatile low-power crossbar memcapacitor-based memory, Microelectronics Journal, v.64 n.C, p.39-44, June 2017"
    },
    "3101269": {
        "abstract": "Cloud infrastructure services such as Amazon EMR allow users to have access to tailor-made Big Data processing clusters within a few clicks from their web browser, thanks to the elastic property of the cloud. In virtual cloud environments, resource management is desired to be performed in a way which optimizes utilization, thus maximizing the value of the resources acquired. As cloud infrastructures become increasingly popular for Big Data analysis, the execution of programs with respect to user selected performance goals, such as job completion deadlines, remains a challenge. In this work we present BARBECUE (joB AwaRe Big-data Elasticity CloUd managEment System), a system that allows a Hadoop MapReduce virtual cluster to automatically adjust its size to the workload it is required to execute in order to respect individual jobs' completion deadlines without acquiring more resources than the least necessary. To that end, BBQ's Decision Making module uses a Performance Model for MapReduce jobs which can express cluster resources (i.e., YARN Container capacity) and execution time as a function of the number of nodes in the cluster. BBQ leverages the abstraction of YARN, making it feasible for integration with other execution frameworks, such as Spark, with the necessary changes to its pluggable Decision Making module. We also add a new feature to Hadoop MapReduce which can now dynamically, on-the-fly update the number of selected ReduceTasks in cases where the cluster is expanded, so that our system makes full use of the resources it has acquired during the reduce phase of the execution. BBQ uses an adaptation of the hill climbing algorithm to estimate the optimal combination of number of nodes and reduce waves given a known job, its data input and an execution deadline. The attendees will be able to watch the system perform cluster resizes in real-time in order to execute its assigned jobs in time.",
        "acm_key": "3101269",
        "bib_stats": {
            "cites": 0,
            "dl": 12,
            "dl_52": 12,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Taleb:2017:EEN:3101112.3101269,\n author = {Taleb, Yacine and Ibrahim, Shadi and Antoniu, Gabriel and Cortes, Toni},\n title = {An Empirical Evaluation of How The Network Impacts The Performance and Energy Efficiency in RAMCloud},\n booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},\n series = {CCGrid '17},\n year = {2017},\n isbn = {978-1-5090-6610-0},\n location = {Madrid, Spain},\n pages = {1027--1034},\n numpages = {8},\n url = {https://doi.org/10.1109/CCGRID.2017.127},\n doi = {10.1109/CCGRID.2017.127},\n acmid = {3101269},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n keywords = {Energy efficiency, In-memory storage, Performance evaluation, RAMCloud},\n} \r\n",
        "key": "3101269",
        "pub_year": "2017",
        "text": "Yacine Taleb , Shadi Ibrahim , Gabriel Antoniu , Toni Cortes, An Empirical Evaluation of How The Network Impacts The Performance and Energy Efficiency in RAMCloud, Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, May 14-17, 2017, Madrid, Spain"
    },
    "3101671": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3101671",
        "bib_stats": {
            "cites": 1
        },
        "bibtex": "\r\n@article{Kang:2017:MEV:3101630.3101671,\n author = {Kang, Wang and Ran, Yi and Zhang, Youguang and Lv, Weifeng and Zhao, Weisheng},\n title = {Modeling and Exploration of the Voltage-Controlled Magnetic Anisotropy Effect for the Next-Generation Low-Power and High-Speed MRAM Applications},\n journal = {IEEE Trans. Nanotechnol.},\n issue_date = {May 2017},\n volume = {16},\n number = {3},\n month = may,\n year = {2017},\n issn = {1536-125X},\n pages = {387--395},\n numpages = {9},\n url = {https://doi.org/10.1109/TNANO.2017.2660530},\n doi = {10.1109/TNANO.2017.2660530},\n acmid = {3101671},\n publisher = {IEEE Press},\n address = {Piscataway, NJ, USA},\n} \r\n",
        "key": "3101671",
        "pub_year": "2017",
        "text": "Wang Kang , Yi Ran , Youguang Zhang , Weifeng Lv , Weisheng Zhao, Modeling and Exploration of the Voltage-Controlled Magnetic Anisotropy Effect for the Next-Generation Low-Power and High-Speed MRAM Applications, IEEE Transactions on Nanotechnology, v.16 n.3, p.387-395, May 2017  \u00a0[doi>"
    },
    "3102988": {
        "abstract": "The paper reports on first steps towards a systematic design process that ensures quantitative stochastic requirements like requirements on the expected energy consumption or resilience requirements by construction. The idea is to automatically extract a formal model from a configurable system and to use formal analysis techniques to automatically determine a configuration such that the system meets the quantitative requirements. As a proof of concept we present a tool that supports the automated synthesis of protocol parameters for IPC (interprocess communication). The tool takes as input a Lua script describing the communication structure of several processes. This script is annotated with quantitative information such as error probabilities and timing information. The output is a Markov chain specified in the input language of the prominent probabilistic model checker PRISM. This Markov chain yields the basis for quantitative formal analysis of failure scenarios caused by hardware faults in IPC channels. The results yield the basis for finding optimal values for protocol parameters that tune, e.g., the level of resiliency. As an initial demonstration of the tool, we analyze and adjust system parameters of a simple scenario with a few communicating processes and report on results. Though achieved under simplified assumptions, the results presented here are a proof-of-concept towards the vision of automated system configuration.",
        "acm_key": "3102988",
        "bib_stats": {
            "cites": 0,
            "dl": 21,
            "dl_52": 21,
            "dl_6": 21
        },
        "bibtex": "\r\n@inproceedings{Zhang:2017:FDL:3102980.3102988,\n author = {Zhang, Tao and Zuck, Aviad and Porter, Donald E. and Tsafrir, Dan},\n title = {Flash Drive Lifespan *is* a Problem},\n booktitle = {Proceedings of the 16th Workshop on Hot Topics in Operating Systems},\n series = {HotOS '17},\n year = {2017},\n isbn = {978-1-4503-5068-6},\n location = {Whistler, BC, Canada},\n pages = {42--49},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/3102980.3102988},\n doi = {10.1145/3102980.3102988},\n acmid = {3102988},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "3102988",
        "pub_year": "2017",
        "text": "Tao Zhang , Aviad Zuck , Donald E. Porter , Dan Tsafrir, Flash Drive Lifespan *is* a Problem, Proceedings of the 16th Workshop on Hot Topics in Operating Systems, p.42-49, May 07-10, 2017, Whistler, BC, Canada"
    },
    "3103964": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3103964",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Liu:2017:EEM:3103649.3103964,\n author = {Liu, Duo and Luo, Xianlu and Li, Yang and Shao, Zili and Guan, Yong},\n title = {An Energy-efficient Encryption Mechanism for NVM-based Main Memory in Mobile Systems},\n journal = {J. Syst. Archit.},\n issue_date = {May 2017},\n volume = {76},\n number = {C},\n month = may,\n year = {2017},\n issn = {1383-7621},\n pages = {47--57},\n numpages = {11},\n url = {https://doi.org/10.1016/j.sysarc.2016.11.002},\n doi = {10.1016/j.sysarc.2016.11.002},\n acmid = {3103964},\n publisher = {Elsevier North-Holland, Inc.},\n address = {New York, NY, USA},\n keywords = {Energy-efficient encryption, Mobile system, Non-volatile memory},\n} \r\n",
        "key": "3103964",
        "pub_year": "2017",
        "text": "Duo Liu , Xianlu Luo , Yang Li , Zili Shao , Yong Guan, An energy-efficient encryption mechanism for NVM-based main memory in mobile systems, Journal of Systems Architecture: the EUROMICRO Journal, v.76 n.C, p.47-57, May 2017"
    },
    "3106863": {
        "abstract": "Efficiently searching top-k representative vertices is crucial for understanding the structure of large dynamic graphs. Recent studies show that communities formed by a vertex with high local clustering coefficient and its neighbours can achieve enhanced information propagation speed as well as disease transmission speed. However, local clustering coefficient, which measures the cliquishness of a vertex in its local neighbourhood, prefers vertices with small degrees. To remedy this issue, in this paper we propose a new ranking measure, weighted clustering coefficient (WCC) of vertices, by integrating both local clustering coefficient and degree. WCC not only inherits the properties of local clustering coefficient but also approximately measures the density (i.e., average degree) of its neighbourhood subgraph. Thus, vertices with higher WCC are more likely to be representative. We study efficiently computing and monitoring top-k representative vertices based on WCC over large dynamic graphs. To reduce the search space, we propose a series of heuristic upper bounds for WCC to prune a large portion of disqualifying vertices from the search space. We also develop an approximation algorithm by utilizing Flajolet-Martin sketch to trade acceptable accuracy for enhanced efficiency. An efficient incremental algorithm dealing with frequent updates in dynamic graphs is explored as well. Extensive experimental results on a variety of real-life graph datasets demonstrate the efficiency and effectiveness of our approaches.",
        "acm_key": "3106863",
        "bib_stats": {
            "cites": 0
        },
        "bibtex": "\r\n@article{Wang:2017:TSI:3106837.3106863,\n author = {Wang, Sheng and Qin, Xiaolin and Bao, Zhifeng and Li, Bohan},\n title = {Tide-tree: A Self-tuning Indexing Scheme for Hybrid Storage System},\n journal = {World Wide Web},\n issue_date = {September 2017},\n volume = {20},\n number = {5},\n month = sep,\n year = {2017},\n issn = {1386-145X},\n pages = {1017--1045},\n numpages = {29},\n url = {https://doi.org/10.1007/s11280-016-0426-9},\n doi = {10.1007/s11280-016-0426-9},\n acmid = {3106863},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n keywords = {Hybrid storage, Memory map, Pointer swizzling, Self-tuning index},\n} \r\n",
        "key": "3106863",
        "pub_year": "2017",
        "text": "Sheng Wang , Xiaolin Qin , Zhifeng Bao , Bohan Li, Tide-tree: A self-tuning indexing scheme for hybrid storage system, World Wide Web, v.20 n.5, p.1017-1045, September 2017"
    },
    "3108105": {
        "abstract": "Field Operation and Manipulation (OpenFOAM) is a free, open-source, feature-rich Computational Fluid Dynamics (CFD) software that is used to solve a variety of problems in continuum mechanics. Depending on the type of problem and required accuracy, an OpenFOAM simulation may take several weeks to complete. For sufficiently large simulations, linear solvers consume a large portion of the execution time. AmgX is a state of the art, high performance library which provides an elegant way to accelerate linear solvers on GPUs. AmgX library provides multi-grid solvers, Krylov methods, smoothers, support for block systems and MPI. In this work, we implemented OpenFOAM solvers on GPUs using the AmgX library. We also created helper functions which enable seamless integration of these solvers with OpenFOAM. These functions will take care of converting the linear system to AmgX's format and apply the user specified configurations to solve it. Experiments carried out using a wind rotor simulation and a fan wing simulation show that the use of AmgX library gives upto 10% speedup in the total simulation time and around ",
        "acm_key": "3108105",
        "bib_stats": {
            "cites": 0,
            "dl": 7,
            "dl_52": 7,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{He:2017:DLH:3108096.3108105,\n author = {He, Jiacong and Callenes-Sloan, Joseph},\n title = {Designing Large Hybrid Cache for Future HPC Systems},\n booktitle = {Proceedings of the 25th High Performance Computing Symposium},\n series = {HPC '17},\n year = {2017},\n isbn = {978-1-5108-3822-2},\n location = {Virginia Beach, Virginia},\n pages = {9:1--9:12},\n articleno = {9},\n numpages = {12},\n url = {http://dl.acm.org/citation.cfm?id=3108096.3108105},\n acmid = {3108105},\n publisher = {Society for Computer Simulation International},\n address = {San Diego, CA, USA},\n keywords = {DRAM cache, HPC, STT-RAM, energy, performance},\n} \r\n",
        "key": "3108105",
        "pub_year": "2017",
        "text": "Jiacong He , Joseph Callenes-Sloan, Designing large hybrid cache for future HPC systems, Proceedings of the 25th High Performance Computing Symposium, p.1-12, April 23-26, 2017, Virginia Beach, Virginia"
    },
    "3109145": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "3109145",
        "bib_stats": {
            "cites": 2
        },
        "bibtex": "\r\n@article{Doroyski:2016:CPM:3108947.3109145,\n author = {Doroyski, Piotr and Czarnul, Pawe and Malinowski, Artur and Czuryo, Krzysztof and Dorau, ukasz and Maciejewski, Maciej and Skowron, Pawe},\n title = {Checkpointing of Parallel MPI Applications Using MPI One-sided API with Support for Byte-addressable Non-volatile RAM},\n journal = {Procedia Comput. Sci.},\n issue_date = {June 2016},\n volume = {80},\n number = {C},\n month = jun,\n year = {2016},\n issn = {1877-0509},\n pages = {30--40},\n numpages = {11},\n url = {https://doi.org/10.1016/j.procs.2016.05.295},\n doi = {10.1016/j.procs.2016.05.295},\n acmid = {3109145},\n publisher = {Elsevier Science Publishers B. V.},\n address = {Amsterdam, The Netherlands, The Netherlands},\n keywords = {NVRAM, checkpointing of parallel applications, parallel MPI one-sided extension, performance optimization},\n} \r\n",
        "key": "3109145",
        "pub_year": "2016",
        "text": "Piotr Doroyski , Pawe Czarnul , Artur Malinowski , Krzysztof Czuryo , ukasz Dorau , Maciej Maciejewski , Pawe Skowron, Checkpointing of Parallel MPI Applications Using MPI One-sided API with Support for Byte-addressable Non-volatile RAM, Procedia Computer Science, v.80 n.C, p.30-40, June 2016"
    },
    "311286": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "311286",
        "bib_stats": {
            "cites": 52
        },
        "bibtex": "\r\n@article{Chiang:1999:UDC:311282.311286,\n author = {Chiang, Mei-Ling and Lee, Paul C. H. and Chang, Ruei-Chuan},\n title = {Using Data Clustering to Improve Cleaning Performance for Plash Memory},\n journal = {Softw. Pract. Exper.},\n issue_date = {March 1999},\n volume = {29},\n number = {3},\n month = mar,\n year = {1999},\n issn = {0038-0644},\n pages = {267--290},\n numpages = {24},\n url = {https://doi.org/10.1002/(SICI)1097-024X(199903)29:3<267::AID-SPE233>3.0.CO;2-T},\n doi = {10.1002/(SICI)1097-024X(199903)29:3<267::AID-SPE233>3.0.CO;2-T},\n acmid = {311286},\n publisher = {John Wiley \\&amp; Sons, Inc.},\n address = {New York, NY, USA},\n keywords = {cleaning policy, consumer electronics, data clustering, flash memory, mobile device},\n} \r\n",
        "key": "311286",
        "pub_year": "1999",
        "text": "Mei-Ling Chiang , Paul C. H. Lee , Ruei-Chuan Chang, Using data clustering to improve cleaning performance for plash memory, Software\u2014Practice & Experience, v.29 n.3, p.267-290, March 1999  \u00a0[doi>"
    },
    "3129636": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129636",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Yan:2017:TFN:3129633.3129636,\n author = {Yan, Shiqin and Li, Huaicheng and Hao, Mingzhe and Tong, Michael Hao and Sundararaman, Swaminatahan and Chien, Andrew A. and Gunawi, Haryadi S.},\n title = {Tiny-tail Flash: Near-perfect Elimination of Garbage Collection Tail Latencies in NAND SSDs},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {15--28},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129636},\n acmid = {3129636},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129636",
        "pub_year": "2017",
        "text": "Shiqin Yan , Huaicheng Li , Mingzhe Hao , Michael Hao Tong , Swaminatahan Sundararaman , Andrew A. Chien , Haryadi S. Gunawi, Tiny-tail flash: near-perfect elimination of garbage collection tail latencies in NAND SSDs, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3129657": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129657",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Lee:2017:WWO:3129633.3129657,\n author = {Lee, Se Kwon and Lim, K. Hyun and Song, Hyunsub and Nam, Beomseok and Noh, Sam H.},\n title = {WORT: Write Optimal Radix Tree for Persistent Memory Storage Systems},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {257--270},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129657},\n acmid = {3129657},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129657",
        "pub_year": "2017",
        "text": "Se Kwon Lee , K. Hyun Lim , Hyunsub Song , Beomseok Nam , Sam H. Noh, WORT: write optimal radix tree for persistent memory storage systems, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3129658": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129658",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:2017:SIS:3129633.3129658,\n author = {Kim, Hyukjoong and Shin, Dongkun and Jeong, Yun Ho and Kim, Kyung Ho},\n title = {SHRD: Improving Spatial Locality in Flash Storage Accesses by Sequentializing in Host and Randomizng in Device},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {271--283},\n numpages = {13},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129658},\n acmid = {3129658},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129658",
        "pub_year": "2017",
        "text": "Hyukjoong Kim , Dongkun Shin , Yun Ho Jeong , Kyung Ho Kim, SHRD: improving spatial locality in flash storage accesses by sequentializing in host and randomizng in device, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3129666": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129666",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Bjorling:2017:LLO:3129633.3129666,\n author = {Bj{\\o}rling, Matias and Gonz\\'{a}lez, Javier and Bonnet, Philippe},\n title = {LightNVM: The Linux Open-channel SSD Subsystem},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {359--373},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129666},\n acmid = {3129666},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129666",
        "pub_year": "2017",
        "text": "Matias Bj\u00f8rling , Javier Gonz\u00e1lez , Philippe Bonnet, LightNVM: the Linux open-channel SSD subsystem, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3129667": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129667",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Huang:2017:FAB:3129633.3129667,\n author = {Huang, Jian and Badam, Anirudh and Caulfield, Laura and Nath, Suman and Sengupta, Sudipta and Sharma, Bikash and Qureshi, Moinuddin K.},\n title = {FlashBlox: Achieving Both Performance Isolation and Uniform Lifetime for Virtualized SSDs},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {375--390},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129667},\n acmid = {3129667},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129667",
        "pub_year": "2017",
        "text": "Jian Huang , Anirudh Badam , Laura Caulfield , Suman Nath , Sudipta Sengupta , Bikash Sharma , Moinuddin K. Qureshi, FlashBlox: achieving both performance isolation and uniform lifetime for virtualized SSDs, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3129668": {
        "abstract": "Recent advances in flash memory technology have reduced the cost-per-bit of flash storage devices such as solid-state drives (SSDs), thereby enabling the development of large-capacity SSDs for enterprise-scale storage. However, two major concerns arise in designing SSDs. The first concern is the poor performance of random writes in an SSD. Server workloads such as databases generate many random writes; therefore, this problem must be resolved to enable the usage of SSDs in enterprise systems. The second concern is that the size of the internal DRAM of an SSD is proportional to the capacity of the SSD. The peculiarities of flash memory require an address translation layer called flash translation layer (FTL) to be implemented within an SSD. The FTL must maintain the address mapping table in the internal DRAM. Although the previously proposed demand map loading technique can reduce the required DRAM size, the technique aggravates the poor random performance. We propose a novel address reshaping technique called sequentializing in host and randomizing in device (SHRD), which transforms random write requests into sequential write requests in the block device driver by assigning the address space of the reserved log area in the SSD. Unlike previous approaches, SHRD can restore the sequentially written data to the original location without requiring explicit copy operations by utilizing the address mapping scheme of the FTL. We implement SHRD in a real SSD device and demonstrate the improved performance resulting from SHRD for various workloads.",
        "acm_key": "3129668",
        "bib_stats": {
            "cites": 0,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Shen:2017:DDI:3129633.3129668,\n author = {Shen, Zhaoyan and Chen, Feng and Jia, Yichen and Shao, Zili},\n title = {DIDACache: A Deep Integration of Device and Application for Flash Based Key-value Caching},\n booktitle = {Proceedings of the 15th Usenix Conference on File and Storage Technologies},\n series = {FAST'17},\n year = {2017},\n isbn = {978-1-931971-36-2},\n location = {Santa clara, CA, USA},\n pages = {391--405},\n numpages = {15},\n url = {http://dl.acm.org/citation.cfm?id=3129633.3129668},\n acmid = {3129668},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "3129668",
        "pub_year": "2017",
        "text": "Zhaoyan Shen , Feng Chen , Yichen Jia , Zili Shao, DIDACache: a deep integration of device and application for flash based key-value caching, Proceedings of the 15th Usenix Conference on File and Storage Technologies, February 27-March 02, 2017, Santa clara, CA, USA"
    },
    "3131082": {
        "abstract": "Current microprocessor architecture is moving towards multi-core/multi-threaded systems. This trend has led to a surge of interest in using multi-threaded computing devices, such as the Graphics Processing Unit (GPU), for general purpose computing. We can utilize the GPU in computation as a massive parallel co-processor because the GPU consists of multiple cores. The GPU is also an affordable, attractive, and user-programmable commodity. Nowadays a lot of information has been flooded into the digital domain around the world. Huge volume of data, such as digital libraries, social networking services, e-commerce product data, and reviews, etc., is produced or collected every moment with dramatic growth in size. Although the inverted index is a useful data structure that can be used for full text searches or document retrieval, a large number of documents will require a tremendous amount of time to create the index. The performance of document inversion can be improved by multi-thread or multi-core GPU. Our approach is to implement a linear-time, hash-based, single program multiple data (SPMD), document inversion algorithm on the NVIDIA GPU/CUDA programming platform utilizing the huge computational power of the GPU, to develop high performance solutions for document indexing. Our proposed parallel document inversion system shows 2--3 times faster performance than a sequential system on two different test datasets from PubMed abstract and e-commerce product reviews.",
        "acm_key": "3131082",
        "bib_stats": {
            "cites": 0,
            "dl": 24,
            "dl_52": 24,
            "dl_6": 24
        },
        "bibtex": "\r\n@article{Ho:2017:WMM:3131080.3131082,\n author = {Ho, Chien-Chung and Chang, Yu-Ming and Chang, Yuan-Hao and Chen, Hsiu-Chang and Kuo, Tei-Wei},\n title = {Write-aware Memory Management for Hybrid SLC-MLC PCM Memory Systems},\n journal = {SIGAPP Appl. Comput. Rev.},\n issue_date = {June 2017},\n volume = {17},\n number = {2},\n month = aug,\n year = {2017},\n issn = {1559-6915},\n pages = {16--26},\n numpages = {11},\n url = {http://doi.acm.org/10.1145/3131080.3131082},\n doi = {10.1145/3131080.3131082},\n acmid = {3131082},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {MLC, MMU, SLC, endurance, memory management, phase change memory, wear leveling},\n} \r\n",
        "key": "3131082",
        "pub_year": "2017",
        "text": "Chien-Chung Ho , Yu-Ming Chang , Yuan-Hao Chang , Hsiu-Chang Chen , Tei-Wei Kuo, Write-aware memory management for hybrid SLC-MLC PCM memory systems, ACM SIGAPP Applied Computing Review, v.17 n.2, p.16-26, June 2017"
    },
    "320427": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "320427",
        "bib_stats": {
            "cites": 10,
            "dl": 479,
            "dl_52": 15,
            "dl_6": 2
        },
        "bibtex": "\r\n@inproceedings{Hosking:1999:MRO:320384.320427,\n author = {Hosking, Antony L. and Chen, Jiawan},\n title = {Mostly-copying Reachability-based Orthogonal Persistence},\n booktitle = {Proceedings of the 14th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications},\n series = {OOPSLA '99},\n year = {1999},\n isbn = {1-58113-238-7},\n location = {Denver, Colorado, USA},\n pages = {382--398},\n numpages = {17},\n url = {http://doi.acm.org/10.1145/320384.320427},\n doi = {10.1145/320384.320427},\n acmid = {320427},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=320427&parent_id=320384&expformat=bibtex&CFID=982036448&CFTOKEN=32462204\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"320427\">\r\n@article{Hosking:1999:MRO:320385.320427,\n author = {Hosking, Antony L. and Chen, Jiawan},\n title = {Mostly-copying Reachability-based Orthogonal Persistence},\n journal = {SIGPLAN Not.},\n issue_date = {Oct. 1999},\n volume = {34},\n number = {10},\n month = oct,\n year = {1999},\n issn = {0362-1340},\n pages = {382--398},\n numpages = {17},\n url = {http://doi.acm.org/10.1145/320385.320427},\n doi = {10.1145/320385.320427},\n acmid = {320427},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "320427",
        "pub_year": "1999",
        "text": "Antony L. Hosking , Jiawan Chen, Mostly-copying reachability-based orthogonal persistence, Proceedings of the 14th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications, p.382-398, November 01-05, 1999, Denver, Colorado, USA  \u00a0[doi>"
    },
    "325670": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "325670",
        "bib_stats": {
            "cites": 50
        },
        "bibtex": "\r\n@article{Chiang:1999:CPM:326672.325670,\n author = {Chiang, M.-L. and Chang, R.-C.},\n title = {Cleaning Policies in Mobile Computers Using Flash Memory},\n journal = {J. Syst. Softw.},\n issue_date = {Nov. 1, 1999},\n volume = {48},\n number = {3},\n month = nov,\n year = {1999},\n issn = {0164-1212},\n pages = {213--231},\n numpages = {19},\n url = {http://dx.doi.org/10.1016/S0164-1212(99)00059-X},\n doi = {10.1016/S0164-1212(99)00059-X},\n acmid = {325670},\n publisher = {Elsevier Science Inc.},\n address = {New York, NY, USA},\n keywords = {cleaning policy, consumer electronics, embedded system, flash memory, mobile computer},\n} \r\n",
        "key": "325670",
        "pub_year": "1999",
        "text": "M.-L. Chiang , R.-C. Chang, Cleaning policies in mobile computers using flash memory, Journal of Systems and Software, v.48 n.3, p.213-231, Nov. 1, 1999  \u00a0[doi>"
    },
    "373128": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "373128",
        "bib_stats": {
            "cites": 11,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Ng:2001:DVR:373115.373128,\n author = {Ng, Wee Teck and Chen, Peter M.},\n title = {The Design and Verification of the Rio File Cache},\n journal = {IEEE Trans. Comput.},\n issue_date = {April 2001},\n volume = {50},\n number = {4},\n month = apr,\n year = {2001},\n issn = {0018-9340},\n pages = {322--337},\n numpages = {16},\n url = {http://dx.doi.org/10.1109/12.919278},\n doi = {10.1109/12.919278},\n acmid = {373128},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {File systems, reliable main memory, software fault injection.},\n} \r\n",
        "key": "373128",
        "pub_year": "2001",
        "text": "Wee Teck Ng , Peter M. Chen, The Design and Verification of the Rio File Cache, IEEE Transactions on Computers, v.50 n.4, p.322-337, April 2001"
    },
    "379000": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "379000",
        "bib_stats": {
            "cites": 42,
            "dl": 714,
            "dl_52": 10,
            "dl_6": 1
        },
        "bibtex": "\r\n@inproceedings{Gibson:2000:FVF:378993.379000,\n author = {Gibson, Jeff and Kunz, Robert and Ofelt, David and Horowitz, Mark and Hennessy, John and Heinrich, Mark},\n title = {FLASH vs. (Simulated) FLASH: Closing the Simulation Loop},\n booktitle = {Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems},\n series = {ASPLOS IX},\n year = {2000},\n isbn = {1-58113-317-0},\n location = {Cambridge, Massachusetts, USA},\n pages = {49--58},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/378993.379000},\n doi = {10.1145/378993.379000},\n acmid = {379000},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=379000&parent_id=378993&expformat=bibtex&CFID=982028130&CFTOKEN=30414291\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"379000\">\r\n@article{Gibson:2000:FVF:378995.379000,\n author = {Gibson, Jeff and Kunz, Robert and Ofelt, David and Horowitz, Mark and Hennessy, John and Heinrich, Mark},\n title = {FLASH vs. (Simulated) FLASH: Closing the Simulation Loop},\n journal = {SIGARCH Comput. Archit. News},\n issue_date = {Dec. 2000},\n volume = {28},\n number = {5},\n month = nov,\n year = {2000},\n issn = {0163-5964},\n pages = {49--58},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/378995.379000},\n doi = {10.1145/378995.379000},\n acmid = {379000},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n</pre>\r\n\r\n<div class=\"small-text\" align=\"right\" style=\"margin-right:10px\">\r\n\t\r\n    [<a href=\"downformats.cfm?id=379000&parent_id=378995&expformat=bibtex&CFID=982028130&CFTOKEN=30414291\" >download</a>]\r\n</div>\r\n\r\n<PRE id=\"379000\">\r\n@article{Gibson:2000:FVF:384264.379000,\n author = {Gibson, Jeff and Kunz, Robert and Ofelt, David and Horowitz, Mark and Hennessy, John and Heinrich, Mark},\n title = {FLASH vs. (Simulated) FLASH: Closing the Simulation Loop},\n journal = {SIGOPS Oper. Syst. Rev.},\n issue_date = {Dec. 2000},\n volume = {34},\n number = {5},\n month = nov,\n year = {2000},\n issn = {0163-5980},\n pages = {49--58},\n numpages = {10},\n url = {http://doi.acm.org/10.1145/384264.379000},\n doi = {10.1145/384264.379000},\n acmid = {379000},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "379000",
        "pub_year": "2000",
        "text": "Jeff Gibson , Robert Kunz , David Ofelt , Mark Horowitz , John Hennessy , Mark Heinrich, FLASH vs. (Simulated) FLASH: closing the simulation loop, ACM SIGARCH Computer Architecture News, v.28 n.5, p.49-58, Dec. 2000"
    },
    "45066": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "45066",
        "bib_stats": {
            "cites": 96,
            "dl": 2,
            "dl_52": 35,
            "dl_6": 4
        },
        "bibtex": "\r\n@article{Atkinson:1987:TPD:62070.45066,\n author = {Atkinson, Malcolm P. and Buneman, O. Peter},\n title = {Types and Persistence in Database Programming Languages},\n journal = {ACM Comput. Surv.},\n issue_date = {June 1987},\n volume = {19},\n number = {2},\n month = jun,\n year = {1987},\n issn = {0360-0300},\n pages = {105--170},\n numpages = {66},\n url = {http://doi.acm.org/10.1145/62070.45066},\n doi = {10.1145/62070.45066},\n acmid = {45066},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "45066",
        "pub_year": "1987",
        "text": "Malcolm P. Atkinson , O. Peter Buneman, Types and persistence in database programming languages, ACM Computing Surveys (CSUR), v.19 n.2, p.105-170, June 1987  \u00a0[doi>"
    },
    "554239": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "554239",
        "bib_stats": {
            "cites": 22
        },
        "bibtex": "\r\n@book{Cappelletti:1999:FM:554239,\n editor = {Cappelletti, Paulo and Golla, Carla},\n title = {Flash Memories},\n year = {1999},\n isbn = {0792384873},\n publisher = {Kluwer Academic Publishers},\n address = {Norwell, MA, USA},\n} \r\n",
        "key": "554239",
        "pub_year": null,
        "text": "Paulo Cappelletti , Carla Golla, Flash Memories, Kluwer Academic Publishers, Norwell, MA, 1999"
    },
    "592936": {
        "abstract": "Efficient data storage, a major concern in the modern computer\r\r\n industry, is mostly provided today by traditional magnetic disks. However, the\r\r\n cost of a disk transfer (measured in processor cycles) continues to\r\r\n increase with time, making disk accesses increasingly expensive. In this paper\r\r\n we describe the design, implementation and evaluation of a Network RamDisk\r\r\n device that uses main memory of remote workstations as a\r\r\n faster-than-disk storage device. In our study we propose various\r\r\n reliability policies, making the device tolerant to single workstation crashes.\r\r\n We show that the Network RamDisk is portable, flexible, and can operate under\r\r\n any of the existing Unix file systems. The Network RamDisk has been implemented\r\r\n both on the Linux and the Digital Unix operating systems, as a block device\r\r\n driver without any modifications to the kernel code. Using several real\r\r\n applications and benchmarks, we measure the performance of the Network RamDisk\r\r\n over an Ethernet and an ATM network, and find it to be usually four to eight\r\r\n times better than the magnetic disk. In one benchmark, our system was two\r\r\n orders of magnitude faster than the disk. We believe that a Network RamDisk can\r\r\n be efficiently used to provide reliable low-latency access to files that\r\r\n would otherwise be stored on magnetic disks.",
        "acm_key": "592936",
        "bib_stats": {
            "cites": 4,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Pnevmatikatos:1999:UNR:592889.592936,\n author = {Pnevmatikatos, Dionisios and Markatos, Evangelos P. and Magklis, Grigorios and Ioannidis, Sotiris},\n title = {On Using Network RAM As a Non-volatile Buffer},\n journal = {Cluster Computing},\n issue_date = {1999},\n volume = {2},\n number = {4},\n month = oct,\n year = {1999},\n issn = {1386-7857},\n pages = {295--303},\n numpages = {9},\n url = {https://doi.org/10.1023/A:1019003514550},\n doi = {10.1023/A:1019003514550},\n acmid = {592936},\n publisher = {Kluwer Academic Publishers},\n address = {Hingham, MA, USA},\n} \r\n",
        "key": "592936",
        "pub_year": "1999",
        "text": "Dionisios Pnevmatikatos , Evangelos P. Markatos , Grigorios Magklis , Sotiris Ioannidis, On using network RAM as a non-volatile buffer, Cluster Computing, v.2 n.4, p.295-303, 1999"
    },
    "64317": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "64317",
        "bib_stats": {
            "cites": 224
        },
        "bibtex": "\r\n@article{Driscoll:1989:MDS:64313.64317,\n author = {Driscoll, James R. and Sarnak, Neil and Sleator, Daniel D. and Tarjan, Robert E.},\n title = {Making Data Structures Persistent},\n journal = {J. Comput. Syst. Sci.},\n issue_date = {February 1989},\n volume = {38},\n number = {1},\n month = feb,\n year = {1989},\n issn = {0022-0000},\n pages = {86--124},\n numpages = {39},\n url = {http://dx.doi.org/10.1016/0022-0000(89)90034-2},\n doi = {10.1016/0022-0000(89)90034-2},\n acmid = {64317},\n publisher = {Academic Press, Inc.},\n address = {Orlando, FL, USA},\n} \r\n",
        "key": "64317",
        "pub_year": "1989",
        "text": "James R. Driscoll , Neil Sarnak , Daniel D. Sleator , Robert E. Tarjan, Making data structures persistent, Journal of Computer and System Sciences, v.38 n.1, p.86-124, February 1989  \u00a0[doi>"
    },
    "673643": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "673643",
        "bib_stats": {
            "cites": 9
        },
        "key": "673643",
        "text": "Wee Teck Ng , Peter M. Chen, Integrating Reliable Memory in Databases, Proceedings of the 23rd International Conference on Very Large Data Bases, p.76-85, August 25-29, 1997"
    },
    "674620": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "674620",
        "bib_stats": {
            "cites": 35,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Kim:1999:NFM:645981.674620,\n author = {Kim, Han-joon and Lee, Sang-goo},\n title = {A New Flash Memory Management for Flash Storage System},\n booktitle = {23rd International Computer Software and Applications Conference},\n series = {COMPSAC '99},\n year = {1999},\n isbn = {0-7695-0368-3},\n pages = {284--},\n url = {http://dl.acm.org/citation.cfm?id=645981.674620},\n acmid = {674620},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {flash memory, flash storage system, cleaning algorithm, cycle-leveling},\n} \r\n",
        "key": "674620",
        "pub_year": "1999",
        "text": "Han-joon Kim , Sang-goo Lee, A New Flash Memory Management for Flash Storage System, 23rd International Computer Software and Applications Conference, p.284, October 19-26, 1999"
    },
    "713872": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "713872",
        "bib_stats": {
            "cites": 27
        },
        "bibtex": "\r\n@inproceedings{Wang:2002:CBP:647057.713872,\n author = {Wang, An-I and Reiher, Peter L. and Popek, Gerald J. and Kuenning, Geoffrey H.},\n title = {Conquest: Better Performance Through a Disk/Persistent-RAM Hybrid File System},\n booktitle = {Proceedings of the General Track of the Annual Conference on USENIX Annual Technical Conference},\n series = {ATEC '02},\n year = {2002},\n isbn = {1-880446-00-6},\n pages = {15--28},\n numpages = {14},\n url = {http://dl.acm.org/citation.cfm?id=647057.713872},\n acmid = {713872},\n publisher = {USENIX Association},\n address = {Berkeley, CA, USA},\n} \r\n",
        "key": "713872",
        "pub_year": "2002",
        "text": "An-I Wang , Peter L. Reiher , Gerald J. Popek , Geoffrey H. Kuenning, Conquest: Better Performance Through a Disk/Persistent-RAM Hybrid File System, Proceedings of the General Track of the annual conference on USENIX Annual Technical Conference, p.15-28, June 10-15, 2002"
    },
    "747079": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "747079",
        "bib_stats": {
            "cites": 8
        },
        "bibtex": "\r\n@inproceedings{Morrison:1989:NTS:648121.747079,\n author = {Morrison, Ronald and Brown, Alfred L. and Carrick, Raymund and Connor, Richard C. H. and Dearle, Alan and Atkinson, Malcolm P.},\n title = {The Napier Type System},\n booktitle = {Proceedings of the Third International Workshop on Persistent Object Systems},\n year = {1989},\n isbn = {3-540-19626-9},\n pages = {3--18},\n numpages = {16},\n url = {http://dl.acm.org/citation.cfm?id=648121.747079},\n acmid = {747079},\n publisher = {Springer-Verlag},\n address = {London, UK, UK},\n} \r\n",
        "key": "747079",
        "pub_year": "1989",
        "text": "Ronald Morrison , Alfred L. Brown , Raymund Carrick , Richard C. H. Connor , Alan Dearle , Malcolm P. Atkinson, The Napier Type System, Proceedings of the Third International Workshop on Persistent Object Systems, p.3-18, January 10-13, 1989"
    },
    "76378": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "76378",
        "bib_stats": {
            "cites": 6,
            "dl": 465,
            "dl_52": 11,
            "dl_6": 0
        },
        "bibtex": "\r\n@article{Gait:1990:PSI:76372.76378,\n author = {Gait, Jason},\n title = {Phoenix: A Safe In-memory File System},\n journal = {Commun. ACM},\n issue_date = {Jan. 1990},\n volume = {33},\n number = {1},\n month = jan,\n year = {1990},\n issn = {0001-0782},\n pages = {81--86},\n numpages = {6},\n url = {http://doi.acm.org/10.1145/76372.76378},\n doi = {10.1145/76372.76378},\n acmid = {76378},\n publisher = {ACM},\n address = {New York, NY, USA},\n} \r\n",
        "key": "76378",
        "pub_year": "1990",
        "text": "Jason Gait, Phoenix: a safe in-memory file system, Communications of the ACM, v.33 n.1, p.81-86, Jan. 1990  \u00a0[doi>"
    },
    "79539": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "79539",
        "bib_stats": {
            "cites": 22
        },
        "bibtex": "\r\n@article{Richardson:1989:PEL:79538.79539,\n author = {Richardson, Joel E. and Carey, Michael J.},\n title = {Persistence in the E Language: Issues and Implementation},\n journal = {Softw. Pract. Exper.},\n issue_date = {Dec. 1989},\n volume = {19},\n number = {12},\n month = nov,\n year = {1989},\n issn = {0038-0644},\n pages = {1115--1150},\n numpages = {36},\n url = {http://dl.acm.org/citation.cfm?id=79538.79539},\n acmid = {79539},\n publisher = {John Wiley \\&amp; Sons, Inc.},\n address = {New York, NY, USA},\n} \r\n",
        "key": "79539",
        "pub_year": "1989",
        "text": "Joel E. Richardson , Michael J. Carey, Persistence in the E Language: Issues and implementation, Software\u2014Practice & Experience, v.19 n.12, p.1115-1150, Dec. 1989"
    },
    "796968": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "796968",
        "bib_stats": {
            "cites": 20,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Ng:1999:SIF:795672.796968,\n author = {Ng, Wee Teck and Chen, Peter M.},\n title = {The Systematic Improvement of Fault Tolerance in the Rio File Cache},\n booktitle = {Proceedings of the Twenty-Ninth Annual International Symposium on Fault-Tolerant Computing},\n series = {FTCS '99},\n year = {1999},\n isbn = {0-7695-0213-X},\n pages = {76--},\n url = {http://dl.acm.org/citation.cfm?id=795672.796968},\n acmid = {796968},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n keywords = {software fault injection, write-back file cache, reliable memory},\n} \r\n",
        "key": "796968",
        "pub_year": "1999",
        "text": "Wee Teck Ng , Peter M. Chen, The Systematic Improvement of Fault Tolerance in the Rio File Cache, Proceedings of the Twenty-Ninth Annual International Symposium on Fault-Tolerant Computing, p.76, June 15-18, 1999"
    },
    "828513": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "828513",
        "bib_stats": {
            "cites": 93,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Chang:2002:ASA:827265.828513,\n author = {Chang, Li-Pin and Kuo, Tei-Wei},\n title = {An Adaptive Striping Architecture for Flash Memory Storage Systems of Embedded Systems},\n booktitle = {Proceedings of the Eighth IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS'02)},\n series = {RTAS '02},\n year = {2002},\n isbn = {0-7695-1739-0},\n pages = {187--},\n url = {http://dl.acm.org/citation.cfm?id=827265.828513},\n acmid = {828513},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "828513",
        "pub_year": "2002",
        "text": "Li-Pin Chang , Tei-Wei Kuo, An Adaptive Striping Architecture for Flash Memory Storage Systems of Embedded Systems, Proceedings of the Eighth IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS'02), p.187, September 25-27, 2002"
    },
    "871609": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "871609",
        "bib_stats": {
            "cites": 14,
            "dl": 353,
            "dl_52": 16,
            "dl_6": 4
        },
        "bibtex": "\r\n@inproceedings{Lee:2003:EMA:871506.871609,\n author = {Lee, Hyung Gyu and Chang, Naehyuck},\n title = {Energy-aware Memory Allocation in Heterogeneous Non-volatile Memory Systems},\n booktitle = {Proceedings of the 2003 International Symposium on Low Power Electronics and Design},\n series = {ISLPED '03},\n year = {2003},\n isbn = {1-58113-682-X},\n location = {Seoul, Korea},\n pages = {420--423},\n numpages = {4},\n url = {http://doi.acm.org/10.1145/871506.871609},\n doi = {10.1145/871506.871609},\n acmid = {871609},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {low-power memory, memory allocation, non-volatile memory},\n} \r\n",
        "key": "871609",
        "pub_year": "2003",
        "text": "Hyung Gyu Lee , Naehyuck Chang, Energy-aware memory allocation in heterogeneous non-volatile memory systems, Proceedings of the 2003 international symposium on Low power electronics and design, August 25-27, 2003, Seoul, Korea  \u00a0[doi>"
    },
    "876403": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "876403",
        "bib_stats": {
            "cites": 23,
            "dl": 0,
            "dl_52": 0,
            "dl_6": 0
        },
        "bibtex": "\r\n@inproceedings{Miller:2001:HHR:874075.876403,\n author = {Miller, Ethan L. and Brandt, Scott A. and Long, Darrell D. E.},\n title = {HeRMES: High-Performance Reliable MRAM-Enabled Storage},\n booktitle = {Proceedings of the Eighth Workshop on Hot Topics in Operating Systems},\n series = {HOTOS '01},\n year = {2001},\n pages = {95--},\n url = {http://dl.acm.org/citation.cfm?id=874075.876403},\n acmid = {876403},\n publisher = {IEEE Computer Society},\n address = {Washington, DC, USA},\n} \r\n",
        "key": "876403",
        "pub_year": "2001",
        "text": "Ethan L. Miller , Scott A. Brandt , Darrell D. E. Long, HeRMES: High-Performance Reliable MRAM-Enabled Storage, Proceedings of the Eighth Workshop on Hot Topics in Operating Systems, p.95, May 20-22, 2001"
    },
    "944684": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "944684",
        "bib_stats": {
            "cites": 25,
            "dl": 1,
            "dl_52": 25,
            "dl_6": 1
        },
        "key": "944684",
        "text": "Chanik Park , Jaeyu Seo , Sunghwan Bae , Hyojun Kim , Shinhan Kim , Bumsoo Kim, A low-cost memory architecture with NAND XIP for mobile embedded systems, Proceedings of the 1st IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis, October 01-03, 2003, Newport Beach, CA, USA"
    },
    "956679": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "956679",
        "bib_stats": {
            "cites": 39,
            "dl": 807,
            "dl_52": 22,
            "dl_6": 5
        },
        "bibtex": "\r\n@inproceedings{Wu:2003:ERI:956676.956679,\n author = {Wu, Chin-Hsien and Chang, Li-Pin and Kuo, Tei-Wei},\n title = {An Efficient R-tree Implementation over Flash-memory Storage Systems},\n booktitle = {Proceedings of the 11th ACM International Symposium on Advances in Geographic Information Systems},\n series = {GIS '03},\n year = {2003},\n isbn = {1-58113-730-3},\n location = {New Orleans, Louisiana, USA},\n pages = {17--24},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/956676.956679},\n doi = {10.1145/956676.956679},\n acmid = {956679},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {GIS, R-tree, embedded systems, flash memory, spatial index structures, storage systems},\n} \r\n",
        "key": "956679",
        "pub_year": "2003",
        "text": "Chin-Hsien Wu , Li-Pin Chang , Tei-Wei Kuo, An efficient R-tree implementation over flash-memory storage systems, Proceedings of the 11th ACM international symposium on Advances in geographic information systems, p.17-24, November 07-08, 2003, New Orleans, Louisiana, USA"
    },
    "988378": {
        "abstract": "\r\n\t\t\t\t\t\r\n                            ",
        "acm_key": "988378",
        "bib_stats": {
            "cites": 36,
            "dl": 218,
            "dl_52": 6,
            "dl_6": 3
        },
        "bibtex": "\r\n@article{Atkinson:1982:PAP:988376.988378,\n author = {Atkinson, Malcolm and Chisholm, Ken and Cockshott, Paul},\n title = {PS-algol: An Algol with a Persistent Heap},\n journal = {SIGPLAN Not.},\n issue_date = {July 1982},\n volume = {17},\n number = {7},\n month = jul,\n year = {1982},\n issn = {0362-1340},\n pages = {24--31},\n numpages = {8},\n url = {http://doi.acm.org/10.1145/988376.988378},\n doi = {10.1145/988376.988378},\n acmid = {988378},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Algol, database, heap, pointer},\n} \r\n",
        "key": "988378",
        "pub_year": "1982",
        "text": "Malcolm Atkinson , Ken Chisholm , Paul Cockshott, PS-algol: an algol with a persistent heap, ACM SIGPLAN Notices, v.17 n.7, July 1982  \u00a0[doi>"
    },
    "A. Ban. \"Flash file system,\" United States Patent, no. 5,404,485, April, 1995.": {
        "acm_key": null,
        "key": "A. Ban. \"Flash file system,\" United States Patent, no. 5,404,485, April, 1995.",
        "text": "A. Ban. \"Flash file system,\" United States Patent, no. 5,404,485, April, 1995."
    },
    "A. Ban. Flash file system. United States Patent, No. 5,404,485, April (1995).": {
        "acm_key": null,
        "key": "A. Ban. Flash file system. United States Patent, No. 5,404,485, April (1995).",
        "text": "A. Ban. Flash file system. United States Patent, No. 5,404,485, April (1995)."
    },
    "A.L. Lacaita, \"Phase change memories: State-of-the-art, challenges and perspectives,\" Solid-State Electronics, vol. 50, no. 1, pp. 24--31, Jan. 2006.": {
        "acm_key": null,
        "key": "A.L. Lacaita, \"Phase change memories: State-of-the-art, challenges and perspectives,\" Solid-State Electronics, vol. 50, no. 1, pp. 24--31, Jan. 2006.",
        "text": "A.L. Lacaita, \"Phase change memories: State-of-the-art, challenges and perspectives,\" Solid-State Electronics, vol. 50, no. 1, pp. 24--31, Jan. 2006."
    },
    "ATKINSON, M. P., BAILEY, P. J., CHISHOLM, K. J., COCKSHOTT, P. W., AND MORRISON, R. An approach to persistent programming. The Computer Journal 26, 4 (Nov. 1983), 360-365.": {
        "acm_key": null,
        "key": "ATKINSON, M. P., BAILEY, P. J., CHISHOLM, K. J., COCKSHOTT, P. W., AND MORRISON, R. An approach to persistent programming. The Computer Journal 26, 4 (Nov. 1983), 360-365.",
        "text": "ATKINSON, M. P., BAILEY, P. J., CHISHOLM, K. J., COCKSHOTT, P. W., AND MORRISON, R. An approach to persistent programming. The Computer Journal 26, 4 (Nov. 1983), 360-365."
    },
    "Aleph One Company, \"Yet Another Flash Filing System\".": {
        "acm_key": null,
        "key": "Aleph One Company, \"Yet Another Flash Filing System\".",
        "text": "Aleph One Company, \"Yet Another Flash Filing System\"."
    },
    "Alex Schepeljanski. 2016. AS SSD Benchmark. http://www.snapfiles.com/get/ssdbenchmark.html.": {
        "acm_key": null,
        "key": "Alex Schepeljanski. 2016. AS SSD Benchmark. http://www.snapfiles.com/get/ssdbenchmark.html.",
        "text": "Alex Schepeljanski. 2016. AS SSD Benchmark. http://www.snapfiles.com/get/ssdbenchmark.html."
    },
    "Amir Ban, Flash File System, United States Patent, No. 5,404,485, 1995.": {
        "acm_key": null,
        "key": "Amir Ban, Flash File System, United States Patent, No. 5,404,485, 1995.",
        "text": "Amir Ban, Flash File System, United States Patent, No. 5,404,485, 1995."
    },
    "Amir Ban. 1995. Flash file system. (April 1995). United States Patent No. 5,404,485.": {
        "acm_key": null,
        "key": "Amir Ban. 1995. Flash file system. (April 1995). United States Patent No. 5,404,485.",
        "text": "Amir Ban. 1995. Flash file system. (April 1995). United States Patent No. 5,404,485."
    },
    "Amir Ban. 1999. Flash file system optimized for page-mode flash technologies. (August 1999). United States Patent No. 5,937,425.": {
        "acm_key": null,
        "key": "Amir Ban. 1999. Flash file system optimized for page-mode flash technologies. (August 1999). United States Patent No. 5,937,425.",
        "text": "Amir Ban. 1999. Flash file system optimized for page-mode flash technologies. (August 1999). United States Patent No. 5,937,425."
    },
    "Amir Ban. Flash file system optimized for page-mode flash technologies, 1999. United States Patent, no. 5,937,425.": {
        "acm_key": null,
        "key": "Amir Ban. Flash file system optimized for page-mode flash technologies, 1999. United States Patent, no. 5,937,425.",
        "text": "Amir Ban. Flash file system optimized for page-mode flash technologies, 1999. United States Patent, no. 5,937,425."
    },
    "Annie Foong, Bryan Veal, and Frank Hady. Towards SSD-ready enterprise platforms. In Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)<i>Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)</i>, Singapore, September 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Singapore, September 2010.": {
        "acm_key": null,
        "key": "Annie Foong, Bryan Veal, and Frank Hady. Towards SSD-ready enterprise platforms. In Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)<i>Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)</i>, Singapore, September 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Singapore, September 2010.",
        "text": "Annie Foong, Bryan Veal, and Frank Hady. Towards SSD-ready enterprise platforms. In Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)<i>Proceedings of the 1st International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS)</i>, Singapore, September 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Singapore, September 2010."
    },
    "B. Cully, J. Wires, D. Meyer, K. Jamieson, K. Fraser, T. Deegan, D. Stodden, G. Lefebvre, D. Ferstay, and A. Warfield. Strata: Scalable High-performance Storage on Virtualized Non-volatile Memory. In Proceedings of the 12th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 12th USENIX Conference on File and Storage Technologies,</i> FAST'14, pages 17--31, 2014. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'14, pages 17--31, 2014.": {
        "acm_key": null,
        "key": "B. Cully, J. Wires, D. Meyer, K. Jamieson, K. Fraser, T. Deegan, D. Stodden, G. Lefebvre, D. Ferstay, and A. Warfield. Strata: Scalable High-performance Storage on Virtualized Non-volatile Memory. In Proceedings of the 12th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 12th USENIX Conference on File and Storage Technologies,</i> FAST'14, pages 17--31, 2014. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'14, pages 17--31, 2014.",
        "text": "B. Cully, J. Wires, D. Meyer, K. Jamieson, K. Fraser, T. Deegan, D. Stodden, G. Lefebvre, D. Ferstay, and A. Warfield. Strata: Scalable High-performance Storage on Virtualized Non-volatile Memory. In Proceedings of the 12th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 12th USENIX Conference on File and Storage Technologies,</i> FAST'14, pages 17--31, 2014. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'14, pages 17--31, 2014."
    },
    "B. Park, S. Cho, M. Park, S. Park, Y. Lee, M. K. Cho, K.-O. Ahn, G. Bae, and S. Park. 2012. Challenges and limitations of NAND flash memory devices based on floating gates. In Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS). 420--423.": {
        "acm_key": null,
        "key": "B. Park, S. Cho, M. Park, S. Park, Y. Lee, M. K. Cho, K.-O. Ahn, G. Bae, and S. Park. 2012. Challenges and limitations of NAND flash memory devices based on floating gates. In Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS). 420--423.",
        "text": "B. Park, S. Cho, M. Park, S. Park, Y. Lee, M. K. Cho, K.-O. Ahn, G. Bae, and S. Park. 2012. Challenges and limitations of NAND flash memory devices based on floating gates. In Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS). 420--423."
    },
    "BRAHNMATH, K. J. Optimizing orthogonal persistence for Java. Master's thesis, Purdue University, May 199g.": {
        "acm_key": null,
        "key": "BRAHNMATH, K. J. Optimizing orthogonal persistence for Java. Master's thesis, Purdue University, May 199g.",
        "text": "BRAHNMATH, K. J. Optimizing orthogonal persistence for Java. Master's thesis, Purdue University, May 199g."
    },
    "Ban A (1995) Flash file system. United States Patent, no 5,404,485.": {
        "acm_key": null,
        "key": "Ban A (1995) Flash file system. United States Patent, no 5,404,485.",
        "text": "Ban A (1995) Flash file system. United States Patent, no 5,404,485."
    },
    "Ban A (1999) Flash file system optimized for page-mode flash technologies. United States Patent, No 5,937,425": {
        "acm_key": null,
        "key": "Ban A (1999) Flash file system optimized for page-mode flash technologies. United States Patent, No 5,937,425",
        "text": "Ban A (1999) Flash file system optimized for page-mode flash technologies. United States Patent, No 5,937,425"
    },
    "Ban, A., Flash file system. United States Patent. v5. 404-485.": {
        "acm_key": null,
        "key": "Ban, A., Flash file system. United States Patent. v5. 404-485.",
        "text": "Ban, A., Flash file system. United States Patent. v5. 404-485."
    },
    "Ban, A.<scp>Ban, A.</scp> 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425.": {
        "acm_key": null,
        "key": "Ban, A.<scp>Ban, A.</scp> 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425.",
        "text": "Ban, A.<scp>Ban, A.</scp> 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1999. Flash file system optimized for page-mode flash technologies. United States Patent 5,937,425."
    },
    "Bum soo Kim and Gui young Lee. Method of driving remapping in flash memory and flash memory architecture suitable therefore, 2002. United States Patent, no. 6,381,176": {
        "acm_key": null,
        "key": "Bum soo Kim and Gui young Lee. Method of driving remapping in flash memory and flash memory architecture suitable therefore, 2002. United States Patent, no. 6,381,176",
        "text": "Bum soo Kim and Gui young Lee. Method of driving remapping in flash memory and flash memory architecture suitable therefore, 2002. United States Patent, no. 6,381,176"
    },
    "C. Manning. YAFFS: Yet Another Flash File System. http://www.aleph1.co.uk/yaffs, 2004.": {
        "acm_key": null,
        "key": "C. Manning. YAFFS: Yet Another Flash File System. http://www.aleph1.co.uk/yaffs, 2004.",
        "text": "C. Manning. YAFFS: Yet Another Flash File System. http://www.aleph1.co.uk/yaffs, 2004."
    },
    "C. Sangyeun and L. Hyunjin, \"Flip-n-write: A Simple Deterministic Technique to Improve PRAM Write Performance, Energy and Endurance,\" in IEEE MICRO<i>IEEE MICRO</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009.": {
        "acm_key": null,
        "key": "C. Sangyeun and L. Hyunjin, \"Flip-n-write: A Simple Deterministic Technique to Improve PRAM Write Performance, Energy and Endurance,\" in IEEE MICRO<i>IEEE MICRO</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009.",
        "text": "C. Sangyeun and L. Hyunjin, \"Flip-n-write: A Simple Deterministic Technique to Improve PRAM Write Performance, Energy and Endurance,\" in IEEE MICRO<i>IEEE MICRO</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009."
    },
    "C. Youngdon, S. Ickhyun, P. Mu-Hui, and et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC<i>ISSCC</i>, 2012, pp. 46--48. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 46--48.": {
        "acm_key": null,
        "key": "C. Youngdon, S. Ickhyun, P. Mu-Hui, and et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC<i>ISSCC</i>, 2012, pp. 46--48. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 46--48.",
        "text": "C. Youngdon, S. Ickhyun, P. Mu-Hui, and et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC<i>ISSCC</i>, 2012, pp. 46--48. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 46--48."
    },
    "CHARLES MANNING. How YAFFS Works. 2010.": {
        "acm_key": null,
        "key": "CHARLES MANNING. How YAFFS Works. 2010.",
        "text": "CHARLES MANNING. How YAFFS Works. 2010."
    },
    "Chen, S., Gibbons, P. B., and Nath, S. 2011. Rethinking database algorithms for phase change memory. In Proceedings of the 5th Biennial Conference on Innovative Data Sysytems Research (CIDR'11), 21--31.": {
        "acm_key": null,
        "key": "Chen, S., Gibbons, P. B., and Nath, S. 2011. Rethinking database algorithms for phase change memory. In Proceedings of the 5th Biennial Conference on Innovative Data Sysytems Research (CIDR'11), 21--31.",
        "text": "Chen, S., Gibbons, P. B., and Nath, S. 2011. Rethinking database algorithms for phase change memory. In Proceedings of the 5th Biennial Conference on Innovative Data Sysytems Research (CIDR'11), 21--31."
    },
    "Compact Flash Association, \"Compact Flash#8482; 1.4 Specification,\" 1998.": {
        "acm_key": null,
        "key": "Compact Flash Association, \"Compact Flash#8482; 1.4 Specification,\" 1998.",
        "text": "Compact Flash Association, \"Compact Flash#8482; 1.4 Specification,\" 1998."
    },
    "Corporation Intel. 1998. Understanding the flash translation layer(ftl) specification. www.intel.com/design/flcomp/applnots/297816.htm.": {
        "acm_key": null,
        "key": "Corporation Intel. 1998. Understanding the flash translation layer(ftl) specification. www.intel.com/design/flcomp/applnots/297816.htm.",
        "text": "Corporation Intel. 1998. Understanding the flash translation layer(ftl) specification. www.intel.com/design/flcomp/applnots/297816.htm."
    },
    "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams, \"The missing memristor found,\" Nature<i>Nature</i>, vol. 453, no. 7191, pp. 80--83, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. 453, no. 7191, pp. 80--83, 2008.": {
        "acm_key": null,
        "key": "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams, \"The missing memristor found,\" Nature<i>Nature</i>, vol. 453, no. 7191, pp. 80--83, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. 453, no. 7191, pp. 80--83, 2008.",
        "text": "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams, \"The missing memristor found,\" Nature<i>Nature</i>, vol. 453, no. 7191, pp. 80--83, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. 453, no. 7191, pp. 80--83, 2008."
    },
    "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams. The missing memristor found. Nature<i>Nature</i>, 453(7191):80--83, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 453(7191):80--83, May 2008.": {
        "acm_key": null,
        "key": "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams. The missing memristor found. Nature<i>Nature</i>, 453(7191):80--83, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 453(7191):80--83, May 2008.",
        "text": "D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams. The missing memristor found. Nature<i>Nature</i>, 453(7191):80--83, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 453(7191):80--83, May 2008."
    },
    "D. H. Kang, et al., \"Two-bit Cell Operation in Diode-Switch Phase Change Memory Cells with 90nm Technology,\" IEEE Symposium on VLSI Technology Digest of Technical Papers, pp. 98--99, 2008.": {
        "acm_key": null,
        "key": "D. H. Kang, et al., \"Two-bit Cell Operation in Diode-Switch Phase Change Memory Cells with 90nm Technology,\" IEEE Symposium on VLSI Technology Digest of Technical Papers, pp. 98--99, 2008.",
        "text": "D. H. Kang, et al., \"Two-bit Cell Operation in Diode-Switch Phase Change Memory Cells with 90nm Technology,\" IEEE Symposium on VLSI Technology Digest of Technical Papers, pp. 98--99, 2008."
    },
    "D. I. Shin, Y. J. Yu, H. S. Kim, J. W. Choi, D. Y. Jung, and H. Y. Yeom. Dynamic Interval Polling and Pipelined Post I/O Processing for Low-latency Storage Class Memory. In Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems<i>Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems</i>, HotStorage'13, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, HotStorage'13, 2013.": {
        "acm_key": null,
        "key": "D. I. Shin, Y. J. Yu, H. S. Kim, J. W. Choi, D. Y. Jung, and H. Y. Yeom. Dynamic Interval Polling and Pipelined Post I/O Processing for Low-latency Storage Class Memory. In Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems<i>Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems</i>, HotStorage'13, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, HotStorage'13, 2013.",
        "text": "D. I. Shin, Y. J. Yu, H. S. Kim, J. W. Choi, D. Y. Jung, and H. Y. Yeom. Dynamic Interval Polling and Pipelined Post I/O Processing for Low-latency Storage Class Memory. In Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems<i>Proceedings of the 5th USENIX Conference on Hot Topics in Storage and File Systems</i>, HotStorage'13, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, HotStorage'13, 2013."
    },
    "D. Ielmini. Modeling the universal set/reset characteristics of bipolar rram by field- and temperature-driven filament growth. Electron Devices, IEEE Transactions on<i>Electron Devices, IEEE Transactions on</i>, 58(12):4309--4317, Dec 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 58(12):4309--4317, Dec 2011.": {
        "acm_key": null,
        "key": "D. Ielmini. Modeling the universal set/reset characteristics of bipolar rram by field- and temperature-driven filament growth. Electron Devices, IEEE Transactions on<i>Electron Devices, IEEE Transactions on</i>, 58(12):4309--4317, Dec 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 58(12):4309--4317, Dec 2011.",
        "text": "D. Ielmini. Modeling the universal set/reset characteristics of bipolar rram by field- and temperature-driven filament growth. Electron Devices, IEEE Transactions on<i>Electron Devices, IEEE Transactions on</i>, 58(12):4309--4317, Dec 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 58(12):4309--4317, Dec 2011."
    },
    "D. J. Lee, R. A. Cernea, M. Mofidi, S. Mehrotra, E. Y. Chang, W. Y. Chien, L. Goh, J. H. Yuan, A. Mihnea, G. Samachisa, Y. Fong, D. C. Guterman, R. D. Norman, K. Sato, H. Onishi, K. Ueda, F. Noro, K. Miyamoto, M. Morita, K. Umeda, and K. Kubo, \"An 18 Mb Serial Flash EEPROM for Solid State Disk Applications,\" Digest of Technical Papers<i>Digest of Technical Papers</i>, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60.": {
        "acm_key": null,
        "key": "D. J. Lee, R. A. Cernea, M. Mofidi, S. Mehrotra, E. Y. Chang, W. Y. Chien, L. Goh, J. H. Yuan, A. Mihnea, G. Samachisa, Y. Fong, D. C. Guterman, R. D. Norman, K. Sato, H. Onishi, K. Ueda, F. Noro, K. Miyamoto, M. Morita, K. Umeda, and K. Kubo, \"An 18 Mb Serial Flash EEPROM for Solid State Disk Applications,\" Digest of Technical Papers<i>Digest of Technical Papers</i>, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60.",
        "text": "D. J. Lee, R. A. Cernea, M. Mofidi, S. Mehrotra, E. Y. Chang, W. Y. Chien, L. Goh, J. H. Yuan, A. Mihnea, G. Samachisa, Y. Fong, D. C. Guterman, R. D. Norman, K. Sato, H. Onishi, K. Ueda, F. Noro, K. Miyamoto, M. Morita, K. Umeda, and K. Kubo, \"An 18 Mb Serial Flash EEPROM for Solid State Disk Applications,\" Digest of Technical Papers<i>Digest of Technical Papers</i>, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 1994 Symposium on VLSI Circuits. Honolulu, June 9-11, 1994, pp. 59-60."
    },
    "D. Liu, T. Wang, Y. Wang, Z. Shao, Q. Zhuge, and E. Sha, \"Curling-PCM: Application-specific wear leveling for phase change memory based embedded systems,\" in ASP-DAC<i>ASP-DAC</i>, 2013, pp. 279--284. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013, pp. 279--284.": {
        "acm_key": null,
        "key": "D. Liu, T. Wang, Y. Wang, Z. Shao, Q. Zhuge, and E. Sha, \"Curling-PCM: Application-specific wear leveling for phase change memory based embedded systems,\" in ASP-DAC<i>ASP-DAC</i>, 2013, pp. 279--284. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013, pp. 279--284.",
        "text": "D. Liu, T. Wang, Y. Wang, Z. Shao, Q. Zhuge, and E. Sha, \"Curling-PCM: Application-specific wear leveling for phase change memory based embedded systems,\" in ASP-DAC<i>ASP-DAC</i>, 2013, pp. 279--284. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013, pp. 279--284."
    },
    "D. Meister and A. Brinkmann. dedupv1: Improving Deduplication Throughput using Solid State Drives (SSD). In Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,<i>Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,</i> pages 1--6. IEEE, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t pages 1--6. IEEE, 2010.": {
        "acm_key": null,
        "key": "D. Meister and A. Brinkmann. dedupv1: Improving Deduplication Throughput using Solid State Drives (SSD). In Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,<i>Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,</i> pages 1--6. IEEE, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t pages 1--6. IEEE, 2010.",
        "text": "D. Meister and A. Brinkmann. dedupv1: Improving Deduplication Throughput using Solid State Drives (SSD). In Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,<i>Mass Storage Systems and Technologies (MSST), 2010 IEEE 26th Symposium on,</i> pages 1--6. IEEE, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t pages 1--6. IEEE, 2010."
    },
    "D.-H. Kang, J.-H. Lee, J. Kong, D. Ha et al.<i>et al.</i>, \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in , \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in Proceedings of the Symposium on VLSI Technology<i>Proceedings of the Symposium on VLSI Technology</i>, 2008, pp. 98--99. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2008, pp. 98--99.": {
        "acm_key": null,
        "key": "D.-H. Kang, J.-H. Lee, J. Kong, D. Ha et al.<i>et al.</i>, \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in , \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in Proceedings of the Symposium on VLSI Technology<i>Proceedings of the Symposium on VLSI Technology</i>, 2008, pp. 98--99. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2008, pp. 98--99.",
        "text": "D.-H. Kang, J.-H. Lee, J. Kong, D. Ha et al.<i>et al.</i>, \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in , \"Two-bit cell operation in diode-switch phase change memory cells with 90nm technology,\" in Proceedings of the Symposium on VLSI Technology<i>Proceedings of the Symposium on VLSI Technology</i>, 2008, pp. 98--99. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2008, pp. 98--99."
    },
    "Daniele Ielmini, Simone Lavizzari, Deepak Sharma, and Andrea L. Lacaita. 2007. Physical interpretation, modeling and impact on phase change memory (PCM) reliability of resistance drift due to chalcogenide structural relaxation. In Proceedings of the International Electron Devices Meeting (IEDM'07). 939--942.": {
        "acm_key": null,
        "key": "Daniele Ielmini, Simone Lavizzari, Deepak Sharma, and Andrea L. Lacaita. 2007. Physical interpretation, modeling and impact on phase change memory (PCM) reliability of resistance drift due to chalcogenide structural relaxation. In Proceedings of the International Electron Devices Meeting (IEDM'07). 939--942.",
        "text": "Daniele Ielmini, Simone Lavizzari, Deepak Sharma, and Andrea L. Lacaita. 2007. Physical interpretation, modeling and impact on phase change memory (PCM) reliability of resistance drift due to chalcogenide structural relaxation. In Proceedings of the International Electron Devices Meeting (IEDM'07). 939--942."
    },
    "Datalight. 2011. Datalight: software for risk-free mobile data. http://www.datalight.com/solutions/linux-flash-file-system/performance-hardware-managed-media.": {
        "acm_key": null,
        "key": "Datalight. 2011. Datalight: software for risk-free mobile data. http://www.datalight.com/solutions/linux-flash-file-system/performance-hardware-managed-media.",
        "text": "Datalight. 2011. Datalight: software for risk-free mobile data. http://www.datalight.com/solutions/linux-flash-file-system/performance-hardware-managed-media."
    },
    "Datasheet of MT29F32G08CBABA. Micro Technology 2008": {
        "acm_key": null,
        "key": "Datasheet of MT29F32G08CBABA. Micro Technology 2008",
        "text": "Datasheet of MT29F32G08CBABA. Micro Technology 2008"
    },
    "Datasheet: NetApp Flash Cache. NetApp. DS-2811-1211.": {
        "acm_key": null,
        "key": "Datasheet: NetApp Flash Cache. NetApp. DS-2811-1211.",
        "text": "Datasheet: NetApp Flash Cache. NetApp. DS-2811-1211."
    },
    "Debnath B, Sengupta S, Li J (2010) ChunkStash: speeding up inline storage deduplication using flash memory. In: Proceeding of USENIX conference on file and storage technologies (FAST)": {
        "acm_key": null,
        "key": "Debnath B, Sengupta S, Li J (2010) ChunkStash: speeding up inline storage deduplication using flash memory. In: Proceeding of USENIX conference on file and storage technologies (FAST)",
        "text": "Debnath B, Sengupta S, Li J (2010) ChunkStash: speeding up inline storage deduplication using flash memory. In: Proceeding of USENIX conference on file and storage technologies (FAST)"
    },
    "Duckhoi Koo and Dongkun Shin. 2009. Adaptive log block mapping scheme for log buffer-based FTL (flash translation layer). In Proceedings of the International Workshop on Software Support for Portable Storage.": {
        "acm_key": null,
        "key": "Duckhoi Koo and Dongkun Shin. 2009. Adaptive log block mapping scheme for log buffer-based FTL (flash translation layer). In Proceedings of the International Workshop on Software Support for Portable Storage.",
        "text": "Duckhoi Koo and Dongkun Shin. 2009. Adaptive log block mapping scheme for log buffer-based FTL (flash translation layer). In Proceedings of the International Workshop on Software Support for Portable Storage."
    },
    "E. Lee, S. Yoo, J.-E. Jang, and H. Bahn. Shortcut-JFS: A Write Efficient Journaling File System for Phase Change Memory. In Proc. of the IEEE MSST<i>Proc. of the IEEE MSST</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012.": {
        "acm_key": null,
        "key": "E. Lee, S. Yoo, J.-E. Jang, and H. Bahn. Shortcut-JFS: A Write Efficient Journaling File System for Phase Change Memory. In Proc. of the IEEE MSST<i>Proc. of the IEEE MSST</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012.",
        "text": "E. Lee, S. Yoo, J.-E. Jang, and H. Bahn. Shortcut-JFS: A Write Efficient Journaling File System for Phase Change Memory. In Proc. of the IEEE MSST<i>Proc. of the IEEE MSST</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012."
    },
    "E. Spanjer. \"Enterprise SSD - the next killer app,\" http://www.flashmemorysummit.com/English/Collaterals/Presentations/2007/20070807_Issues_Spanjer.pdf, 2007.": {
        "acm_key": null,
        "key": "E. Spanjer. \"Enterprise SSD - the next killer app,\" http://www.flashmemorysummit.com/English/Collaterals/Presentations/2007/20070807_Issues_Spanjer.pdf, 2007.",
        "text": "E. Spanjer. \"Enterprise SSD - the next killer app,\" http://www.flashmemorysummit.com/English/Collaterals/Presentations/2007/20070807_Issues_Spanjer.pdf, 2007."
    },
    "ELPHINSTONE, K., RUSSELL, S., HEISER, G., AND LIEDTKE, J. Supporting persistent object systems in a single address space. In Connor and Nettles {27}, pp. 111-119.": {
        "acm_key": null,
        "key": "ELPHINSTONE, K., RUSSELL, S., HEISER, G., AND LIEDTKE, J. Supporting persistent object systems in a single address space. In Connor and Nettles {27}, pp. 111-119.",
        "text": "ELPHINSTONE, K., RUSSELL, S., HEISER, G., AND LIEDTKE, J. Supporting persistent object systems in a single address space. In Connor and Nettles {27}, pp. 111-119."
    },
    "F. Bedeschi et al., \"A multi-level-cell bipolar-selected phase-change memory\", in Proceedings of the IEEE International Solid-State Circuits Conference, Feb. 2008, pp. 428--625.": {
        "acm_key": null,
        "key": "F. Bedeschi et al., \"A multi-level-cell bipolar-selected phase-change memory\", in Proceedings of the IEEE International Solid-State Circuits Conference, Feb. 2008, pp. 428--625.",
        "text": "F. Bedeschi et al., \"A multi-level-cell bipolar-selected phase-change memory\", in Proceedings of the IEEE International Solid-State Circuits Conference, Feb. 2008, pp. 428--625."
    },
    "F. Bedeschi, R. Fackenthal, C. Resta, E. M. Donze, M. Jagasivamani, E. C. Buda, F. Pellizzer, D. W. Chow, A. Cabrini, G. Calvi, et al. A bipolar-selected phase change memory featuring multi-level cell storage. IEEE Journal of Solid-State Circuits, 2009.": {
        "acm_key": null,
        "key": "F. Bedeschi, R. Fackenthal, C. Resta, E. M. Donze, M. Jagasivamani, E. C. Buda, F. Pellizzer, D. W. Chow, A. Cabrini, G. Calvi, et al. A bipolar-selected phase change memory featuring multi-level cell storage. IEEE Journal of Solid-State Circuits, 2009.",
        "text": "F. Bedeschi, R. Fackenthal, C. Resta, E. M. Donze, M. Jagasivamani, E. C. Buda, F. Pellizzer, D. W. Chow, A. Cabrini, G. Calvi, et al. A bipolar-selected phase change memory featuring multi-level cell storage. IEEE Journal of Solid-State Circuits, 2009."
    },
    "F. Sala, R. Gabrys, and L. Dolecek. Dynamic threshold schemes for multi-level non-volatile memories. IEEE Transactions on Communications, 61(7):2624--2634, July 2013.": {
        "acm_key": null,
        "key": "F. Sala, R. Gabrys, and L. Dolecek. Dynamic threshold schemes for multi-level non-volatile memories. IEEE Transactions on Communications, 61(7):2624--2634, July 2013.",
        "text": "F. Sala, R. Gabrys, and L. Dolecek. Dynamic threshold schemes for multi-level non-volatile memories. IEEE Transactions on Communications, 61(7):2624--2634, July 2013."
    },
    "F. Yeung and et al. ge2sb2te5<i>ge2sb2te5</i> confined structures and integration of 64mb phase-change random access memory.  confined structures and integration of 64mb phase-change random access memory. Japanese Journal of Applied Physics<i>Japanese Journal of Applied Physics</i>, pages 2691--2695, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 2691--2695, 2005.": {
        "acm_key": null,
        "key": "F. Yeung and et al. ge2sb2te5<i>ge2sb2te5</i> confined structures and integration of 64mb phase-change random access memory.  confined structures and integration of 64mb phase-change random access memory. Japanese Journal of Applied Physics<i>Japanese Journal of Applied Physics</i>, pages 2691--2695, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 2691--2695, 2005.",
        "text": "F. Yeung and et al. ge2sb2te5<i>ge2sb2te5</i> confined structures and integration of 64mb phase-change random access memory.  confined structures and integration of 64mb phase-change random access memory. Japanese Journal of Applied Physics<i>Japanese Journal of Applied Physics</i>, pages 2691--2695, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 2691--2695, 2005."
    },
    "File system support on Multi Level Cell (MLC) flash in open source.<i>File system support on Multi Level Cell (MLC) flash in open source.</i> 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2008.": {
        "acm_key": null,
        "key": "File system support on Multi Level Cell (MLC) flash in open source.<i>File system support on Multi Level Cell (MLC) flash in open source.</i> 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2008.",
        "text": "File system support on Multi Level Cell (MLC) flash in open source.<i>File system support on Multi Level Cell (MLC) flash in open source.</i> 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2008."
    },
    "Flash File System. US Patent 540,448. Intel<i>Intel</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t.": {
        "acm_key": null,
        "key": "Flash File System. US Patent 540,448. Intel<i>Intel</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t.",
        "text": "Flash File System. US Patent 540,448. Intel<i>Intel</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t."
    },
    "FlashCache. https://github.com/facebook/flashcache.": {
        "acm_key": null,
        "key": "FlashCache. https://github.com/facebook/flashcache.",
        "text": "FlashCache. https://github.com/facebook/flashcache."
    },
    "Frankie F. Roohparvar. 2007. Single level cell programming in a multiple level cell non-volatile memory device. U.S. Patent 20070133249 A1.": {
        "acm_key": null,
        "key": "Frankie F. Roohparvar. 2007. Single level cell programming in a multiple level cell non-volatile memory device. U.S. Patent 20070133249 A1.",
        "text": "Frankie F. Roohparvar. 2007. Single level cell programming in a multiple level cell non-volatile memory device. U.S. Patent 20070133249 A1."
    },
    "Fusion-IO. ioTurbine. http://www.fusionio.com/systems/ioturbine/, 2012.": {
        "acm_key": null,
        "key": "Fusion-IO. ioTurbine. http://www.fusionio.com/systems/ioturbine/, 2012.",
        "text": "Fusion-IO. ioTurbine. http://www.fusionio.com/systems/ioturbine/, 2012."
    },
    "H. Pozidis, N. Papandreou, A. Sebastian, T. Mittelholzer, M. BrightSky, C. Lam, and E. Eleftheriou. 2012. A framework for reliability assessment in multilevel phase-change memory. In IEEE International Memory Workshop.": {
        "acm_key": null,
        "key": "H. Pozidis, N. Papandreou, A. Sebastian, T. Mittelholzer, M. BrightSky, C. Lam, and E. Eleftheriou. 2012. A framework for reliability assessment in multilevel phase-change memory. In IEEE International Memory Workshop.",
        "text": "H. Pozidis, N. Papandreou, A. Sebastian, T. Mittelholzer, M. BrightSky, C. Lam, and E. Eleftheriou. 2012. A framework for reliability assessment in multilevel phase-change memory. In IEEE International Memory Workshop."
    },
    "H. S. P. Wong, S. Raoux, S. Kim, J. Liang et al<i>et al</i>., \"Phase Change Memory,\" in ., \"Phase Change Memory,\" in Proc. of the IEEE<i>Proc. of the IEEE</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.": {
        "acm_key": null,
        "key": "H. S. P. Wong, S. Raoux, S. Kim, J. Liang et al<i>et al</i>., \"Phase Change Memory,\" in ., \"Phase Change Memory,\" in Proc. of the IEEE<i>Proc. of the IEEE</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.",
        "text": "H. S. P. Wong, S. Raoux, S. Kim, J. Liang et al<i>et al</i>., \"Phase Change Memory,\" in ., \"Phase Change Memory,\" in Proc. of the IEEE<i>Proc. of the IEEE</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010."
    },
    "H. Shim, S.-S. Lee, B. Kim, et al. Highly reliable 26nm 64Gb MLC E2NAND (Embedded-ECC & Enhanced-efficiency) flash memory with MSP (Memory Signal Processing) controller. In VLSI Technology (VLSIT), 2011 Symposium on, pages 216--217, 2011.": {
        "acm_key": null,
        "key": "H. Shim, S.-S. Lee, B. Kim, et al. Highly reliable 26nm 64Gb MLC E2NAND (Embedded-ECC & Enhanced-efficiency) flash memory with MSP (Memory Signal Processing) controller. In VLSI Technology (VLSIT), 2011 Symposium on, pages 216--217, 2011.",
        "text": "H. Shim, S.-S. Lee, B. Kim, et al. Highly reliable 26nm 64Gb MLC E2NAND (Embedded-ECC & Enhanced-efficiency) flash memory with MSP (Memory Signal Processing) controller. In VLSI Technology (VLSIT), 2011 Symposium on, pages 216--217, 2011."
    },
    "HAINING, T. R., AND LONG, D. D. E. Management policies for non-volatile write caches. In Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99<i>Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t.": {
        "acm_key": null,
        "key": "HAINING, T. R., AND LONG, D. D. E. Management policies for non-volatile write caches. In Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99<i>Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t.",
        "text": "HAINING, T. R., AND LONG, D. D. E. Management policies for non-volatile write caches. In Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99<i>Proceedings of the 1999 IEEE International Performance, Computing and Communications Conference - IPCCC '99</i>. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t."
    },
    "Han-joon Kim, S.-g. L., An effective flash memory manager for reliable flash memory space management<i>An effective flash memory manager for reliable flash memory space management</i>, in , in IEICE Transactions on Information and Systems.<i>IEICE Transactions on Information and Systems.</i> 2002. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2002.": {
        "acm_key": null,
        "key": "Han-joon Kim, S.-g. L., An effective flash memory manager for reliable flash memory space management<i>An effective flash memory manager for reliable flash memory space management</i>, in , in IEICE Transactions on Information and Systems.<i>IEICE Transactions on Information and Systems.</i> 2002. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2002.",
        "text": "Han-joon Kim, S.-g. L., An effective flash memory manager for reliable flash memory space management<i>An effective flash memory manager for reliable flash memory space management</i>, in , in IEICE Transactions on Information and Systems.<i>IEICE Transactions on Information and Systems.</i> 2002. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2002."
    },
    "Hans Olav Norheim. 2008. How Flash Memory Changes the DBMS World. Retrieved from http://www.hansolav.net/blog/content/binary/HowFlashMemory.pdf.": {
        "acm_key": null,
        "key": "Hans Olav Norheim. 2008. How Flash Memory Changes the DBMS World. Retrieved from http://www.hansolav.net/blog/content/binary/HowFlashMemory.pdf.",
        "text": "Hans Olav Norheim. 2008. How Flash Memory Changes the DBMS World. Retrieved from http://www.hansolav.net/blog/content/binary/HowFlashMemory.pdf."
    },
    "Hybrid Hard Drives with Non-Volatile Flash and Longhorn. http://www.samsung.com/Products/ HardDiskDrive/news/HardDiskDrive_ 20050425_0000117556.htm.": {
        "acm_key": null,
        "key": "Hybrid Hard Drives with Non-Volatile Flash and Longhorn. http://www.samsung.com/Products/ HardDiskDrive/news/HardDiskDrive_ 20050425_0000117556.htm.",
        "text": "Hybrid Hard Drives with Non-Volatile Flash and Longhorn. http://www.samsung.com/Products/ HardDiskDrive/news/HardDiskDrive_ 20050425_0000117556.htm."
    },
    "Hynix Semiconductor Inc. 2006. Hynix NAND flash data sheet. http://www.hynix.com/datasheet/pdf/flash/HY27UH08AG(5_D)M (Rev0.6).pdf.": {
        "acm_key": null,
        "key": "Hynix Semiconductor Inc. 2006. Hynix NAND flash data sheet. http://www.hynix.com/datasheet/pdf/flash/HY27UH08AG(5_D)M (Rev0.6).pdf.",
        "text": "Hynix Semiconductor Inc. 2006. Hynix NAND flash data sheet. http://www.hynix.com/datasheet/pdf/flash/HY27UH08AG(5_D)M (Rev0.6).pdf."
    },
    "H\u00e4rder, T., et al.: Towards flash disk use in databases--keeping performance while saving energy? In: BTW. LNI, vol. 144, pp. 167-186 (2009).": {
        "acm_key": null,
        "key": "H\u00e4rder, T., et al.: Towards flash disk use in databases--keeping performance while saving energy? In: BTW. LNI, vol. 144, pp. 167-186 (2009).",
        "text": "H\u00e4rder, T., et al.: Towards flash disk use in databases--keeping performance while saving energy? In: BTW. LNI, vol. 144, pp. 167-186 (2009)."
    },
    "INTEL CORPORATION. Understanding the Flash Translation Layer (FTL) Specification. 1998.": {
        "acm_key": null,
        "key": "INTEL CORPORATION. Understanding the Flash Translation Layer (FTL) Specification. 1998.",
        "text": "INTEL CORPORATION. Understanding the Flash Translation Layer (FTL) Specification. 1998."
    },
    "Intel Corporation (1995). Technical Report. Ftl logger exchanging data with ftl systems.": {
        "acm_key": null,
        "key": "Intel Corporation (1995). Technical Report. Ftl logger exchanging data with ftl systems.",
        "text": "Intel Corporation (1995). Technical Report. Ftl logger exchanging data with ftl systems."
    },
    "Intel Corporation, \"FTL Logger Exchanging Data with FTL Systems\".": {
        "acm_key": null,
        "key": "Intel Corporation, \"FTL Logger Exchanging Data with FTL Systems\".",
        "text": "Intel Corporation, \"FTL Logger Exchanging Data with FTL Systems\"."
    },
    "Intel Corporation, \"Understanding the Flash Translation Layer (FTL) Specification\", 1998.": {
        "acm_key": null,
        "key": "Intel Corporation, \"Understanding the Flash Translation Layer (FTL) Specification\", 1998.",
        "text": "Intel Corporation, \"Understanding the Flash Translation Layer (FTL) Specification\", 1998."
    },
    "Intel Corporation. 2009. Understanding the flash translation layer(ftl) specification. http://developer.intel.com.": {
        "acm_key": null,
        "key": "Intel Corporation. 2009. Understanding the flash translation layer(ftl) specification. http://developer.intel.com.",
        "text": "Intel Corporation. 2009. Understanding the flash translation layer(ftl) specification. http://developer.intel.com."
    },
    "Intel Corporation: Understanding the Flash Translation Layer (FTL) Specification": {
        "acm_key": null,
        "key": "Intel Corporation: Understanding the Flash Translation Layer (FTL) Specification",
        "text": "Intel Corporation: Understanding the Flash Translation Layer (FTL) Specification"
    },
    "Intel. 1998. Understanding the Flash Translation Layer (FTL) specification. Application Note AP-684.": {
        "acm_key": null,
        "key": "Intel. 1998. Understanding the Flash Translation Layer (FTL) specification. Application Note AP-684.",
        "text": "Intel. 1998. Understanding the Flash Translation Layer (FTL) specification. Application Note AP-684."
    },
    "Intel. Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum<i>Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009.": {
        "acm_key": null,
        "key": "Intel. Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum<i>Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009.",
        "text": "Intel. Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum<i>Intel X18-M/X25-M SATA Solid State Drive - Enterprise Server/Storage Applications Product Manual Addendum</i>, 2009. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009."
    },
    "Intel. NVM Library . https://github.com/pmem/nvml.": {
        "acm_key": null,
        "key": "Intel. NVM Library . https://github.com/pmem/nvml.",
        "text": "Intel. NVM Library . https://github.com/pmem/nvml."
    },
    "Intel.<scp>Intel.</scp> 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation.": {
        "acm_key": null,
        "key": "Intel.<scp>Intel.</scp> 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation.",
        "text": "Intel.<scp>Intel.</scp> 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 1998. Understanding the Flash Translation Layer (FTL) Specification. Tech. rep., Intel Corporation."
    },
    "Ishida, K., Yasufuku, T., Miyamoto, S., Nakai, H., Takamiya, M., Sakurai, T., Takeuchi, K.: A 1.8V 30nJ adaptive program-voltage (20V) generator for 3D-integrated NAND flash SSD. In: International Solid-State Circuits Conference, pp. 238-239. IEEE, Los Alamitos (2009)": {
        "acm_key": null,
        "key": "Ishida, K., Yasufuku, T., Miyamoto, S., Nakai, H., Takamiya, M., Sakurai, T., Takeuchi, K.: A 1.8V 30nJ adaptive program-voltage (20V) generator for 3D-integrated NAND flash SSD. In: International Solid-State Circuits Conference, pp. 238-239. IEEE, Los Alamitos (2009)",
        "text": "Ishida, K., Yasufuku, T., Miyamoto, S., Nakai, H., Takamiya, M., Sakurai, T., Takeuchi, K.: A 1.8V 30nJ adaptive program-voltage (20V) generator for 3D-integrated NAND flash SSD. In: International Solid-State Circuits Conference, pp. 238-239. IEEE, Los Alamitos (2009)"
    },
    "J. Janesky. Device performance in a fully functional 800MHz DDR3 Spin Torque Magnetic Random Access Memory. In IMW<i>IMW</i>, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013.": {
        "acm_key": null,
        "key": "J. Janesky. Device performance in a fully functional 800MHz DDR3 Spin Torque Magnetic Random Access Memory. In IMW<i>IMW</i>, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013.",
        "text": "J. Janesky. Device performance in a fully functional 800MHz DDR3 Spin Torque Magnetic Random Access Memory. In IMW<i>IMW</i>, 2013. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2013."
    },
    "J. Li, K. Zhao, J. Ma, and T. Zhang, \u201c Realizing unequal error correction for NAND flash memory at minimal read latency overhead,\u201d IEEE Trans. Circuits Syst. II, Express Briefs, vol. Volume 61, no. Issue 5, pp. 354\u2013358, 2014.": {
        "acm_key": null,
        "key": "J. Li, K. Zhao, J. Ma, and T. Zhang, \u201c Realizing unequal error correction for NAND flash memory at minimal read latency overhead,\u201d IEEE Trans. Circuits Syst. II, Express Briefs, vol. Volume 61, no. Issue 5, pp. 354\u2013358, 2014.",
        "text": "J. Li, K. Zhao, J. Ma, and T. Zhang, \u201c Realizing unequal error correction for NAND flash memory at minimal read latency overhead,\u201d IEEE Trans. Circuits Syst. II, Express Briefs, vol. Volume 61, no. Issue 5, pp. 354\u2013358, 2014."
    },
    "J. Meza, Y. Luo, S. Khan, J. Zhao, Y. Xie, and O. Mutlu. A case for efficient hardware-software cooperative management of storage and memory. In Proceedings of the 5th Workshop on Energy-Efficient Design (WEED), pages 1--7, 2013.": {
        "acm_key": null,
        "key": "J. Meza, Y. Luo, S. Khan, J. Zhao, Y. Xie, and O. Mutlu. A case for efficient hardware-software cooperative management of storage and memory. In Proceedings of the 5th Workshop on Energy-Efficient Design (WEED), pages 1--7, 2013.",
        "text": "J. Meza, Y. Luo, S. Khan, J. Zhao, Y. Xie, and O. Mutlu. A case for efficient hardware-software cooperative management of storage and memory. In Proceedings of the 5th Workshop on Energy-Efficient Design (WEED), pages 1--7, 2013."
    },
    "J. Moon, J. No, S. Lee, S. Kim, S. Choi, and Y. Song. 2013. Statistical characterization of noise and interference in NAND flash memory. IEEE Trans. Circuits Syst. I: Regular Papers 60, 8 (2013), 2153--2164.": {
        "acm_key": null,
        "key": "J. Moon, J. No, S. Lee, S. Kim, S. Choi, and Y. Song. 2013. Statistical characterization of noise and interference in NAND flash memory. IEEE Trans. Circuits Syst. I: Regular Papers 60, 8 (2013), 2153--2164.",
        "text": "J. Moon, J. No, S. Lee, S. Kim, S. Choi, and Y. Song. 2013. Statistical characterization of noise and interference in NAND flash memory. IEEE Trans. Circuits Syst. I: Regular Papers 60, 8 (2013), 2153--2164."
    },
    "J. Yang, D. B. Minturn, and F. Hady. When Poll is Better Than Interrupt. In Proceedings of the 10th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 10th USENIX Conference on File and Storage Technologies,</i> FAST'12, pages 25--32, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'12, pages 25--32, 2012.": {
        "acm_key": null,
        "key": "J. Yang, D. B. Minturn, and F. Hady. When Poll is Better Than Interrupt. In Proceedings of the 10th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 10th USENIX Conference on File and Storage Technologies,</i> FAST'12, pages 25--32, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'12, pages 25--32, 2012.",
        "text": "J. Yang, D. B. Minturn, and F. Hady. When Poll is Better Than Interrupt. In Proceedings of the 10th USENIX Conference on File and Storage Technologies,<i>Proceedings of the 10th USENIX Conference on File and Storage Technologies,</i> FAST'12, pages 25--32, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t FAST'12, pages 25--32, 2012."
    },
    "J.-D. Lee, J.-H. Choi, D. Park, and K. Kim. Effects of interface trap generation and annihilation on the data retention characteristics of flash memory cells. IEEE Transactions on Device and Materials Reliability, 4(1):110--117, March 2004.": {
        "acm_key": null,
        "key": "J.-D. Lee, J.-H. Choi, D. Park, and K. Kim. Effects of interface trap generation and annihilation on the data retention characteristics of flash memory cells. IEEE Transactions on Device and Materials Reliability, 4(1):110--117, March 2004.",
        "text": "J.-D. Lee, J.-H. Choi, D. Park, and K. Kim. Effects of interface trap generation and annihilation on the data retention characteristics of flash memory cells. IEEE Transactions on Device and Materials Reliability, 4(1):110--117, March 2004."
    },
    "J.-D. Lee, S.-H. Hur, and J.-D. Choi. 2002. Effects of floating-gate interference on NAND flash memory cell operation. IEEE Electron. Device Lett. 23, 5 (2002), 264--266.": {
        "acm_key": null,
        "key": "J.-D. Lee, S.-H. Hur, and J.-D. Choi. 2002. Effects of floating-gate interference on NAND flash memory cell operation. IEEE Electron. Device Lett. 23, 5 (2002), 264--266.",
        "text": "J.-D. Lee, S.-H. Hur, and J.-D. Choi. 2002. Effects of floating-gate interference on NAND flash memory cell operation. IEEE Electron. Device Lett. 23, 5 (2002), 264--266."
    },
    "Johan Akerman. 2005. Toward a universal memory. Science 308<i>Science 308</i>, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549.": {
        "acm_key": null,
        "key": "Johan Akerman. 2005. Toward a universal memory. Science 308<i>Science 308</i>, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549.",
        "text": "Johan Akerman. 2005. Toward a universal memory. Science 308<i>Science 308</i>, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 5721, 508--510. DOI:http://dx.doi.org/10.1126/science.1110549."
    },
    "K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet<i>K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet</i>, Samsung Electronics, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics, 2005.": {
        "acm_key": null,
        "key": "K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet<i>K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet</i>, Samsung Electronics, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics, 2005.",
        "text": "K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet<i>K9NBG08U5M 4G * 8 Bit NAND Flash Memory Data Sheet</i>, Samsung Electronics, 2005. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics, 2005."
    },
    "K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet<i>K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet</i>, Samsung Electronics Company. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Company.": {
        "acm_key": null,
        "key": "K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet<i>K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet</i>, Samsung Electronics Company. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Company.",
        "text": "K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet<i>K9XXG08UXA 1G*8bit NAND flash-memory Data Sheet</i>, Samsung Electronics Company. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Company."
    },
    "Kerekes, Z. 2005. Charting the rise of the solid state disk market. http://www.storagesearch.com/chartingtheriseofssds.html.]]": {
        "acm_key": null,
        "key": "Kerekes, Z. 2005. Charting the rise of the solid state disk market. http://www.storagesearch.com/chartingtheriseofssds.html.]]",
        "text": "Kerekes, Z. 2005. Charting the rise of the solid state disk market. http://www.storagesearch.com/chartingtheriseofssds.html.]]"
    },
    "L. Ramos, R. Bianchini, Exploiting phase-change memory in server clusters, Tech. Rep. DCS-TR-692, Rutgers University, 2011.": {
        "acm_key": null,
        "key": "L. Ramos, R. Bianchini, Exploiting phase-change memory in server clusters, Tech. Rep. DCS-TR-692, Rutgers University, 2011.",
        "text": "L. Ramos, R. Bianchini, Exploiting phase-change memory in server clusters, Tech. Rep. DCS-TR-692, Rutgers University, 2011."
    },
    "Laura M. Grupp, Adrian M. Caulfield, Joel Coburn, Steven Swanson, Eitan Yaakobi, Paul H. Siegel, and Jack K. Wolf. 2009. Characterizing flash memory: Anomalies, observations, and applications. In 42nd Annual IEEE/ACM International Symposium on Microarchitecture, 2009 (MICRO-42). IEEE, 24--33.": {
        "acm_key": null,
        "key": "Laura M. Grupp, Adrian M. Caulfield, Joel Coburn, Steven Swanson, Eitan Yaakobi, Paul H. Siegel, and Jack K. Wolf. 2009. Characterizing flash memory: Anomalies, observations, and applications. In 42nd Annual IEEE/ACM International Symposium on Microarchitecture, 2009 (MICRO-42). IEEE, 24--33.",
        "text": "Laura M. Grupp, Adrian M. Caulfield, Joel Coburn, Steven Swanson, Eitan Yaakobi, Paul H. Siegel, and Jack K. Wolf. 2009. Characterizing flash memory: Anomalies, observations, and applications. In 42nd Annual IEEE/ACM International Symposium on Microarchitecture, 2009 (MICRO-42). IEEE, 24--33."
    },
    "Lin CC, Chen CL, Tseng CH (2007) Source code arrangement of embedded Java virtual machine for NAND flash memory. In: Proceeding of international conference on international symposium on communications and information technologies (ISCIT), pp 152---157": {
        "acm_key": null,
        "key": "Lin CC, Chen CL, Tseng CH (2007) Source code arrangement of embedded Java virtual machine for NAND flash memory. In: Proceeding of international conference on international symposium on communications and information technologies (ISCIT), pp 152---157",
        "text": "Lin CC, Chen CL, Tseng CH (2007) Source code arrangement of embedded Java virtual machine for NAND flash memory. In: Proceeding of international conference on international symposium on communications and information technologies (ISCIT), pp 152---157"
    },
    "Linux. 2009. Memory technology device (mtd) subsystem for linux. http://www.linux-mtd.infradead.org.": {
        "acm_key": null,
        "key": "Linux. 2009. Memory technology device (mtd) subsystem for linux. http://www.linux-mtd.infradead.org.",
        "text": "Linux. 2009. Memory technology device (mtd) subsystem for linux. http://www.linux-mtd.infradead.org."
    },
    "M-Systems, \"Flash-Memory translation layer for NAND flash (NFTL)\", 1998.": {
        "acm_key": null,
        "key": "M-Systems, \"Flash-Memory translation layer for NAND flash (NFTL)\", 1998.",
        "text": "M-Systems, \"Flash-Memory translation layer for NAND flash (NFTL)\", 1998."
    },
    "M. Calabrese, C. Miccoli, C. Compagnoni, L. Chiavarone, S. Beltrami, A. Parisi, S. Bartolone, A. L. Lacaita, A. S. Spinelli, and A. Visconti. 2013. Accelerated reliability testing of flash memory: Accuracy and issues on a 45nm NOR technology. In Proceedings of the International Conference on IC Design Technology (ICICDT). IEEE, 37--40.": {
        "acm_key": null,
        "key": "M. Calabrese, C. Miccoli, C. Compagnoni, L. Chiavarone, S. Beltrami, A. Parisi, S. Bartolone, A. L. Lacaita, A. S. Spinelli, and A. Visconti. 2013. Accelerated reliability testing of flash memory: Accuracy and issues on a 45nm NOR technology. In Proceedings of the International Conference on IC Design Technology (ICICDT). IEEE, 37--40.",
        "text": "M. Calabrese, C. Miccoli, C. Compagnoni, L. Chiavarone, S. Beltrami, A. Parisi, S. Bartolone, A. L. Lacaita, A. S. Spinelli, and A. Visconti. 2013. Accelerated reliability testing of flash memory: Accuracy and issues on a 45nm NOR technology. In Proceedings of the International Conference on IC Design Technology (ICICDT). IEEE, 37--40."
    },
    "M. Charles. YAFFS: The NAND-specific Flash File System - Introductory Article (http://www.yaffs.net/). 2002.": {
        "acm_key": null,
        "key": "M. Charles. YAFFS: The NAND-specific Flash File System - Introductory Article (http://www.yaffs.net/). 2002.",
        "text": "M. Charles. YAFFS: The NAND-specific Flash File System - Introductory Article (http://www.yaffs.net/). 2002."
    },
    "M. Dunn and A. L. N. Reddy. A new I/O scheduler for solid state devices. Technical Report TAMU-ECE-2009- 02, Dept. of Electrical and Computer Engineering, Texas A&M Univ., Apr. 2009.": {
        "acm_key": null,
        "key": "M. Dunn and A. L. N. Reddy. A new I/O scheduler for solid state devices. Technical Report TAMU-ECE-2009- 02, Dept. of Electrical and Computer Engineering, Texas A&M Univ., Apr. 2009.",
        "text": "M. Dunn and A. L. N. Reddy. A new I/O scheduler for solid state devices. Technical Report TAMU-ECE-2009- 02, Dept. of Electrical and Computer Engineering, Texas A&M Univ., Apr. 2009."
    },
    "M. Jung, E. Wilson, D. Donofrio, J. Shalf, and M. Kandemir, \"Nandflashsim: Intrinsic latency variation aware nand flash memory system modeling and simulation at microarchitecture level,\" in Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on<i>Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on</i>, 2012, pp. 1--12. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 1--12.": {
        "acm_key": null,
        "key": "M. Jung, E. Wilson, D. Donofrio, J. Shalf, and M. Kandemir, \"Nandflashsim: Intrinsic latency variation aware nand flash memory system modeling and simulation at microarchitecture level,\" in Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on<i>Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on</i>, 2012, pp. 1--12. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 1--12.",
        "text": "M. Jung, E. Wilson, D. Donofrio, J. Shalf, and M. Kandemir, \"Nandflashsim: Intrinsic latency variation aware nand flash memory system modeling and simulation at microarchitecture level,\" in Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on<i>Mass Storage Systems and Technologies (MSST), 2012 IEEE 28th Symposium on</i>, 2012, pp. 1--12. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012, pp. 1--12."
    },
    "M. K. Qureshi, M. M. Franceschini, and L. A. Lastras-Montano. 2010a. Improving read performance of phase change memories via write cancellation and write pausing. In HPCA.": {
        "acm_key": null,
        "key": "M. K. Qureshi, M. M. Franceschini, and L. A. Lastras-Montano. 2010a. Improving read performance of phase change memories via write cancellation and write pausing. In HPCA.",
        "text": "M. K. Qureshi, M. M. Franceschini, and L. A. Lastras-Montano. 2010a. Improving read performance of phase change memories via write cancellation and write pausing. In HPCA."
    },
    "M. Polte, J. Simsa, and G. Gibson. Comparing performance of solid state devices and mechanical disks. In 3rd Petascale Data Storage Workshop<i>3rd Petascale Data Storage Workshop</i>, Austin, TX, Nov. 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Austin, TX, Nov. 2008.": {
        "acm_key": null,
        "key": "M. Polte, J. Simsa, and G. Gibson. Comparing performance of solid state devices and mechanical disks. In 3rd Petascale Data Storage Workshop<i>3rd Petascale Data Storage Workshop</i>, Austin, TX, Nov. 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Austin, TX, Nov. 2008.",
        "text": "M. Polte, J. Simsa, and G. Gibson. Comparing performance of solid state devices and mechanical disks. In 3rd Petascale Data Storage Workshop<i>3rd Petascale Data Storage Workshop</i>, Austin, TX, Nov. 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Austin, TX, Nov. 2008."
    },
    "M.K. McKusick M.J. Karels and K. Bostic, \u201cA Pageable Memory Based Filesystem,\u201d <i>Proc. USENIX Summer Conf.,</i> June 1990.]]": {
        "acm_key": null,
        "key": "M.K. McKusick M.J. Karels and K. Bostic, \u201cA Pageable Memory Based Filesystem,\u201d <i>Proc. USENIX Summer Conf.,</i> June 1990.]]",
        "text": "M.K. McKusick M.J. Karels and K. Bostic, \u201cA Pageable Memory Based Filesystem,\u201d <i>Proc. USENIX Summer Conf.,</i> June 1990.]]"
    },
    "MANNING, C. YAFFS: The NAND-specific flash file system. LinuxDevices.Org<i>LinuxDevices.Org</i> (September 2002). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (September 2002).": {
        "acm_key": null,
        "key": "MANNING, C. YAFFS: The NAND-specific flash file system. LinuxDevices.Org<i>LinuxDevices.Org</i> (September 2002). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (September 2002).",
        "text": "MANNING, C. YAFFS: The NAND-specific flash file system. LinuxDevices.Org<i>LinuxDevices.Org</i> (September 2002). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (September 2002)."
    },
    "MARSH, B., DOUGLIS, F., AND KRISHNAN, P. Flash memory file caching for mobile computers. In Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture<i>Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture</i> (January 1994). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (January 1994).": {
        "acm_key": null,
        "key": "MARSH, B., DOUGLIS, F., AND KRISHNAN, P. Flash memory file caching for mobile computers. In Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture<i>Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture</i> (January 1994). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (January 1994).",
        "text": "MARSH, B., DOUGLIS, F., AND KRISHNAN, P. Flash memory file caching for mobile computers. In Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture<i>Proceedings of the Twenty-Seventh Hawaii Internanal Conference on Architecture</i> (January 1994). \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t (January 1994)."
    },
    "MICRON, INC. Design and Use Considerations for NAND Flash Memory Introduction. 2006.": {
        "acm_key": null,
        "key": "MICRON, INC. Design and Use Considerations for NAND Flash Memory Introduction. 2006.",
        "text": "MICRON, INC. Design and Use Considerations for NAND Flash Memory Introduction. 2006."
    },
    "Memory Management in NAND Flash Arrays. Micron, Inc. Technical Note TN-29-28. http://download.micron.com/pdf/technotes/nand/tn2928.pdf, 2005.": {
        "acm_key": null,
        "key": "Memory Management in NAND Flash Arrays. Micron, Inc. Technical Note TN-29-28. http://download.micron.com/pdf/technotes/nand/tn2928.pdf, 2005.",
        "text": "Memory Management in NAND Flash Arrays. Micron, Inc. Technical Note TN-29-28. http://download.micron.com/pdf/technotes/nand/tn2928.pdf, 2005."
    },
    "Memory Technology Device (MTD), http://www.linuxmtd.infradead.org/doc/general.html.": {
        "acm_key": null,
        "key": "Memory Technology Device (MTD), http://www.linuxmtd.infradead.org/doc/general.html.",
        "text": "Memory Technology Device (MTD), http://www.linuxmtd.infradead.org/doc/general.html."
    },
    "Memory Technology Devices (MTD): Subsystem for Linux. 2008.": {
        "acm_key": null,
        "key": "Memory Technology Devices (MTD): Subsystem for Linux. 2008.",
        "text": "Memory Technology Devices (MTD): Subsystem for Linux. 2008."
    },
    "Micron Technology, Inc. 2007. NAND flash memory MLC datasheet, MT29F8G08MAAWC, MT29F16G08QASWC. http://www.micron.com/.": {
        "acm_key": null,
        "key": "Micron Technology, Inc. 2007. NAND flash memory MLC datasheet, MT29F8G08MAAWC, MT29F16G08QASWC. http://www.micron.com/.",
        "text": "Micron Technology, Inc. 2007. NAND flash memory MLC datasheet, MT29F8G08MAAWC, MT29F16G08QASWC. http://www.micron.com/."
    },
    "Micron Technology, Inc. 2011. NAND Flash Translation Layer (NFTL) 4.6.0. NFTL User Guide Rev. L. (February 2011).": {
        "acm_key": null,
        "key": "Micron Technology, Inc. 2011. NAND Flash Translation Layer (NFTL) 4.6.0. NFTL User Guide Rev. L. (February 2011).",
        "text": "Micron Technology, Inc. 2011. NAND Flash Translation Layer (NFTL) 4.6.0. NFTL User Guide Rev. L. (February 2011)."
    },
    "Micron annouces availability of phase change memory for mobile devices. http://investors.micron.com/releasedetail.cfm?ReleaseID=692563.": {
        "acm_key": null,
        "key": "Micron annouces availability of phase change memory for mobile devices. http://investors.micron.com/releasedetail.cfm?ReleaseID=692563.",
        "text": "Micron annouces availability of phase change memory for mobile devices. http://investors.micron.com/releasedetail.cfm?ReleaseID=692563."
    },
    "Micron. SLC NAND Flash Memory Features MT29F8G08ABACA<i>SLC NAND Flash Memory Features MT29F8G08ABACA</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.": {
        "acm_key": null,
        "key": "Micron. SLC NAND Flash Memory Features MT29F8G08ABACA<i>SLC NAND Flash Memory Features MT29F8G08ABACA</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.",
        "text": "Micron. SLC NAND Flash Memory Features MT29F8G08ABACA<i>SLC NAND Flash Memory Features MT29F8G08ABACA</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010."
    },
    "Mun-Kyu Choi, B.-G.J., et al.: A 0.25-um 3.0V 1T1C 32-Mb Nonvolatile Ferroelectric RAM With Address Transition Detector and Current Forcing Latch Sense Amplifier Scheme. IEEE Journal of Solid-State Circuits 37 (2002)": {
        "acm_key": null,
        "key": "Mun-Kyu Choi, B.-G.J., et al.: A 0.25-um 3.0V 1T1C 32-Mb Nonvolatile Ferroelectric RAM With Address Transition Detector and Current Forcing Latch Sense Amplifier Scheme. IEEE Journal of Solid-State Circuits 37 (2002)",
        "text": "Mun-Kyu Choi, B.-G.J., et al.: A 0.25-um 3.0V 1T1C 32-Mb Nonvolatile Ferroelectric RAM With Address Transition Detector and Current Forcing Latch Sense Amplifier Scheme. IEEE Journal of Solid-State Circuits 37 (2002)"
    },
    "Myers, D. 2007. On the Use of NAND Flash Memory in High-Performance Relational Databases. Master's thesis. MIT.": {
        "acm_key": null,
        "key": "Myers, D. 2007. On the Use of NAND Flash Memory in High-Performance Relational Databases. Master's thesis. MIT.",
        "text": "Myers, D. 2007. On the Use of NAND Flash Memory in High-Performance Relational Databases. Master's thesis. MIT."
    },
    "N. Agrawal, V. Prabhakaran, T. Wobber, J. D. Davis, M. Manasse, and R. Panigrahy. Design Tradeoffs for SSD Performance. In USENIX 2008 Annual Technical Conference,<i>USENIX 2008 Annual Technical Conference,</i> ATC'08, pages 57--70, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t ATC'08, pages 57--70, 2008.": {
        "acm_key": null,
        "key": "N. Agrawal, V. Prabhakaran, T. Wobber, J. D. Davis, M. Manasse, and R. Panigrahy. Design Tradeoffs for SSD Performance. In USENIX 2008 Annual Technical Conference,<i>USENIX 2008 Annual Technical Conference,</i> ATC'08, pages 57--70, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t ATC'08, pages 57--70, 2008.",
        "text": "N. Agrawal, V. Prabhakaran, T. Wobber, J. D. Davis, M. Manasse, and R. Panigrahy. Design Tradeoffs for SSD Performance. In USENIX 2008 Annual Technical Conference,<i>USENIX 2008 Annual Technical Conference,</i> ATC'08, pages 57--70, 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t ATC'08, pages 57--70, 2008."
    },
    "N. Ioannou, I. Koltsidas, R. Pletka, S. Tomic, R. Stoica, T. Weigold, and E. Eleftheriou. SALSA: Treating the Weaknesses of Low-cost Flash in Software. In as a poster in 6th Annual Non- Volatile Memories Workshop,<i>as a poster in 6th Annual Non- Volatile Memories Workshop,</i> 2015. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2015.": {
        "acm_key": null,
        "key": "N. Ioannou, I. Koltsidas, R. Pletka, S. Tomic, R. Stoica, T. Weigold, and E. Eleftheriou. SALSA: Treating the Weaknesses of Low-cost Flash in Software. In as a poster in 6th Annual Non- Volatile Memories Workshop,<i>as a poster in 6th Annual Non- Volatile Memories Workshop,</i> 2015. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2015.",
        "text": "N. Ioannou, I. Koltsidas, R. Pletka, S. Tomic, R. Stoica, T. Weigold, and E. Eleftheriou. SALSA: Treating the Weaknesses of Low-cost Flash in Software. In as a poster in 6th Annual Non- Volatile Memories Workshop,<i>as a poster in 6th Annual Non- Volatile Memories Workshop,</i> 2015. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2015."
    },
    "N. Mielke, T. Marquart, N. Wu, J. Kessenich, H. Belgal, E. Schares, F. Trivedi, E. Goodness, and L. Nevill. Bit error rate in NAND Flash memories. In Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)<i>Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)</i>, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, May 2008.": {
        "acm_key": null,
        "key": "N. Mielke, T. Marquart, N. Wu, J. Kessenich, H. Belgal, E. Schares, F. Trivedi, E. Goodness, and L. Nevill. Bit error rate in NAND Flash memories. In Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)<i>Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)</i>, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, May 2008.",
        "text": "N. Mielke, T. Marquart, N. Wu, J. Kessenich, H. Belgal, E. Schares, F. Trivedi, E. Goodness, and L. Nevill. Bit error rate in NAND Flash memories. In Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)<i>Proc. 2008 IEEE International Reliability Physics Symposium (IRPS '08)</i>, May 2008. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, May 2008."
    },
    "N. Papandreou, H. Pozidis, A. Pantazi, A. Sebastian, M. Breitwisch, C. Lam, and E. Eleftheriou. 2011b. Programming algorithms for multilevel phase-change memory. In ISCAS. 329--332.": {
        "acm_key": null,
        "key": "N. Papandreou, H. Pozidis, A. Pantazi, A. Sebastian, M. Breitwisch, C. Lam, and E. Eleftheriou. 2011b. Programming algorithms for multilevel phase-change memory. In ISCAS. 329--332.",
        "text": "N. Papandreou, H. Pozidis, A. Pantazi, A. Sebastian, M. Breitwisch, C. Lam, and E. Eleftheriou. 2011b. Programming algorithms for multilevel phase-change memory. In ISCAS. 329--332."
    },
    "N. Papandreou, H. Pozidis, T. Mittelholzer, and et al., \"Drift-Tolerant Multilevel Phase-Change Memory,\" in IMW<i>IMW</i>, 2011, pp. 1--4. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2011, pp. 1--4.": {
        "acm_key": null,
        "key": "N. Papandreou, H. Pozidis, T. Mittelholzer, and et al., \"Drift-Tolerant Multilevel Phase-Change Memory,\" in IMW<i>IMW</i>, 2011, pp. 1--4. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2011, pp. 1--4.",
        "text": "N. Papandreou, H. Pozidis, T. Mittelholzer, and et al., \"Drift-Tolerant Multilevel Phase-Change Memory,\" in IMW<i>IMW</i>, 2011, pp. 1--4. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2011, pp. 1--4."
    },
    "NVM Express explained. http://nvmexpress.org/wp-content/uploads/2013/04/NVM_whitepaper.pdf.": {
        "acm_key": null,
        "key": "NVM Express explained. http://nvmexpress.org/wp-content/uploads/2013/04/NVM_whitepaper.pdf.",
        "text": "NVM Express explained. http://nvmexpress.org/wp-content/uploads/2013/04/NVM_whitepaper.pdf."
    },
    "NetApp, Inc. 2013. Flash cache for enterprise. http://www.netapp.com/us/products/storage-systems/flash- cache.": {
        "acm_key": null,
        "key": "NetApp, Inc. 2013. Flash cache for enterprise. http://www.netapp.com/us/products/storage-systems/flash- cache.",
        "text": "NetApp, Inc. 2013. Flash cache for enterprise. http://www.netapp.com/us/products/storage-systems/flash- cache."
    },
    "OCZ. 2012. OCZ synapse cache SSD. http://www.ocztechnology.com/ocz-synapse-cache-sata-iii-2-5-ssd.html.": {
        "acm_key": null,
        "key": "OCZ. 2012. OCZ synapse cache SSD. http://www.ocztechnology.com/ocz-synapse-cache-sata-iii-2-5-ssd.html.",
        "text": "OCZ. 2012. OCZ synapse cache SSD. http://www.ocztechnology.com/ocz-synapse-cache-sata-iii-2-5-ssd.html."
    },
    "Personal communication with an employee of a major flash manufacturer, August 2012.": {
        "acm_key": null,
        "key": "Personal communication with an employee of a major flash manufacturer, August 2012.",
        "text": "Personal communication with an employee of a major flash manufacturer, August 2012."
    },
    "Petro Estakhri, Berhanu Iman. Moving sequential sectors within a block of information in a flash memory mass storage architecture, 1999. United States Patent, no. 5,930,815.": {
        "acm_key": null,
        "key": "Petro Estakhri, Berhanu Iman. Moving sequential sectors within a block of information in a flash memory mass storage architecture, 1999. United States Patent, no. 5,930,815.",
        "text": "Petro Estakhri, Berhanu Iman. Moving sequential sectors within a block of information in a flash memory mass storage architecture, 1999. United States Patent, no. 5,930,815."
    },
    "PureStorage FlashArray. http://www.purestorage.com/flash-array/purity.html": {
        "acm_key": null,
        "key": "PureStorage FlashArray. http://www.purestorage.com/flash-array/purity.html",
        "text": "PureStorage FlashArray. http://www.purestorage.com/flash-array/purity.html"
    },
    "Q. Yang and J. Ren. I-CASH<i>I-CASH</i>: Intelligently Coupled Array of SSD and HDD. In : Intelligently Coupled Array of SSD and HDD. In High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.<i>High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.</i> IEEE, 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t IEEE, 2011.": {
        "acm_key": null,
        "key": "Q. Yang and J. Ren. I-CASH<i>I-CASH</i>: Intelligently Coupled Array of SSD and HDD. In : Intelligently Coupled Array of SSD and HDD. In High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.<i>High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.</i> IEEE, 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t IEEE, 2011.",
        "text": "Q. Yang and J. Ren. I-CASH<i>I-CASH</i>: Intelligently Coupled Array of SSD and HDD. In : Intelligently Coupled Array of SSD and HDD. In High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.<i>High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on.</i> IEEE, 2011. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t IEEE, 2011."
    },
    "R. Haas and X. Hu. The fundamental limit of flash random write performance: Understanding, analysis and performance modelling. TR IBM Research<i>TR IBM Research</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.": {
        "acm_key": null,
        "key": "R. Haas and X. Hu. The fundamental limit of flash random write performance: Understanding, analysis and performance modelling. TR IBM Research<i>TR IBM Research</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010.",
        "text": "R. Haas and X. Hu. The fundamental limit of flash random write performance: Understanding, analysis and performance modelling. TR IBM Research<i>TR IBM Research</i>, 2010. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2010."
    },
    "R. Micheloni, R. Ravasio, A. Marelli, E. Alice, V. Altieri, A. Bovino, L. Crippa, E. D. Martino, L. D. Onofrio, A. Gambardella, E. Grillea, G. Guerra, D. Kim, C. Missiroli, I. Motta, A. Prisco, G. Ragone, M. Romano, M. Sangalli, P. Sauro, M. Scotti, and S. Won. A 4Gb 2b/cell NAND Flash Memory with Embedded 5b BCH ECC for 36MB/s System Read Throughput. In Proc. Int'l Solid-State Circuits Conference<i>Proc. Int'l Solid-State Circuits Conference</i>, pages 497-506, Feb 2006. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 497-506, Feb 2006.": {
        "acm_key": null,
        "key": "R. Micheloni, R. Ravasio, A. Marelli, E. Alice, V. Altieri, A. Bovino, L. Crippa, E. D. Martino, L. D. Onofrio, A. Gambardella, E. Grillea, G. Guerra, D. Kim, C. Missiroli, I. Motta, A. Prisco, G. Ragone, M. Romano, M. Sangalli, P. Sauro, M. Scotti, and S. Won. A 4Gb 2b/cell NAND Flash Memory with Embedded 5b BCH ECC for 36MB/s System Read Throughput. In Proc. Int'l Solid-State Circuits Conference<i>Proc. Int'l Solid-State Circuits Conference</i>, pages 497-506, Feb 2006. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 497-506, Feb 2006.",
        "text": "R. Micheloni, R. Ravasio, A. Marelli, E. Alice, V. Altieri, A. Bovino, L. Crippa, E. D. Martino, L. D. Onofrio, A. Gambardella, E. Grillea, G. Guerra, D. Kim, C. Missiroli, I. Motta, A. Prisco, G. Ragone, M. Romano, M. Sangalli, P. Sauro, M. Scotti, and S. Won. A 4Gb 2b/cell NAND Flash Memory with Embedded 5b BCH ECC for 36MB/s System Read Throughput. In Proc. Int'l Solid-State Circuits Conference<i>Proc. Int'l Solid-State Circuits Conference</i>, pages 497-506, Feb 2006. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 497-506, Feb 2006."
    },
    "RAJIMWALE, A., PRABHAKARAN, V., AND DAVIS, J. D. Block management in solid state devices. Unpublished Technical Report, January 2009.": {
        "acm_key": null,
        "key": "RAJIMWALE, A., PRABHAKARAN, V., AND DAVIS, J. D. Block management in solid state devices. Unpublished Technical Report, January 2009.",
        "text": "RAJIMWALE, A., PRABHAKARAN, V., AND DAVIS, J. D. Block management in solid state devices. Unpublished Technical Report, January 2009."
    },
    "S. Ahn et al., \"Highly manufacturable high density phase change memory of 64Mb and beyond,\" in IEDM, 2004.": {
        "acm_key": null,
        "key": "S. Ahn et al., \"Highly manufacturable high density phase change memory of 64Mb and beyond,\" in IEDM, 2004.",
        "text": "S. Ahn et al., \"Highly manufacturable high density phase change memory of 64Mb and beyond,\" in IEDM, 2004."
    },
    "S. Aritome. NAND Flash innovations. IEEE Solid-State Circuits Magazine, 5(4):21--29, 2013.": {
        "acm_key": null,
        "key": "S. Aritome. NAND Flash innovations. IEEE Solid-State Circuits Magazine, 5(4):21--29, 2013.",
        "text": "S. Aritome. NAND Flash innovations. IEEE Solid-State Circuits Magazine, 5(4):21--29, 2013."
    },
    "S. Braga, A. Sanasi, A. Cabrini, and G. Torelli. 2010. Voltage-driven partial-RESET multilevel programming in phase-change memories. IEEE Transactions on Electron Devices 57, 10 (2010), 2556-- 2563.": {
        "acm_key": null,
        "key": "S. Braga, A. Sanasi, A. Cabrini, and G. Torelli. 2010. Voltage-driven partial-RESET multilevel programming in phase-change memories. IEEE Transactions on Electron Devices 57, 10 (2010), 2556-- 2563.",
        "text": "S. Braga, A. Sanasi, A. Cabrini, and G. Torelli. 2010. Voltage-driven partial-RESET multilevel programming in phase-change memories. IEEE Transactions on Electron Devices 57, 10 (2010), 2556-- 2563."
    },
    "S. Chen, P. B. Gibbons, and S. Nath. 2011. Rethinking database algorithms for phase change memory. In 2011 5th Biennial Conference on Innovative Data Systems Research. 21--31.": {
        "acm_key": null,
        "key": "S. Chen, P. B. Gibbons, and S. Nath. 2011. Rethinking database algorithms for phase change memory. In 2011 5th Biennial Conference on Innovative Data Systems Research. 21--31.",
        "text": "S. Chen, P. B. Gibbons, and S. Nath. 2011. Rethinking database algorithms for phase change memory. In 2011 5th Biennial Conference on Innovative Data Systems Research. 21--31."
    },
    "S. Eilert, M. Leinwander, and G. Crisenza, \"Phase change memory: A new memory enables new memory usage models,\" in IMW<i>IMW</i>, 2009, pp. 1--2. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009, pp. 1--2.": {
        "acm_key": null,
        "key": "S. Eilert, M. Leinwander, and G. Crisenza, \"Phase change memory: A new memory enables new memory usage models,\" in IMW<i>IMW</i>, 2009, pp. 1--2. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009, pp. 1--2.",
        "text": "S. Eilert, M. Leinwander, and G. Crisenza, \"Phase change memory: A new memory enables new memory usage models,\" in IMW<i>IMW</i>, 2009, pp. 1--2. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2009, pp. 1--2."
    },
    "S. Kang et al<i>et al</i>. A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. . A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. IEEE JSSC<i>IEEE JSSC</i>, 42(1), 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 42(1), 2007.": {
        "acm_key": null,
        "key": "S. Kang et al<i>et al</i>. A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. . A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. IEEE JSSC<i>IEEE JSSC</i>, 42(1), 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 42(1), 2007.",
        "text": "S. Kang et al<i>et al</i>. A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. . A 0.1-um 1.8-V 256-Mb Phase-Change Random Access Memory (PRAM) with 66-MHz Synchronous Burst-Read Operation. IEEE JSSC<i>IEEE JSSC</i>, 42(1), 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 42(1), 2007."
    },
    "S. Lai. Current status of the phase change memory and its future. In IEDM<i>IEDM</i>, pages 10.1.1--10.1.4, 2003. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 10.1.1--10.1.4, 2003.": {
        "acm_key": null,
        "key": "S. Lai. Current status of the phase change memory and its future. In IEDM<i>IEDM</i>, pages 10.1.1--10.1.4, 2003. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 10.1.1--10.1.4, 2003.",
        "text": "S. Lai. Current status of the phase change memory and its future. In IEDM<i>IEDM</i>, pages 10.1.1--10.1.4, 2003. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 10.1.1--10.1.4, 2003."
    },
    "S. Lee et al, \"BlueSSD: An Open Platform for Cross-layer Experiments for NAND Flash-based SSDs,\" in 5th Annual Workshop on Architecture Research Prototyping, 2010.": {
        "acm_key": null,
        "key": "S. Lee et al, \"BlueSSD: An Open Platform for Cross-layer Experiments for NAND Flash-based SSDs,\" in 5th Annual Workshop on Architecture Research Prototyping, 2010.",
        "text": "S. Lee et al, \"BlueSSD: An Open Platform for Cross-layer Experiments for NAND Flash-based SSDs,\" in 5th Annual Workshop on Architecture Research Prototyping, 2010."
    },
    "S. Lee, Y. Lee, W. Han, D. Kim, M. Kim, S. Moon, H. Cho, J. Lee, D. Byeon, Y. Lim, H. Kim, S. Hur, and K. Suh. A 3.3V 4Gb Four-Level NAND Flash Memory with 90nm CMOS Technology. In Proc. Int'l Solid-State Circuits Conference <i>Proc. Int'l Solid-State Circuits Conference </i>, pages 52-53, 2004. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 52-53, 2004.": {
        "acm_key": null,
        "key": "S. Lee, Y. Lee, W. Han, D. Kim, M. Kim, S. Moon, H. Cho, J. Lee, D. Byeon, Y. Lim, H. Kim, S. Hur, and K. Suh. A 3.3V 4Gb Four-Level NAND Flash Memory with 90nm CMOS Technology. In Proc. Int'l Solid-State Circuits Conference <i>Proc. Int'l Solid-State Circuits Conference </i>, pages 52-53, 2004. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 52-53, 2004.",
        "text": "S. Lee, Y. Lee, W. Han, D. Kim, M. Kim, S. Moon, H. Cho, J. Lee, D. Byeon, Y. Lim, H. Kim, S. Hur, and K. Suh. A 3.3V 4Gb Four-Level NAND Flash Memory with 90nm CMOS Technology. In Proc. Int'l Solid-State Circuits Conference <i>Proc. Int'l Solid-State Circuits Conference </i>, pages 52-53, 2004. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 52-53, 2004."
    },
    "S. Lee. 2012. Scaling challenges in NAND flash device toward 10nm technology. In Proceedings of the IEEE International Memory Workshop (IMW). 1--4.": {
        "acm_key": null,
        "key": "S. Lee. 2012. Scaling challenges in NAND flash device toward 10nm technology. In Proceedings of the IEEE International Memory Workshop (IMW). 1--4.",
        "text": "S. Lee. 2012. Scaling challenges in NAND flash device toward 10nm technology. In Proceedings of the IEEE International Memory Workshop (IMW). 1--4."
    },
    "S.-Y. Kim and S.-I. Jung. A log-based flash translation layer for large nand flash memory. In Advanced Communication Technology, 2006. ICACT 2006. The 8th International Conference, volume 3, pages 1641--1644, Feb 2006.": {
        "acm_key": null,
        "key": "S.-Y. Kim and S.-I. Jung. A log-based flash translation layer for large nand flash memory. In Advanced Communication Technology, 2006. ICACT 2006. The 8th International Conference, volume 3, pages 1641--1644, Feb 2006.",
        "text": "S.-Y. Kim and S.-I. Jung. A log-based flash translation layer for large nand flash memory. In Advanced Communication Technology, 2006. ICACT 2006. The 8th International Conference, volume 3, pages 1641--1644, Feb 2006."
    },
    "SNIA. Solid State Storage (SSS) Performance Test Specification (PTS) Enterprise Version 1.0. http://www.snia.org/sites/ default/files/SSS_PTS_Enterprise_v1.0.pdf, 2011.": {
        "acm_key": null,
        "key": "SNIA. Solid State Storage (SSS) Performance Test Specification (PTS) Enterprise Version 1.0. http://www.snia.org/sites/ default/files/SSS_PTS_Enterprise_v1.0.pdf, 2011.",
        "text": "SNIA. Solid State Storage (SSS) Performance Test Specification (PTS) Enterprise Version 1.0. http://www.snia.org/sites/ default/files/SSS_PTS_Enterprise_v1.0.pdf, 2011."
    },
    "STEC Incorporation. ZeusIOPS Solid State Drive Specification<i>ZeusIOPS Solid State Drive Specification</i>, 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2007.": {
        "acm_key": null,
        "key": "STEC Incorporation. ZeusIOPS Solid State Drive Specification<i>ZeusIOPS Solid State Drive Specification</i>, 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2007.",
        "text": "STEC Incorporation. ZeusIOPS Solid State Drive Specification<i>ZeusIOPS Solid State Drive Specification</i>, 2007. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2007."
    },
    "Samsung (2011). http://www.eetimes.com/electronics-news/42 30958/ISSCC-Samsung-preps-8-Gbit-phase-change-memory. Accessed 2 Dec 2011.": {
        "acm_key": null,
        "key": "Samsung (2011). http://www.eetimes.com/electronics-news/42 30958/ISSCC-Samsung-preps-8-Gbit-phase-change-memory. Accessed 2 Dec 2011.",
        "text": "Samsung (2011). http://www.eetimes.com/electronics-news/42 30958/ISSCC-Samsung-preps-8-Gbit-phase-change-memory. Accessed 2 Dec 2011."
    },
    "Samsung Corporation. 2002. Nand flash-memory datasheet and smartmedia data book.": {
        "acm_key": null,
        "key": "Samsung Corporation. 2002. Nand flash-memory datasheet and smartmedia data book.",
        "text": "Samsung Corporation. 2002. Nand flash-memory datasheet and smartmedia data book."
    },
    "Samsung Electronics (2009) Page program addressing for MLC NAND application note": {
        "acm_key": null,
        "key": "Samsung Electronics (2009) Page program addressing for MLC NAND application note",
        "text": "Samsung Electronics (2009) Page program addressing for MLC NAND application note"
    },
    "Samsung Electronics co (2011). MZ-5PAXXX SATA SSD product data sheet. June http://www. samsung.com/sec/consumer/it/harddiskdrives/ssd/index.idx?pagetype=subtype": {
        "acm_key": null,
        "key": "Samsung Electronics co (2011). MZ-5PAXXX SATA SSD product data sheet. June http://www. samsung.com/sec/consumer/it/harddiskdrives/ssd/index.idx?pagetype=subtype",
        "text": "Samsung Electronics co (2011). MZ-5PAXXX SATA SSD product data sheet. June http://www. samsung.com/sec/consumer/it/harddiskdrives/ssd/index.idx?pagetype=subtype"
    },
    "Samsung Electronics. 2009b. TFS4 Samsung's integrated flash software solution for nand flash memory.": {
        "acm_key": null,
        "key": "Samsung Electronics. 2009b. TFS4 Samsung's integrated flash software solution for nand flash memory.",
        "text": "Samsung Electronics. 2009b. TFS4 Samsung's integrated flash software solution for nand flash memory."
    },
    "Samsung Electronics. NAND flash-memory datasheet and SmartMedia data book, 2002.": {
        "acm_key": null,
        "key": "Samsung Electronics. NAND flash-memory datasheet and SmartMedia data book, 2002.",
        "text": "Samsung Electronics. NAND flash-memory datasheet and SmartMedia data book, 2002."
    },
    "Samsung Electronics. Nand flash memory & smartmedia data book, 2004": {
        "acm_key": null,
        "key": "Samsung Electronics. Nand flash memory & smartmedia data book, 2004",
        "text": "Samsung Electronics. Nand flash memory & smartmedia data book, 2004"
    },
    "Samsung Electronics<scp>Samsung Electronics</scp>. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet.": {
        "acm_key": null,
        "key": "Samsung Electronics<scp>Samsung Electronics</scp>. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet.",
        "text": "Samsung Electronics<scp>Samsung Electronics</scp>. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t. Samsung K9LBG08U0M(v1.0) - 32Gb DDP MLC data sheet."
    },
    "Samsung Semiconductor, Inc. 2003. Selecting the Right Flash Partner to Turn Technology Advantages into Profits. Position Paper CG2020-A (January 2003).": {
        "acm_key": null,
        "key": "Samsung Semiconductor, Inc. 2003. Selecting the Right Flash Partner to Turn Technology Advantages into Profits. Position Paper CG2020-A (January 2003).",
        "text": "Samsung Semiconductor, Inc. 2003. Selecting the Right Flash Partner to Turn Technology Advantages into Profits. Position Paper CG2020-A (January 2003)."
    },
    "Samsung, E.: K9D1G08V0A: 128MB Smart Media\u2122 Card, http://www.samsungsemi. com": {
        "acm_key": null,
        "key": "Samsung, E.: K9D1G08V0A: 128MB Smart Media\u2122 Card, http://www.samsungsemi. com",
        "text": "Samsung, E.: K9D1G08V0A: 128MB Smart Media\u2122 Card, http://www.samsungsemi. com"
    },
    "Samsung. Fusion Memory: Flex-OneNAND. http://www. samsung.com/global/business/semiconductor/ products/fusionmemory/Products_FlexOneNAND. html.": {
        "acm_key": null,
        "key": "Samsung. Fusion Memory: Flex-OneNAND. http://www. samsung.com/global/business/semiconductor/ products/fusionmemory/Products_FlexOneNAND. html.",
        "text": "Samsung. Fusion Memory: Flex-OneNAND. http://www. samsung.com/global/business/semiconductor/ products/fusionmemory/Products_FlexOneNAND. html."
    },
    "SanDisk, \"Longterm Data Endurance (LDE) for Client SSD,\" http://www.sandisk.com/Assets/File/pdf/oem/LDE White Paper.pdf, 2008.": {
        "acm_key": null,
        "key": "SanDisk, \"Longterm Data Endurance (LDE) for Client SSD,\" http://www.sandisk.com/Assets/File/pdf/oem/LDE White Paper.pdf, 2008.",
        "text": "SanDisk, \"Longterm Data Endurance (LDE) for Client SSD,\" http://www.sandisk.com/Assets/File/pdf/oem/LDE White Paper.pdf, 2008."
    },
    "Shin, Y. 2005. Non-volatile Memory Technologies for Beyond 2010. In 2005 Symposium on VLSI Circuits (June 2005), 156--159.": {
        "acm_key": null,
        "key": "Shin, Y. 2005. Non-volatile Memory Technologies for Beyond 2010. In 2005 Symposium on VLSI Circuits (June 2005), 156--159.",
        "text": "Shin, Y. 2005. Non-volatile Memory Technologies for Beyond 2010. In 2005 Symposium on VLSI Circuits (June 2005), 156--159."
    },
    "Steve Byan, James Lentini, Luis Pabon, Christopher Small, and Mark W. Storer. 2011. Mercury: Host-side flash caching for the datacenter. In Proceedings of FAST (Poster).": {
        "acm_key": null,
        "key": "Steve Byan, James Lentini, Luis Pabon, Christopher Small, and Mark W. Storer. 2011. Mercury: Host-side flash caching for the datacenter. In Proceedings of FAST (Poster).",
        "text": "Steve Byan, James Lentini, Luis Pabon, Christopher Small, and Mark W. Storer. 2011. Mercury: Host-side flash caching for the datacenter. In Proceedings of FAST (Poster)."
    },
    "Sungkap Yeo, Nak Hee Seong, and Hsien-Hsin S. Lee. 2012. Can multi-level cell PCM be reliable and usable? Analyzing the impact of resistance drift. In Workshop on Duplicating, Deconstructing and Debunking.": {
        "acm_key": null,
        "key": "Sungkap Yeo, Nak Hee Seong, and Hsien-Hsin S. Lee. 2012. Can multi-level cell PCM be reliable and usable? Analyzing the impact of resistance drift. In Workshop on Duplicating, Deconstructing and Debunking.",
        "text": "Sungkap Yeo, Nak Hee Seong, and Hsien-Hsin S. Lee. 2012. Can multi-level cell PCM be reliable and usable? Analyzing the impact of resistance drift. In Workshop on Duplicating, Deconstructing and Debunking."
    },
    "T.-W. Kuo, Y.-H. Chang, P.-C. Huang, and C.-W. Chang, \"Special issues in flash,\" in Proc. IEEE/ACM Int. Conf. Comput.-Aided Design<i>Proc. IEEE/ACM Int. Conf. Comput.-Aided Design</i>, Nov. 2008, pp. 821-826. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Nov. 2008, pp. 821-826.": {
        "acm_key": null,
        "key": "T.-W. Kuo, Y.-H. Chang, P.-C. Huang, and C.-W. Chang, \"Special issues in flash,\" in Proc. IEEE/ACM Int. Conf. Comput.-Aided Design<i>Proc. IEEE/ACM Int. Conf. Comput.-Aided Design</i>, Nov. 2008, pp. 821-826. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Nov. 2008, pp. 821-826.",
        "text": "T.-W. Kuo, Y.-H. Chang, P.-C. Huang, and C.-W. Chang, \"Special issues in flash,\" in Proc. IEEE/ACM Int. Conf. Comput.-Aided Design<i>Proc. IEEE/ACM Int. Conf. Comput.-Aided Design</i>, Nov. 2008, pp. 821-826. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Nov. 2008, pp. 821-826."
    },
    "Tae-Sun Chung, Stein Park, Myung-Jin Jung, et al. 2004. STAFF: State transition applied fast flash translation layer. In Proceedings of the International Conference on Architecture of Computing Systems. 199--212.": {
        "acm_key": null,
        "key": "Tae-Sun Chung, Stein Park, Myung-Jin Jung, et al. 2004. STAFF: State transition applied fast flash translation layer. In Proceedings of the International Conference on Architecture of Computing Systems. 199--212.",
        "text": "Tae-Sun Chung, Stein Park, Myung-Jin Jung, et al. 2004. STAFF: State transition applied fast flash translation layer. In Proceedings of the International Conference on Architecture of Computing Systems. 199--212."
    },
    "Technical Note: TrueFFS Wear-Leveling Mechanism(TN-DOC-017). http://www.embeddedfreebsd. org/Documents/TrueFFS_Wear_Leveling_ Mechanism.pdf.": {
        "acm_key": null,
        "key": "Technical Note: TrueFFS Wear-Leveling Mechanism(TN-DOC-017). http://www.embeddedfreebsd. org/Documents/TrueFFS_Wear_Leveling_ Mechanism.pdf.",
        "text": "Technical Note: TrueFFS Wear-Leveling Mechanism(TN-DOC-017). http://www.embeddedfreebsd. org/Documents/TrueFFS_Wear_Leveling_ Mechanism.pdf."
    },
    "Texas Memory Systems. An In-depth Look at the RamSan-630 Flash Solid State Disk, 2010. http://www.ramsan.com.": {
        "acm_key": null,
        "key": "Texas Memory Systems. An In-depth Look at the RamSan-630 Flash Solid State Disk, 2010. http://www.ramsan.com.",
        "text": "Texas Memory Systems. An In-depth Look at the RamSan-630 Flash Solid State Disk, 2010. http://www.ramsan.com."
    },
    "The OpenSSD Project. Cosmos OpenSSD Platform. http://www.openssd-project.org/wiki/The_OpenSSD_Project.": {
        "acm_key": null,
        "key": "The OpenSSD Project. Cosmos OpenSSD Platform. http://www.openssd-project.org/wiki/The_OpenSSD_Project.",
        "text": "The OpenSSD Project. Cosmos OpenSSD Platform. http://www.openssd-project.org/wiki/The_OpenSSD_Project."
    },
    "The OpenSSD project. http://www.openssd-project.org/wiki/The_OpenSSD_Project": {
        "acm_key": null,
        "key": "The OpenSSD project. http://www.openssd-project.org/wiki/The_OpenSSD_Project",
        "text": "The OpenSSD project. http://www.openssd-project.org/wiki/The_OpenSSD_Project"
    },
    "Trevor Bunker, Michael Wei, and Steven Swanson. 2012. Ming II: A flexible platform for NAND flash-based research. Technical Report, TR CS2012-0978. University of California, San Diego.": {
        "acm_key": null,
        "key": "Trevor Bunker, Michael Wei, and Steven Swanson. 2012. Ming II: A flexible platform for NAND flash-based research. Technical Report, TR CS2012-0978. University of California, San Diego.",
        "text": "Trevor Bunker, Michael Wei, and Steven Swanson. 2012. Ming II: A flexible platform for NAND flash-based research. Technical Report, TR CS2012-0978. University of California, San Diego."
    },
    "Understanding the Flash Translation Layer (FTL) Specification, http://developer.intel.com/. Technical report, Intel Corporation, Dec 1998.": {
        "acm_key": null,
        "key": "Understanding the Flash Translation Layer (FTL) Specification, http://developer.intel.com/. Technical report, Intel Corporation, Dec 1998.",
        "text": "Understanding the Flash Translation Layer (FTL) Specification, http://developer.intel.com/. Technical report, Intel Corporation, Dec 1998."
    },
    "Understanding the Flash Translation Layer (FTL) Specification.": {
        "acm_key": null,
        "key": "Understanding the Flash Translation Layer (FTL) Specification.",
        "text": "Understanding the Flash Translation Layer (FTL) Specification."
    },
    "V. Technology. Arxcis-nv (tm): Non-volatile dimm. http://www.vikingtechnology.com/arxcis-nv, 2014.": {
        "acm_key": null,
        "key": "V. Technology. Arxcis-nv (tm): Non-volatile dimm. http://www.vikingtechnology.com/arxcis-nv, 2014.",
        "text": "V. Technology. Arxcis-nv (tm): Non-volatile dimm. http://www.vikingtechnology.com/arxcis-nv, 2014."
    },
    "W. Bux. Performance evaluation of the write operation in flash-based solid-state drives. IBM Research Report RZ 3757, IBM, Nov. 2009.": {
        "acm_key": null,
        "key": "W. Bux. Performance evaluation of the write operation in flash-based solid-state drives. IBM Research Report RZ 3757, IBM, Nov. 2009.",
        "text": "W. Bux. Performance evaluation of the write operation in flash-based solid-state drives. IBM Research Report RZ 3757, IBM, Nov. 2009."
    },
    "W. Noureddine. Implementing NVMe over Fabrics, http://www.snia.org/sites/default/files/SDC15_presentations/networking/WaelNoureddine_Implementing_%20NVMe_revision.pdf.": {
        "acm_key": null,
        "key": "W. Noureddine. Implementing NVMe over Fabrics, http://www.snia.org/sites/default/files/SDC15_presentations/networking/WaelNoureddine_Implementing_%20NVMe_revision.pdf.",
        "text": "W. Noureddine. Implementing NVMe over Fabrics, http://www.snia.org/sites/default/files/SDC15_presentations/networking/WaelNoureddine_Implementing_%20NVMe_revision.pdf."
    },
    "W. Otsuka et al., \"A 4Mb conductive-bridge resistive memory with 2.3GB/s read-throughput and 216MB/s program-throughput,\" in ISSCC, 2011.": {
        "acm_key": null,
        "key": "W. Otsuka et al., \"A 4Mb conductive-bridge resistive memory with 2.3GB/s read-throughput and 216MB/s program-throughput,\" in ISSCC, 2011.",
        "text": "W. Otsuka et al., \"A 4Mb conductive-bridge resistive memory with 2.3GB/s read-throughput and 216MB/s program-throughput,\" in ISSCC, 2011."
    },
    "Weiler, Y. 2007. White paper: Bringing solid state drive benefits to computer notebook users. http://www.sandisk.com/OEM/WhitePapers.": {
        "acm_key": null,
        "key": "Weiler, Y. 2007. White paper: Bringing solid state drive benefits to computer notebook users. http://www.sandisk.com/OEM/WhitePapers.",
        "text": "Weiler, Y. 2007. White paper: Bringing solid state drive benefits to computer notebook users. http://www.sandisk.com/OEM/WhitePapers."
    },
    "Woodhouse D (2001) JFFS: the journaling flash file system. In: Proceeding of Ottawa Linux symposium": {
        "acm_key": null,
        "key": "Woodhouse D (2001) JFFS: the journaling flash file system. In: Proceeding of Ottawa Linux symposium",
        "text": "Woodhouse D (2001) JFFS: the journaling flash file system. In: Proceeding of Ottawa Linux symposium"
    },
    "Woodhouse, D. 2001. Jffs: The journalling flash file system. http://sourceware.org/jcfs2/.": {
        "acm_key": null,
        "key": "Woodhouse, D. 2001. Jffs: The journalling flash file system. http://sourceware.org/jcfs2/.",
        "text": "Woodhouse, D. 2001. Jffs: The journalling flash file system. http://sourceware.org/jcfs2/."
    },
    "Woodhouse, D. JFFS: The Journaling Flash File System.<i>JFFS: The Journaling Flash File System.</i> in  in Proceeding of Ottawa Linux Symp.<i>Proceeding of Ottawa Linux Symp.</i> 2001. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2001.": {
        "acm_key": null,
        "key": "Woodhouse, D. JFFS: The Journaling Flash File System.<i>JFFS: The Journaling Flash File System.</i> in  in Proceeding of Ottawa Linux Symp.<i>Proceeding of Ottawa Linux Symp.</i> 2001. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2001.",
        "text": "Woodhouse, D. JFFS: The Journaling Flash File System.<i>JFFS: The Journaling Flash File System.</i> in  in Proceeding of Ottawa Linux Symp.<i>Proceeding of Ottawa Linux Symp.</i> 2001. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 2001."
    },
    "Y. Choi et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC, 2012.": {
        "acm_key": null,
        "key": "Y. Choi et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC, 2012.",
        "text": "Y. Choi et al., \"A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth,\" in ISSCC, 2012."
    },
    "Y. Choi, I. Song, M.-H. Park, H. Chung, S. Chang, B. Cho, J. Kim, Y. Oh, D. Kwon, J. Sunwoo, J. Shin, Y. Rho, C. Lee, M.-G. Kang, J. Lee, Y. Kwon, S. Kim, J. Kim, Y.-J. Lee, Q. Wang, S. Cha, S. Ahn, H. Horii, J. Lee, K. Kim, H. Joo, K. Lee, Y.-T. Lee, J. Yoo, and G. Jeong. A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth. In ISSCC<i>ISSCC</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012.": {
        "acm_key": null,
        "key": "Y. Choi, I. Song, M.-H. Park, H. Chung, S. Chang, B. Cho, J. Kim, Y. Oh, D. Kwon, J. Sunwoo, J. Shin, Y. Rho, C. Lee, M.-G. Kang, J. Lee, Y. Kwon, S. Kim, J. Kim, Y.-J. Lee, Q. Wang, S. Cha, S. Ahn, H. Horii, J. Lee, K. Kim, H. Joo, K. Lee, Y.-T. Lee, J. Yoo, and G. Jeong. A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth. In ISSCC<i>ISSCC</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012.",
        "text": "Y. Choi, I. Song, M.-H. Park, H. Chung, S. Chang, B. Cho, J. Kim, Y. Oh, D. Kwon, J. Sunwoo, J. Shin, Y. Rho, C. Lee, M.-G. Kang, J. Lee, Y. Kwon, S. Kim, J. Kim, Y.-J. Lee, Q. Wang, S. Cha, S. Ahn, H. Horii, J. Lee, K. Kim, H. Joo, K. Lee, Y.-T. Lee, J. Yoo, and G. Jeong. A 20nm 1.8V 8Gb PRAM with 40MB/s program bandwidth. In ISSCC<i>ISSCC</i>, 2012. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, 2012."
    },
    "Y. Lu et al., \"Loose-ordering consistency for persistent memory,\" in ICCD, 2014.": {
        "acm_key": null,
        "key": "Y. Lu et al., \"Loose-ordering consistency for persistent memory,\" in ICCD, 2014.",
        "text": "Y. Lu et al., \"Loose-ordering consistency for persistent memory,\" in ICCD, 2014."
    },
    "Y. Wang, D. Liu, Z. Qin, and Z. Shao, \"An endurance-enhanced flash translation layer via reuse for NAND flash memory storage systems,\" in Proc. Design, Autom. Test Eur. Conf. Exhibit.<i>Proc. Design, Autom. Test Eur. Conf. Exhibit.</i>, Mar. 2011, pp. 1-6. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Mar. 2011, pp. 1-6.": {
        "acm_key": null,
        "key": "Y. Wang, D. Liu, Z. Qin, and Z. Shao, \"An endurance-enhanced flash translation layer via reuse for NAND flash memory storage systems,\" in Proc. Design, Autom. Test Eur. Conf. Exhibit.<i>Proc. Design, Autom. Test Eur. Conf. Exhibit.</i>, Mar. 2011, pp. 1-6. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Mar. 2011, pp. 1-6.",
        "text": "Y. Wang, D. Liu, Z. Qin, and Z. Shao, \"An endurance-enhanced flash translation layer via reuse for NAND flash memory storage systems,\" in Proc. Design, Autom. Test Eur. Conf. Exhibit.<i>Proc. Design, Autom. Test Eur. Conf. Exhibit.</i>, Mar. 2011, pp. 1-6. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Mar. 2011, pp. 1-6."
    },
    "Y.-B. Kim, S.R. Lee, D. Lee, et al. 2011. Bi-layered RRAM with unlimited endurance and extremely uniform switching. In Proceedings of the Symposium on VLSI Technology. 52--53.": {
        "acm_key": null,
        "key": "Y.-B. Kim, S.R. Lee, D. Lee, et al. 2011. Bi-layered RRAM with unlimited endurance and extremely uniform switching. In Proceedings of the Symposium on VLSI Technology. 52--53.",
        "text": "Y.-B. Kim, S.R. Lee, D. Lee, et al. 2011. Bi-layered RRAM with unlimited endurance and extremely uniform switching. In Proceedings of the Symposium on VLSI Technology. 52--53."
    },
    "Yi Wang, Min Huang, Zili Shao, Henry C. B. Chan, Luis Angel D. Bathen, and Nikil D. Dutt. 2014a. A reliability-aware address mapping strategy for NAND flash memory storage systems. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) 33, 11 (November 2014), 1623--1631.": {
        "acm_key": null,
        "key": "Yi Wang, Min Huang, Zili Shao, Henry C. B. Chan, Luis Angel D. Bathen, and Nikil D. Dutt. 2014a. A reliability-aware address mapping strategy for NAND flash memory storage systems. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) 33, 11 (November 2014), 1623--1631.",
        "text": "Yi Wang, Min Huang, Zili Shao, Henry C. B. Chan, Luis Angel D. Bathen, and Nikil D. Dutt. 2014a. A reliability-aware address mapping strategy for NAND flash memory storage systems. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) 33, 11 (November 2014), 1623--1631."
    },
    "Yun, H.-c., Flash memory management method<i>Flash memory management method</i>, Samsung Electronics Co., Ltd. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Co., Ltd.": {
        "acm_key": null,
        "key": "Yun, H.-c., Flash memory management method<i>Flash memory management method</i>, Samsung Electronics Co., Ltd. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Co., Ltd.",
        "text": "Yun, H.-c., Flash memory management method<i>Flash memory management method</i>, Samsung Electronics Co., Ltd. \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, Samsung Electronics Co., Ltd."
    },
    "{16} Marshall Kirk McKusick, Michael J. Karels, and Keith Bostic. A pageable memory based file system. In USENIX Conference Proceedings<i>USENIX Conference Proceedings</i>, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]]": {
        "acm_key": null,
        "key": "{16} Marshall Kirk McKusick, Michael J. Karels, and Keith Bostic. A pageable memory based file system. In USENIX Conference Proceedings<i>USENIX Conference Proceedings</i>, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]]",
        "text": "{16} Marshall Kirk McKusick, Michael J. Karels, and Keith Bostic. A pageable memory based file system. In USENIX Conference Proceedings<i>USENIX Conference Proceedings</i>, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, pages 137-144, Anaheim, CA, Summer 1990. USENIX.]]"
    },
    "{21} McKusick MK, Karels MJ, Bostic K. A Pageable Memory Based Filesystem. Proceeding of USENIX Conference<i>Proceeding of USENIX Conference</i>, June 1990.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, June 1990.]]": {
        "acm_key": null,
        "key": "{21} McKusick MK, Karels MJ, Bostic K. A Pageable Memory Based Filesystem. Proceeding of USENIX Conference<i>Proceeding of USENIX Conference</i>, June 1990.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, June 1990.]]",
        "text": "{21} McKusick MK, Karels MJ, Bostic K. A Pageable Memory Based Filesystem. Proceeding of USENIX Conference<i>Proceeding of USENIX Conference</i>, June 1990.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, June 1990.]]"
    },
    "{2} N. A. Takahiro Ohnakado and, \"Review of device technologies of flash memories,\" IEICE Transactions on Electronics<i>IEICE Transactions on Electronics</i>, vol. E84-C, no. 6, pp. 724-733, 2001.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. E84-C, no. 6, pp. 724-733, 2001.]]": {
        "acm_key": null,
        "key": "{2} N. A. Takahiro Ohnakado and, \"Review of device technologies of flash memories,\" IEICE Transactions on Electronics<i>IEICE Transactions on Electronics</i>, vol. E84-C, no. 6, pp. 724-733, 2001.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. E84-C, no. 6, pp. 724-733, 2001.]]",
        "text": "{2} N. A. Takahiro Ohnakado and, \"Review of device technologies of flash memories,\" IEICE Transactions on Electronics<i>IEICE Transactions on Electronics</i>, vol. E84-C, no. 6, pp. 724-733, 2001.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t, vol. E84-C, no. 6, pp. 724-733, 2001.]]"
    },
    "{3} Boeve H, Bruynseraede C, Das J, Dessein K, Borghs G, De Boeck J, Sousa R, Melo L, Freitas P. Technology assessment for the implementation of magnetoresistive elements with semiconductor components in magnetic random access memory (MRAM) architectures. IEEE Transactions on Magnetics<i>IEEE Transactions on Magnetics</i> 35(5), pp. 2820-2825, 1999.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 35(5), pp. 2820-2825, 1999.]]": {
        "acm_key": null,
        "key": "{3} Boeve H, Bruynseraede C, Das J, Dessein K, Borghs G, De Boeck J, Sousa R, Melo L, Freitas P. Technology assessment for the implementation of magnetoresistive elements with semiconductor components in magnetic random access memory (MRAM) architectures. IEEE Transactions on Magnetics<i>IEEE Transactions on Magnetics</i> 35(5), pp. 2820-2825, 1999.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 35(5), pp. 2820-2825, 1999.]]",
        "text": "{3} Boeve H, Bruynseraede C, Das J, Dessein K, Borghs G, De Boeck J, Sousa R, Melo L, Freitas P. Technology assessment for the implementation of magnetoresistive elements with semiconductor components in magnetic random access memory (MRAM) architectures. IEEE Transactions on Magnetics<i>IEEE Transactions on Magnetics</i> 35(5), pp. 2820-2825, 1999.]] \t\t\t\t\t\t\t\t\t&#13;\n\t\t\t\t\t\t\t\t 35(5), pp. 2820-2825, 1999.]]"
    },
    "{7} K. M. J. Lofgren, R. D. Norman, G. B. Thelin, and A. Gupta, \"Wear leveling techniques for flash EEPROM systems,\" U.S. Patent 6 081 447, June 27, 2000.]]": {
        "acm_key": null,
        "key": "{7} K. M. J. Lofgren, R. D. Norman, G. B. Thelin, and A. Gupta, \"Wear leveling techniques for flash EEPROM systems,\" U.S. Patent 6 081 447, June 27, 2000.]]",
        "text": "{7} K. M. J. Lofgren, R. D. Norman, G. B. Thelin, and A. Gupta, \"Wear leveling techniques for flash EEPROM systems,\" U.S. Patent 6 081 447, June 27, 2000.]]"
    },
    "{9} D. Woodhouse, \"JFFS: The journaling flash file system,\" July 2001, presented in the Ottawa Linux Symposium, July 2001 (no proceedings); a 12-page article available online from http://sources.redhat. com/jffs2/jffs2.pdf.]]": {
        "acm_key": null,
        "key": "{9} D. Woodhouse, \"JFFS: The journaling flash file system,\" July 2001, presented in the Ottawa Linux Symposium, July 2001 (no proceedings); a 12-page article available online from http://sources.redhat. com/jffs2/jffs2.pdf.]]",
        "text": "{9} D. Woodhouse, \"JFFS: The journaling flash file system,\" July 2001, presented in the Ottawa Linux Symposium, July 2001 (no proceedings); a 12-page article available online from http://sources.redhat. com/jffs2/jffs2.pdf.]]"
    }
}